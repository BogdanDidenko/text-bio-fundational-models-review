{
  "database": "PubMed",
  "search_date": "2026-02-15",
  "query": "((\"single cell\"[Title/Abstract] OR \"single-cell\"[Title/Abstract] OR scRNA-seq[Title/Abstract] OR \"RNA-seq\"[Title/Abstract] OR \"RNA seq\"[Title/Abstract] OR \"gene expression\"[Title/Abstract] OR scATAC-seq[Title/Abstract] OR \"ATAC-seq\"[Title/Abstract] OR \"chromatin accessibility\"[Title/Abstract] OR CITE-seq[Title/Abstract] OR \"spatial transcriptomics\"[Title/Abstract] OR \"multi-omics\"[Title/Abstract] OR \"multi omics\"[Title/Abstract] OR multiomics[Title/Abstract] OR transcriptomics[Title/Abstract] OR genomics[Title/Abstract] OR proteomics[Title/Abstract] OR epigenomics[Title/Abstract] OR \"cell type\"[Title/Abstract] OR \"gene regulatory\"[Title/Abstract]) AND (\"language model\"[Title/Abstract] OR LLM[Title/Abstract] OR \"large language model\"[Title/Abstract] OR \"natural language\"[Title/Abstract] OR GPT[Title/Abstract] OR CLIP[Title/Abstract] OR \"cross-modal\"[Title/Abstract] OR multimodal[Title/Abstract] OR \"multi-modal\"[Title/Abstract] OR tokenization[Title/Abstract] OR \"gene token\"[Title/Abstract] OR prompt[Title/Abstract] OR \"text generation\"[Title/Abstract] OR \"cell-to-text\"[Title/Abstract] OR \"text-to-cell\"[Title/Abstract] OR NLP[Title/Abstract]) AND (\"foundation model\"[Title/Abstract] OR pretrained[Title/Abstract] OR \"pre-trained\"[Title/Abstract] OR \"self-supervised\"[Title/Abstract] OR transformer[Title/Abstract] OR generative[Title/Abstract] OR decoder[Title/Abstract] OR autoregressive[Title/Abstract] OR \"transfer learning\"[Title/Abstract] OR \"zero-shot\"[Title/Abstract] OR \"few-shot\"[Title/Abstract] OR \"masked modeling\"[Title/Abstract] OR \"attention mechanism\"[Title/Abstract] OR \"deep learning\"[Title/Abstract])) AND (\"2018/01/01\"[Date - Publication] : \"2026/02/28\"[Date - Publication]) AND \"free full text\"[sb] AND English[Language]",
  "filters": "free full text[sb], English[Language], 2018-01-01 to 2026-02-28",
  "total_results": 631,
  "records_fetched": 631,
  "records": [
    {
      "pmid": "41681806",
      "doi": "10.3390/diagnostics16030488",
      "title": "Artificial Intelligence and the Expanding Universe of Cardio-Oncology: Beyond Detection Toward Prediction and Prevention of Therapy-Related Cardiotoxicity-A Comprehensive Review.",
      "abstract": "",
      "authors": "Ștefan Miruna Florina; Magda Lucia Ștefania; Vinereanu Dragoș",
      "year": "2026",
      "month": "Feb",
      "journal": "Diagnostics (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "41678736",
      "doi": "10.1093/bib/bbag043",
      "title": "GATCL: graph attention network meets contrastive learning for spatial domain identification.",
      "abstract": "Spatial domain identification is an essential task for revealing spatial heterogeneity within tissues, providing insights into disease mechanisms, tissue development, and the cellular microenvironment. In recent years, spatial multi-omics has emerged as the new frontier in spatial domain identification that offers deeper insights into the complex interplay and functional dynamics of heterogeneous cell communities within their native tissue context. Most existing methods rely on static graph structures that treat all neighboring cells uniformly, failing to capture the nuanced cellular interactions within the microenvironment and thus blurring functional boundaries. Furthermore, cross-modal reconstruction performance is often degraded by overfitting to modality-specific noise, which may impair the precise delineation of spatial domains. Therefore, we present GATCL, a novel deep learning framework that integrates a graph attention network with contrastive learning (CL) for robust spatial domain identification. First, GATCL leverages the graph attention mechanism to dynamically assign weights to neighboring spots, adaptively modeling the complex cellular architecture. Second, it implements a cross-modal CL strategy that forces representations from the same spatial location to be similar while pushing those from different locations apart, thereby achieving robust alignment between modalities. Comprehensive experiments across six distinct datasets (spanning transcriptome, proteome, and chromatin) reveal that GATCL is superior to seven representative methods across six key evaluation metrics.",
      "authors": "Mu Jichong; Yao Yachen; Chen Qiuhao; Sun Jiqiu; Zhao Tianyi",
      "year": "2026",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41676719",
      "doi": "10.64898/2026.02.05.703637",
      "title": "Short-Context Regulatory DNA Language Models with Motif-Discovery Regularization.",
      "abstract": "Self-supervised DNA language models (DNALMs) are typically trained at massive scale on whole genomes and long contexts. However, regulatory sequence features are sparse, heterogeneous, and dominated by poorly conserved flexible syntax of short motifs, which can be difficult to learn from genome-wide self-supervision. As a result, annotation agnostic, long-context DNALMs struggle to learn regulatory syntax and can underperform simpler baseline models on key regulatory tasks. We therefore introduce ",
      "authors": "Patel Aman; Kundaje Anshul",
      "year": "2026",
      "month": "Feb",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41676689",
      "doi": "10.64898/2026.02.07.704075",
      "title": "Integrative Single-Cell Epigenomic Atlas Annotates the Regulatory Genome of the Adult Mouse Brain.",
      "abstract": "Histone modifications underpin the cell-type-specific gene regulatory networks that drive the remarkable cellular heterogeneity of the adult mammalian brain. Here, we profiled four histone modifications jointly with transcriptome in 2.5 million nuclei across multiple adult mouse brain regions. By integrating these data with existing maps of chromatin accessibility, DNA methylation, and 3D genome organization, we established a unified regulatory framework for over 100 brain cell subclasses. This integrative epigenomic atlas annotates 81% of the genome, defining distinct active, primed, and repressive states. Notably, active chromatin states marked by combinatorial histone modifications more precisely identify functional enhancers than chromatin accessibility alone, while Polycomb- and H3K9me3-mediated repression contributes prominently to cell-type-specific regulation. Finally, this multi-modal resource enables deep learning models to predict epigenomic features and gene expression from DNA sequences. This work provides a comprehensive annotation of the mouse brain regulatory genome and a framework for interpreting non-coding variation in complex tissues.",
      "authors": "Wang Zhaoning; Zu Songpeng; Armand Ethan J; Loe Timothy H; Rink Jonathan A; Wu Wanying; Xie Yang; Chang Lei; Zhu Chenxu; Johnson Nicholas D; Lee Jasper; Willier Jackson K; Cho Silvia; Cao Stella; Barcoma Ariana S; Emerson Nora; Liu Hanqing; Wang Kangli; Gibbs Zane A; Gao Xiaomeng; Xu Sunan; Guo David; Tu Zhuowen; Li Yang E; Ecker Joseph R; Behrens Maria Margarita; Ren Bing",
      "year": "2026",
      "month": "Feb",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41676679",
      "doi": "10.64898/2026.02.02.703166",
      "title": "Single-Cell Atlas of Transcription and Chromatin States Reveals Regulatory Programs in the Human Brain.",
      "abstract": "Directly measuring chromatin states alongside transcription is essential for understanding how cell-type-specific regulatory programs are established and maintained in the adult human brain. We present a large-scale single-cell multimodal atlas generated by jointly profiling transcriptome with active (H3K27ac) and repressive (H3K27me3) histone modifications across 18 brain regions. We profile >750,000 nuclei spanning 160 cell types and integrate these data with chromatin accessibility, DNA methylation, 3D genome architecture, and spatial transcriptome. This framework annotates >500,000 regulatory elements and resolves cell-type-specific chromatin states. We link enhancers to target genes, infer gene regulatory networks, and classify chromatin interactions, revealing neuron-enriched long-range Polycomb repression of developmental genes. Integrating these maps with GWAS data and sequence-based model prioritizes noncoding variants, effector genes, and vulnerable cell types for neuropsychiatric disorders. Finally, cross-species comparisons show conserved activation but more divergent repression. Together, this study provides a functional reference for interpreting noncoding variants, epigenetic memory, and brain organization. Joint single-cell profiling of transcriptomes with active or repressive histone modification in >750,000 nuclei across adult human brain. Chromatin state annotation of >500,000 candidate ",
      "authors": "Xie Yang; Chang Lei; Zhong Guojie; Rink Jonathan A; Báez-Becerra Tatiana; Armand Ethan; Ding Wubin; Li Kai; Bonne Eric; Lie Audrey; Indralingam Hannah S; Dong Keyi; Loe Timothy; Huang Bohan; Wang Zhaoning; Barcoma Ariana S; Willier Jackson K; Knutson Kyle W; Liu Jiayi; Cho Silvia; Cao Stella; Russo Kaitlyn G; Young Carissa K; Arzavala Jessica; Sanchez Yareli; Bikkina Aleksandra; Schenker-Ahmed Natalie; Kern Colin; Zhao Zoey; Klein Amit; Flores Jesus; Tai Chu-Yi; Olness Jacqueline; Monell Alexander; Moghadami Siavash; Barragan Cesar; Chen Chumo; Owens William; O'Connor Carolyn; Liem Michelle; Marrin Mikayla V; Rose Cynthia; Alt Shane N; Emerson Nora; Osteen Julia; Lucero Jacinta; Li Daofeng; Hodge Rebecca D; Wang Ting; Keene C Dirk; Xu Xiangming; Zhu Quan; Ecker Joseph R; Behrens M Margarita; Ren Bing",
      "year": "2026",
      "month": "Feb",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41676675",
      "doi": "10.64898/2026.02.02.703375",
      "title": "Structure-aware Graph Learning Predicts RNA Editability Across Tissues and Species.",
      "abstract": "Programmable A-to-I RNA editing using endogenous ADAR enzymes is emerging as a therapeutic strategy, but editability remains difficult to predict because ADAR recognition depends on double-stranded RNA geometry and stability rather than sequence alone. We present A dar E dit , a structure-explicit graph-attention framework that represents each dsRNA substrate as a nucleotide graph with backbone and base-pair edges and augments this representation with typed interactions and a motif-sensitive sequence branch. We trained and evaluated the model on high-confidence inverted ",
      "authors": "Rosenwasser Zohar; Levitt Michael; Levanon Erez Y; Oren Gal",
      "year": "2026",
      "month": "Feb",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41656155",
      "doi": "10.1080/0886022X.2026.2613606",
      "title": "Risk prediction in IgA nephropathy: from conventional models to machine learning, deep learning, and precision nephrology.",
      "abstract": "IgA nephropathy (IgAN) is the most prevalent primary glomerular disease worldwide and a leading cause of end-stage kidney disease (ESKD). Its clinical heterogeneity results in divergent renal outcomes, making early identification of high-risk patients essential. Prognostic models are crucial for stratifying ESKD risk, guiding treatment intensity, optimizing timing of interventions such as immunosuppressive therapy, and informing clinical trial enrollment. Over recent decades, multiple prognostic approaches have emerged, ranging from traditional clinical and histopathological scoring systems to advanced machine learning (ML) and deep learning (DL) models designed to capture complex nonlinear interactions and improve predictive precision. Among them, the International IgA Nephropathy Prediction Tool (IIgAN-PT), endorsed by the 2021 KDIGO guidelines, represents a landmark in globally validated risk assessment and has set the foundation for standardized clinical decision support. However, classical models often rely on static baseline parameters and may not adequately reflect dynamic disease trajectories, limiting their utility in real-time clinical management. To overcome these limitations, ML- and DL-based models increasingly integrate multi-omics data, serial clinical measurements, and digital pathology features, offering enhanced accuracy, dynamic risk tracking, and potential for personalized response prediction. These data-driven approaches are progressively bridging the gap between prognostic research and precision nephrology. This review provides a comprehensive overview of the evolution of IgAN prognostic models, summarizes their strengths and limitations, and discusses considerations for clinical translation. By highlighting emerging trends toward explainable AI, dynamic time-series modeling, and multimodal prognostication, we outline how next-generation prediction tools may enable real-time, AI-driven decision support for individualized IgAN management.",
      "authors": "Xu Han; Ge Shuwang",
      "year": "2026",
      "month": "Dec",
      "journal": "Renal failure",
      "source": "pubmed"
    },
    {
      "pmid": "41652996",
      "doi": "10.1093/bioinformatics/btaf655",
      "title": "CeLLTra: aligning cell names with gene expression via a pathway-informed transformer.",
      "abstract": "Single-cell RNA sequencing (scRNA-Seq) technology enables detailed exploration of gene expression at the individual cell level, crucial for annotating cell types and understanding cellular diversity. Traditional methods for cell type annotation often rely on marker genes and manual labeling, posing challenges due to low data quality and incomplete reference datasets. We developed CeLLTra, a novel contrastive learning framework that leverages a Transformer-based model integrating biological pathway information to group genes into super tokens, effectively capturing comprehensive gene expression from scRNA-Seq data. By combining this pathway-informed Transformer with a pretrained domain-specific language model, CeLLTra accurately aligns cell-type annotations with gene expression profiles. Evaluations on a large-scale human scRNA-Seq dataset showed that CeLLTra significantly outperformed state-of-the-art methods in supervised and zero-shot cell-type prediction. Additionally, CeLLTra generalized well to external datasets, improving clustering performance and enabling better characterization of cancerous cell states in tumor-infiltrating myeloid cells from non-small cell lung cancer patients. CeLLTra is freely available on GitHub (https://github.com/WJZheng-group/CeLLTra) and Zenodo (https://doi.org/10.5281/zenodo.17666735). The datasets underlying this article are the following: GSE201333 and GSE127465. All these datasets are publicly available and can be freely accessed on the Gene Expression Omnibus repository.",
      "authors": "Li Zhao; Zheng Zaiyi; Li Rongbin; Chen Wenbo; Yang Yuntao; Ali Meer A; Li Jundong; Zheng W Jim",
      "year": "2026",
      "month": "Jan",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "41650976",
      "doi": "10.1016/j.xgen.2026.101141",
      "title": "MultiSP deciphers tissue structure and multicellular communication from spatial multi-omics data.",
      "abstract": "Recent breakthroughs in spatial multi-omics enable simultaneous profiling of different modalities while preserving tissue architecture, providing unprecedented opportunities to explore tissue complexity. However, due to the sparse and noisy nature of the data, interpreting these complex tissue structures and cellular communication remains challenging. We present MultiSP, a deep learning framework that enhances data representation through efficient spatial and feature similarity fusion, modality-specific probabilistic generative modeling, and cross-modality adversarial learning. Applied to various spatial multi-omics datasets, it outperforms existing methods in capturing biologically interpretable spatial domains. MultiSP also denoises spatial data, uncovers modality-specific spatial variations, and reveals gene regulation mechanisms. In the tumor microenvironment, it unravels fine-resolution cellular distribution maps, such as spatially neighboring macrophage-enriched sub-regions with distinct prognosis outcomes. Additionally, MultiSP facilitates the inference of spatially multimodal cell-cell communication. Together, MultiSP serves as a powerful framework for uncovering spatially multimodal heterogeneity and communication by integrating complementary information from multiple modalities.",
      "authors": "Mo Chenfeng; Zou Xiufen; Jin Suoqin",
      "year": "2026",
      "month": "Feb",
      "journal": "Cell genomics",
      "source": "pubmed"
    },
    {
      "pmid": "41647441",
      "doi": "10.1093/pcmedi/pbaf040",
      "title": "Spatial proteomics in precision medicine: technologies, bioinformatics, and translational applications.",
      "abstract": "Protein function is inherently spatial: the same molecule can elicit distinct biological outcomes depending on its localization, interacting partners, and surrounding microenvironment. Spatial proteomics enables systematic ",
      "authors": "Li Yiwen; Zhang Yusheng; Zhang Ying; Wang Qing; Ji Boyang; Yang Hongjun; Li Xianyu",
      "year": "2026",
      "month": "Mar",
      "journal": "Precision clinical medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41639911",
      "doi": "10.1186/s13321-026-01158-w",
      "title": "Cosynllm: predicting drug combination synergy with LLM-generated descriptions.",
      "abstract": "Drug combination therapy is a well-established strategy for treating complex diseases. However, the vast combinatorial space renders exhaustive experimental screening impractical and costly. Recent studies have shown that deep learning techniques can effectively prioritize synergistic drug combinations by leveraging their powerful nonlinear modeling and automatic feature extraction capabilities. Meanwhile, Large Language Models (LLMs) offer great promise in drug discovery. In this paper, we propose CoSynLLM, an LLM-assisted predictive framework for predicting drug combination synergy. We fully leverage the latent knowledge embedded in LLMs to generate semantic-level chemical information, complemented by drug fingerprints to incorporate explicit structural details, while cell line gene expression profiles represent the cellular context. To effectively merge drug and cell line representations, a hierarchical feature fusion strategy is employed to progressively integrate features through multiple stages for predicting drug combination synergy. Extensive experiments on two benchmark datasets, NCI-ALMANAC and O'Neil, demonstrate that CoSynLLM achieves competitive performance, highlighting its effectiveness in predicting drug combination synergy. In summary, CoSynLLM effectively identifies synergistic drug combinations, offering a robust and practical computational framework for predicting drug combination synergy.",
      "authors": "Mao Suwan; Tang Wenjie; Li Li; Jing Mang; Liu Yun; Wang Junjie",
      "year": "2026",
      "month": "Feb",
      "journal": "Journal of cheminformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41639008",
      "doi": "10.1093/gpbjnl/qzag007",
      "title": "Forensic Transcriptomics: Research Progress of the Past Two Decades.",
      "abstract": "Over the last two decades, advancements in sequencing technology and data science have significantly deepened the study of transcriptomics, especially non-coding transcriptomics, leading to substantial developments in forensic applications. During the 2000s, forensic transcriptomics analysis technology evolved from targeted messenger ribonucleic acid (mRNA) typing to massive parallel sequencing and deoxyribonucleic acid (DNA) microarray. This progression facilitated the source tracing and degradation dynamics of biomaterials from crime scenes, as well as transcriptomic changes associated with cadavers, injuries and toxicology, thereby providing additional clues for solving forensic cases. In the next decade, the development of high-throughput sequencing technology further expanded the research frontiers of forensic transcriptomics from mRNA to non-coding RNAs (ncRNAs). These molecules have been demonstrated to exhibit unique functions in expression regulation and epigenetic modifications, showing great potential in forensic practices such as forensic polymorphism studies, tissue and body fluid tracing, forensic RNA molecular clock, death & wound analyses, as well as forensic toxicology. Modern transcriptomics combined with deep learning and multimodal analysis through multidisciplinary integration can potentially characterize the dynamic spatiotemporal panoramic features of forensic biological samples. However, these technologies will face bottlenecks such as standardization, sample collection and processing, ethics, and evidence interpretation in forensic practice. Breaking through these obstacles will be the core task of forensic transcriptomics in the next ten years. This integrative review, building on bibliometric analysis, details the new paradigms and latest advances in forensic transcriptomics across multiple forensic fields, demonstrating its wide-ranging prospects in practical applications.",
      "authors": "Lei Fanzhang; Yuan Xi; Lan Qiong; Shen Ruonan; Wu Yiman; Shi Xin; Zhu Bofeng; Cong Bin",
      "year": "2026",
      "month": "Feb",
      "journal": "Genomics, proteomics & bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41635571",
      "doi": "10.3389/fgene.2025.1694070",
      "title": "A systematic review on the generative AI applications in human medical genetics.",
      "abstract": "Although traditional statistical techniques and machine learning methods have contributed significantly to genetics and, in particular, inherited disease diagnosis, they often struggle with complex, high-dimensional data, a challenge now addressed by state-of-the-art deep learning models. Large language models (LLMs), based on transformer architectures, have excelled in tasks requiring contextual comprehension of unstructured medical data. This systematic review examines the role of generative Artificial Intelligence (AI) methods in human medical genomics, focusing on the genetic research and diagnostics of both rare and common diseases. Automated keyword-based search in PubMed, bioRxiv, medRxiv, and arXiv was conducted, targeting studies on LLM applications in diagnostics and education within genetics and removing irrelevant or outdated models. A total of 195 studies were analyzed, highlighting the prospects of their applications in knowledge navigation, analysis of clinical and genetic data, and interaction with patients and medical professionals. Key findings indicate that while transformer-based models perform well across a diverse range of tasks (such as identification of tentative molecular diagnosis from clinical data or genetic variant interpretation), major challenges persist in integrating multimodal data (genomic sequences, imaging, and clinical records) into unified and clinically robust pipelines, facing limitations in generalizability and practical implementation in clinical settings. This review provides a comprehensive classification and assessment of the current capabilities and limitations of LLMs in transforming hereditary disease diagnostics and supporting genetic education, serving as a guide to navigate this rapidly evolving field, while outlining application use cases, implementation guidance, and forward-looking research directions.",
      "authors": "Changalidis Anton; Barbitoff Yury; Nasykhova Yulia; Glotov Andrey",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in genetics",
      "source": "pubmed"
    },
    {
      "pmid": "41633767",
      "doi": "10.1101/gr.281001.125",
      "title": "spRefine denoises and imputes spatial transcriptomics with a reference-free framework powered by genomic language model.",
      "abstract": "The analysis of spatial transcriptomics is hindered by high noise levels and missing gene measurements, challenges that are further compounded by the higher cost of spatial data compared to traditional single-cell data. To overcome this challenge, we introduce spRefine, a deep learning framework that leverages genomic language models to jointly denoise and impute spatial transcriptomic data. Our results demonstrate that spRefine yields more robust cell- and spot-level representations after denoising and imputation, substantially improving data integration. In addition, spRefine serves as a strong framework for model pretraining and the discovery of novel biological signals, as highlighted by multiple downstream applications across datasets of varying scales. Notably, spRefine enhances the accuracy of spatial ageing clock estimations and uncovers new aging-related relationships associated with key biological processes, such as neuronal function loss, which offers new insights for analyzing ageing effect with spatial transcriptomics.",
      "authors": "Liu Tianyu; Huang Tinglin; Jin Wengong; Chu Tinyi; Ying Rex; Zhao Hongyu",
      "year": "2026",
      "month": "Feb",
      "journal": "Genome research",
      "source": "pubmed"
    },
    {
      "pmid": "41632767",
      "doi": "10.1371/journal.pone.0341649",
      "title": "Deep learning framework for RNA 5hmC prediction using RNA language model embeddings.",
      "abstract": "By influencing gene expression and contributing to epigenetic modifications, Ribonucleic Acid (RNA) 5-Hydroxymethylcytosine (5hmC) modification significantly affects cellular pathways. It plays an important role in complex regulatory networks and gene expression. Moreover, 5hmC modifications are linked to a variety of human diseases, including diabetes, cancer, and cardiovascular conditions. However, experimental methods to identify RNA 5hmC modifications, such as chromatography and Polymerase Chain Reaction (PCR) amplification, are costly and time-consuming. So, computational methods are necessary to predict these modifications. In this study, several feature descriptors were analyzed and compared to finalize the best ones. Different deep-learning models were explored to design the proposed model architecture. Neighbourhood analysis was conducted on the dataset to provide insights into a deeper understanding of RNA 5hmC modifications. The proposed model, InTrans-RNA5hmC, is a dual-branch deep learning model that has two branches: the Inception branch and the Transformer branch. Word embeddings having the contextual information and language model embeddings from the RiboNucleic Acid Language Model (RiNALMo) were used as the finalized feature descriptors. InTrans-RNA5hmC outperformed existing SOTA methods, achieving 0.97 sensitivity, 0.985 balanced accuracy, and 0.985 F1 score on the Independent test set.",
      "authors": "Nafi Md Muhaiminul Islam",
      "year": "2026",
      "month": "",
      "journal": "PloS one",
      "source": "pubmed"
    },
    {
      "pmid": "41624314",
      "doi": "10.1002/cai2.70047",
      "title": "AI and Big Data in Oncology: A Physician-Centered Perspective on Emerging Clinical and Research Applications.",
      "abstract": "The convergence of artificial intelligence (AI) and big data is reshaping contemporary oncology by enabling the integration of multimodal information across imaging, pathology, genomics, and clinical records. From a physician-centered perspective, these technologies can potentially be used to improve diagnostic precision, support individualized treatment planning, enhance longitudinal patient management, and accelerate both clinical and translational research. In this review, we synthesize the core AI methodologies most relevant to oncology-machine learning, deep learning, and large language models-and examine how they interact with established and emerging oncology data platforms. We further highlight practical use cases in clinical workflows and research pipelines, emphasizing opportunities for advancing precision cancer care while also addressing challenges associated with data heterogeneity, model generalizability, privacy protection, and real-world implementation. By underscoring the synergistic value of AI and big data, this review aims to inform the development of clinically meaningful, context-adapted strategies that promote translational innovation in both global and locally resourced healthcare environments.",
      "authors": "Liu Binliang; Shang Qingyao; Li Jun; Yao Shuna; Ouyang Meishuo; Wang Yu; Luo Sheng; Ouyang Quchang",
      "year": "2026",
      "month": "Feb",
      "journal": "Cancer innovation",
      "source": "pubmed"
    },
    {
      "pmid": "41623885",
      "doi": "10.3389/fdgth.2025.1678047",
      "title": "Federated multimodal AI for precision-equitable diabetes care.",
      "abstract": "Type 2 diabetes mellitus (T2DM) constitutes a rapidly expanding global epidemic whose societal burden is amplified by deep-rooted health inequities. Socio-economic disadvantage, minority ethnicity, low health literacy, and limited access to nutritious food or timely care disproportionately expose under-insured populations to earlier onset, poorer glycaemic control, and higher rates of cardiovascular, renal, and neurocognitive complications. Artificial intelligence (AI) is emerging as a transformative counterforce, capable of mitigating these disparities across the entire care continuum. Early detection and risk prediction have progressed from static clinical scores to dynamic machine-learning (ML) models that integrate multimodal data-electronic health records, genomics, socio-environmental variables, and wearable-derived behavioural signatures-to yield earlier and more accurate identification of high-risk individuals. Complication surveillance is being revolutionised by AI systems that screen for diabetic retinopathy with near-specialist accuracy, forecast renal function decline, and detect pre-ulcerative foot lesions through image-based deep learning, enabling timely, targeted interventions. Convergence with continuous glucose monitoring (CGM) and wearable technologies supports real-time, AI-driven glycaemic forecasting and decision support, while telemedicine platforms extend these benefits to remote or resource-constrained settings. Nevertheless, widespread implementation faces challenges of data heterogeneity, algorithmic bias against minority groups, privacy risks, and the digital divide that could paradoxically widen inequities if left unaddressed. Future directions centre on multimodal large language models, digital-twin simulations for personalised policy testing, and human-in-the-loop governance frameworks that embed ethical oversight, trauma-informed care, and community co-design. Realising AI's societal promise demands coordinated action across patients, clinicians, technologists, and policymakers to ensure solutions are not only clinically effective but also equitable, culturally attuned, and economically sustainable.",
      "authors": "Bai Bing; Liu Xilin; Li Hong",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in digital health",
      "source": "pubmed"
    },
    {
      "pmid": "41623484",
      "doi": "10.1016/j.isci.2026.114627",
      "title": "Artificial intelligence for colposcopic and cytological image analysis in early cervical cancer detection.",
      "abstract": "Artificial intelligence (AI) is reshaping cervical cancer screening by automating interpretation of cytology, colposcopic, and related imaging to improve early detection, especially in low- and middle-income countries. This review synthesizes advances in preprocessing; segmentation; representation learning; and supervised, semi-supervised, unsupervised, and transformer-based models, with emphasis on multimodal fusion with HPV testing, spectroscopy, and MRI. Across retrospective datasets and growing real-world deployments, AI systems can achieve high accuracy and sensitivity, accelerate workflows, reduce costs, and expand coverage via portable and edge-computing devices. However, translation is constrained by data bias, variable image quality, opaque decision-making, and fragmented regulation. We outline requirements for clinically robust and equitable deployment, including diverse multi-center datasets, federated and privacy-preserving learning, explainable interfaces, standardized validation with histopathologic endpoints, and clinician-in-the-loop workflows. Finally, we highlight future directions such as hybrid explainable AI with large language models, multi-omics integration, and adaptive models resilient to data drift.",
      "authors": "Wang Xiaodong; Wang Qianqian; Ding Gouping; Wang Junjie; Tang Yixuan; Feng Yeqian",
      "year": "2026",
      "month": "Feb",
      "journal": "iScience",
      "source": "pubmed"
    },
    {
      "pmid": "41619215",
      "doi": "10.1093/bib/bbaf723",
      "title": "Advances and challenges in single-cell RNA sequencing data analysis: a comprehensive review.",
      "abstract": "Single-cell RNA sequencing (scRNA-seq) has transformed the resolution of cellular heterogeneity, offering insights into dynamic biological processes from tumor evolution to immune regulation. However, its clinical translation is limited by challenges such as data sparsity, batch effects (differences caused by technical variation rather than biology), and the absence of standardized benchmarks for core pipelines like Seurat and Scanpy. This review outlines emerging computational strategies that address these limitations: (A) robust preprocessing, including SCTransform for zero-inflation(an excess of zero counts in gene-expression data) correction and Harmony for batch integration-achieving 30% faster alignment than BBKNN in cohorts exceeding 100,000 cells; (B) transformer-based annotation tools such as scGPT and CellTypist, which reach >95% accuracy in immune profiling using models pretrained on 33 million cells; and (C) multimodal integration with spatial transcriptomics (e.g., 10x Visium, cell2location v2), which delineate microenvironmental niches and rare CX3CR1+ T-cell subsets in disease contexts like glioblastoma and severe COVID-19. We further assess how scANVI bridges scRNA-seq and ATAC-seq to uncover epigenetic mechanisms underlying therapy resistance, and how spatial methods elucidate tumor-immune crosstalk at subcellular resolution. Despite these advances, ethical risks remain, particularly around re-identification of rare patient-derived clones such as pre-metastatic cells. To promote clinical adoption, we propose a roadmap that prioritizes benchmarked workflows (e.g., scverse ecosystem), privacy-aware data sharing via federated learning, and causal AI approaches to disentangle biological signal from technical artifact. By synthesizing computational innovations with translational case studies, this review equips researchers to navigate both the analytical and ethical complexities of scRNA-seq in pursuit of actionable diagnostics.",
      "authors": "Nesari Ali Mohammad; MotieGhader Habib; Ghorbian Saeid",
      "year": "2026",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41618385",
      "doi": "10.1186/s13321-026-01155-z",
      "title": "Chemical genomics language model toward reliable and explainable compound-protein interaction exploration.",
      "abstract": "Accurate prediction of compound-protein interactions (CPIs) is crucial for chemical biology and drug discovery. Despite recent advancements, existing deep learning (DL)-based CPI models often struggle to simultaneously achieve high generalization performance, quantify prediction confidence, and ensure explainability. Here, we propose ChemGLaM, a chemical genomics language model designed to address these three crucial challenges, thereby enabling reliable and explainable CPI predictions. ChemGLaM integrates independently pre-trained chemical and protein language models through an interaction block with a cross-attention mechanism, achieving near state-of-the-art performance in predicting novel CPIs at a low computational cost. Incorporating uncertainty estimation and attention visualization enables ChemGLaM to enhance the success rate of virtual screening and to provide molecular insights into CPIs. To demonstrate the practical impact of ChemGLaM, we constructed a publicly available database containing large-scale CPI predictions for every possible pairing between all 20,434 human proteins and all 11,455 drugs and validated its practical applicability in a case study on amyotrophic lateral sclerosis. ChemGLaM marks an important step forward in addressing the challenges of AI-driven CPI exploration and drug discovery.Scientific ContributionThis study established a unified CPI prediction framework that simultaneously achieves high generalization performance, confidence quantification, and explainability. We leveraged this framework to create a community resource by constructing a comprehensive CPI database and demonstrated its practical utility by successfully prioritizing hit compounds and deconvoluting their targets in a phenotypic screening for amyotrophic lateral sclerosis.",
      "authors": "Koyama Takuto; Tsumura Hayato; Okita Ryunosuke; Yamazaki Kimihiro; Hasegawa Aki; Imamura Keiko; Kato Takashi; Iwata Hiroaki; Kojima Ryosuke; Inoue Haruhisa; Matsumoto Shigeyuki; Okuno Yasushi",
      "year": "2026",
      "month": "Jan",
      "journal": "Journal of cheminformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41617774",
      "doi": "10.1038/s41598-026-35971-y",
      "title": "Identification of diagnostic and prognostic biomarkers in lung adenocarcinoma through integrated bioinformatics analysis and real time PCR validation.",
      "abstract": "Lung cancer is the third most common cancer in the US with a 5-year survival rate of 17%. Non-small cell lung cancer, especially adenocarcinoma, prevails. Therefore, early detection and biomarker discovery are extremely important. This study uses deep learning to find new biomarkers for lung adenocarcinoma. RNA-Seq data from 522 samples, including 506 lung adenocarcinoma patients and 16 healthy controls, were analyzed. DEGs were identified after strict preprocessing, and deep learning algorithms predicted markers. Functional annotation, pathway, and protein interaction analyses elucidated the biological importance of DEGs. Clinical relevance was assessed by correlation with clinical parameters and survival analysis. External validation was carried out using GDAC and GEO datasets. Blood samples from 30 lung adenocarcinoma patients and 30 healthy people were analyzed by real-time PCR to validate the expression levels of key genes. Among 522 participants(506 cases, 16 controls), the mean age was 62.95 ± 15.71 years. Normalized data showed 3,513 DEGs. The deep learning model had a predictive accuracy of 98.44%, Brier score (probability MSE) = 0.0013, and AUC of 1.0. CYP3A7 had the highest effect size. ROC analysis found diagnostic genes A2M, CYP2C9, and SIRPD (Ensembl ID: 128646) with a sensitivity of 0.96. Real-time PCR showed upregulated CYP2C9, KRT14, and PECAM1 and downregulated A2M in patients compared to controls(P < 0.001). Bioinformatics-identified genes are potential markers for early lung adenocarcinoma detection and management. RT-PCR validation shows AI's effectiveness in identifying biomarkers, enabling prompt treatment to halt disease progression.",
      "authors": "Hossein Zadeh Rasoul; Hossein Zadeh Reza; Hajimoradi Maryam; Islampanah Muhammad; Zarimeidani Fatemeh; Rahmati Rahem; Ahmadinia Mahdi; Bahrami Naghmeh; Mohamadnia Abdolreza; Shafaghi Shadi; Nazari Elham",
      "year": "2026",
      "month": "Jan",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "41610146",
      "doi": "10.1371/journal.pcbi.1013893",
      "title": "SpaConTDS: A multimodal contrastive learning framework for identifying spatial domains by applying tuple disturbing strategy.",
      "abstract": "The rational utilization of multimodal spatial transcriptomics (ST) data enables accurate identification of spatial domains, which is essential for investigating cellular structure and functions. In this study, we proposed SpaConTDS, a novel framework that integrates reinforcement learning with self-supervised multimodal contrastive learning. SpaConTDS generates positive and negative samples through data augmentation and a pseudo-label tuple perturbation strategy, enabling the learning of fused representations that capture global semantics and cross-modal interactions. The model's hyper-parameters are dynamically optimized using reinforcement learning. Extensive experiments across various resolutions and platforms demonstrate that SpaConTDS achieves state-of-the-art accuracy in spatial domain identification and outperforms existing methods in downstream tasks such as denoising, trajectory inference, and UMAP visualization. Moreover, SpaConTDS effectively integrates multiple tissue sections and corrects batch effects without requiring prior alignment. Compared to existing approaches, SpaConTDS offers more robust fused representations of multimodal data, providing researchers with a flexible and powerful tool for a wide range of spatial transcriptomics analyses.",
      "authors": "Xu Ruiwen; Cheng Xiaoqing; Ching Waiki; Wu Siyao; Zhang Yuanben; Zhang Yidan",
      "year": "2026",
      "month": "Jan",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    },
    {
      "pmid": "41595426",
      "doi": "10.3390/genes17010006",
      "title": "The Evolving Role of Artificial Intelligence in Medical Genetics: Advancing Healthcare, Research, and Biosafety Management.",
      "abstract": "The integration of artificial intelligence (AI) with medical genetics is transforming healthcare by addressing the analytical challenges posed by the vast complexity of multi-omics data. This review explores the synergistic convergence of these fields, highlighting AI's transformative role in enhancing diagnostic precision, enabling non-invasive molecular profiling through imaging-genetics, and advancing predictive and personalized medicine via polygenic risk scores and pharmacogenomics. AI is also emerging as a powerful generative tool in therapeutic design, accelerating drug discovery, protein engineering, and precision gene editing. However, this powerful synergy introduces significant ethical, regulatory, and biosecurity challenges, including data privacy, algorithmic bias, and the dual-use risks of AI-enabled genetic engineering. The future envisions a responsible co-evolution, with multimodal AI and the concept of the Digital Twin driving precision medicine, underpinned by interdisciplinary collaboration to ensure fairness, transparency, and societal trust. This article charts the current landscape and proposes actionable directions, emphasizing the need for robust governance to harness AI's potential while mitigating its risks for the benefit of human health.",
      "authors": "Wu Ying-Cheng; Tuo Nan; Shi Guoming; Li Ka; Song Zhenju; Li Yanying",
      "year": "2025",
      "month": "Dec",
      "journal": "Genes",
      "source": "pubmed"
    },
    {
      "pmid": "41594331",
      "doi": "10.3390/diagnostics16020356",
      "title": "A Clinically Translatable Multimodal Deep Learning Model for HRD Detection from Histopathology Images.",
      "abstract": "",
      "authors": "Uttarwar Mohan; Khandare Jayant; Shivamurthy P M; Satpute Aditya; Panwar Mohit; Kothavade Hrishita; Ramesh Aarthi; Iyer Sandhya; Shafi Gowhar",
      "year": "2026",
      "month": "Jan",
      "journal": "Diagnostics (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "41592570",
      "doi": "10.1016/j.xgen.2025.101130",
      "title": "ChromBERT: A foundation model for learning interpretable representations for context-specific transcriptional regulatory networks.",
      "abstract": "Gene expression is shaped by transcriptional regulatory networks (TRNs), where transcription regulators interact within regulatory elements in a context-specific manner. Deciphering context-specific TRNs has long been constrained by the severe sparsity of cell-type-specific chromatin immunoprecipitation sequencing (ChIP-seq) profiles. Here, we present ChromBERT, a foundation model pre-trained on large-scale human ChIP-seq datasets covering ∼1,000 transcription regulators. ChromBERT learns the genome-wide syntax of regulatory cooperation and generates interpretable TRN representations. After prompt-enhanced fine-tuning, it outperforms existing methods for imputing unseen cistromes. Moreover, lightweight fine-tuning on cell-type-specific downstream tasks adapts the TRN representations to capture regulatory effects and dynamics within any given cellular context. The resulting context-specific representations can then be interpreted to infer regulatory roles of transcription regulators underlying these cell-type-specific regulatory outcomes without requiring additional ChIP-seq experiments. By overcoming the limitations of sparse transcription regulator data, ChromBERT significantly enhances our ability to model and interpret transcriptional regulation across a wide range of biological contexts.",
      "authors": "Yu Zhaowei; Yang Dongxu; Chen Qianqian; Zhang Yuxuan; Li Zhanhao; Wang Yucheng; Wang Chenfei; Zhang Yong",
      "year": "2026",
      "month": "Jan",
      "journal": "Cell genomics",
      "source": "pubmed"
    },
    {
      "pmid": "41588477",
      "doi": "10.1186/s13073-025-01586-7",
      "title": "Aligned cross-modal integration and regulatory heterogeneity characterization of single-cell multiomic data with deep contrastive learning.",
      "abstract": "Single-cell multi-omics (scMulti-omics) technologies have revolutionized our understanding of cellular functions and interactions by enabling the simultaneous measurement of diverse cellular modalities. Integrating these heterogeneous data types presents significant challenges due to differences in scale, resolution, and biological variability across the omics layers. Traditional computational methods often fail to reconcile these differences, leading to a loss of critical biological variability and subtle intermolecular interactions. To address these challenges, we have developed a single-cell multi-omics deep learning model (scMDCF) based on contrastive learning, tailored for the efficient characterization and integration of scMulti-omics data. scMDCF features a cross-modality contrastive learning module that harmonizes data representations across different omics types, ensuring consistency and preserving data heterogeneity by accommodating information entropy. Furthermore, a cross-modality feature fusion module extracts common low-dimensional latent representations of scMulti-omics data, effectively balancing the diverse characteristics of these data types. Extensive empirical studies demonstrate that scMDCF outperforms existing state-of-the-art scMulti-omics models across various types of scMulti-omics data. In particular, scMDCF exhibits advanced analytical capabilities in extracting cell-type-specific peak-gene associations and cis-regulatory elements from SNARE-seq data, and in elucidating immune regulation from CITE-seq data. In a post-BNT162b2 mRNA SARS-CoV-2 vaccination dataset, scMDCF successfully annotates specific vaccine-induced B cell subpopulations, uncovering dynamic interactions and regulatory mechanisms within the immune system post-vaccination. Most importantly, using Alzheimer's disease-specific data, scMDCF identifies computational minority Microglia and Endothelial cell populations, revealing ELF1 as a putative candidate transcription factor biomarker in Microglia, which potentially influences GTPase activity and may suppresses Alzheimer's pathology. We propose scMDCF, a contrastive learning based framework for single-cell multi-omics integration that harmonizes cross-modality representations while preserving biological heterogeneity. Applications across diverse scMulti-omics datasets demonstrate improved clustering performance, effective batch-effect mitigation, and mechanistic insights into underlying biological processes. Code and reproducible workflows are openly available.",
      "authors": "Cheng Yue; Su Yanchi; Fan Yi; Yang Yuning; Chen Xingjian; Wang Fuzhou; Wong Ka-Chun; Li Xiangtao",
      "year": "2026",
      "month": "Jan",
      "journal": "Genome medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41587322",
      "doi": "10.1093/bib/bbaf728",
      "title": "BiChemoCLAM: a weakly supervised multimodal framework for chemotherapy response prediction.",
      "abstract": "Chemotherapy is an important treatment for cancer patients, but it comes with risks. Therefore, effective chemotherapy response prediction is crucial. While whole slide image provides high-resolution insights into tumour environments, existing weakly supervised learning frameworks struggle to effectively integrate molecular data, such as gene expression, limiting their predictive power in complex chemotherapy response and small-sample scenarios. We present a bimodal chemotherapy response multi-instance learning framework, BiChemoCLAM, a novel multimodal deep learning framework that combines attention-driven multiple instance learning with multimodal compact bilinear pooling for interpretable and data-efficient chemotherapy response prediction. It achieves an Area Under Curve (AUC) of 80.91%, 71.68%, and 75.80% on ovarian serous cystadenocarcinoma, colorectal adenocarcinoma, and bladder urothelial carcinoma cancer datasets, respectively. The experimental results show that BiChemoCLAM is an effective model for predicting response to chemotherapy.",
      "authors": "Gui Jinglong; Sun Changming; Zhou Jia; Xie Cun; Wei Leyi; Zhao Jia; Liu Xiaofeng; Su Ran",
      "year": "2026",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41584223",
      "doi": "10.3389/frai.2025.1716706",
      "title": "Multimodal graph neural networks in healthcare: a review of fusion strategies across biomedical domains.",
      "abstract": "Graph Neural Networks (GNNs) have transformed multimodal healthcare data integration by capturing complex, non-Euclidean relationships across diverse sources such as electronic health records, medical imaging, genomic profiles, and clinical notes. This review synthesizes GNN applications in healthcare, highlighting their impact on clinical decision-making through multimodal integration, advanced fusion strategies, and attention mechanisms. Key applications include drug interaction and discovery, cancer detection and prognosis, clinical status prediction, infectious disease modeling, genomics, and the diagnosis of mental health and neurological disorders. Various GNN architectures demonstrate consistent applications in modeling both intra- and intermodal relationships. GNN architectures, such as Graph Convolutional Networks and Graph Attention Networks, are integrated with Convolutional Neural Networks (CNNs), transformer-based models, temporal encoders, and optimization algorithms to facilitate robust multimodal integration. Early, intermediate, late, and hybrid fusion strategies, enhanced by attention mechanisms like multi-head attention, enable dynamic prioritization of critical relationships, improving accuracy and interpretability. However, challenges remain, including data heterogeneity, computational demands, and the need for greater interpretability. Addressing these challenges presents opportunities to advance GNN adoption in medicine through scalable, transparent GNN models.",
      "authors": "Vaida Maria; Huang Ziyuan",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in artificial intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "41584179",
      "doi": "10.3389/fpubh.2025.1656603",
      "title": "AI-driven transformation of precision medicine: a comprehensive narrative review of key application areas, emerging paradigms, and future directions.",
      "abstract": "This study aims to elucidate the pivotal role of Artificial Intelligence (AI) in driving the transformation of precision medicine, comprehensively analyzing how it reshapes healthcare systems from traditional diagnosis and treatment paradigms into personalized health management ecosystems. A comprehensive narrative review was conducted to systematically synthesize and critically evaluate the innovative applications, paradigm shifts, and future prospects of AI across the entire precision medicine value chain. A comprehensive literature search was performed across multiple databases up to April 30, 2025, with a focus on the clinical implementation and breakthroughs of technologies such as deep learning (DL), machine learning (ML), and natural language processing (NLP). AI technologies have significantly enhanced the accuracy and efficiency of disease diagnosis through medical image analysis, genomics, and multimodal data fusion. At the treatment level, AI enables the development of personalized therapeutic plans and drug dosing optimization, while revolutionarily accelerating the drug development pipeline from discovery to clinical trials. Integrated with wearable devices and telemedicine platforms, AI facilitates full-cycle health monitoring. However, the clinical translation of AI faces challenges, including an uneven evidence base, insufficient model generalizability, and ethical concerns regarding data privacy, algorithmic fairness, and interpretability. AI is a key driver of paradigm shift in precision medicine. To address existing challenges, future efforts should focus on generating more robust clinical evidence, adopting technologies like federated learning to ensure data privacy, and promoting the human-centered, collaborative framework of Symbiotic AI (SAI). By establishing sound ethical and governance structures, the deployment of AI technologies can be ensured to be not only efficient and advanced but also equitable and trustworthy, ultimately paving the way for an intelligent and inclusive healthcare ecosystem.",
      "authors": "Zeng Qin; Huang Cheng; Zhu Jun",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in public health",
      "source": "pubmed"
    },
    {
      "pmid": "41573270",
      "doi": "10.3389/frai.2025.1743921",
      "title": "Multi-modal AI in precision medicine: integrating genomics, imaging, and EHR data for clinical insights.",
      "abstract": "Precision healthcare is increasingly oriented toward the development of therapeutic strategies that are as individualized as the patients receiving them. Central to this paradigm shift is artificial intelligence (AI)-enabled multi-modal data integration, which consolidates heterogeneous data streams-including genomic, transcriptomic, proteomic, imaging, environmental, and electronic health record (EHR) data into a unified analytical framework. This integrative approach enhances early disease detection, facilitates the discovery of clinically actionable biomarkers, and accelerates rational drug development, with particularly significant implications for oncology, neurology, and cardiovascular medicine. Advanced machine learning (ML) and deep learning (DL) algorithms are capable of extracting complex, non-linear associations across data modalities, thereby improving diagnostic precision, enabling robust risk stratification, and informing patient-specific therapeutic interventions. Furthermore, AI-driven applications in digital health, such as wearable biosensors and real-time physiological monitoring, allow for continuous, dynamic refinement of treatment plans. This review examines the transformative potential of multi-modal AI in precision medicine, with emphasis on its role in multi-omics data integration, predictive modeling, and clinical decision support. In parallel, it critically evaluates prevailing challenges, including data interoperability, algorithmic bias, and ethical considerations surrounding patient privacy. The synergistic convergence of AI and multi-modal data represents not merely a technological innovation but a fundamental redefinition of individualized healthcare delivery.",
      "authors": "Khan Shahper Nazeer; Danishuddin; Khan Mohd Wajid Ali; Guarnera Luca; Akhtar Syed Mohammad Fauzan",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in artificial intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "41555433",
      "doi": "10.1186/s13059-026-03948-9",
      "title": "CLAMP: predicting specific protein-mediated chromatin loops in diverse species with a chromatin accessibility language model.",
      "abstract": "Emerging DNA language models provide powerful tools to address the challenge of accurately predicting chromatin loops, fundamental structures governing 3D genome organization and gene regulation. Here we present CLAMP, which utilizes a deep language model pre-trained on broad cross-species chromatin accessibility data. CLAMP achieves superior performance compared to existing methods in predicting specific protein-mediated loops across 10 species, 18 proteins, and 24 cell types. CLAMP incorporates a novel CoVE explainer that reveals context-dependent genomic feature contributions, providing insights into the features driving predictions. CLAMP predictions effectively identify functionally significant chromatin loops and associated biological pathways.",
      "authors": "He Zhijie; Sun Yu; Li Hao; Sun Canzhuang; Yang Xianhui; Chen Hebing; Liao Mingzhi; Bo Xiaochen",
      "year": "2026",
      "month": "Jan",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "41555097",
      "doi": "10.1038/s44320-025-00184-4",
      "title": "The DNA dialect: a comprehensive guide to pretrained genomic language models.",
      "abstract": "Following their success in natural language processing and protein biology, pretrained large language models have started appearing in genomics in large numbers. These genomic language models (gLMs), trained on diverse DNA and RNA sequences, promise improved performance on a variety of downstream prediction and understanding tasks. In this review, we trace the rapid evolution of gLMs, analyze current trends, and offer an overview of their application in genomic research. We investigate each gLM component in detail, from training data curation to the architecture, and highlight the present trends of increasing model complexity. We review major benchmarking efforts, suggesting that no single model dominates, and that task-specific design and pretraining data often outweigh general model scale or architecture. In addition, we discuss requirements for making gLMs practically useful for genomic research. While several applications, ranging from genome annotation to DNA sequence generation, showcase the potential of gLMs, their use highlights gaps and pitfalls that remain unresolved. This guide aims to equip researchers with a grounded understanding of gLM capabilities, limitations, and best practices for their effective use in genomics.",
      "authors": "Veiner Marcell; Supek Fran",
      "year": "2026",
      "month": "Jan",
      "journal": "Molecular systems biology",
      "source": "pubmed"
    },
    {
      "pmid": "41551846",
      "doi": "10.1038/s44387-025-00050-6",
      "title": "A multimodal framework to identify molecular mechanisms driving patient group-associated morphology through the integration of spatial transcriptomics and whole slide imaging.",
      "abstract": "Spatial organization of the disease microenvironment informs patient prognosis. Key modalities for studying spatial biology include H&E images (WSIs) for tissue structure and spatial transcriptomics (ST) for transcriptome-level programs. Spatial analysis aims to (1) identify markers linked to clinical outcome, (2) understand functional programs driving these associations, and (3) guide targeted therapies. Current research addresses these topics but offers limited explainability across the full morphology - molecular mechanism - outcome axis. Further, given the abundance of WSIs and limited availability of ST, there is a need for analyses integrating these complementary datasets. We present an AI-driven framework combining foundation-model features, multiple-instance learning, unsupervised clustering, and molecular analyses to identify mechanisms underlying outcome associated patterns. Applied to HER2+ breast cancer, we identify CCND1 and PTK6 signaling in tumor regions linked to trastuzumab resistance, consistent with prior studies. Our approach offers interpretable insights for multi-level resistance mechanisms, tissue-specific drug targeting, and precision medicine.",
      "authors": "Kulkarni Reva; Maddox Avery; Bailey Sara; Rao Arvind",
      "year": "2026",
      "month": "",
      "journal": "NPJ artificial intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "41546050",
      "doi": "10.1186/s12951-025-03952-4",
      "title": "Machine learning for extracellular vesicles enables diagnostic and therapeutic nanobiotechnology.",
      "abstract": "Extracellular vesicles (EVs) are emerging as naturally bioactive nanomaterials with intrinsic biocompatibility and targeting potential. Recent integration of machine learning (ML) into EV research has accelerated advances in molecular profiling, structure-function prediction, and rational design of vesicle-based therapeutics. Yet, the inherent complexity and heterogeneity of EV populations pose major analytical challenges. Concurrently, machine learning is revolutionizing biomedical science by uncovering patterns in high dimensional, multimodal datasets. In EV research, ML has enabled major advances across automated imaging, multi omics integration, disease classification, therapeutic engineering, and standardization. This review presents a comprehensive synthesis of ML-enabled EV studies, organized by data modality (imaging, omics, cytometry), algorithmic paradigm (CNNs, random forests, autoencoders, GNNs), and translational application (diagnosis, prognosis, drug delivery, manufacturing QC). Unlike prior reviews that have typically considered EV biology and AI methods in relative isolation, we introduce a unified three-axis taxonomy that explicitly links EV data modalities, machine learning architectures, and clinical use-cases, thereby providing a structured map of the field. We discuss key technical barriers including data sparsity, batch variability, and model explainability and spotlight frontier developments such as federated learning, self-supervised models, and real-time EV analytics. At the nexus of computational intelligence and nanomedicine, ML-enhanced EV platforms are rapidly progressing from fragmented innovations to clinically actionable systems. This review offers a roadmap for advancing AI-integrated EV technologies in cancer precision medicine.",
      "authors": "Tiwari Ashutosh; Widodo; Krisnawati Dyah Ika; Tzou Kai-Yi; Kuo Tsung-Rong",
      "year": "2026",
      "month": "Jan",
      "journal": "Journal of nanobiotechnology",
      "source": "pubmed"
    },
    {
      "pmid": "41542080",
      "doi": "10.1016/j.csbj.2025.09.004",
      "title": "STAG-LLM: Predicting TCR-pHLA binding with protein language models and computationally generated 3D structures.",
      "abstract": "",
      "authors": "Slone Jared K; Zhang Minying; Jiang Peixin; Montoya Amanda; Bontekoe Emily; Rausseo Barbara Nassif; Reuben Alexandre; Kavraki Lydia E",
      "year": "2025",
      "month": "",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "41527854",
      "doi": "10.1093/bib/bbaf721",
      "title": "EpiXFormer: a cross-attention neural network for predicting cell type-specific transcription factor binding sites.",
      "abstract": "Transcription factors (TFs) bind to specific sequences in the genome to regulate gene expression and specify cell states. TF binding sites (TFBSs) are cell type-specific, which can be attributed to epigenomic contexts. Comprehensive profiling of TFBSs across various cell types through experimental approaches is neither practical nor cost-friendly. Accurately identifying cell type-specific TFBSs through computational approaches remains challenging. Here, we develop EpiXFormer, a novel transformer-based neural network for cell type-specific TFBS prediction. EpiXFormer achieves exceptional performance in predicting binding sites of DNA-binding proteins (DBPs) across a diverse collection of cell types. It models the effects of proximal and distal epigenomic information on DBP binding and learns the identified motifs of the examined TFs and their potential co-occurring proteins. Moreover, we demonstrate that EpiXFormer can infer pioneer factors during cell type transition and delineate the cell type-specific regulatory functions of TFs. Overall, EpiXFormer enables cell type-specific TFBS prediction in the examined cell lines and is readily applied to other cell types of interest. It provides a robust, scalable framework for characterizing and interpreting multimodal genomic data.",
      "authors": "Peng Yonglin; Liu Xinhua; Wu Jun; Lin Sang; Zhan Shengxuan; Li Hua; Wang Ju; Zhao Xiaodong",
      "year": "2026",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41518203",
      "doi": "10.1093/gigascience/giag004",
      "title": "Harnessing artificial intelligence for genomic variant prediction: advances, challenges, and future directions.",
      "abstract": "Accurate genetic variant interpretation is crucial for disease research and the development of targeted therapies. Artificial intelligence is transforming this field by integrating computational methodologies across structural biology, evolutionary analysis, and multimodal genomic data. This review examines the evolution from traditional rule-based systems and statistical models to contemporary machine learning, deep learning, and protein language models, while addressing critical challenges in variant classification. Key obstacles include data heterogeneity, interpretability, and the persistence of variants of uncertain significance, emphasizing the critical need for explainable artificial intelligence frameworks and more inclusive genomic databases to improve predictive accuracy across diverse populations. Based on the assessment of current variant impact predictors, we propose strategies for enhanced predictor selection, effective multi-omics data integration, and optimized computational workflows. These recommendations aim to enhance variant interpretation accuracy in both research settings and clinical practice, ultimately contributing to advances in personalized medicine.",
      "authors": "Pakpahan Indah; Sihombing Mentari; Liu Haohan; Wang Mengyao; Su Zheng; Fang Mingyan",
      "year": "2026",
      "month": "Jan",
      "journal": "GigaScience",
      "source": "pubmed"
    },
    {
      "pmid": "41515227",
      "doi": "10.3390/nu18010110",
      "title": "AI-Enabled Precision Nutrition in the ICU: A Narrative Review and Implementation Roadmap.",
      "abstract": "",
      "authors": "Briassoulis George; Briassouli Efrossini",
      "year": "2025",
      "month": "Dec",
      "journal": "Nutrients",
      "source": "pubmed"
    },
    {
      "pmid": "41514844",
      "doi": "10.3390/biology15010002",
      "title": "Pattern Learning and Knowledge Distillation for Single-Cell Data Annotation.",
      "abstract": "Transferring cell type annotations from reference dataset to query dataset is a fundamental problem in AI-based single-cell data analysis. However, single-cell measurement techniques lead to domain gaps between multiple batches or datasets. The existing deep learning methods lack consideration on batch integration when learning reference annotations, which is a challenge for cell type annotation on multiple query batches. For cell representation, batch integration can not only eliminate the gaps between batches or datasets but also improve the heterogeneity of cell clusters. In this study, we proposed PLKD, a cell type annotation method based on pattern learning and knowledge distillation. PLKD consists of Teacher (Transformer) and Student (MLP). Teacher groups all input genes (features) into different gene sets (patterns), and each pattern represents a specific biological function. This design enables model to focus on biologically relevant functions interaction rather than gene-level expression that is susceptible to gaps of batches. In addition, knowledge distillation makes lightweight Student resistant to noise, allowing Student to infer quickly and robustly. Furthermore, PLKD supports multi-modal cell type annotation, multi-modal integration and other tasks. Benchmark experiments demonstrate that PLKD is able to achieve accurate and robust cell type annotation.",
      "authors": "Zhang Ming; Ren Boran; Li Xuedong",
      "year": "2025",
      "month": "Dec",
      "journal": "Biology",
      "source": "pubmed"
    },
    {
      "pmid": "41509387",
      "doi": "10.64898/2025.12.22.696111",
      "title": "MOTLAB: A Weighted Multi-Omics Transfer Learning Approach to Mitigate Breast Cancer Racial Disparities.",
      "abstract": "Breast cancer (BC) is a leading cause of cancer death among women in United States. Previous studies have indicated that Black American women have disproportionately higher mortality than non-Hispanic White American women. Existing studies have demonstrated that artificial intelligence (AI) and machine learning (ML) especially transfer learning (TL) could address BC health disparities by transferring information learned from a majority group (e.g., White American women) to minority groups (e.g., Black American women). However, these studies have the following limitations: (1) the performance will decrease significantly as limited patient samples for training can be collected in clinical settings; and (2) most of existing studies only leverage single-omics data without exploring multi-omics integration. We recently presented a transfer learning method by integrating two multi-omics data for reducing cancer disparities. However, the integration model was not optimized, and its performance in reducing disparities was not robust. To address these concerns, we propose a weighted multi-modal transfer learning framework called MOTLAB designed to optimize the multi-omics integration equipped with data augmentation to systematically mitigate racial disparities in BC. Specifically, we first calculated patient-patient similarity using the Pearson Correlation Coefficient (PCC), which were used to construct a weighted integration of multi-omics data. Then, we performed a nested grid search method to optimize the weight combinations for each omics modality, which were subsequently used in multi-omics data integration to generate input data of the transfer learning model. In addition, to reduce the impact of data imbalance problems for our TL model, we leveraged a data augmentation named Synthetic Minority Oversampling Technique (SMOTE) for the minority groups to further boost performance of reducing health disparities. Results based on a dataset of 1085 female BC patient samples from The Cancer Genome Atlas (TCGA) database suggested that MOTLAB with optimized weighted integration of three omics data (including mRNA, miRNA and methylation) outperformed existing multi-omics transfer learning models. Moreover, MOTLAB achieved better performance than single-omics and two-omics-integration transfer learning models as well as conventional mixed models and independent models for BC health disparities mitigation. We anticipate that MOTLAB will serve as a new approach to reduce health disparities in BC diagnosis, prognosis, and treatment, and be extensible to mitigate health disparities for other types of cancer.",
      "authors": "Baek Min-Jeong; Li Lusheng; Band Vimla; Wang Jieqiong; Wan Shibiao",
      "year": "2025",
      "month": "Dec",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41501996",
      "doi": "10.1093/gpbjnl/qzaf129",
      "title": "Generalizable Single-cell Multimodal Data Integration with Self-supervised Learning.",
      "abstract": "Recent breakthroughs in single-cell multi-omics technologies have enabled simultaneous measurement of diverse cellular modalities, offering unprecedented biological insights. However, integrating such multimodal data faces dual challenges: Small-scale paired-modality studies (hundreds of cells) risk overfitting, while large-scale reference atlases often struggle to generalize effectively to new datasets. To overcome these challenges, we present multimodal integration with self-supervised learning (MINERVA), a unified deep learning framework employing self-supervised strategies for single-cell multimodal integration. MINERVA outperforms six state-of-the-art methods in dimensionality reduction, missing feature imputation, and batch effect correction, even with limited training cells. For large-scale applications, MINERVA constructs scalable multi-tissue references that support zero-shot knowledge transfer to unseen datasets, instant cell type annotation, novel cell states identification, and comprehensive downstream analyses, all without model retraining. Uniquely bridging small-scale precision with atlas-level generalization, MINERVA serves as a versatile tool for both de novo integration and cost-effective atlas reuse in single-cell research.",
      "authors": "Shi Jinhui; Hu Shuofeng; Liu Runyan; Zhou Jiahao; Wang Jing; Ying Xiaomin; He Zhen",
      "year": "2026",
      "month": "Jan",
      "journal": "Genomics, proteomics & bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41484923",
      "doi": "10.1186/s40001-025-03769-9",
      "title": "Molecular and multimodal biomarkers in Moyamoya disease: from pathogenic mechanisms to clinical translation.",
      "abstract": "Moyamoya disease (MMD) is a chronic, progressive cerebrovascular condition marked by narrowing or blockage of the terminal segments of the internal carotid arteries, resulting in ischemic and hemorrhagic strokes. Its pathogenesis involves a multifactorial interplay between genetic susceptibility, immune-inflammatory dysregulation, endothelial dysfunction, and aberrant vascular remodeling, influenced by non-genetic and environmental factors. Despite considerable research progress, clinically useful biomarkers remain limited, lacking sufficient sensitivity and specificity for predicting disease onset, progression, or treatment response. Current management relies primarily on surgical revascularization, which restores cerebral perfusion but does not address underlying biological mechanisms, while pharmacological interventions remain largely empirical and nonspecific. This review systematically searched PubMed and Web of Science up to September 2025 using combinations of \"Moyamoya disease\" and \"biomarker\" with \"genomics,\" \"transcriptomics,\" \"proteomics,\" \"metabolomics,\" \"neuroimaging,\" \"artificial intelligence,\" and \"machine learning.\" We summarize recent advances in genetic and molecular biomarker discovery, including the identification of RNF213 as a major susceptibility gene in East Asian populations, alongside emerging roles of variants in MTHFR, DIAPH1, and GUCY1A3. Beyond genomics, proteomic and metabolomic profiling have revealed dysregulation of vascular repair pathways, extracellular-matrix remodeling, and lipid-amino acid metabolism, offering new insights into disease heterogeneity and progression. Noncoding RNAs and exosome-derived biomarkers-such as plasma miR-512-3p, miR-328-3p, and miR-125b-5p-have shown potential as minimally invasive tools for diagnosis and monitoring, linking posttranscriptional regulation to vascular pathophysiology. Parallel advances in neuroimaging biomarkers, enhanced by artificial intelligence (AI), are enabling the integration of morphological and hemodynamic data with molecular findings. Deep learning-based models trained on digital subtraction angiography (DSA), computed tomography angiography (CTA), and retinal imaging have achieved diagnostic accuracies exceeding 90%, while multimodal integration approaches are beginning to correlate imaging phenotypes with genetic and metabolic profiles. Future research must transcend single-omics paradigms to establish integrative, multidimensional frameworks that connect genetic variation to cellular function, vascular remodeling, and clinical phenotype. Progress will depend on international multicenter collaboration, open-access biomarker databases, and the incorporation of explainable AI to bridge discovery and clinical application. Together, these developments may usher in biomarker-driven precision diagnosis and personalized therapy for MMD.",
      "authors": "Li Jinghong; Zhang Lilei; Zhan Yanqiang; Han Xiaohua; Deng Chunchu",
      "year": "2026",
      "month": "Jan",
      "journal": "European journal of medical research",
      "source": "pubmed"
    },
    {
      "pmid": "41477342",
      "doi": "10.1016/j.apsb.2025.09.039",
      "title": "Artificial intelligence for radiopharmaceutical and molecular imaging.",
      "abstract": "Artificial intelligence (AI)-driven data-centric paradigms are catalyzing a paradigm shift in radiopharmaceutical development and molecular imaging, two pivotal technologies that underpin precision nuclear medicine. This review focuses on the cutting-edge applications of AI in radiopharmaceutical discovery and molecular image analytics, and systematically investigates the technical principles and typical cases of Deep Learning algorithms (",
      "authors": "Tao Jinping; Liang Ling; Hao Siqi; Chen Yan; Yang Zhi; Cai Yimao; Zhu Hua",
      "year": "2025",
      "month": "Dec",
      "journal": "Acta pharmaceutica Sinica. B",
      "source": "pubmed"
    },
    {
      "pmid": "41476170",
      "doi": "10.1038/s41467-025-66961-9",
      "title": "Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions.",
      "abstract": "Emerging research has highlighted that artificial intelligence-based multimodal fusion of digital pathology and transcriptomic features can improve cancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction. However, such direct fusion is impractical in clinical settings, where histopathology remains the gold standard and transcriptomic tests are rarely requested in public healthcare. We experiment on two publicly available multimodal datasets, The Cancer Genomic Atlas and the Clinical Proteomic Tumor Analysis Consortium, spanning four independent cohorts: glioma-glioblastoma, renal, uterine, and breast, and observe significant performance gains in gradation and risk estimation (p-value  < 0.05) when incorporating synthesized transcriptomic data with WSIs. Also, predictions using synthesized features were statistically close to those obtained with real transcriptomic data (p-value  > 0.05), consistently across cohorts. Here we show that with our diffusion based crossmodal generative AI model, PathGen, gene expressions synthesized from digital histopathology jointly predict cancer grading and patient survival risk with high accuracy (state-of-the-art performance), certainty (through conformal coverage guarantee) and interpretability (through distributed co-attention maps). PathGen code is available on GitHub at https://github.com/Samiran-Dey/PathGen for open use.",
      "authors": "Dey Samiran; Banerji Christopher R S; Basuchowdhuri Partha; Saha Sanjoy K; Parashar Deepak; Chakraborti Tapabrata",
      "year": "2025",
      "month": "Dec",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "41473198",
      "doi": "10.3389/fnut.2025.1698147",
      "title": "Can artificial intelligence uncover the bioactive peptides' benefits for human health and knowledge? A narrative review.",
      "abstract": "The intersection of Artificial Intelligence (AI) and food science has opened new frontiers in understanding the \"dark matter\" of food, the vast array of unidentified bioactive compounds that influence human health. This narrative review examines how AI, particularly machine learning and deep learning, is revolutionizing the discovery, characterization, and application of bioactive peptides and amino acids derived from food sources, both plant- and animal-based. These compounds exhibit diverse health benefits, including antioxidant, anti-inflammatory, antihypertensive, and antimicrobial properties, yet their complexity and the limitations of traditional methods have hindered comprehensive study. AI-driven approaches, such as predictive modeling, molecular dynamics simulations, and natural language processing, are accelerating the identification of bioactive peptides, optimizing extraction processes, and enabling personalized nutrition strategies. The integration of AI with omics technologies (e.g., nutrigenomics, proteomics) further enhances our understanding of how these peptides modulate physiological pathways. However, this is not without challenges and limitations, such as data quality, model interpretability, and persistent gaps in interdisciplinary collaboration. Additionally, the review highlights the lack of standardized databases and concerns about the use of AI, including the need for ethical approvals and protocols aligned with privacy laws, particularly in the context of personalized nutrition guidance. This review synthesizes current advancements, identifies research gaps, and underscores the transformative potential of AI in functional food development and precision nutrition. By addressing these challenges, AI can unlock the full therapeutic potential of food-derived bioactive compounds, providing innovative solutions to global health challenges such as non-communicable diseases. The findings advocate for robust interdisciplinary efforts to bridge computational and nutritional sciences, paving the way for scalable, evidence-based applications in health and wellness.",
      "authors": "Al Shareef Rolan; Fathelrahman Eihab; Osman Raeda; Gebiso Tamrat; Platat Carine",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in nutrition",
      "source": "pubmed"
    },
    {
      "pmid": "41472882",
      "doi": "10.1093/nargab/lqaf174",
      "title": "Integrating natural language processing and genome analysis enables accurate bacterial phenotype prediction.",
      "abstract": "Understanding microbial phenotypes from genomic data is crucial for studying co-evolution, ecology, and pathology. This study presents a scalable approach that integrates literature-extracted information with genomic data, combining natural language processing and functional genome analysis. We applied this method to publicly available data, providing novel insights into predicting microbial phenotypes. We fine-tuned transformer-based language models to analyze 3.83 million open-access scientific articles, extracting a phenotypic network of bacterial strains. This network maps relationships between strains and traits such as pathogenicity, metabolism, and biome preference. By annotating their reference genomes, we predicted key genes influencing these traits. Our findings align with known phenotypes, reveal novel correlations, and uncover genes involved in disease and host associations. The network's interconnectivity provides deeper understanding of microbial communities and allowed identification of hub species through inferred trophic connections that are difficult to infer experimentally. This work demonstrates the potential of machine learning for uncovering cross-species gene-phenotype patterns. As microbial genomic data and literature expand, such methods will be essential for extracting meaningful insights and advancing microbiology research. In summary, this integrative approach can accelerate discovery and understanding in microbial genomics. Ultimately, such techniques will facilitate the study of microbial ecology, co-evolutionary processes, and disease pathogenesis to an unprecedented depth.",
      "authors": "Gómez-Pérez Daniel; Keller Alexander",
      "year": "2025",
      "month": "Dec",
      "journal": "NAR genomics and bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41466129",
      "doi": "10.1038/s41746-025-02282-x",
      "title": "Interpretable multimodal deep learning improves postoperative risk stratification in intrahepatic cholangiocarcinoma in multicentre cohorts.",
      "abstract": "Surgical resection is the primary curative treatment for intrahepatic cholangiocarcinoma (ICC), yet high postoperative recurrence rates pose a significant challenge. We developed an interpretable, transformer-based deep-learning pipeline that integrates multimodal data-including clinical variables, radiomic features, and whole-slide pathology images-by fusing a pre-trained encoder with a transformer network. To biologically validate our model, we leveraged spatial transcriptomics and proteomics to decipher the attention mechanisms underlying its predictions. It demonstrated robust performance in predicting 2-year overall survival, with area under the curve (AUC) values of 0.952 (95% CI: 0.909-0.983), 0.924 (95% CI: 0.804-1.000), and 0.924 (95% CI: 0.828-0.993) in three independent validation cohorts. Interrogation via spatial multi-omics revealed that the model's attention was preferentially focused on regions histologically and molecularly associated with tumor invasion and aggressive behavior. We present a novel, interpretable multimodal deep-learning framework that achieves superior postoperative risk stratification for ICC patients.",
      "authors": "Wan Mingyu; Ding Yongfeng; Wang Yanli; Jia Yunlu; Wu Siqi; Qu Wenxin; Xu Yifan; Fu Wenguang; Timko Michael P; Wan Ledong; Ying Le; Ye Chanqi; Chen Ruyin; Li Qiong; He Yuqing; Xu Keyi; Xu Nong; Chen Jinzhang; Zheng Dayong; Shen Yifei; Ruan Jian",
      "year": "2025",
      "month": "Dec",
      "journal": "NPJ digital medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41465283",
      "doi": "10.3390/ijms262411854",
      "title": "Application of Artificial Intelligence Technology in Plant MicroRNA Research: Progress, Challenges, and Prospects.",
      "abstract": "Plant microRNAs (miRNAs) are endogenous non-coding RNAs (~20-24 nucleotides) that regulate gene expression post-transcriptionally, playing critical roles in plant growth, development, and stress responses. This review systematically examines AI applications in plant miRNA research, tracing evolution from traditional machine learning to deep learning architectures. Plant miRNAs exhibit distinctive features necessitating plant-specific computational approaches: nuclear-localized biogenesis, high target complementarity (>80%), and coding region targeting. These characteristics enable more accurate computational prediction and experimental validation than animal systems. Methodological advances have improved prediction accuracy from ~90% (early SVMs) to >99% (recent deep learning), though metrics reflect different evaluation contexts. We analyze applications across miRNA identification, target prediction with degradome validation, miRNA-lncRNA interactions, and ceRNA networks. Critical assessment reveals that degradome data capture mixed RNA fragments from multiple sources beyond miRNA cleavage, requiring stringent multi-evidence validation. Similarly, fundamental ambiguities in lncRNA definition compound prediction uncertainties. Major challenges include severe data imbalance (positive to negative ratios of 1:100 to 1:10,000), limited cross-species generalization, insufficient model interpretability, and experimental validation bottlenecks. Approximately 75% of plant miRNA families in miRBase v20 lack convincing evidence, underscoring the need for rigorous annotation standards. Future directions encompass multimodal deep learning, explainable AI, spatiotemporal graph neural networks, and ultimately AI-driven de novo miRNA design, though the latter requires substantial advances in both computation and high-throughput validation. This synthesis demonstrates that AI has become indispensable for plant miRNA research, providing essential support for crop improvement while acknowledging persistent challenges demanding continued innovation.",
      "authors": "Yang Ruilin; Zhang Hanma",
      "year": "2025",
      "month": "Dec",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "41465115",
      "doi": "10.3390/genes16121439",
      "title": "What Do Single-Cell Models Already Know About Perturbations?",
      "abstract": "",
      "authors": "Bjerregaard Andreas; Prada-Luengo Iñigo; Das Vivek; Krogh Anders",
      "year": "2025",
      "month": "Dec",
      "journal": "Genes",
      "source": "pubmed"
    },
    {
      "pmid": "41458885",
      "doi": "10.1093/geroni/igaf102",
      "title": "A novel computational analysis integrating social determinants information from EHR and literature with Alzheimer's disease biological knowledge through large language models and knowledge graphs.",
      "abstract": "Alzheimer's disease (AD) and AD-related dementias (ADRD) are expected to affect over 100 million people by 2050, placing a significant strain on public health systems. Social determinants of health (SDoH), which include factors such as socioeconomic conditions and environment, play a crucial role in AD risk. Despite growing evidence, the understanding of SDoH's impact on AD remains limited. This study leverages large language models and knowledge graphs (KGs) to extract AD-related SDoH knowledge from literature and electronic health records (EHR). We integrate this knowledge into biological research on AD through KG construction and graph deep learning, performing KG-link predictions validated by multimodal biological data from single-cell RNA-seq and proteomics. We generated an SDoH knowledge graph with around 92k triplets, integrating literature and EHR data. In various link prediction experiments, we observed higher accuracy when integrating SDoH into knowledge graphs. Additionally, exploratory predictions uncovered potential SDoH-gene interactions, many of which were validated through differential expression analysis using proteomics and RNA-seq data. This novel KG-based analysis enhances link prediction in AD-related biomedical networks by integrating SDoH and biological knowledge. Our findings highlight the potential interaction between social determinants and biological factors in AD, offering insights into more personalized and socially aware healthcare interventions.",
      "authors": "Shang Tianqi; Yang Shu; Zhai Tianhua; He Weiqing; Mamourian Elizabeth; Zhang Jiayu; Hou Bojian; Lee Joseph; Duong-Tran Duy; Moore Jason H; Ritchie Marylyn D; Shen Li",
      "year": "2025",
      "month": "Dec",
      "journal": "Innovation in aging",
      "source": "pubmed"
    },
    {
      "pmid": "41455823",
      "doi": "10.1038/s41746-025-02257-y",
      "title": "Multimodal deep learning for cancer prognosis prediction with clinical information prompts integration.",
      "abstract": "Survival prediction is crucial for guiding cancer treatment and evaluating therapeutic efficacy. However, tumor heterogeneity presents challenges of accurate prognosis. Multimodal learning, which integrates data from imaging, genomics, and clinical records, offers a promising approach for this complex task. While recent studies mainly focus on imaging and genomic data, clinical information, which reflecting patients' overall health, remains underutilized due to its discrete, sparse, and low-dimensional characteristics. We propose SurvPGC, an integrated model combining pathology images, genomic data and clinical records for cancer prognosis. Clinical information is transformed into high-dimensional vectors using text templates and foundation models, enabling their integration through a cross-attention module. Validation on three datasets of The Cancer Genome Atlas demonstrated that the model effectively captures modality-specific features, with attention visualization revealing distinct focus areas across data types. This highlights the importance of incorporating diverse information sources for improved survival prediction.",
      "authors": "Hou Jiaxin; Zhang Ranran; Xie Yaoqin; Li Chao; Qin Wenjian",
      "year": "2025",
      "month": "Dec",
      "journal": "NPJ digital medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41454831",
      "doi": "10.1093/bib/bbaf686",
      "title": "Proformer: a multimodal proteomics transformer model for multidisease early risk assessment.",
      "abstract": "Early identification of individuals at high risk for chronic diseases is crucial for prevention and intervention, yet current risk assessment tools are disease-specific, require extensive clinical data collection, and cannot provide multidisease risk profiles from a single measurement. Several protein large language models have been developed for tasks such as protein structure prediction, function prediction, and sequence design. However, none of these models can be directly applied in clinical settings to predict an individual's future disease risk. Here, we present a multimodal proteomics Transformer (Proformer) model that integrates protein expression, sequence, and function information for multidisease risk assessment. We trained Proformer using real proteomics data from 47 124 individuals from the UK Biobank to evaluate its performance in discriminating the risk of 20 common chronic diseases. Proformer achieved state-of-the-art (SOTA) performance in all 20 diseases compared with five common machine learning and deep learning models. Compared to three common clinical predictors, Proformer's 10-year discriminative performance outperforms Age + Sex model for 19 diseases, outperforms the ASCVD risk score for 16 diseases, and outperforms the panel composed of 35 clinical variables for 11 diseases. These results were replicated in the Scotland and Wales cohort from UK Biobank. In conclusion, Proformer enabled users to directly obtain a 10-year risk report for common chronic diseases by inputting their individual proteomics data.",
      "authors": "Qiu Shizheng; Hu Yang; Liu Jingjing; Wang Yadong",
      "year": "2025",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41452988",
      "doi": "10.1073/pnas.2525268122",
      "title": "Predicting the unseen: A diffusion-based debiasing framework for transcriptional response prediction at single-cell resolution.",
      "abstract": "Predicting cellular responses to genetic perturbations is critical for advancing our understanding of gene regulation. While single-cell CRISPR perturbation assays such as Perturb-seq provide direct measurements of gene function, the scale of these experiments is limited by cost and feasibility. This motivates the development of computational approaches that can accurately infer responses to unmeasured perturbations from related experimental data. We introduce dbDiffusion, a generative framework that integrates diffusion models with classifier-free guidance derived from perturbation information, operating in latent space through a variational autoencoder. Diffusion models are probabilistic generative models that approximate data distributions by reversing a Markovian diffusion process, progressively denoising Gaussian noise into structured outputs. By exploiting biological similarities in gene expression profiles and relationships among perturbations, dbDiffusion enables the conditional generation of gene expressions for previously unobserved perturbations. In contrast to competing approaches, dbDiffusion does not rely on Large Language Model or foundation models, which have been found to yield unsatisfactory results. Rather, it leverages embeddings derived from measured perturbations to generalize to unseen perturbations, effectively transferring information across related experimental conditions. In benchmarking against state-of-the-art methods on Perturb-seq datasets, dbDiffusion demonstrates superior accuracy in predicting perturbation responses. A methodological innovation of dbDiffusion is the integration of prediction-powered inference, which corrects for biases inherent in generative models and enables statistically rigorous downstream tasks, including the identification of differentially expressed genes. By combining deep generative modeling with principled inference, dbDiffusion establishes a scalable computational framework for predicting and analyzing transcriptomic perturbation responses, significantly extending the utility of Perturb-seq experiments.",
      "authors": "Shang Ergan; Wei Yuting; Roeder Kathryn",
      "year": "2025",
      "month": "Dec",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "source": "pubmed"
    },
    {
      "pmid": "41451540",
      "doi": "10.1093/bib/bbaf693",
      "title": "CELLetter: leveraging large language model and dual-stream network to identify context-specific ligand-receptor interactions for cell-cell communication analysis.",
      "abstract": "Cell-to-cell communication (CCC) facilitates the coordination of various cellular behaviors in multicellular organisms. Many computational methods neglect downstream intracellular signaling and are limited by static and predefined ligand-receptor (L-R) databases. To address these limitations, we present CELLetter, a deep learning framework to identify potential L-R interactions through a novel feature learning model and decipher cellular signaling by integrating L-R co-expression with downstream transcription factor (TF) activity inferred from gene regulatory network. CELLetter begins by leveraging the protein large language model, ProstT5, for feature embedding. It then employs a dual-stream architecture for feature extraction and dimensionality reduction, a gate mechanism with dynamic weight adjustment for feature fusion, absolute difference, and element-wise product for feature interaction. After that, CELLetter combines interacting L-R pairs, single-cell RNA sequencing (scRNA-seq) data, and downstream TF activity to quantify communication strength. We comprehensively evaluated CELLetter using 11 evaluation metrics, benchmarking it against 4 state-of-the-art L-R classification models, 6 L-R validation tools, 10 CCC inference methods. CELLetter demonstrated superior L-R classification performance. Notably, we introduced a novel multi-faceted validation strategy employing colocalization distance, co-expression ratio, and co-detection probability on spatial transcriptomics data from human heart and distal lung epithelial tissues. CELLetter's predicted L-R pairs exhibited significant spatial relevance compared with other baselines. When applied to human head and neck squamous cell carcinoma (HNSCC) data, CELLetter produced CCC inferences broadly consistent with established methods. More importantly, ligand macrophage migration inhibitory factor (MIF) and receptor CD44 were predicted as a central signaling axis within HNSCC tumor microenvironment, suggesting their potentials as therapeutic targets . CELLetter is freely available at https://github.com/plhhnu/CELLetter.",
      "authors": "Wu Wei; Huang Junfeng; Jiang Yan; Nie Libo; Peng Lihong",
      "year": "2025",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41446223",
      "doi": "10.64898/2025.12.15.694538",
      "title": "A Multi-Modal Transfer Learning Framework to Reduce Health Disparities in Prostate Adenocarcinoma.",
      "abstract": "Prostate cancer is the second most common cancer in men across the United States, of which prostate adenocarcinoma (PRAD) is the most common subtype. Despite remarkable progress has been made in PRAD diagnosis and prognosis, Black American men have been found to have disproportionately high incidence and mortality rate in PRAD compared with non-Hispanic White men in the United States. While machine learning (ML) methods like transfer learning (TL) have shown promise in reducing racial disparities in PRAD, its effectiveness is often compromised by the requirement for large-scale training datasets, which are challenging to obtain in clinical settings. In addition, existing ML approaches only leverage single-omics data without integrating multi-omics information. To address these concerns, we propose a novel approach called ",
      "authors": "Li Lusheng; Wang Jieqiong; Wan Shibiao",
      "year": "2025",
      "month": "Dec",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41445817",
      "doi": "",
      "title": "From Classical Machine Learning to Emerging Foundation Models: Review on Multimodal Data Integration for Cancer Research.",
      "abstract": "Cancer research is increasingly driven by the integration of diverse data modalities, spanning from genomics and proteomics to imaging and clinical factors. However, extracting actionable insights from these vast and heterogeneous datasets remains a key challenge. The rise of foundation models (FMs) -- large deep-learning models pretrained on extensive amounts of data serving as a backbone for a wide range of downstream tasks -- offers new avenues for discovering biomarkers, improving diagnosis, and personalizing treatment. This paper presents a comprehensive review of widely adopted integration strategies of multimodal data to assist advance the computational approaches for data-driven discoveries in oncology. We examine emerging trends in machine learning (ML) and deep learning (DL), including methodological frameworks, validation protocols, and open-source resources targeting cancer subtype classification, biomarker discovery, treatment guidance, and outcome prediction. This study also comprehensively covers the shift from traditional ML to FMs for multimodal integration. We present a holistic view of recent FMs advancements and challenges faced during the integration of multi-omics with advanced imaging data. We identify the state-of-the-art FMs, publicly available multi-modal repositories, and advanced tools and methods for data integration. We argue that current state-of-the-art integrative methods provide the essential groundwork for developing the next generation of large-scale, pre-trained models poised to further revolutionize oncology. To the best of our knowledge, this is the first review to systematically map the transition from conventional ML to advanced FM for multimodal data integration in oncology, while also framing these developments as foundational for the forthcoming era of large-scale AI models in cancer research.",
      "authors": "Muneer Amgad; Waqas Muhammad; Saad Maliazurina B; Showkatian Eman; Bandyopadhyay Rukhmini; Xu Hui; Li Wentao; Chang Joe Y; Liao Zhongxing; Haymaker Cara; Soto Luisa Solis; Wu Carol C; Vokes Natalie I; Le Xiuning; Byers Lauren A; Gibbons Don L; Heymach John V; Zhang Jianjun; Wu Jia",
      "year": "2025",
      "month": "Dec",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "41440336",
      "doi": "10.3390/dj13120578",
      "title": "Deep Learning Analysis of CBCT Images for Periodontal Disease: Phenotype-Level Concordance with Independent Transcriptomic and Microbiome Datasets.",
      "abstract": "Periodontitis is a common inflammatory disease characterized by progressive loss of alveolar bone. Cone-beam computed tomography (CBCT) can visualize 3D periodontal bone defects, but its interpretation is time-consuming and examiner-dependent. Deep learning may support standardized CBCT assessment if performance and biological relevance are adequately characterized. We used the publicly available MMDental dataset (403 CBCT volumes from 403 patients) to train a 3D ResNet-18 classifier for binary discrimination between periodontitis and healthy status based on volumetric CBCT scans. Volumes were split by subject into training (n = 282), validation (n = 60), and test (n = 61) sets. Model performance was evaluated using area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), and calibration metrics with 95% bootstrap confidence intervals. Grad-CAM saliency maps were used to visualize the anatomical regions driving predictions. To explore phenotype-level biological concordance, we analyzed an independent gingival transcriptomic cohort (GSE10334, n ≈ 220 arrays after quality control) and an independent oral microbiome cohort based on 16S rRNA amplicon sequencing, using unsupervised clustering, differential expression/abundance testing, and pathway-level summaries. On the held-out CBCT test set, the model achieved an AUROC of 0.729 (95% CI: 0.599-0.850) and an AUPRC of 0.551 (95% CI: 0.404-0.727). At a high-sensitivity operating point (sensitivity 0.95), specificity was 0.48, yielding an overall accuracy of 0.62. Grad-CAM maps consistently highlighted the alveolar crest and furcation regions in periodontitis cases, in line with expected patterns of bone loss. In the transcriptomic cohort, inferred periodontitis samples showed up-regulation of inflammatory and osteoclast-differentiation pathways and down-regulation of extracellular-matrix and mitochondrial programs. In the microbiome cohort, disease-associated samples displayed a dysbiotic shift with enrichment of classic periodontal pathogens and depletion of health-associated commensals. These omics patterns are consistent with an inflammatory-osteolytic phenotype that conceptually aligns with the CBCT-defined disease class. This study presents a proof-of-concept 3D deep learning model for CBCT-based periodontal disease classification that achieves moderate discriminative performance and anatomically plausible saliency patterns. Independent transcriptomic and microbiome analyses support phenotype-level biological concordance with the imaging-defined disease class, but do not constitute subject-level multimodal validation. Given the modest specificity, single-center imaging source, and inferred labels in the omics cohorts, our findings should be interpreted as exploratory and hypothesis-generating. Larger, multi-center CBCT datasets and prospectively collected paired imaging-omics cohorts are needed before clinical implementation can be considered.",
      "authors": "Burlea Ștefan Lucian; Buzea Călin Gheorghe; Nedeff Florin; Mirilă Diana; Nedeff Valentin; Agop Maricel; Ochiuz Lăcrămioara; Armencia Adina Oana",
      "year": "2025",
      "month": "Dec",
      "journal": "Dentistry journal",
      "source": "pubmed"
    },
    {
      "pmid": "41438031",
      "doi": "10.1016/j.isci.2025.114082",
      "title": "Artificial intelligence in multidisciplinary tumor boards enhancing decision making and clinical outcomes in oncology.",
      "abstract": "Multidisciplinary tumor boards (MDTs) coordinate complex oncology decisions across imaging, pathology, genomics, and patient factors. Here we synthesize how artificial intelligence (AI)-including machine learning, natural language processing, deep learning, and large language models-supports MDT preparation and deliberation. Across cancers, reported agreement between AI recommendations and MDT decisions commonly ranges from 70% to 90%, and task-focused tools achieve high diagnostic performance in screening and staging. Benefits include faster information synthesis, more consistent guideline alignment, and clearer documentation of options, while human review remains central. Key limitations-data bias, uneven generalizability, privacy and governance concerns, and limited prospective validation-temper adoption. We outline implementation priorities: prospective multicenter evaluation, integration with electronic records, clinician training, and transparent oversight. Overall, AI can augment MDT decision-making and help personalize care and workflow efficiency when deployed with rigorous evaluation and safeguards.",
      "authors": "Wang Xiaodong; Wang Qianqian; Ding Gouping; Wang Junjie; Tang Yixuan; Feng Yeqian",
      "year": "2025",
      "month": "Dec",
      "journal": "iScience",
      "source": "pubmed"
    },
    {
      "pmid": "41417905",
      "doi": "10.1126/sciadv.aea6007",
      "title": "Advances in machine learning-enhanced microfluidic cell sorting.",
      "abstract": "Cell sorting, essential for diagnostics and early intervention, has evolved from conventional methods to sophisticated microfluidic approaches. These miniaturized systems leverage precise hydrodynamic control, facilitating major advances in tumor cell isolation, single-cell analysis, and biomarker detection. However, the vast imaging data generated by these microfluidic techniques necessitate advanced computational methods. Machine learning, particularly computer vision and deep learning, now offers transformative capabilities for automated feature extraction, pattern recognition, and real-time classification, enhancing sorting accuracy, accelerating diagnostics, and informing clinical decisions. This review synthesizes the convergence of microfluidics and machine intelligence, examining their synergistic roles in flow-field optimization, cellular classification, and error correction. While highlighting breakthroughs in diagnostic sensitivity and analytical throughput, we critically address challenges including model generalizability and hardware-software integration. Last, we provide an outlook on multimodal data fusion and the development of on-chip intelligent systems, proposing a roadmap for advancing precision medicine through embedded, adaptive biosensing platforms.",
      "authors": "Li Haodong; Bai Jie; Ma Xiaxian; Li Linwei; Liu Yuanchao; Liu Xiaoyan; Shen Shaofei; Lim ChweeTeck",
      "year": "2025",
      "month": "Dec",
      "journal": "Science advances",
      "source": "pubmed"
    },
    {
      "pmid": "41415434",
      "doi": "10.64898/2025.12.11.693669",
      "title": "Query-driven generative AI synthesizes multi-modal spatial omics from histology.",
      "abstract": "Spatial omics technologies offer unprecedented insights into the cellular organization of tissues; however, they are not yet scalable for routine clinical use. In contrast, images of histological staining remain the foundation of pathological diagnosis despite lacking molecular information. Bridging this gap requires computational methods that can accurately infer spatial molecular data from histology alone. Here, we introduce TissueCraftAI, a generative artificial intelligence framework that predicts multi-modal spatial omics maps directly from standard histology images using natural language prompts. To train and validate our model, we created PRISM-12M, a large-scale dataset comprising over twelve million spatially registered histology and spatial omics image patches across fourteen tissue types from humans and mice. TissueCraftAI significantly outperforms existing methods in generating realistic histology images and predicting spatial proteomics and transcriptomics data with high fidelity. We demonstrated its utility in various downstream applications, including improving cell type annotation and enhancing the accuracy of patient survival predictions across multiple cancer types. By enabling flexible, query-driven ",
      "authors": "Pang Minxing; Roy Tarun Kanti; Wu Xiaodong; Tan Kai",
      "year": "2025",
      "month": "Dec",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41408105",
      "doi": "10.1038/s41746-025-02144-6",
      "title": "A Representation Fusion Framework for Decoupling Diagnostic Information in Multimodal Learning.",
      "abstract": "Modern medicine increasingly relies on multimodal data, ranging from clinical notes to imaging and genomics, to guide diagnosis and treatment. However, integrating these heterogeneous data sources in a principled and interpretable manner remains a major challenge. We present MODES (Multi-mOdal Disentangled Embedding Space), a representation fusion framework that explicitly separates shared and modality-specific factors of variation, offering a structured latent space for multimodal information that improves both prediction and interpretability. By leveraging pre-trained unimodal foundation models, MODES mitigates the dependency on extensive paired datasets, crucial in data-scarce clinical settings. We introduce a masking strategy that optimizes representation dimensionality by eliminating low-information dimensions, to achieve compact, information-rich representations. Our framework demonstrates superior performance in predicting diagnoses and phenotypes compared to unimodal and conventional fusion models. MODES also enables robust diagnostic inference in missing data scenarios, offering an opportunity toward interpretable and efficient multimodal diagnostics in personalized healthcare.",
      "authors": "Tonekaboni Sana; Friedman Sam Freesun; Zhang Xinyi; Maddah Mahnaz; Uhler Caroline",
      "year": "2025",
      "month": "Dec",
      "journal": "NPJ digital medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41400327",
      "doi": "10.1097/CM9.0000000000003922",
      "title": "Development, advancement, and clinical integration of artificial intelligence technology in gastric cancer.",
      "abstract": "Personalized medicine for gastric cancer continues to face numerous challenges, primarily due to the complexity of clinical decision making and the difficulty of integrating multimodal data. Artificial intelligence (AI), with its powerful capabilities in feature learning and pattern recognition, is emerging as a key technology to overcome these barriers. It provides critical support in areas such as early screening, histological subtyping, prediction of treatment response, and prognostic risk stratification. This review examines the application of AI in diagnosing and treating gastric cancer, with particular attention to the current mainstream AI methodologies, including feature engineering and deep learning and the rapidly evolving pretrained foundation models and multimodal large models. With the integration of medical images, digital pathology, multiomics data, and structured clinical information, AI systems are increasingly effective at capturing tumor heterogeneity and supporting complex clinical decisions in real time. On the one hand, task-specific models have demonstrated excellent performance in subtyping, staging, and prognosis assessment. On the other hand, the rise of foundation models and general-purpose large models is redefining the limits of AI in cross-task transfer, complex reasoning, and human-machine interaction. These technologies hold promise in addressing key obstacles such as data scarcity, modality heterogeneity, and fragmented clinical workflows, offering a feasible path toward a unified and efficient AI-driven diagnostic and therapeutic system for gastric cancer. As technological maturity progresses alongside the development of robust safety and ethical frameworks, AI is expected to evolve from a static auxiliary interpretation tool into an intelligent decision-making platform capable of semantic understanding, dynamic feedback, and multidisciplinary collaboration-therefore playing a pivotal role across the full spectrum of precision medicine in gastric cancer.",
      "authors": "Fu Jia; Fang Mengjie; Wu Ling; Li Xiaodong; De Cobelli Francesco; Palumbo Diego; Xie Xuebin; Feng Xin; Zhang Xu-Yao; Zhang Jingliang; Zheng Zhuozhao; Dong Di",
      "year": "2025",
      "month": "Nov",
      "journal": "Chinese medical journal",
      "source": "pubmed"
    },
    {
      "pmid": "41394628",
      "doi": "10.1101/2025.11.24.690325",
      "title": "TissueNarrator: Generative Modeling of Spatial Transcriptomics with Large Language Models.",
      "abstract": "The intricate spatial organization and molecular communication among cells are fundamental to multicellular systems. Spatial transcriptomics (ST) enables gene expression profiling while preserving spatial context, providing rich data for studying cellular interactions and tissue dynamics. However, most existing computational approaches focus on embedding-based tasks and provide limited generative capacity for simulating cell behavior ",
      "authors": "Liu Sizhe; Tang Junjie; Ma Jian; Liang Shaoheng",
      "year": "2025",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41387679",
      "doi": "10.1038/s41467-025-66220-x",
      "title": "A multimodal knowledge-enhanced whole-slide pathology foundation model.",
      "abstract": "Computational pathology has advanced through foundation models, yet faces challenges in multimodal integration and capturing whole-slide context. Current approaches typically utilize either vision-only or image-caption data, overlooking distinct insights from pathology reports and gene expression profiles. Additionally, most models focus on patch-level analysis, failing to capture comprehensive whole-slide patterns. Here we present mSTAR (Multimodal Self-TAught PRetraining), the pathology foundation model that incorporates three modalities: pathology slides, expert-created reports, and gene expression data, within a unified framework. Our dataset includes 26,169 slide-level modality pairs across 32 cancer types, comprising over 116 million patch images. This approach injects multimodal whole-slide context into patch representations, expanding modeling from single to multiple modalities and from patch-level to slide-level analysis. Across oncological benchmark spanning 97 tasks, mSTAR outperforms previous state-of-the-art models, particularly in molecular prediction and multimodal tasks, revealing that multimodal integration yields greater improvements than simply expanding vision-only datasets.",
      "authors": "Xu Yingxue; Wang Yihui; Zhou Fengtao; Ma Jiabo; Jin Cheng; Yang Shu; Li Jinbang; Zhang Zhengyu; Zhao Chenglong; Zhou Huajun; Li Zhenhui; Lin Huangjing; Wang Xin; Wang Jiguang; Han Anjia; Chan Ronald Cheong Kin; Liang Li; Zhang Xiuming; Chen Hao",
      "year": "2025",
      "month": "Dec",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "41387122",
      "doi": "10.1002/advs.202518949",
      "title": "Artificial Intelligence Revolution in Transcriptomics: From Single Cells to Spatial Atlases.",
      "abstract": "Single-cell RNA sequencing (scRNA-seq) and spatial transcriptomics (ST) have revolutionized the study of cellular heterogeneity and tissue organization. However, the increasing scale and complexity of these data demand more powerful and integrative computational strategies. Although conventional statistical and machine learning methods remain effective in specific contexts, they face limitations in scalability, multimodal integration, and generalization. In response, artificial intelligence (AI) has emerged as a transformative force, enabling new modes of analysis and interpretation. In this review, we survey AI applications across the transcriptomic analysis workflow-from initial preprocessing through key downstream analyses such as trajectory inference, gene regulatory network reconstruction, and spatial domain detection. For each analytical task, we trace the developmental trajectory and evolving trends of AI models, summarize their advantages, limitations, and domain-specific applicability. We also highlight key innovations, ongoing challenges, and future directions. Furthermore, this review provides practical guidance to assist researchers in model selection and support developers in the design of novel AI tools. An online companion supplement providing an in-depth look at all methods discussed: https://zhanglab-kiz.github.io/review-ai-transcriptomics.",
      "authors": "Li Shixin; Xiao Tianxiang; Lan Yuanyuan; Wu Chengxiao; Li Zhouying; Liu Rong; Fang Qing; Zhang Chao",
      "year": "2026",
      "month": "Jan",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "41386265",
      "doi": "10.1093/bioinformatics/btaf653",
      "title": "Benchmarking large language models for identifying transcription factor regulatory interactions.",
      "abstract": "Transcription factors (TFs) and their target genes form regulatory networks that control gene expression and influence diverse biological processes and disease outcomes. Although multiple computational methods and curated databases have been developed to identify TF-target interactions, they often require specialized expertise. Large language models (LLMs) chatbots offer a more accessible alternative for querying TF-target interactions. In this study, we benchmarked four prominent LLMs, Anthropic's Claude 3.5 Sonnet, Google's Gemini 1.0 Pro, OpenAI's GPT-4o, and Meta's Llama3 8b, using 8432 literature-curated human TF-target interactions. We examined four regulatory categories: bidirectional, ambiguous, self-regulated, and unidirectional interactions. Under single-turn queries, Claude 3.5 Sonnet and GPT-4o outperformed the others, with balanced accuracies reaching 50.0 ± 7.6% (GPT-4o, self-regulated) and 48.2 ± 1.0% (Claude 3.5 Sonnet, unidirectional). Zero-temperature settings generally enhanced reproducibility, and multi-turn prompting improved performance for most models, increasing Claude 3.5 Sonnet's accuracy on self-regulated pairs by 32.6%. Excluding TF-target pairs with all unknown regulation types also generally improved accuracy, with unidirectional regulation reaching near 70% balanced accuracy in some cases. We also benchmarked Anthropic's Claude 3.5 Sonnet, Google's Gemini 2.0 Flash, OpenAI's GPT-4o, and Meta's Llama3 using 5148 experimentally derived TF-target interactions. Claude 3.5 Sonnet consistently outperformed the other models across conditions. Our findings highlight that prompt engineering and strategic use of model parameters consistently influence LLM chatbots' performance on TF-target identifications. This study establishes a benchmarking framework and demonstrates the potential of pre-trained general-purpose LLMs to support regulatory biology research, especially for researchers without extensive computational expertise. The literature-based TF-target interactions ground truth were obtained from TRRUST v2 human dataset (www.grnpedia.org/trrust). The experimental derived TF-target interactions ground truth were obtained from TFLink Home Sapiens small-scale interaction table (https://tflink.net/). Processed TF-target interactions data and the analytical pipeline has been compiled as an interactive Python notebook file and is available at https://github.com/pengpclab/LLM-TF-interactions.",
      "authors": "Noel Lake; Hsiao Yi-Wen; He Yimeng; Hung Andrew; Cui Xiaojiang; Ray Edward; Moore Jason H; Peng Pei-Chen; Huang Xiuzhen",
      "year": "2026",
      "month": "Jan",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "41381900",
      "doi": "10.1038/s41746-025-02198-6",
      "title": "AI-driven virtual cell models in preclinical research: technical pathways, validation mechanisms, and clinical translation potential.",
      "abstract": "AI-driven virtual cell models show the potential to transform the paradigm of life sciences research by integrating multimodal omics data (e.g., single-cell transcriptomics and proteomics) with advanced algorithms such as deep generative models and graph neural networks to enable high-precision predictions of drug responses, gene perturbations, and disease progression. These models enable high-precision predictions of drug responses, gene perturbations, and disease progression. This review outlines the technical pathways and validation mechanisms of virtual cells, emphasizing a closed-loop workflow from computational evaluation to experimental verification using CRISPR assays and organoid platforms. The applications of virtual cells in personalized drug screening and disease modeling are highlighted, showcasing their potential to reduce animal testing and optimize therapy. However, challenges in regulatory acceptance, data privacy, and model interpretability remain. Global policy and standardization trends are driving clinical translation, and future advancements will involve cross-disciplinary integration and greater standardization to enhance the impact of virtual cells in precision medicine and drug discovery.",
      "authors": "Ma Chunyu; Zhang Han; Rao Yiwei; Jiang Xinyu; Liu Boheng; Sun Zhikang; Song Zhenyu; Gao Yuan; Cui Yuhao; Liu Xinyu; Li Zedong",
      "year": "2025",
      "month": "Dec",
      "journal": "NPJ digital medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41377492",
      "doi": "10.1101/2025.11.27.690951",
      "title": "GPTAnno: Ontology-tree-guided hierarchical cell type annotation based on GPT models for single-cell data.",
      "abstract": "Cell type annotation is critical for interpreting single-cell transcriptomic data but remains challenging due to uncertain cellular clustering granularity and inconsistent labeling across studies. Here we present GPTAnno, an automated, ontology-tree-guided, uncertainty-aware, hierarchical cell type annotation method based on GPT models. GPTAnno directly handles gene expression matrices, integrates multi-resolution clustering with large language model reasoning constrained by the cell ontology to produce standardized, ontology-aware, and reproducible annotations with automatic resolution selection. GPTAnno selects optimal clustering resolutions based on the annotation distance on the ontology tree and quantifies annotation uncertainty to flag ambiguous clusters for expert review. Benchmarking across twelve large-scale datasets demonstrates GPTAnno's superior accuracy on annotating cell types across various species, tissues, and disease contexts against existing methods. Implemented in R and Python with Seurat and Scanpy compatibility, GPTAnno allows simple inputs to streamline the reproducible annotation, considerably reducing human efforts in repeated reclustering, assigning and examining the labels.",
      "authors": "Song Yiran; Tang Muyao; Liu Qi; Wang Haofei; Qian Li; Zou Fei; Hou Wenpin",
      "year": "2025",
      "month": "Dec",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41366150",
      "doi": "10.1038/s43588-025-00916-4",
      "title": "AUTOENCODIX: a generalized and versatile framework to train and evaluate autoencoders for biological representation learning and beyond.",
      "abstract": "In recent years, autoencoders, a family of deep learning-based methods for representation learning, are advancing data-driven research owing to their variability and nonlinear power for multimodal data integration. Despite their success, current implementations lack standardization, versatility, comparability and generalizability. Here we present AUTOENCODIX, an open-source framework, designed as a standardized and flexible pipeline for preprocessing, training and evaluation of autoencoder architectures. These architectures, such as ontology-based and cross-modal autoencoders, provide key advantages over traditional methods by offering explainability of embeddings or the ability to translate across data modalities. We apply the method to datasets from pan-cancer studies (The Cancer Genome Atlas) and single-cell sequencing as well as in combination with imaging. Our studies provide important user-centric insights and recommendations to navigate through architectures, hyperparameters and important tradeoffs in representation learning. These include the reconstruction capability of input data, the quality of embedding for downstream machine learning models and the reliability of ontology-based embeddings for explainability.",
      "authors": "Joas Maximilian Josef; Jurenaite Neringa; Praščević Dušan; Scherf Nico; Ewald Jan",
      "year": "2026",
      "month": "Jan",
      "journal": "Nature computational science",
      "source": "pubmed"
    },
    {
      "pmid": "41361444",
      "doi": "10.1186/s12967-025-07348-8",
      "title": "Multi-modal integration of histopathology and transcriptomics reveals STAB1",
      "abstract": "Colon adenocarcinoma (COAD) has a limited response to immunotherapy due to its immunologically “cold” tumor microenvironment (TME). Efferocytosis is an important process that regulates the TME, but its mechanism and clinical significance in COAD are unclear. We integrated histopathological images, transcriptomic profiles, and clinical data from 387 COAD patients. Image features were extracted using ResNet50 and CellProfiler, followed by construction of a multimodal machine learning model to evaluate prognostic risk. We further combined bulk RNA-seq, single-cell RNA-seq, and spatial transcriptomics to comprehensively characterize efferocytosis-associated immune cell subsets and signaling pathways. The efferocytosis-based risk model demonstrated strong prognostic performance across multiple time points and remained independent of conventional clinical indicators. Mechanistically, we identified a subset of STAB1 This study establishes a multimodal prognostic system that integrates histopathological imaging with molecular profiling, and for the first time reveals the pivotal role of STAB1 [Image: see text] The online version contains supplementary material available at 10.1186/s12967-025-07348-8.",
      "authors": "Chang Zhanhao; Zhong Chongli; Xu Shuo; Zhang Yuyang; Guo Xingqi; Yu Jielin; Xu Zitong; Han Shukun; Han Bing; Lv Chao; Tian Yu",
      "year": "2025",
      "month": "Dec",
      "journal": "Journal of translational medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41340634",
      "doi": "10.1016/j.jpi.2025.100524",
      "title": "Predicability of PD-L1 expression in cancer cells based solely on H&E-stained sections.",
      "abstract": "PD-L1 expression is an important biomarker for selecting patients who are eligible for immune checkpoint inhibitor (ICI) therapy. However, evaluating PD-L1 through immunohistochemistry often faces significant interobserver variability and requires considerable time and resources. Recent advancements in artificial intelligence (AI) have transformed the field of pathology, leading to more standardized and reproducible methods for biomarker quantification. In this study, we examine the application of AI-driven models, particularly deep learning algorithms, to predict PD-L1 expression directly from hematoxylin and eosin-stained histological slides. Several AI-based approaches have been studied, demonstrating high accuracy in estimating PD-L1 expression and predicting responses to ICIs across various cancer types. AI-driven assessments of PD-L1 have been shown to reduce the subjectivity associated with manual scoring methods, such as the Tumor Proportion Score and the Combined Positive Score. Moreover, integrating AI with multimodal data, including genomics, radiomics, and real-world clinical data, can further enhance predictive accuracy and improve patient stratification for immunotherapy. Finally, AI-driven computational pathology offers a transformative approach to biomarker evaluation, providing a faster, more objective, and cost-effective alternative to traditional methods, with significant implications for personalized oncology and precision medicine. Despite these promising results, several challenges remain to be addressed, such as the need for large-scale validation, standardization of AI models, and regulatory approvals for clinical implementation. Tackling these issues will be crucial for incorporating AI-based PD-L1 assessments into routine pathology workflows.",
      "authors": "Faa Gavino; Fraschini Matteo; Ziranu Pina; Pretta Andrea; Porcu Giuseppe; Saba Luca; Scartozzi Mario; Shokun Nazar; Rugge Massimo",
      "year": "2025",
      "month": "Nov",
      "journal": "Journal of pathology informatics",
      "source": "pubmed"
    },
    {
      "pmid": "41339875",
      "doi": "10.1186/s12935-025-04063-8",
      "title": "AI-based neoadjuvant immunotherapy response prediction across pan-cancer: a comprehensive review.",
      "abstract": "Neoadjuvant immunotherapy (NIT) has emerged as a transformative treatment strategy across various cancer types. However, due to the significant heterogeneity of tumors, patients exhibit highly variable responses to NIT, making the accurate preoperative identification of those who would benefit a pressing clinical challenge. In recent years, artificial intelligence (AI), particularly machine learning (ML) and deep learning (DL), has opened new pathways for predicting treatment response. AI-driven approaches have the ability to extract latent features from high-dimensional, multimodal oncological data, facilitating the construction of efficient predictive models that can optimize individualized treatment strategies. In this review, we systematically summarize existing AI-driven computational approaches for NIT response prediction, categorizing them into indirect and direct predictive paradigms. The indirect paradigm predicts clinically validated surrogate biomarkers to infer therapeutic response to NIT. In contrast, the direct paradigm leverages AI to analyze high-throughput data and establish data-driven biomarkers that directly predict clinical endpoints of NIT. Additionally, we categorize existing AI predictive models based on data modalities, spanning radiomics, pathomics, genomics, and multi-omics approaches, each providing distinct insights into tumor characteristics and treatment response. Despite notable progress, current predictive models still face significant challenges, which we broadly classify into biomarker-based and AI-based limitations. We further discuss potential strategies to address these challenges. This review systematically summarizes recent AI-based predictive models for NIT response across cancer types. By offering a structured analysis of current methodologies and challenges, we aim to guide future research and accelerate the integration of AI into precision immunotherapy.",
      "authors": "Deng Yishu; Li Tailin; Wang Yunze; Chen Silin; Tang Feilong; Zhu Taoyu; Ran Jiayi; Yang Bo; Zhang Xiaohan; Xu Ruijie; Ray Manas K; Zhang Yimin; Chen Shuifang; Liu Jian",
      "year": "2025",
      "month": "Dec",
      "journal": "Cancer cell international",
      "source": "pubmed"
    },
    {
      "pmid": "41332705",
      "doi": "10.1101/2025.11.20.689521",
      "title": "ARCADIA Reveals Spatially Dependent Transcriptional Programs through Integration of scRNA-seq and Spatial Proteomics.",
      "abstract": "Cellular states are strongly influenced by spatial context, but single-cell RNA sequencing (scRNA-seq) loses information about local tissue organization, while spatial proteomic assays capture limited marker panels that constrain transcriptomic inference. Integrating these modalities can elucidate how spatial niches shape transcriptional programs, yet existing approaches depend on either feature-level correspondence such as gene-protein linkage or cell-level barcode pairing, which is often unavailable. We present ARCADIA (ARchetype-based Clustering and Alignment with Dual Integrative Autoencoders), a generative framework for cross-modal integration that operates without cell barcode pairing and does not assume direct feature-to-feature correspondence. ARCADIA identifies modality-specific archetypes, i.e., convex combinations of cells representing extreme phenotypic states, and aligns these archetype anchors across modalities by minimizing the discrepancy between their cell-type composition profiles. The aligned archetypes define a shared coordinate system that anchors a pair of dual variational autoencoders (VAEs) trained with cross-modal geometric regularization, preserving archetype structure and spatial neighborhood information while enabling bidirectional translation between modalities. On a semi-synthetic benchmark derived from paired CITE-seq and synthetic spatial grids, ARCADIA accurately recapitulates cell-type correspondences and spatially dependent subpopulation structures, outperforming existing weak-linkage methods. Applied to independent human tonsil scRNA-seq and CODEX data, ARCADIA reconstructs known tissue architecture and reveals spatially dependent transcriptional programs linking B-cell maturation and T-cell activation or exhaustion to their microenvironmental niches. All data analyzed in this work have been previously published and are available in the original studies. ARCADIA is publicly accessible at https://github.com/azizilab/ARCADIA_public. The notebooks to reproduce figures and a preprocessed version of the semi-synthetic dataset are available at https://github.com/azizilab/arcadia_reproducibility.",
      "authors": "Rozenman Bar; Hoffer-Hawlik Kevin; Djedjos Nicholas; Azizi Elham",
      "year": "2025",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41330094",
      "doi": "10.1016/j.media.2025.103889",
      "title": "Spatial transcriptomics expression prediction from histopathology based on cross-modal mask reconstruction and contrastive learning.",
      "abstract": "Spatial transcriptomics is a technology that captures gene expression at different spatial locations, widely used in tumor microenvironment analysis and molecular profiling of histopathology, providing valuable insights into resolving gene expression and clinical diagnosis of cancer. Due to the high cost of data acquisition, large-scale spatial transcriptomics data remain challenging to obtain. In this study, we develop a contrastive learning-based deep learning method to predict spatially resolved gene expression from the whole-slide images (WSIs). Unlike existing end-to-end prediction frameworks, our method leverages multi-modal contrastive learning to establish a correspondence between histopathological morphology and spatial gene expression in the feature space. By computing cross-modal feature similarity, our method generates spatially resolved gene expression directly from WSIs. Furthermore, to enhance the standard contrastive learning paradigm, a cross-modal masked reconstruction is designed as a pretext task, enabling feature-level fusion between modalities. Notably, our method does not rely on large-scale pretraining datasets or abstract semantic representations from either modality, making it particularly effective for scenarios with limited spatial transcriptomics data. Evaluation across six different disease datasets demonstrates that, compared to existing studies, our method improves Pearson Correlation Coefficient (PCC) in the prediction of highly expressed genes, highly variable genes, and marker genes by 6.27 %, 6.11 %, and 11.26 % respectively. Further analysis indicates that our method preserves gene-gene correlations and applies to datasets with limited samples. Additionally, our method exhibits potential in cancer tissue localization based on biomarker expression. The code repository for this work is available at https://github.com/ngfufdrdh/CMRCNet.",
      "authors": "Liu Junzhuo; Eckstein Markus; Wang Zhixiang; Feuerhake Friedrich; Merhof Dorit",
      "year": "2026",
      "month": "Feb",
      "journal": "Medical image analysis",
      "source": "pubmed"
    },
    {
      "pmid": "41326702",
      "doi": "10.1038/s42003-025-09312-0",
      "title": "Hypergraph-driven spatial multimodal fusion for precise domain delineation and tumor microenvironment decoding.",
      "abstract": "Recent advancements in spatial transcriptomics have transformed tumor microenvironment research by providing insights into cellular interactions and spatial heterogeneity. A fundamental challenge is the precise delineation of spatial domains. However, existing methods remain limited in accurately identifying spatial domains, partially due to their reliance on single-view features. Moreover, these methods often struggle with many-to-many spot relationships, such as shared biological functions. To this end, we propose HAST, a hypergraph-driven spatial multimodal fusion tool for precise domain delineation and tumor microenvironment decoding. HAST integrates gene expression, spatial coordinates, and histological features to construct local hypergraphs that effectively model many-to-many spatial relationships. These local hypergraphs are dynamically aggregated into a global hypergraph, capturing higher-order interactions. To learn discriminative and biologically meaningful representations, we employ a hypergraph convolutional network, coupled with self-supervised contrastive learning, to fuse multi-view information. Extensive benchmarking across multiple datasets demonstrates that HAST outperforms state-of-the-art methods, accurately delineating spatial domains and uncovering domain-associated genes. Functional enrichment analyses further reveal biologically relevant pathways and provide novel insights into tumor microenvironment. In summary, HAST is a robust framework for decoding the spatial complexity of tumors, paving the way for precise spatial omics analyses in cancer research.",
      "authors": "Zhang Chengyang; Li Xulong; Li Bo; Deng Chenxun; Li Mengran; Zhang Shiqi; Yu Weijiang; Zhang Hongyu; Wang Zheng; Yang Yuedong; Zeng Yuansong",
      "year": "2025",
      "month": "Dec",
      "journal": "Communications biology",
      "source": "pubmed"
    },
    {
      "pmid": "41325188",
      "doi": "10.1093/bioinformatics/btaf639",
      "title": "Guided co-clustering transfer across unpaired and paired single-cell multi-omics data.",
      "abstract": "Single-cell multi-omics technologies enable the simultaneous profiling of gene expression and chromatin accessibility, providing complementary insights into cellular identity and gene regulatory mechanisms. However, integrating paired scRNA-seq and scATAC-seq data (i.e. profiles from the same single cell) remains challenging due to inherent sparsity, technical noise, and the limited availability of high-quality paired measurements. In contrast, large-scale unpaired scRNA-seq datasets often exhibit robust and biologically meaningful cell cluster structures. We introduce Guided Co-clustering Transfer (GuidedCoC), a novel framework that transfers structural knowledge from unpaired scRNA-seq source data to improve both cell clustering and feature alignment in paired scRNA-seq/scATAC-seq target data. GuidedCoC jointly co-cluster cells and features across modalities and domains via a unified information-theoretic objective, aligning gene expression modules with regulatory elements while implicitly performing cross-modal dimensionality reduction to reduce noise. Additionally, it automatically aligns cell populations across unpaired and paired datasets without requiring explicit annotations. Extensive experiments on multiple benchmark datasets demonstrate that GuidedCoC achieves superior clustering accuracy and biological interpretability compared to existing methods. These results highlight the promise of structure-guided transfer learning for robust, scalable, and interpretable integration of single-cell multi-omics data. GuidedCoC is available as open-source code at https://github.com/No-AgCl/GuidedCoC.",
      "authors": "Li Hongyao; Liu Yunrui; Zeng Pengcheng",
      "year": "2025",
      "month": "Dec",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "41310905",
      "doi": "10.1186/s40364-025-00874-z",
      "title": "From multi-omics to deep learning: advances in cfDNA-based liquid biopsy for multi-cancer screening.",
      "abstract": "Cancer remains a leading cause of mortality worldwide, with early detection being critical for improving survival rates. Traditional diagnostic methods, such as tissue biopsies and imaging, face limitations in invasiveness, cost, and accessibility, making liquid biopsy a compelling non-invasive alternative. Among liquid biopsy approaches, circulating cell-free DNA (cfDNA) analysis has gained prominence for its ability to capture tumor-derived genetic and epigenetic alterations. This review summarizes key cfDNA biomarkers, including gene mutations, copy number variations (CNVs), DNA methylation, fragmentation patterns, and end motifs (EMs), and highlights their utility in cancer detection and monitoring. By integrating these multi-modal cfDNA biomarkers, feature fusion approaches have not only enhanced the performance of cancer classification models but also stabilized low-abundance signals, thus ensuring more reliable cancer detection and monitoring. Furthermore, the diagnostic power of cfDNA analysis has been further amplified by machine learning (ML), with both traditional ML and deep learning (DL) methods demonstrating strong predictive performance in routine clinical liquid biopsy applications. However, challenges remain, including tumor heterogeneity, standardization of data processing, model explainability, and cost constraints. Future advancements should focus on refining multi-modal feature integration, developing explainable AI (XAI) models, and optimizing cost-effective strategies to enhance clinical applicability. As computational methodologies advance, the integration of cfDNA biomarkers with ML frameworks holds great promise to reshape non-invasive cancer detection by enabling earlier diagnostics, more accurate prognostic evaluation and personalized treatment strategies.",
      "authors": "Luo Xinwei; Xie Sijia; Hong Feitong; Li Xiaolong; Wei Yijie; Zhou Yuwei; Su Wei; Yang Yuhe; Tang Lixia; Dao Fuying; Cai Peiling; Lin Hao; Lai Hongyan; Lyu Hao",
      "year": "2025",
      "month": "Nov",
      "journal": "Biomarker research",
      "source": "pubmed"
    },
    {
      "pmid": "41298467",
      "doi": "10.1038/s41467-025-66644-5",
      "title": "scGALA advances graph link prediction-based cell alignment for comprehensive data integration and harmonization.",
      "abstract": "Single-cell technologies have transformed our understanding of cellular heterogeneity through multimodal data acquisition. However, robust cell alignment remains a major challenge for data integration and harmonization, including batch correction, label transfer, and multi-omics integration. Many existing methods constrain alignment based on rigid feature-wise distance metrics, limiting their ability to capture accurate cell correspondence across diverse cell populations and conditions. We introduce scGALA, a graph-based learning framework that redefines cell alignment by combining graph attention networks with a score-driven, task-independent optimization strategy. scGALA constructs enriched graphs of cell-cell relationships by integrating gene expression profiles with auxiliary information, such as spatial coordinates, and iteratively refines alignment via self-supervised graph link prediction, where a deep neural network is trained to identify and reinforce high-confidence correspondences across datasets. In extensive benchmarks, scGALA identifies over 25 percent more high-confidence alignments without compromising accuracy. By improving the core step of cell alignment, scGALA serves as a versatile enhancer for a wide range of single-cell data integration tasks.",
      "authors": "Jiang Guo; Song Kailu; Fonseca Gregory J; Wagner Darcy E; Clark Iain C; Wang Hui; Ding Jun",
      "year": "2025",
      "month": "Nov",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "41295107",
      "doi": "10.3390/jimaging11110390",
      "title": "Next-Generation Advances in Prostate Cancer Imaging and Artificial Intelligence Applications.",
      "abstract": "Prostate cancer is one of the leading causes of cancer-related morbidity and mortality worldwide, and imaging plays a critical role in its detection, localization, staging, treatment, and management. The advent of artificial intelligence (AI) has introduced transformative possibilities in prostate imaging, offering enhanced accuracy, efficiency, and consistency. This review explores the integration of AI in prostate cancer diagnostics across key imaging modalities, including multiparametric MRI (mpMRI), PSMA PET/CT, and transrectal ultrasound (TRUS). Advanced AI technologies, such as machine learning, deep learning, and radiomics, are being applied for lesion detection, risk stratification, segmentation, biopsy targeting, and treatment planning. AI-augmented systems have demonstrated the ability to support PI-RADS scoring, automate prostate and tumor segmentation, guide targeted biopsies, and optimize radiation therapy. Despite promising performance, challenges persist regarding data heterogeneity, algorithm generalizability, ethical considerations, and clinical implementation. Looking ahead, multimodal AI models integrating imaging, genomics, and clinical data hold promise for advancing precision medicine in prostate cancer care and assisting clinicians, particularly in underserved regions with limited access to specialists. Continued multidisciplinary collaboration will be essential to translate these innovations into evidence-based practice. This article explores current AI applications and future directions that are transforming prostate imaging and patient care.",
      "authors": "Miao Kathleen H; Miao Julia H; Finkelstein Mark; Chatterjee Aritrick; Oto Aytekin",
      "year": "2025",
      "month": "Nov",
      "journal": "Journal of imaging",
      "source": "pubmed"
    },
    {
      "pmid": "41292913",
      "doi": "10.1101/2025.11.09.687403",
      "title": "Heimdall: A Modular Framework for Tokenization in Single-Cell Foundation Models.",
      "abstract": "Foundation models trained on single-cell RNA-sequencing (scRNA-seq) data have rapidly become powerful tools for single-cell analysis. Their performance, however, depends critically on how cells are tokenized into model inputs - a design space that remains poorly understood. Here, we present Heimdall, a comprehensive framework and open-source toolkit for systematically evaluating tokenization strategies in single-cell foundation models (scFMs). Heimdall decomposes each scFM into modular components: a gene identity encoder (",
      "authors": "Haber Ellie; Alam Shahul; Ho Nicholas; Liu Renming; Trop Evan; Liang Shaoheng; Yang Muyu; Krieger Spencer; Ma Jian",
      "year": "2025",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41286991",
      "doi": "10.1186/s13059-025-03862-6",
      "title": "scKGBERT: a knowledge-enhanced foundation model for single-cell transcriptomics.",
      "abstract": "Single-cell transcriptomics enables precise characterization of cellular heterogeneity, but current pre-trained models relying solely on expression data fail to capture gene associations. We present scKGBERT, a knowledge-enhanced foundation model integrating 41 M single-cell RNA-seq profiles and 8.9 M protein-protein interactions to jointly learn gene and cell representations. scKGBERT employs Gaussian attention to emphasize key genes and improve biomarker identification, achieving superior performance across gene annotation, drug response, and disease prediction tasks. scKGBERT enhances biological interpretability and offers a powerful resource for precision medicine and disease mechanism discovery.",
      "authors": "Li Yang; Qiao Guanyu; Du Hongli; Gao Xin; Wang Guohua",
      "year": "2025",
      "month": "Nov",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "41283813",
      "doi": "10.1093/bib/bbaf622",
      "title": "Single-cell omics arena: evaluation of large language models for automatic cell-type annotations on single-cell omics data via RNA-seq bridging.",
      "abstract": "The single-cell sequencing revolution enables simultaneous molecular profiling of various modalities across thousands of individual cells, allowing scientists to investigate the diverse functions of complex tissues. Among all the analysis steps, assigning individual cells to specific types is fundamental for understanding cellular heterogeneity. However, this process is labor-intensive and requires extensive expert knowledge. Recent advances in large language models (LLMs) have demonstrated their ability to automatically extract biological knowledge, such as marker genes, promoting efficient, and automated cell-type annotations. To evaluate the capability of modern LLMs in automating the cell-type identification process, we first introduce an automated cell-type annotation method with comprehensive benchmark: Single-cell Omics Arena). Specifically, we began by compiling 11 publicly available single-cell RNA sequencing (scRNA-seq) datasets and evaluating eight LLMs across 1226 cell-type annotation-related tasks. This effort established a foundation for automated cell-type annotation from scRNA-seq data using interpretable features such as gene names. Building upon this benchmark, we introduced domain-specific chain-of-thought prompting techniques to enhance the accuracy of cell-type annotation and facilitate the extraction of relevant biological insights. Finally, to accommodate non-interpretable features, we proposed to leverage a pretrained VAE-based cross-modality translation module to convert features such as epigenetic marks into interpretable representations, which enables the seamless extension of LLM-based cell-type annotation to non-RNA-based sequencing technologies. In summary, our benchmark provides key insights into automated cell-type annotation from scRNA-seq data and demonstrates the potential of cross-modality translation for handling non-interpretable features.",
      "authors": "Liu Junhao; Xu Siwei; Wu Yongxian; Zhang Jing",
      "year": "2025",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41282136",
      "doi": "10.21203/rs.3.rs-7681940/v1",
      "title": "Predicting dynamic expression patterns in budding yeast with a fungal DNA language model.",
      "abstract": "Predicting gene expression from DNA sequence remains challenging due to complex regulatory codes. We introduce a masked DNA language model pretrained on 165 fungal genomes closely related to budding yeast that captures conserved regulatory grammar. Fine-tuning the LM on yeast RNA-seq data-including high-resolution transcriptional regulator induction time courses generated in this study-yielded Shorkie, a model that substantially improves gene expression prediction compared to baselines trained without self-supervision. Shorkie identified canonical transcription factor (TF) binding motifs and tracked their usage across induction experiments. Furthermore, Shorkie accurately predicted variant effects, outperforming leading sequence-to-expression models in ",
      "authors": "Chao Kuan-Hao; Magzoub Majed Mohamed; Stoops Emily; Hackett Sean; Linder Johannes; Kelley David R",
      "year": "2025",
      "month": "Oct",
      "journal": "Research square",
      "source": "pubmed"
    },
    {
      "pmid": "41279662",
      "doi": "10.1101/2025.10.31.685877",
      "title": "GeneCAD: Plant Genome Annotation with a DNA Foundation Model.",
      "abstract": "Accurate genome annotation remains a bottleneck in plants, where polyploidy and repeat-rich sequence confound homology- and RNA-based pipelines. We introduce GeneCAD, a sequence-only method that predicts complete plant gene models directly from DNA. GeneCAD couples representations from a plant DNA foundation model, PlantCAD2, with a lightweight ModernBERT encoder and a chromosome-wide conditional random field that enforces splice-phase and feature order, and applies a protein language-model screen to suppress repeat-driven open reading frames. To limit label noise, we rank and filter public annotations using a sequence-based masked-motif score and fine-tune on five phylogenetically diverse, high-quality references. Across five held out angiosperms, including the allotetraploid ",
      "authors": "Liu Zong-Yan; Berthel Ana; Czech Eric; Stitzer Michelle; Hsu Sheng-Kai; Pennell Matt; Buckler Edward S; Zhai Jingjing",
      "year": "2025",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41279640",
      "doi": "10.1101/2025.11.02.686137",
      "title": "MERFISH+, a large-scale, multi-omics spatial technology resolves the molecular holograms of the 3D human developing heart.",
      "abstract": "Hybridization-based spatial transcriptomics technologies have advanced our ability to map cellular and subcellular organization in complex tissues. However, existing methods remain constrained in gene coverage, multimodal compatibility, and scalability. Here, we present MERFISH+, an enhanced version of Multiplexed Error-Robust Fluorescence in Situ Hybridization (MERFISH), which integrates chemical probe anchoring in protective hydrogels with high-throughput microfluidics and microscopy. This optimized design supports robust and repeated hybridization cycles across an entire centimeter-scale tissue sample. MERFISH+ allowed to simultaneously quantify over 1,800 genes and resolve the 3D organization of chromatin loci and their associated epigenomic marks in developing human hearts. Using a generative integration framework for spatial multimodal data (Spateo-VI), we harmonized these MERFISH+ transcriptomic and chromatin data to reconstruct a 3D spatially-resolved multi-omic atlas of the developing human heart at subcellular resolution capturing 3.1 million cells across 34 distinct populations. This 3D atlas provides a holistic view of an entire organ enabling the characterization of 3D cellular neighborhoods and transcriptional gradients of substructures such as the descending arteries. Thus, MERFISH+ offers a robust, large-format platform for spatial multi-omics that enables high resolution mapping of gene expression at subcellular resolution and the characterization of cellular organization within 3D organs.",
      "authors": "Kern Colin; Zhang Qingquan; Lu Yifan; Eschbach Jacqueline; Zeng Zehua; Farah Elie N; Tai Chu-Yi; Yang Kaifu; Jenie Ignatius; Yao Fenyong; Zhao Zoey; Ma Qixuan; Padilla Carlos Garcia; Monell Alexander; Moghadami Siavash; Zhu Fugui; Li Bin; Hou Angie; Tucker Grant; Ellison David; Chi Neil C; Qiu Xiaojie; Zhu Quan; Bintu Bogdan",
      "year": "2025",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41279541",
      "doi": "10.1101/2024.12.10.627665",
      "title": "ProCyon: A multimodal foundation model for protein phenotypes.",
      "abstract": "Characterizing human proteins remains a major challenge: approximately 29% of human proteins lack experimentally validated functions and even well-annotated proteins often lack context-specific phenotypic insights. To enable universal modeling of protein phenotypes, we present ProCyon, a multimodal foundation model that utilizes protein sequence, structure, and natural language for generating and predicting protein phenotypes across diverse knowledge domains. ProCyon is trained on our novel dataset, ProCyon-Instruct, with 33 million protein phenotype instructions. On dozens of benchmarking tasks, ProCyon performs competitively against single-modal and multimodal models. Further, ProCyon conditionally retrieves proteins via mechanisms of action of small molecule drugs and disease contexts, and it generates candidate phenotypic descriptions for poorly characterized proteins, including those implicated in Parkinson's disease that were identified after ProCyon's knowledge cutoff date. We experimentally confirm ProCyon's predictions in multiple sclerosis using post-mortem brain RNA-seq, identifying novel MS genes and elucidating associated pathway mechanisms consistent with cortical pathology. ProCyon paves the way toward a general approach to generate functional insights into the human proteome.",
      "authors": "Queen Owen; Huang Yepeng; Calef Robert; Giunchiglia Valentina; Chen Tianlong; Dasoulas George; Tai LeAnn; Abbadessa Gianmarco; Howell Owain; Li Michelle M; Ektefaie Yasha; Noori Ayush; Farkas Ildiko; Brown Joseph; Cobley Tom; Hrovatin Karin; Hartvigsen Tom; Theis Fabian J; Pentelute Bradley L; Zou James; Khurana Vikram; Owen David; Nicholas Richard; Kellis Manolis; Zitnik Marinka",
      "year": "2025",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41279458",
      "doi": "10.1101/2025.11.03.685753",
      "title": "Atacformer: A transformer-based foundation model for analysis and interpretation of ATAC-seq data.",
      "abstract": "Chromatin accessibility profiling is an important tool for understanding gene regulation and cellular function. While public repositories house nearly 10,000 scATAC-seq experiments, unifying this data for meaningful analysis remains challenging. Existing tools struggle with the scale and complexity of scATAC-seq datasets, limiting tasks like clustering, cell-type annotation, and reference mapping. A promising solution is using foundation models adapted to specific tasks via transfer learning. While transfer learning has been applied to scRNA-seq, its potential for scATAC-seq remains underexplored. We introduce Atacformer, a transformer-based foundation model for scATAC-seq data analysis. Unlike other models that only produce cell-level representations, Atacformer generates embeddings for individual cis-regulatory elements. Pre-trained on a large atlas of scATAC-seq experiments, Atacformer learns robust representations of genomic regulatory regions for downstream use. After pretraining, the model is fine-tuned for cell-type prediction and batch correction. We also integrated Atacformer with RNA-seq data to build a Contrastive RNA-ATAC Fine Tuning (CRAFT) model capable of cross-modal alignment and RNA imputation from ATAC data. Atacformer matches or exceeds leading scATAC-seq clustering tools in adjusted rand index and runtime, with fine-tuned models achieving top performance across datasets. It processes raw fragment files end-to-end 80% faster than existing tools while preserving biological structure. Fine-tuned on bulk BED files, it recovers cell type and assay labels with >80% accuracy. We show how the Atacformer architecture produces contextualized embeddings of individual genomic regions, which we use to identify unannotated, cell-type-specific promoter elements directly from chromatin accessibility data.",
      "authors": "LeRoy Nathan J; Zheng Guangtao; Khoroshevskyi Oleksandr; Campbell Donald R; Zhang Aidong; Sheffield Nathan C",
      "year": "2025",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41279430",
      "doi": "10.1101/2025.10.03.680290",
      "title": "SCREAM: Single-cell Clustering using Representation Autoencoder of Multiomics.",
      "abstract": "Single-cell multiomics technologies offer unprecedented opportunities to study cellular heterogeneity. But, integrating information across different omics modalities remains a major challenge due to high dimensionality, sparsity, and modality-specific noise characteristics. To address this, we develop SCREAM (Single-cell Clustering using Representation Autoencoder of Multiomics), a novel deep learning framework for the robust integration and clustering of multimodal single-cell data. SCREAM leverages Stacked Autoencoders (SAEs) to generate robust latent representations for each omics modality as well as for their fusion. Subsequently, borrowing Deep Embedding Clustering (DEC), SCREAM iteratively fine tunes the integrated mulitomics latent space and single-cell cluster assignments. We evaluated SCREAM against eleven state-of-the-art methods using SNARE-seq and CITE-seq datasets. In this benchmarking, SCREAM consistently demonstrated superior performance, yielding the highest or near-highest Adjusted Rand Index (ARI) and Normalized Mutual Information (NMI) scores on both datasets. These findings validate SCREAM as a highly accurate and robust approach for identifying cell types from multiomics data. Furthermore, its multiomics embeddings provides biologically meaningful latent representations for diverse downstream analyses. SCREAM is available at http://www.github.com/cabsel/scream. rgunawan@buffalo.edu.",
      "authors": "Chrysinas Panagiotis; Venkatesan Shriramprasad; Patel Priya Ghanshyambhai; Gunawan Rudiyanto",
      "year": "2025",
      "month": "Oct",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41279228",
      "doi": "10.1101/2025.10.21.683449",
      "title": "Multi-omics integration and batch correction using a modality-agnostic deep learning framework.",
      "abstract": "State-of-the-art biotechnologies allow the detection of different molecular species on the same biological sample, generating complex highly-dimensional multi-modal datasets. Gaining a holistic understanding of biological phenomena, such as oncogenesis or aging, requires integrating these diverse modalities into low-dimensional data representations while correcting for technical artifacts. Here we present MIMA, a modular, unsupervised AI framework for multi-omics data integration and batch correction. Applied to complex spatial and single-cell datasets, MIMA effectively removes batch effects, while preserving biologically relevant information, and learns representations predictive of expert pathologist annotations. Additionally, it enables cross-modal translation, uncovers molecular patterns not captured by manual annotations, and despite being modality-agnostic performs on par with specialized state-of-the-art tools. MIMA's flexibility and scalability make it a powerful tool for multimodal data analysis. MIMA provides a foundation for AI-based, multi-omics augmented digital pathology frameworks, offering new opportunities for improved patient stratification and precision medicine through the comprehensive integration of high-dimensional molecular data and histopathological imaging.",
      "authors": "Alvira Larizgoitia Jose Ignacio; Partel Gabriele; Venturelli Lorenzo; Zhang Wanqiu; Spotbeen Xander; Vanuytven Sebastiaan; Kint Sam; Vandereyken Katy; Wouters David; Ismail Anis; Scarceriaux Regis; Idkowiak Jakub; Sarretto Tassiani; Ellis Shane R; Loda Massimo; Socciarelli Fabio; Gevaert Thomas; Joniau Steven; Claesen Marc; Verbeeck Nico; Voet Thierry; Swinnen Johannes V; Jacobs Jelle; Sifrim Alejandro",
      "year": "2025",
      "month": "Oct",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41279114",
      "doi": "10.1101/2025.04.14.648850",
      "title": "Scaling Large Language Models for Next-Generation Single-Cell Analysis.",
      "abstract": "Single-cell RNA sequencing has transformed our understanding of cellular diversity, yet current single-cell foundation models (scFMs) remain limited in their scalability, flexibility across diverse tasks, and ability to natively integrate textual information. In this work, we build upon the Cell2Sentence (C2S) framework, which represents scRNA-seq profiles as textual \"cell sentences,\" to train Large Language Models (LLMs) on a corpus comprising over one billion tokens of transcriptomic data, biological text, and metadata. Scaling the model to 27 billion parameters yields consistent improvements in predictive and generative capabilities and supports advanced downstream tasks that require synthesis of information across multi-cellular contexts. Targeted fine-tuning with modern reinforcement learning techniques produces strong performance in perturbation response prediction, natural language interpretation, and complex biological reasoning. This predictive strength enabled a dual-context virtual screen that nominated the kinase inhibitor silmitasertib (CX-4945) as a candidate for context-selective upregulation of antigen presentation. Experimental assessment in human cell models unseen during training supported this prediction, demonstrating that C2S-Scale can effectively guide the discovery of context-conditioned biology. C2S-Scale unifies transcriptomic and textual data at unprecedented scales, surpassing both specialized single-cell models and general-purpose LLMs to provide a platform for next-generation single-cell analysis and the development of \"virtual cells.\"",
      "authors": "Rizvi Syed Asad; Levine Daniel; Patel Aakash; Zhang Shiyang; Wang Eric; Perry Curtis Jamison; Vrkic Ivan; Constante Nicole Mayerli; Fu Zirui; He Sizhuang; Zhang David; Tang Cerise; Lyu Zhuoyang; Darji Rayyan; Li Chang; Sun Emily; Jeong David; Zhao Lawrence; Kwan Jennifer; Braun David; Hafler Brian; Chung Hattie; Dhodapkar Rahul M; Jaeger Paul; Perozzi Bryan; Ishizuka Jeffrey; Azizi Shekoofeh; van Dijk David",
      "year": "2026",
      "month": "Jan",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41278946",
      "doi": "10.1101/2024.12.13.628448",
      "title": "Evaluating the role of pre-training dataset size and diversity on single-cell foundation model performance.",
      "abstract": "The success of transformer-based foundation models on natural language and images has motivated their use in single-cell biology. Single-cell foundation models have been trained on increasingly larger transcriptomic datasets, scaling from initial studies with 1 million cells to newer atlases with over 100 million cells. This study investigates the role of pre-training dataset size and diversity on the performance of single-cell foundation models on both zero-shot and fine-tuned tasks. Using a large corpus of 22.2 million cells, we pre-train a total of 400 models, which we evaluate by conducting 6,400 experiments. Our results show that current methods tend to plateau in performance with pre-training datasets that are only a fraction of the size of current training corpora.",
      "authors": "DenAdel Alan; Hughes Madeline; Thoutam Akshaya; Gupta Anay; Navia Andrew W; Fusi Nicolo; Raghavan Srivatsan; Winter Peter S; Amini Ava P; Crawford Lorin",
      "year": "2025",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41278937",
      "doi": "10.1101/2024.12.06.627299",
      "title": "SubCell: Proteome-aware vision foundation models for microscopy capture single-cell biology.",
      "abstract": "Cell morphology and subcellular protein organization provide important insights into cellular function and behavior. These features of cells can be studied using large-scale protein fluorescence microscopy, and machine learning has become a powerful tool to interpret the resulting images for biological insights. Here, we introduce SubCell, a suite of self-supervised deep learning models for fluorescence microscopy designed to accurately capture cellular morphology, protein localization, cellular organization, and biological function beyond what humans can readily perceive. These models were trained on the proteome-wide image collection from the Human Protein Atlas with a novel proteome-aware learning objective. SubCell outperforms state-of-the-art methods across a variety of tasks relevant to single-cell biology and generalizes to other fluorescence microscopy datasets without any fine-tuning. Additionally, we construct the first proteome-wide hierarchical map of proteome organization that is directly learned from image data. This vision-based multiscale cell map defines cellular subsystems with high resolution of protein complexes, reveals proteins with similar functions, and distinguishes dynamic and stable behaviors within cellular compartments. Finally, Subcell enables a rich multimodal protein representation when integrated with a protein sequence model, allowing for a more comprehensive capture of gene function than either vision-only or sequence-only models alone. In conclusion, SubCell creates deep, image-driven representations of cellular architecture that are applicable across diverse biological contexts and datasets.",
      "authors": "Gupta Ankit; Wefers Zoe; Kahnert Konstantin; Hansen Jan N; Misra Mohini K; Leineweber Will; Cesnik Anthony; Lu Dan; Axelsson Ulrika; Ballllosera Frederic; Altman Russ B; Karaletsos Theofanis; Lundberg Emma",
      "year": "2025",
      "month": "Oct",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41278680",
      "doi": "10.1101/2025.10.03.680242",
      "title": "SpaGene: A Deep Adversarial Framework for Spatial Gene Imputation.",
      "abstract": "Integrating transcriptome-wide single-cell gene expression data with spatial context significantly enhances our understanding of tissue biology, cellular interactions, and disease progression. Although single-cell RNA sequencing (scRNA-seq) provides high-resolution gene expression data, it lacks crucial spatial context, whereas spatial transcriptomics techniques offer spatial resolution but are limited in the transcriptomic coverage. To address these limitations, integrating scRNA-seq and spatial transcriptomics data is essential. We introduce SpaGene, a novel deep learning framework designed to integrate scRNA-seq data and spatial transcriptomics data. SpaGene consists of two encoder-decoder pairs combined with two translators and two discriminators to effectively impute missing gene expressions within spatial transcriptomics datasets. We benchmarked SpaGene against existing state-of-the-art methods across diverse datasets. Across the datasets, SpaGene achieved an average 33% higher Pearson correlation coefficient (PCC), 21% higher Structural similarity index (SSIM), and 6.6% lower Root mean squared error (RMSE) compared to the existing approaches, highlighting its capability to reliably impute missing genes and provide comprehensive transcriptomics profiles. Application of our model to lung tumor tissue revealed immune cell enrichment at tumor boundaries, restricted myeloid cell trafficking in adjacent normal regions, and microenvironmental-driven pathways linked to immune neighborhoods. These results provide novel insight into immune exclusion and tumor-immune interactions that drive tumor progression, highlighting potential avenues for therapeutic development. Thus, SpaGene extends the power of spatial transcriptomics by delivering spatially resolved, enhanced transcriptome data that enable deeper biological understanding.",
      "authors": "Budhkar Aishwarya; Ha Juhyung; Song Qianqian; Su Jing; Zhang Xuhong",
      "year": "2025",
      "month": "Oct",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41276529",
      "doi": "10.1038/s41467-025-66049-4",
      "title": "Protein Set Transformer: a protein-based genome language model to power high-diversity viromics.",
      "abstract": "Exponential increases in microbial and viral genomic data demand transformational advances in scalable, generalizable frameworks for their interpretation. Standard homology-based functional analyses are hindered by the rapid divergence of microbial and especially viral genomes and proteins that significantly decreases the volume of usable data. Here, we present Protein Set Transformer (PST), a protein-based genome language model that models genomes as sets of proteins without considering sparsely available functional labels. Trained on >100k viruses, PST outperforms other homology- and language model-based approaches for relating viral genomes based on shared protein content. Further, PST demonstrates protein structural and functional awareness by clustering capsid-fold-containing proteins with known capsid proteins and uniquely clustering late gene proteins within related viruses. Our data establish PST as a valuable method for diverse viral genomics, ecology, and evolutionary applications. We posit that the PST framework can be a foundation model for microbial genomics when trained on suitable data.",
      "authors": "Martin Cody; Gitter Anthony; Anantharaman Karthik",
      "year": "2025",
      "month": "Nov",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "41274606",
      "doi": "10.1016/j.slast.2025.100371",
      "title": "Single-cell RNA insights and densely scaled vision transformer-based MRI classification for precision brain tumors.",
      "abstract": "There are >1600 evolutionarily conserved RNA-binding proteins (RBPs) in the human genome. Many multi-omics studies have demonstrated that these proteins are often not working properly in malignancies like glioblastoma and melanoma. These RBPs are very important for the complex regulatory networks that govern the activities that are typical of cancer. RBPs' intricate control of RNA activity at many levels and their post-translational modifications, which make them more functional, make things even more convoluted. Additionally, other RBP-based therapies have emerged, each underpinned by distinct molecular mechanisms, including genomic analysis and the inhibition of RBP functionality. This paper reports findings from patients with brain tumours undergoing experimental RNA interference treatment. We also suggest a Densely Scaled Vision Transformer (DSViT) made to find and locate brain tumors of different types. The model is evaluated on the FigShare Brain Tumor Dataset comprising 3064 MRI images categorized into Glioma, Meningioma, and Pituitary tumors, with final testing conducted on 614 samples. Experimental results show that DSViT achieves an accuracy of 96.09 %, precision of 96.57 %, recall of 95.97 %, and an F1-score of 96.27 %, significantly outperforming the ViT-Baseline and ablation variants. Future directions include extending DSViT into multimodal pipelines that fuse imaging with molecular profiles, thereby enhancing precision neuro-oncology. Its modular structure also enables integration into radiological reporting systems for automated annotation and clinician-guided decision support. This innovative RNA interference (iRNAi) based therapeutic intervention has significant therapeutic potential and is, as far as we are aware, the first time RNA interference has been used to treat human disease.",
      "authors": "Chauhan Pratikkumar; Lunagaria Munindra; Verma Deepak Kumar",
      "year": "2025",
      "month": "Dec",
      "journal": "SLAS technology",
      "source": "pubmed"
    },
    {
      "pmid": "41272032",
      "doi": "10.1038/s41698-025-01159-2",
      "title": "Leveraging artificial intelligence in antibody-drug conjugate development: from target identification to clinical translation in oncology.",
      "abstract": "Artificial intelligence (AI) is opening new frontiers in the development of antibody-drug conjugates (ADCs), offering unprecedented opportunities for precision therapy. This review outlines how AI empowers each stage of the ADC pipeline. In target discovery, multi-omics integration and graph-based learning prioritize tumor-selective and internalizing antigens. In antibody engineering, structure prediction, affinity optimization, and developability modeling streamline candidate selection. For linker-payload design, generative models and multi-objective optimization approaches support the rational design of conjugates that balance potency, stability, and immunogenicity. In absorption, distribution, metabolism, excretion, and toxicity (ADMET) modeling, deep learning and transformer-based frameworks predict pharmacokinetics and toxicity with increasing accuracy and mechanistic clarity. In clinical development, AI facilitates patient stratification, response prediction, and trial simulation through digital twin models, adaptive dosing algorithms, and real-world data integration. These capabilities support a more personalized and efficient pathway from bench to bedside. To further realize the impact of AI in ADC development, we highlight strategic priorities including the creation of curated, multimodal datasets, interpretable model architectures, and closed-loop experimental platforms. Together, these advances will be essential for realizing the full potential of AI to support rational, scalable, and personalized ADC-based therapies in oncology.",
      "authors": "Lu Ye; Huang Weijun; Li Yuxuan; Xu Yanzhi; Wei Qing; Sha Chulin; Guo Peng",
      "year": "2025",
      "month": "Nov",
      "journal": "NPJ precision oncology",
      "source": "pubmed"
    },
    {
      "pmid": "41266662",
      "doi": "10.1007/s10238-025-01965-9",
      "title": "AI-driven multi-omics integration in precision oncology: bridging the data deluge to clinical decisions.",
      "abstract": "Cancer's staggering molecular heterogeneity demands innovative approaches beyond traditional single-omics methods. The integration of multi-omics data, spanning genomics, transcriptomics, proteomics, metabolomics and radiomics, can improve diagnostic and prognostic accuracy when accompanied by rigorous preprocessing and external validation; for example, recent integrated classifiers report AUCs around 0.81-0.87 for difficult early-detection tasks. This review synthesizes how artificial intelligence (AI), particularly deep learning and machine learning, bridges this gap by enabling scalable, non-linear integration of disparate omics layers into clinically actionable insights. We explore cutting-edge AI methodologies, including graph neural networks for biological network modeling, transformers for cross-modal fusion, and explainable AI (XAI) for transparent clinical decision support. Critical applications are highlighted, such as AI-driven therapy selection (e.g., predicting targeted therapy resistance), proteogenomic early detection, and radiogenomic non-invasive diagnostics. We further address translational challenges: data harmonization, batch correction, missing data imputation, and computational scalability. Emerging trends, federated learning for privacy-preserving collaboration, spatial/single-cell omics for microenvironment decoding, quantum computing, and patient-centric \"N-of-1\" models, signal a paradigm shift toward dynamic, personalized cancer management. Despite persistent hurdles in model generalizability, ethical equity, and regulatory alignment, AI-powered multi-omics integration promises to transform precision oncology from reactive population-based approaches to proactive, individualized care.",
      "authors": "Hsu Chou-Yi; Askar Shavan; Alshkarchy Samer Saleem; Nayak Priya Priyadarshini; Attabi Kassem A L; Khan Mohammad Ahmar; Mayan J Albert; Sharma M K; Islomov Sarvar; Soleimani Samarkhazan Hamed",
      "year": "2025",
      "month": "Nov",
      "journal": "Clinical and experimental medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41263940",
      "doi": "10.1093/bib/bbaf613",
      "title": "SciSt: single-cell reference-informed spatial gene expression prediction from pathological images.",
      "abstract": "The widespread application of spatial transcriptomics in uncovering disease mechanisms remains limited by the scarcity of samples and the high experimental costs, which have not declined substantially in recent years. Unlocking the vast resources of clinical H&E-stained images could provide an efficient and cost-effective alternative for large-scale spatial analysis. However, predicting spatial gene expression from histopathological images remains challenging, as existing end-to-end frameworks often fail to capture the intrinsic transcriptomic structures observed in real transcriptomics data. To address this, we developed SciSt, a deep learning framework that predicts spatial gene expression by integrating pathological features with biologically informed initial gene expressions. These initial expressions are generated through a weighted strategy combining cell segmentation and single-cell reference data, thereby enhancing biological interpretability. SciSt achieved state-of-the-art performance across three benchmark datasets, outperforming the second-best models by 21.4% and 13.7%, respectively, and demonstrated robust generalization on the TCGA-BRCA and TCGA-LIHC cohorts. Beyond accurate prediction, SciSt enables cross-modal translation between morphology and gene expression, offering new avenues for mining the untapped potential of clinical image archives. This work highlights how prior biological knowledge can substantially advance the interpretability and scalability of biomedical AI models.",
      "authors": "Li Yixin; Zhong Fan; Liu Lei",
      "year": "2025",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41261132",
      "doi": "10.1038/s41586-025-09749-7",
      "title": "Semantic design of functional de novo genes from a genomic language model.",
      "abstract": "Generative genomic models can design increasingly complex biological systems",
      "authors": "Merchant Aditi T; King Samuel H; Nguyen Eric; Hie Brian L",
      "year": "2026",
      "month": "Jan",
      "journal": "Nature",
      "source": "pubmed"
    },
    {
      "pmid": "41260205",
      "doi": "10.1016/j.xcrm.2025.102452",
      "title": "A prognostic index integrating deep learning baseline PET/CT biomarkers and multi-omics profiling in diffuse large B cell lymphoma.",
      "abstract": "[",
      "authors": "Wang Yue; Wang Xue; Huang Xin-Yun; Jing Hong-Mei; Jiang Song-Fu; Li He; Mu Rong-Ji; Shi Qing; Fu Di; Li Zhuo-Han; Yi Hong-Mei; Ouyang Bin-Shen; Li Biao; Yan Fu-Hua; Niu Ting; Cheng Shu; Wang Li; Wen Ning; Xu Peng-Peng; Zhao Wei-Li",
      "year": "2025",
      "month": "Nov",
      "journal": "Cell reports. Medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41258300",
      "doi": "10.1038/s41467-025-65066-7",
      "title": "Omnireg-gpt: a high-efficiency foundation model for comprehensive genomic sequence understanding.",
      "abstract": "The human genome contains a sophisticated array of elements that regulate gene activity and organismal functions. Developing a large window foundation model capable of efficiently processing long sequence inputs is essential yet challenging for decoding the multi-layered and complex landscape of the cis-regulatory elements. Here, we introduce OmniReg-GPT, a generative foundation model designed for the low-resource pretraining of long genomic sequences by optimized attention mechanism. During pretraining, OmniReg-GPT captures the complete distribution of regulatory elements across nucleotide to megabase scales with efficient training speed and memory usage. We demonstrate exceptional performance in downstream regulotary applications spanning the entire spectrum of genomic scales, including various cis-regulatory elements identification, context dependent gene expression prediction, single-cell chromatin accessibility analysis, and 3D chromatin contact modeling. As a generative model, OmniReg-GPT also holds the potential to generate candidate cell-type-specific enhancers through prompt engineering. Overall, OmniReg-GPT extends the boundaries of foundation models in the genomic field, and provides a valuable pretraining model resource which can be extensively applied for genomic researches.",
      "authors": "Wang Aowen; Li Jiaqi; Dong Hongyu; Xu Bocheng; Yin Qingyu; Xu Yanchao; Fu Jie; Zhao Junbo",
      "year": "2025",
      "month": "Nov",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "41256895",
      "doi": "",
      "title": "Nephrobase Cell+: Multimodal Single-Cell Foundation Model for Decoding Kidney Biology.",
      "abstract": "Large foundation models have revolutionized single-cell analysis, yet no kidney-specific model currently exists, and it remains unclear whether organ-focused models can outperform generalized models. The kidney's complex cellular architecture further complicate integration of large-scale omics data, where current frameworks trained on limited datasets struggle to correct batch effects, capture cross-modality variation, and generalize across species. We developed Nephrobase Cell+, the first kidney-focused large foundation model, pretrained on ~100 billion tokens from ~39.5 million single-cell and single-nucleus profiles across 4,319 samples. Nephrobase Cell+ uses a transformer-based encoder-decoder architecture with gene-token cross-attention and a mixture-of-experts module for scalable representation learning. Nephrobase Cell+ sets a new benchmark for kidney single-cell analysis. It produces tightly clustered, biologically coherent embeddings in human and mouse kidneys, far surpassing previous foundation models such as Geneformer, scGPT, and UCE, as well as traditional methods such as PCA and autoencoders. It achieves the highest cluster concordance and batch-mixing scores, effectively removing donor/assay batch effects while preserving cell-type structure. Cross-species evaluation shows superior alignment of homologous cell types and >90% zero-shot annotation accuracy for major kidney lineages in both human and mouse. Even its 1B-parameter and 500M variants consistently outperform all existing models. Nephrobase Cell+ delivers a unified, high-fidelity representation of kidney biology that is robust, cross-species transferable, and unmatched by current single-cell foundation models, offering a powerful resource for kidney genomics and disease research.",
      "authors": "Li Chenyu; Ziyadeh Elias; Sharma Yash; Dumoulin Bernhard; Levinsohn Jonathan; Ha Eunji; Pan Siyu; Rao Vishwanatha; Subramaniyam Madhav; Szegedy Mario; Zhang Nancy; Susztak Katalin",
      "year": "2025",
      "month": "Sep",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "41256893",
      "doi": "",
      "title": "A Deep Learning Pipeline for Epilepsy Genomic Analysis Using GPT-2 XL and NVIDIA H100.",
      "abstract": "Epilepsy is a chronic neurological condition characterized by recurrent seizures, with global prevalence estimated at 50 million people worldwide. While progress in high-throughput sequencing has allowed for broad-based transcriptomic profiling of brain tissues, the deciphering of these highly complex datasets remains one of the challenges. To address this issue, in this paper we propose a new analysis pipeline that integrates the power of deep learning strategies with GPU-acceleration computation for investigating Gene expression patterns in epilepsy. Specifically, our proposed approach employs GPT-2 XL, a transformer-based Large Language Model (LLM) with 1.5 billion parameters for genomic sequence analysis over the latest NVIDIA H100 Tensor Core GPUs based on Hopper architecture. Our proposed method enables efficient preprocessing of RNA sequence data, gene sequence encoding, and subsequent pattern identification. We conducted experiments on two epilepsy datasets including GEO accession GSE264537 and GSE275235. The obtained results reveal several significant transcriptomic modifications, including reduced hippocampal astrogliosis after ketogenic diet treatment as well as restored excitatory-inhibitory signaling equilibrium in zebrafish epilepsy model. Moreover, our results highlight the effectiveness of leveraging LLMs in combination with advanced hardware acceleration for transcriptomic characterization in neurological diseases.",
      "authors": "Latif Muhammad Omer; Ullah Hayat; Shafique Muhammad Ali; Dong Zhihua",
      "year": "2025",
      "month": "Oct",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "41256652",
      "doi": "10.1101/2025.09.30.679628",
      "title": "Qimai: a multi-agent framework for zero-shot DNA-protein interaction prediction.",
      "abstract": "Accurate prediction of DNA-protein interactions, a fundamental task in genomics, is limited by the poor generalization of existing models to novel proteins not seen during training. To address this challenge, we introduce Qimai, a modular AI agent framework that integrates deep learning predictions with biological evidence using Large Language Model (LLM) as reasoning engine. Qimai combines direct motif evidence from the query protein, indirect motif evidence from its interactors, and quantitative prediction from a new transformer-based DPI model to produce explainable predictions with confidence scores. On a benchmark of 78 unseen proteins, Qimai consistently outperforms standalone deep learning models across all metrics, increasing the Area Under Curve of the Precision-Recall (AUC-PR), the Area Under Curve of the Receiver Operating Characteristic (AUC-ROC), and Matthews Correlation Coefficient (MCC) by 17.6%, 15.6%, and 244% respectively compared to the best standalone model. Ablation analyses reveal that this gain is driven by the LLM's ability to dynamically weigh diverse evidence, with indirect motif evidence of co-factors particularly critical for unseen proteins. Qimai establishes a generalizable and interpretable paradigm for integrating heterogeneous data in predictive genomics. This framework is accessible via the Qimai web portal (https://qimai.wanglab.ucsd.edu/).",
      "authors": "Liu Cong; Yao Mina; Wang Wei",
      "year": "2025",
      "month": "Oct",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41256511",
      "doi": "10.1101/2025.09.30.679471",
      "title": "Nephrobase Cell+: Multimodal Single-Cell Foundation Model for Decoding Kidney Biology.",
      "abstract": "Large foundation models have revolutionized single-cell analysis, yet no kidney-specific model currently exists, and it remains unclear whether organ-focused models can outperform generalized models. The kidney's complex cellular architecture and dynamic microenvironments further complicate integration of large-scale single-cell and spatial omics data, where current frameworks trained on limited datasets struggle to correct batch effects, capture cross-modality variation, and generalize across species. We developed Nephrobase Cell+, the first kidney-focused large foundation model, pretrained on ~100 billion tokens from ~39.5 million single-cell and single-nucleus profiles across 4,319 samples, four mammalian species (human, mouse, rat, pig), and multiple assay modalities (scRNA-seq, snRNA-seq, snATAC-seq, spatial transcriptomics). Nephrobase Cell+ uses a transformer-based encoder-decoder architecture with gene-token cross-attention and a mixture-of-experts module for scalable representation learning. Nephrobase Cell+ sets a new benchmark for kidney single-cell analysis. It produces tightly clustered, biologically coherent embeddings in human and mouse kidneys, far surpassing previous foundation models such as Geneformer, scGPT, and UCE, as well as traditional methods such as PCA and autoencoders. It achieves the highest cluster concordance and batch-mixing scores, effectively removing donor/assay batch effects while preserving cell-type structure. Cross-species evaluation shows superior alignment of homologous cell types and >90% zero-shot annotation accuracy for major kidney lineages in both human and mouse. Even its 1B-parameter and 500M variants consistently outperform all existing models. With organ-scale multimodal pretraining and a specialized transformer architecture, Nephrobase Cell+ delivers a unified, high-fidelity representation of kidney biology that is robust, cross-species transferable, and unmatched by current single-cell foundation models, offering a powerful resource for kidney genomics and disease research.",
      "authors": "Li Chenyu; Ziyadeh Elias; Sharma Yash; Dumoulin Bernhard; Levinsohn Jonathan; Ha Eunji; Pan Siyu; Rao Vishwanatha; Subramaniyam Madhav; Szegedy Mario; Zhang Nancy; Susztak Katalin",
      "year": "2025",
      "month": "Oct",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41245657",
      "doi": "10.1016/j.jpha.2025.101386",
      "title": "Fast-adapting graph neural network with prior knowledge for drug response prediction across preclinical and clinical data.",
      "abstract": "Efficient drug response prediction is crucial for reducing drug development costs and time, but current computational models struggle with limited experimental data and out-of-distribution issues between ",
      "authors": "Guo Hui; Lv Xiang; Li Shenghao; Ma Daichuan; Li Yizhou; Li Menglong",
      "year": "2025",
      "month": "Oct",
      "journal": "Journal of pharmaceutical analysis",
      "source": "pubmed"
    },
    {
      "pmid": "41243712",
      "doi": "10.1002/advs.202513210",
      "title": "CELLama: Foundation Model for Single Cell and Spatial Transcriptomics by Cell Embedding Leveraging Language Model Abilities.",
      "abstract": "Large-scale single-cell RNA sequencing (scRNA-seq) and spatial transcriptomics (ST) have transformed biomedical research into a data-driven field, enabling the creation of comprehensive atlases. These methodologies facilitate detailed understanding of biology and pathophysiology; however, the complexity and sheer volume of data present analytical challenges, particularly in robust cell typing, integration, and understanding complex spatial relationships of cells. To address these challenges, CELLama (Cell Embedding Leverage Language Model Abilities) develops a framework that leverage language model to transform cell data into \"sentences\" that encapsulate gene expressions and metadata, enabling universal cell embedding. CELLama, serving as a foundation model, supports flexible applications ranging from cell typing to analysis of spatial contexts, independent of complex dataset-specific analysis workflows by using a large cell atlas. The results demonstrate that CELLama has significant potential to transform cellular analysis in various contexts, from determining cell types using multi-tissue atlases and their interactions to unraveling intricate tissue dynamics.",
      "authors": "Park Jeongbin; Kim Sumin; Kim Jiwon; Lee Dongjoo; Bae Sungwoo; Shin Haenara; Lee Daeseung; Choi Hongyoon",
      "year": "2026",
      "month": "Feb",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "41241819",
      "doi": "10.1093/bib/bbaf594",
      "title": "Advancing toxicity AI-based prediction with multilevel systems biology: a case study on genotoxicity.",
      "abstract": "The rapid expansion of chemical diversity presents substantial challenges for health and environmental risk assessment, necessitating the development of alternative, high-throughput computational methodologies. A key hurdle in toxicity prediction lies in the heterogeneous nature of adverse health outcomes at the tissue and cellular levels, as biological processes exhibit cell-type-specific and context-dependent responses. Effective prediction of individual-level health effects thus requires the integration of multimodal data, capturing both structural and biological perturbations induced by chemical exposures. We present GenotoxNet, a multimodal deep learning framework that enhances genotoxicity prediction by systematically integrating chemical structures, high-throughput in vitro assay data, and transcriptomics data. By leveraging this multimodal integration, GenotoxNet effectively captures cellular heterogeneity and mechanistic complexity, enabling more comprehensive evaluation of chemical-induced genotoxicity. The model outperformed single-modality approaches, achieving AUCROC of 0.891 ± 0.017 on the internal test set, demonstrating superior predictive capability over models relying solely on chemical structures or individual biological features. The model still performed well on the external chemical set. Beyond classification, GenotoxNet facilitates mechanistic interpretation by aligning multimodal feature representations of genotoxic chemicals with adverse outcome pathway (AOP). This framework not only offers a robust approach for predicting genotoxicity but also aids in the development of preventive strategies and regulatory decisions aimed at mitigating the health risks posed by hazardous chemicals.",
      "authors": "Zhang Xin; Zhang Huazhou; Yun Xiao; Pan Wenxiao; Xue Qiao; Liu Xian; Fu Jianjie; Zhang Aiqian",
      "year": "2025",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41223195",
      "doi": "10.1371/journal.pone.0335863",
      "title": "Improved CRISPR/Cas9 off-target prediction with DNABERT and epigenetic features.",
      "abstract": "CRISPR/Cas9 is a powerful genome editing tool, but its clinical application is hindered by off-target effects. Accurate computational prediction of these unintended edits is crucial for ensuring the safety and efficacy of therapeutic applications. While various deep learning models have been developed, most are trained only on task-specific data, failing to leverage the vast knowledge embedded in entire genomes. To address this limitation, we introduce a novel approach that integrates DNABERT, a deep learning model pre-trained on the human genome, with epigenetic features (H3K4me3, H3K27ac, and ATAC-seq). We conducted a comprehensive benchmark of our model, DNABERT-Epi, against five state-of-the-art methods across seven distinct off-target datasets. Our results demonstrate that the pre-trained DNABERT-based models achieve competitive or even superior performance. Rigorous ablation studies quantitatively confirmed that both genomic pre-training and the integration of epigenetic features are critical factors that significantly enhance predictive accuracy. Furthermore, by applying advanced interpretability techniques (SHAP and Integrated Gradients), we identified the specific epigenetic marks and sequence-level patterns that influence the model's predictions, offering insights into its decision-making process. This study is the first to establish the significant potential of a pre-trained DNA foundation model for CRISPR/Cas9 off-target prediction. Our findings underscore that leveraging both large-scale genomic knowledge and multi-modal data is a key strategy for advancing the development of safer genome editing tools.",
      "authors": "Kimata Kai; Satou Kenji",
      "year": "2025",
      "month": "",
      "journal": "PloS one",
      "source": "pubmed"
    },
    {
      "pmid": "41209345",
      "doi": "10.1016/j.csbj.2025.10.038",
      "title": "Multimodal fusion strategies for survival prediction in breast cancer: A comparative deep learning study.",
      "abstract": "Accurate survival prediction in breast cancer remains a key challenge in oncology, requiring models that can integrate diverse clinical, molecular, and imaging data sources to guide breast cancer management. While recent deep learning models have explored multimodal integration for cancer survival prediction, their generalizability to unseen data remains limited. In this study, we developed and optimized unimodal and multimodal models for breast cancer survival prediction, systematically assessing our optimized early and late integration strategies and their impact on out-of-sample generalization performance. We integrated clinical variables, somatic mutations, RNA expression, copy number variation, miRNA expression, and histopathology images from The Cancer Genome Atlas breast cancer dataset. Across all modality combinations, late fusion models consistently outperformed early fusion approaches and late and intermediate benchmark methods, with the combination of omics and clinical data yielding the highest test-set concordance indices. Explainability analyses showed that our models captured biologically relevant features associated with patient survival. These findings highlight the value of late-fusion multimodal deep learning frameworks for robust and explainable survival prediction in breast cancer.",
      "authors": "Sucre Aurora; Calle Sánchez Xabier; Perez-Herrera Laura Valeria; Vivanco María dM; García-González María Jesús; López-Linares Karen; Calvo Borja; Garin-Muga Alba",
      "year": "2025",
      "month": "",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "41206950",
      "doi": "10.1093/bib/bbaf584",
      "title": "GT-GRN: a graph transformer framework for enhanced gene regulatory network inference via multimodal embedding of expression data and existing network knowledge.",
      "abstract": "The inference of gene regulatory networks (GRNs) is critical for understanding the regulatory mechanisms underlying cellular development, functional specialization, and disease progression. Predicting regulatory gene interactions-often framed as a link prediction task-is a foundational step toward modeling cellular behavior. However, GRN inference from gene coexpression data alone is limited by noise, low interpretability, and difficulty in capturing indirect regulatory signals. Additionally, challenges such as data sparsity, nonlinearity, and complex gene interactions hinder accurate network reconstruction. To address these issues, we propose, a novel graph transformer (GT) based framework (GT-GRN) that enhances GRN inference by integrating multimodal gene embeddings. Our method combines three complementary sources of information: (i) autoencoder-based embeddings, which capture high-dimensional gene expression patterns while preserving biological signals; (ii) structural embeddings, derived from previously inferred GRNs and encoded via random walks and a Bidirectional Encoder Representations from Transformers (BERT) based language model to learn global gene representations; (iii) positional encodings, capturing each gene's role within the network topology . These heterogeneous features are fused and processed using a GT, allowing the joint modeling of both local and global regulatory structures. Experimental results on benchmark datasets show that GT-GRN outperforms existing GRN inference methods in predictive accuracy and robustness. Furthermore, it reconstructs cell-type-specific GRNs with high fidelity and produces gene embeddings that generalize to other tasks such as cell-type annotation.",
      "authors": "Teji Binon; Roy Swarup; Bhandari Dinabandhu; Kalita Jugal",
      "year": "2025",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41206113",
      "doi": "10.1093/bib/bbaf576",
      "title": "Artificial intelligence in bioinformatics: a survey.",
      "abstract": "The widespread adoption of high-throughput sequencing technologies and multi-omics approaches has led to rapid accumulation of genomic, transcriptomic, proteomic, and even single-cell multimodal datasets, resulting in an exponential growth of biological data. The massive scale and inherent complexity of these datasets pose significant challenges for data management, analysis, and interpretation in the field of bioinformatics. Concurrently, artificial intelligence (AI) techniques, particularly deep learning and reinforcement learning, have achieved groundbreaking advances in medical diagnostics, drug discovery, and genomic analyses, providing novel theoretical tools and analytical paradigms for bioinformatics research. AI techniques are now extensively applied to DNA, RNA, and protein sequence prediction and design, 3D structural elucidation, functional annotation, integrative analysis of multi-omics data, and personalized drug design for precision medicine, significantly advancing biological research. This review systematically summarizes recent research progress and representative applications of AI techniques in bioinformatics, specifically discussing suitable scenarios and advantages of traditional machine learning algorithms, deep learning models, and reinforcement learning methods. We highlight AI's transformative impact with quantitative metrics from landmark achievements: accurate near-atomic protein structure prediction (median 0.96 Å on CASP14), robust single-cell modeling (AvgBIO $\\approx $ 0.82), high protein design success rates (up to 92%), and sensitive cancer detection (Area Under Curve (AUC) $\\approx $ 0.93). Furthermore, the paper provides an in-depth analysis of the latest advancements of AI in specific tasks, including biomedical text mining, multimodal omics integration, and single-cell analyses, while highlighting current challenges such as data noise and sparsity, difficulties in modeling long biological sequences, complexities in multimodal data integration, insufficient model interpretability, and ethical and privacy concerns. Finally, the paper outlines promising future research directions, emphasizing large-scale data mining, cross-domain model generalization, innovations in drug design and personalized medicine, and advocates for establishing an open and collaborative research ecosystem.",
      "authors": "Jiang Jiyue; Li Yunke; Cao Shiwei; Shan Yuheng; Liu Yuexing; Fei Tianyi; Yu Yule; Feng Yi; Li Yu; Li Yixue; Yuan Jiao",
      "year": "2025",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41188846",
      "doi": "10.1186/s12951-025-03774-4",
      "title": "Multi-modal single-cell platform for nanoparticle-enhanced time-series metabolic profiles of CD8",
      "abstract": "Cytotoxic T cells (CD8",
      "authors": "Yang Chenjie; Gao Mingxia; Zhang Xiangmin; Yu Hailong; Deng Chunhui",
      "year": "2025",
      "month": "Nov",
      "journal": "Journal of nanobiotechnology",
      "source": "pubmed"
    },
    {
      "pmid": "41188290",
      "doi": "10.1038/s41598-025-17439-7",
      "title": "Transcriptome-conditioned molecule generation via gene interaction-aware fragment modeling with a GPT-based architecture.",
      "abstract": "Phenotype-driven drug discovery leverages cellular responses to guide the design of therapeutic molecules. Recent advancements in transcriptomics have provided extensive datasets describing how gene expression changes in response to various chemical stimuli, presenting an opportunity to directly link molecular generation to specific cellular phenotypes. However, effectively linking transcriptomic perturbations to chemical structure generation remains challenging due to the complexity of gene interactions and chemical feasibility constraints. We developed GGIFragGPT, a novel generative model that integrates transcriptomic perturbation profiles with biologically informed gene-gene interaction embeddings to guide fragment-based molecular generation. The model employs an autoregressive transformer architecture to sequentially assemble chemically valid fragments, with cross-attention mechanisms highlighting biologically relevant genes guiding the molecular generation process. Comparative analysis confirmed that the proposed approach yields chemically feasible, novel, and diverse molecules. By leveraging transcriptomic profiles, GGIFragGPT successfully generated compounds aligned with the biological context suggested by transcriptomic data, validated through gene-level interpretability analysis that identified key target genes. Case studies demonstrated the model's capability to produce structurally plausible inhibitors, exemplified by targeted molecule generation against CDK7. This work demonstrates the potential of integrating biological insights into chemical generation processes, offering a promising approach for phenotype-driven therapeutic discovery.",
      "authors": "Koo Bonil; Park Bo Kyung; Kim Sun",
      "year": "2025",
      "month": "Nov",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "41181553",
      "doi": "10.1177/20552076251393286",
      "title": "AI-Powered histopathology slide image interpretation in oncology: A comprehensive knowledge mapping and bibliometric analysis.",
      "abstract": "To map global research on AI-driven histopathological image interpretation in oncology (2000-2024). Scopus-based bibliometrics using Boolean queries; data exported, cleaned, and analyzed in VOSviewer. The dataset included 1874 publications, surging after 2015. China (n = 561) and the United States (n = 467) led output; leading institutions included Harvard Medical School and the Chinese Academy of Sciences. Top journals were Scientific Reports, Cancers, and IEEE Access; the corpus H-index was 112. Collaboration networks intensified, especially U.S.-Asia. Keyword mapping showed four clusters: (1) deep learning for breast cancer/CNN diagnostics; (2) transfer learning/feature extraction; (3) prognostic modeling/tumor microenvironment; and (4) digital infrastructure/explainable AI. Overlay analyses traced a shift from classical machine learning to transformers and multimodal models integrating molecular and clinical data; emerging themes include semantic segmentation, self-supervised learning, and therapy-response prediction. Applications spanned breast, prostate, colorectal, head-neck, gynecologic, and gastrointestinal/liver cancers. Models primarily used whole-slide images (e.g., TCGA) and multi-omics; algorithms included CNNs, deep learning, classical machine learning, and weakly supervised approaches. Evidence ranged from proof-of-concept to multicenter validation and workflow integration; adoption remains constrained by data standardization, interpretability, and regulation. Clinically, AI improved diagnostic accuracy/efficiency and supported personalization via multi-omics. Bibliographic coupling revealed three clusters: clinical/translational journals; engineering/computational outlets; and interdisciplinary venues linking algorithmic innovation with digital pathology. AI histopathology is advancing toward clinical-grade deployment, propelled by collaboration and methodological innovation, yet limited by data standards, explainability, and regulatory requirements.",
      "authors": "Sweileh Moutaz W",
      "year": "2025",
      "month": "",
      "journal": "Digital health",
      "source": "pubmed"
    },
    {
      "pmid": "41181383",
      "doi": "10.2147/AMEP.S554692",
      "title": "Gliomas Analysis via Multimodal MRI-Deep Learning Fusion: Technical Innovations in Segmentation, Molecular Subtyping, and Clinical Translation Pathways.",
      "abstract": "The integration of multimodal MRI and deep learning is reshaping glioma diagnosis and treatment, shifting from experience-dependent to data-driven paradigms. Conventional radiology, limited by subjective qualitative assessment, fails to fully quantify glioma heterogeneity, whereas deep learning addresses multidimensional data complexity through cross-modal feature fusion-particularly via Transformer-3D CNN hybrid models with cross-modal attention mechanisms. These models have enhanced glioma segmentation accuracy to a Dice coefficient of 0.92 and enabled noninvasive prediction of critical molecular markers (eg, IDH mutation), while uncovering biological links between imaging features and EGFR/PI3K-AKT signaling pathways. Clinically, this framework predicts glioma recurrence 3-6 months earlier and traces metastatic brain tumor primary lesions with 87.5% accuracy. However, challenges remain, including data heterogeneity, poor model interpretability, and ethical constraints, which demand standardized protocols for clinical translation. Future efforts will focus on integrating multi-omics data, developing real-time decision systems, and establishing evidence-based medical frameworks via interdisciplinary collaboration to achieve personalized whole-process glioma management. This review systematically synthesizes recent advances in multimodal MRI-deep learning fusion for glioma care, clarifies technical development trajectories, addresses core bottlenecks (eg, cross-center data discrepancies, clinical translation latency), and provides a theoretical basis for translating these technologies into clinical practice.",
      "authors": "Yi Guangming; Ma Wenhui; Yu Zhenni; Bai Hong; Zhang Hengsheng; Wang Yujun; Huang Cong",
      "year": "2025",
      "month": "",
      "journal": "Advances in medical education and practice",
      "source": "pubmed"
    },
    {
      "pmid": "41180200",
      "doi": "10.3389/fendo.2025.1618412",
      "title": "Artificial intelligence-driven approaches in pituitary neuroendocrine tumors: integrating endocrine-metabolic profiling for enhanced diagnostics and therapeutics.",
      "abstract": "Pituitary neuroendocrine tumors (PitNETs) pose diagnostic and therapeutic challenges due to their heterogeneity and complex endocrine-metabolic interactions. Artificial intelligence (AI) enhances PitNET management through improved classification, outcome prediction, and personalized treatment. However, current AI models face limitations, including small, single-center datasets and insufficient integration of multi-omics or autoimmune-associated biomarkers. Future advancements require multicenter standardized databases, explainable AI frameworks, and multimodal data fusion. By decoding endocrine-metabolic dysregulation and its link to tumor behavior, AI-driven precision medicine can optimize PitNET care. This review highlights AI's potential in PitNETs while addressing key challenges and future directions for clinical translation.",
      "authors": "Zheng Aiping; Tang Dan; He Huijuan; Liang Xinyu",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in endocrinology",
      "source": "pubmed"
    },
    {
      "pmid": "41174554",
      "doi": "10.1186/s12859-025-06219-9",
      "title": "A novel modality contribution confidence-enhanced multimodal deep learning framework for multiomics data.",
      "abstract": "Multimodal learning for classification tasks has recently gained significant attention in bioinformatics. Current approaches primarily concentrate on devising efficient deep learning architectures to capture features within and across modalities. However, they typically assume that each modality contributes equally to the classification objective, overlooking inherent biases within multimodal learning. This paper presents a modality contribution confidence-enhanced deep learning framework to address this issue, resulting in an improved fusion space and improved classification performance on multiomics data. Specifically, we propose utilising a non-parametric Gaussian Process to assess the unimodal confidence of each modality and learn within-modality features. Additionally, we introduce the use of the Kullback-Leibler divergence to align multiple modalities and learn cross-modality features. Extensive experiments on four multiomics datasets, incorporating modalities such as static information, DNA, mRNA, miRNA, and protein data, validate the effectiveness of the proposed method. Furthermore, a case study on the blister recovery task is included to demonstrate the practical utility of our model.",
      "authors": "Zhang Duoyi; Bashar Md Abul; Nayak Richi; Cuttle Leila",
      "year": "2025",
      "month": "Oct",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41168713",
      "doi": "10.1186/s12864-025-12196-3",
      "title": "A novel prediction method for protein-DNA binding sites based on protein language model fusion features with SE-connection pyramidal network and ensemble learning.",
      "abstract": "Protein-DNA interactions are crucial in life processes such as gene expression and regulation. Therefore, the accurate prediction of DNA-binding sites on proteins is highly important for the advancement of scientific understanding in the field of biological activities. In this work, we propose a protein-DNA binding site prediction framework, termed Evolutionary Scale Modeling-SE-Connection Pyramidal (ESM-SECP), which integrates a sequence-feature-based prediction method with a sequence-homology-based predictor via ensemble learning. The sequence-feature-based prediction method is built on two types of input features: ESM-2 protein language model embeddings and evolutionary conservation information computed by PSI-BLAST. These features are fused by a multi-head attention mechanism and processed through the newly proposed SE-Connection Pyramidal(SECP) network for prediction. The sequence-template method, based on sequence homology, serves as a complementary approach to predict DNA-binding residues. The two predictors are combined via ensemble learning to improve overall model performance. Through the experimental validation of the TE46 and TE129 datasets, ESM-SECP outperforms the traditional methods in several evaluation indices, demonstrating its outstanding performance in Protein-DNA binding site prediction.",
      "authors": "Zhang Chenrui; Jiang Jingqing; Zhao Haiyan; Song Jiazhi",
      "year": "2025",
      "month": "Oct",
      "journal": "BMC genomics",
      "source": "pubmed"
    },
    {
      "pmid": "41167326",
      "doi": "10.1016/j.joca.2025.10.012",
      "title": "Artificial intelligence, machine learning and omic data integration in osteoarthritis.",
      "abstract": "Artificial intelligence (AI), particularly its subfield of machine learning (ML), offer promising tools for integrating and interpreting high-dimensional omic data to advance our understanding of osteoarthritis (OA), a complex, multifactorial disease. The objective of this review is to summarize recent progress in applying ML approaches to single and integrative multi-omic data in OA and to highlight emerging trends, challenges, and opportunities. We conducted a literature search of PubMed and preprint databases upto April 2025. This search identified studies that applied ML techniques including supervised learning, unsupervised clustering, deep learning, and integrative modeling to OA datasets. These datasets included transcriptomic, epigenomic, proteomic, metabolomic, and multi-omic profiles in human OA samples and relevant preclinical models. We synthesized findings across omic types, ML methodologies, and clinical or mechanistic OA outcomes, highlighting key trends in multi-omic integration strategies and their implications for OA research. Recent studies have applied ML to identify transcriptomic and epigenomic biomarkers, stratify OA patient subtypes, and predict disease progression. Advanced approaches such as variational autoencoders, contrastive learning, and multimodal transformers are emerging as powerful tools for multi-omic integration. However, challenges remain related to small sample sizes, overfitting, lack of external validation, model interpretability, and demographic underrepresentation in omic datasets. ML techniques are advancing OA research by enabling nuanced analysis of complex omic datasets. Addressing current limitations and embracing new developments in spatial and single-cell omics, generative models, and federated learning will be essential to unlock the full potential of multi-omic integration for personalized OA diagnosis and treatment.",
      "authors": "Sharma Divya",
      "year": "2025",
      "month": "Oct",
      "journal": "Osteoarthritis and cartilage",
      "source": "pubmed"
    },
    {
      "pmid": "41164160",
      "doi": "10.3389/fmed.2025.1685254",
      "title": "Advances in artificial intelligence applications for the management of chronic obstructive pulmonary disease.",
      "abstract": "Chronic obstructive pulmonary disease (COPD), characterized by high incidence and mortality rates, is a chronic respiratory disorder that places a substantial burden on healthcare systems. Artificial Intelligence (AI), with its deep integration into the medical field, particularly through its core branches-Machine Learning (ML) and Deep Learning (DL)-has demonstrated significant potential in the intervention and management of COPD. From early risk prediction based on multimodal data to the enhancement of precise diagnosis and treatment through radiomics and clinical decision support systems, and further to the dynamic assessment of acute exacerbation and comorbidity risks via machine learning models, AI has, in combination with bioinformatics and multi-omics analysis, established a novel intelligent management framework that spans the entire disease continuum. This framework offers innovative, individualized solutions aimed at alleviating the burden on healthcare systems. This article reviews the technical applications and clinical value of AI in the diagnosis, prevention, treatment, and prognosis of COPD, discusses current challenges, and outlines future development directions to provide insights for clinical practice and research.",
      "authors": "Wang Mingyu; Li Luhan; Feng Min; Liu Zhuo",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41162996",
      "doi": "10.1186/s12967-025-07245-0",
      "title": "SpateCV: cross-modality alignment regularization of cell types improves spatial gene imputation for spatial transcriptomics.",
      "abstract": "The integration of single-cell RNA sequencing (scRNA-seq) and high-resolution spatial transcriptomics (ST) could improve our understanding of both tissue architecture and cellular heterogeneity simultaneously. The key to accomplishing this goal mainly relies on effectively co-embedding similar cells with consistent representations from the two types of data. In this paper, we construct a conditional variational autoencoder (CVAE) architecture, named SpateCV, to explicitly regularize the embedding alignment of similar cells from scRNA-seq and ST data in a shared latent through a clustering loss. Benchmark results across twelve datasets demonstrate that SpateCV achieves superior performance in spatial gene imputation and spatial patterns reconstruction. Critically, SpateCV translates this technical accuracy into biological insight. With the imputed genome-wide expression, our method enables the identification of novel spatially differentially expressed genes, such as the astrocyte marker Hepacam, and facilitates the inference of layer-specific intercellular communication networks, identifying corpus callosum cells as key signaling hubs in the mouse visual cortex. Additionally, SpateCV enables the in silico spatial mapping of neuronal subtypes by integrating spatial context into scRNA-seq data. SpateCV provides a robust framework for extracting biological knowledge from multimodal spatial-omics data. The online version contains supplementary material available at 10.1186/s12967-025-07245-0.",
      "authors": "Yuan Jiaqi; Yu Junhua; Yi Qianbei; Ye Zheng; Xu Peng; Liu Wenbin",
      "year": "2025",
      "month": "Oct",
      "journal": "Journal of translational medicine",
      "source": "pubmed"
    },
    {
      "pmid": "41158510",
      "doi": "10.3389/fgene.2025.1634882",
      "title": "Gene-LLMs: a comprehensive survey of transformer-based genomic language models for regulatory and clinical genomics.",
      "abstract": "The convergence of natural language processing (NLP) and genomics has given rise to a new class of transformer-based models-genome large language models (Gene-LLMs)-capable of interpreting the language of life at an unprecedented scale and resolution. These models represent a revolution in the field of bioinformatics since they use only raw nucleotide sequences, gene expression data, and multi-omic annotations, leveraging self-supervised pretraining to decipher complex regulatory grammars hidden within the genome. This survey presents a comprehensive overview of the Gene-LLM lifecycle, including stages such as raw data ingestion, k-mer or gene-level tokenization, and pretext learning tasks like masked nucleotide prediction and sequence alignment. We specify their wide range of applications, spanning crucial downstream activities such as finding the enhancer or promoter, modeling the chromatin state, predicting the RNA-protein interaction, and creating synthetic sequences. We further explore how Gene-LLMs have created an impact on functional genomics, clinical diagnostics, and evolutionary inference by analyzing recent benchmarks, including CAGI5, GenBench, NT-Bench, and BEACON. We also highlight recent advances encoder-decoder modifications and the incorporation of positional embeddings, a feature specific to living organisms, which may enhance both interpretability and translational potential. Finally, this study outlines a pathway toward federated genomic learning, multimodal sequence modeling, and low-resource adaptation for rare variant discovery, establishing Gene-LLMs as a cornerstone technology for the responsible and proactive future of biomedicine.",
      "authors": "Balakrishnan P; Anny Leema A; Dhivya Shree V; Mohammad Saad C; Mohan Babu A",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in genetics",
      "source": "pubmed"
    },
    {
      "pmid": "41155036",
      "doi": "10.3390/bioengineering12101037",
      "title": "Integrating Spatial Omics and Deep Learning: Toward Predictive Models of Cardiomyocyte Differentiation Efficiency.",
      "abstract": "Advances in cardiac regenerative medicine increasingly rely on integrating artificial intelligence with spatial multi-omics technologies to decipher intricate cellular dynamics in cardiomyocyte differentiation. This systematic review, synthetising insights from 88 PRISMA selected studies spanning 2015-2025, explores how deep learning architectures, specifically Graph Neural Networks (GNNs) and Recurrent Neural Networks (RNNs), synergise with multi-modal single-cell datasets, spatially resolved transcriptomics, and epigenomics to advance cardiac biology. Innovations in spatial omics technologies have revolutionised our understanding of the organisation of cardiac tissue, revealing novel cellular communities and metabolic landscapes that underlie cardiovascular health and disease. By synthesising cutting-edge methodologies and technical innovations across these 88 studies, this review establishes the foundation for AI-enabled cardiac regeneration, potentially accelerating the clinical adoption of regenerative treatments through improved therapeutic prediction models and mechanistic understanding. We examine deep learning implementations in spatiotemporal genomics, spatial multi-omics applications in cardiac tissues, cardiomyocyte differentiation challenges, and predictive modelling innovations that collectively advance precision cardiology and next-generation regenerative strategies.",
      "authors": "Kgabeng Tumo; Wang Lulu; Ngwangwa Harry M; Pandelani Thanyani",
      "year": "2025",
      "month": "Sep",
      "journal": "Bioengineering (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "41152264",
      "doi": "10.1038/s41598-025-14949-2",
      "title": "Transformer-based representation learning for robust gene expression modeling and cancer prognosis.",
      "abstract": "Transformer models have achieved remarkable success in natural language and vision tasks, but their application to gene expression analysis remains limited due to data sparsity, high dimensionality, and missing values. We present GexBERT, a transformer-based encoder-decoder framework for robust representation learning of gene expression data. GexBERT learns context-aware gene embeddings by pretraining on large-scale transcriptomic profiles with a masking and restoration objective that captures co-expression relationships among thousands of genes. We evaluate GexBERT across three critical tasks in cancer research: pan-cancer classification, cancer-specific survival prediction, and missing value imputation. GexBERT achieves state-of-the-art classification accuracy from limited gene subsets, improves survival prediction by restoring expression of prognostic anchor genes, and outperforms conventional imputation methods under high missingness. These findings demonstrate the utility of GexBERT as a scalable and effective tool for gene expression modeling, with translational potential in settings where gene coverage is limited or incomplete.",
      "authors": "Jiang Shuai; Hassanpour Saeed",
      "year": "2025",
      "month": "Oct",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "41151585",
      "doi": "10.1016/j.crmeth.2025.101211",
      "title": "Single-cell multiomics data integration and generation with scPairing.",
      "abstract": "Single-cell multiomics technologies generate paired measurements of different cellular modalities, such as gene expression and chromatin accessibility. However, multiomics technologies are more expensive than their unimodal counterparts, resulting in smaller and fewer available multiomics datasets. Here, we present scPairing, a deep learning model inspired by contrastive language-image pre-training (CLIP), which embeds different modalities from the same single cells onto a common embedding space. We leverage the common embedding space to generate novel multiomics data following bridge integration, a method that uses an existing multiomics bridge to link unimodal data. Through extensive benchmarking, we show that scPairing constructs an embedding space that fully captures both coarse and fine biological structures. We then use scPairing to generate new multiomics data from retina, immune, and renal cells. Furthermore, we extend scPairing to generate trimodal data. The generated multiomics datasets can facilitate the discovery of novel cross-modality relationships and the validation of existing biological hypotheses.",
      "authors": "Niu Jeffrey; Vasquez-Rios Carlos; Ding Jiarui",
      "year": "2025",
      "month": "Nov",
      "journal": "Cell reports methods",
      "source": "pubmed"
    },
    {
      "pmid": "41133269",
      "doi": "10.1093/nargab/lqaf137",
      "title": "An ensemble-based model comprising deep learning for predicting peptide-binding residues in proteins.",
      "abstract": "Protein-peptide interactions are fundamental to numerous cellular processes and are linked to diseases like cancer when disrupted. Understanding these interactions is critical for both functional genomics and drug discovery. Despite growing availability of protein-peptide complexes, experimental methods to study them remain resource-intensive and costly. While computational approaches offer a complementary solution, their predictive accuracy is often inadequate. To overcome these limitations, we present PepENS, an ensemble model combining deep learning and traditional machine learning techniques that integrates both structural and sequence-based features from primary protein sequences. By leveraging half-sphere exposure, position-specific scoring matrices from multiple-sequence alignments, and embeddings from a pre-trained protein language model, PepENS demonstrates superior performance compared to the state-of-the-art methods. The proposed model demonstrated strong performance, achieving a precision of 0.596 and an AUC of 0.860 on the Dataset 1 test set. On the Dataset 2 test set, it attained a precision of 0.539 and an AUC of 0.846. Notably, these results reflect improvements over state-of-the-art methods in terms of precision and AUC by 2.8% and 0.5%, respectively, on Dataset 1, and by 2.3% and 2.4%, respectively, on Dataset 2. The PepENS software and associated datasets are available at https://doi.org/10.6084/m9.figshare.28490012.v2.",
      "authors": "Chandra Abel; Dehzangi Iman; Tsunoda Tatsuhiko; Sattar Abdul; Sharma Alok",
      "year": "2025",
      "month": "Dec",
      "journal": "NAR genomics and bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41132477",
      "doi": "10.7759/cureus.95178",
      "title": "Modernizing Colorectal Cancer Care With Artificial Intelligence: Real-Time Detection, Radiomics, and Digital Pathology.",
      "abstract": "Colorectal cancer (CRC) remains a major global burden, demanding earlier detection and more precise care. Artificial intelligence (AI) is reshaping the CRC pathway by boosting lesion detection, expediting molecular triage, and enabling quantitative, multimodal decision support. Evidence shows computer-aided detection increases adenoma detection and lowers miss rates; digital pathology can infer microsatellite instability from routine slides to prioritize confirmatory testing. AI also strengthens CT/MRI via segmentation, radiomics-based risk stratification, nodal staging, and response prediction, while blood- and genomics-driven models extend noninvasive screening and prognosis. Translating these gains requires high-quality data, external validation, interpretability, workflow integration, and robust governance. Priorities include multicenter prospective studies, lifecycle performance monitoring, and implementation frameworks that ensure usability, equity, and cost-effectiveness, enabling AI to evolve into a dependable infrastructure that improves CRC outcomes.",
      "authors": "Nasr Elmoatazbellah; Al-Hamid Zaid; Younan Mina H; Omran Mohamed; Sarsam Maan; Abdellatif Mohamed",
      "year": "2025",
      "month": "Oct",
      "journal": "Cureus",
      "source": "pubmed"
    },
    {
      "pmid": "41125796",
      "doi": "10.1038/s41592-025-02854-5",
      "title": "scooby: modeling multimodal genomic profiles from DNA sequence at single-cell resolution.",
      "abstract": "Understanding how regulatory sequences shape gene expression across individual cells is a fundamental challenge in genomics. Joint RNA sequencing and epigenomic profiling provides opportunities to build models capturing sequence determinants across steps of gene expression. However, current models, developed primarily for bulk omics data, fail to capture the cellular heterogeneity and dynamic processes revealed by single-cell multimodal technologies. Here, we introduce scooby, a framework to model genomic profiles of single-cell RNA-sequencing coverage and single-cell assay for transposase-accessible chromatin using sequencing insertions from sequence at single-cell resolution. For this, we leverage the pretrained multiomics profile predictor Borzoi and equip it with a cell-specific decoder. Scooby recapitulates cell-specific expression levels of held-out genes and identifies regulators and their putative target genes. Moreover, scooby allows resolving single-cell effects of bulk expression quantitative trait loci and delineating their impact on chromatin accessibility and gene expression. We anticipate scooby to aid unraveling the complexities of gene regulation at the resolution of individual cells.",
      "authors": "Hingerl Johannes C; Martens Laura D; Karollus Alexander; Manz Trevor; Buenrostro Jason D; Theis Fabian J; Gagneur Julien",
      "year": "2025",
      "month": "Nov",
      "journal": "Nature methods",
      "source": "pubmed"
    },
    {
      "pmid": "41122975",
      "doi": "10.1093/gigascience/giaf132",
      "title": "Genos: a human-centric genomic foundation model.",
      "abstract": "The rapid expansion of human genomic data demands foundation models that manage ultra-long sequences and capture population diversity, limitations common in existing models that lack human-specific representation, and clinical inference efficiency. Here, we introduce Genos (Genos-1.2B/Genos-10B), a human-centric genomic foundation model engineered for million-basepair sequence modeling. Genos utilizes a large-scale mixture of experts structure, optimized for a 1-Mb context, trained on high-quality human de novo assemblies from datasets such as the Human Pangenome Reference Consortium and the Human Genome Structural Variation Consortium, representing diverse global populations. A suite of optimization strategies was implemented to ensure training stability and enhance computational efficiency, which collectively reduces costs and facilitates million-basepair context modeling. Functionally, Genos performs single-nucleotide resolution analysis and dynamically simulates the cascade effects of noncoding variations on RNA expression profiles. In comprehensive evaluations, Genos uniformly surpasses state-of-the-art models on critical human genomics benchmarks and demonstrates robust omics-text cross-modal diagnostic capabilities. We present a systematic technical evaluation and validation of Genos's architecture, training convergence, and performance across standard benchmarks. This work provides a reliable technical blueprint and performance benchmark for the development of the next generation of high-efficiency genomic foundation models. Genos model weights, inference code, and usage documentation are publicly available on GitHub (https://github.com/BGI-HangzhouAI/Genos) and Hugging Face Hub (https://huggingface.co/BGI-HangzhouAI).",
      "authors": "Lin Adi; Xie Bin; Ye Cheng; Wang Cheng; Chen Duoyuan; Wang Ercheng; Lu Fanfeng; Xue Guirong; Zhang Haiqiang; Zhan Jiajie; Zhang Jianfeng; Pang Jiangshuan; Liang Jianqiang; Lin Jiawei; Ma Jiaxin; Hu Jie; Ma Jing; Dong Jinni; Li Jiongzhen; Liu Junchen; Chen Junhong; Li Junyou; Ding Kai; Deng Kaiwen; Chen Kui; Wang Lihui; Liu Longqi; Guo Ling; Xiong Liwen; Yang Luhao; Cheng Ming; Chen Nanning; Chen Renzhong; Sun Shanxin; Li Shaoshuai; Chen Shicheng; Liu Shiping; Xie Siwei; Liu Suyan; Zhou Tao; Tang Wangyang; Zhang Weiqiang; Jiang Xianyue; Qi Xianzhi; Jin Xin; Tan Xinjiang; Hu Xinyue; Xu Xun; Feng Xuyang; Lu Yafei; Gao Yifan; Shang Yong; He Youzhe; Yuan Yue; Wang Yufan; Liu Yuqi; Xiao Zhan; Meng Zhangyuan; Li Zhaorong; Zhao Zhe; Yang Zheng; Wang Zilin",
      "year": "2025",
      "month": "Jan",
      "journal": "GigaScience",
      "source": "pubmed"
    },
    {
      "pmid": "41105015",
      "doi": "10.1093/gigascience/giaf053",
      "title": "Cross-modal contrastive learning decodes developmental regulatory features through chromatin potential analysis.",
      "abstract": "Emerging large-scale multimodal single-cell data jointly measure chromatin accessibility and transcription in the same cell, thus reconciling matched data paves an integrated route for comprehensive regulatory analysis. Here, we introduce Attune, a cross-modal contrastive learning framework to align paired gene expression and accessibility information. Systematic benchmarking shows Attune's superior performance for omics integration and gene expression prediction. We further introduce transformer-based cross-modal attention over fine-tuned gene and peak embeddings to infer regulatory interaction and discover significant differential signals of cell subtypes. Applied to a hair follicle maturation dataset, Attune reveals chromatin potential for the bifunctional transcription factor Gli3 at the gene level. In addition, the paired representations determine transmitted states across neonatal and mature cell types of cortical neuron differentiation at the cell level. Taken together, Attune offers an approach for regulatory inference across omics layers and enables more advanced omics analyses. Attune offers a versatile framework for integrating gene expression and chromatin accessibility, enabling the inference of regulatory mechanisms and the prediction of gene expression from cross-modal data.",
      "authors": "Yang Yueyuxiao; Xie Chenxi; He Qiushun; Yang Meng",
      "year": "2025",
      "month": "Jan",
      "journal": "GigaScience",
      "source": "pubmed"
    },
    {
      "pmid": "41097693",
      "doi": "10.3390/cancers17193165",
      "title": "Artificial Intelligence-Enhanced Liquid Biopsy and Radiomics in Early-Stage Lung Cancer Detection: A Precision Oncology Paradigm.",
      "abstract": "Lung cancer remains the leading cause of cancer-related mortality globally, largely due to delayed diagnosis in its early stages. While conventional diagnostic tools like low-dose CT and tissue biopsy are routinely used, they suffer from limitations including invasiveness, radiation exposure, cost, and limited sensitivity for early-stage detection. Liquid biopsy, a minimally invasive alternative that captures circulating tumor-derived biomarkers such as ctDNA, cfRNA, and exosomes from body fluids, offers promising diagnostic potential-yet its sensitivity in early disease remains suboptimal. Recent advances in Artificial Intelligence (AI) and radiomics are poised to bridge this gap. This review aims to explore how AI, in combination with radiomics, enhances the diagnostic capabilities of liquid biopsy for early detection of lung cancer and facilitates personalized monitoring strategies. Content Overview: We begin by outlining the molecular heterogeneity of lung cancer, emphasizing the need for earlier, more accurate detection strategies. The discussion then transitions into liquid biopsy and its key analytes, followed by an in-depth overview of AI techniques-including machine learning (e.g., SVMs, Random Forest) and deep learning models (e.g., CNNs, RNNs, GANs)-that enable robust pattern recognition across multi-omics datasets. The role of radiomics, which quantitatively extracts spatial and morphological features from imaging modalities such as CT and PET, is explored in conjunction with AI to provide an integrative, multimodal approach. This convergence supports the broader vision of precision medicine by integrating omics data, imaging, and electronic health records. The synergy between AI, liquid biopsy, and radiomics signifies a shift from traditional diagnostics toward dynamic, patient-specific decision-making. Radiomics contributes spatial information, while AI improves pattern detection and predictive modeling. Despite these advancements, challenges remain-including data standardization, limited annotated datasets, the interpretability of deep learning models, and ethical considerations. A push toward rigorous validation and multimodal AI frameworks is necessary to facilitate clinical adoption. The integration of AI with liquid biopsy and radiomics holds transformative potential for early lung cancer detection. This non-invasive, scalable, and individualized diagnostic paradigm could significantly reduce lung cancer mortality through timely and targeted interventions. As technology and regulatory pathways mature, collaborative research is crucial to standardize methodologies and translate this innovation into routine clinical practice.",
      "authors": "Cherukuri Swathi Priya; Kaur Anmolpreet; Goyal Bipasha; Kukunoor Hanisha Reddy; Sahito Areesh Fatima; Sachdeva Pratyush; Yerrapragada Gayathri; Elangovan Poonguzhali; Shariff Mohammed Naveed; Natarajan Thangeswaran; Janarthanan Jayarajasekaran; Richard Samuel; Pallikaranai Venkatesaprasath Shakthidevi; Karuppiah Shiva Sankari; Iyer Vivek N; Helgeson Scott A; Arunachalam Shivaram P",
      "year": "2025",
      "month": "Sep",
      "journal": "Cancers",
      "source": "pubmed"
    },
    {
      "pmid": "41092581",
      "doi": "10.1016/j.ebiom.2025.105957",
      "title": "Consistent performance of large language models in rare disease diagnosis across ten languages and 4917 cases.",
      "abstract": "Large language models (LLMs) are increasingly used medicine for diverse applications including differential diagnostic support. The training data used to create LLMs such as the Generative Pretrained Transformer (GPT) predominantly consist of English-language texts, but LLMs could be used across the globe to support diagnostics if language barriers could be overcome. Initial pilot studies on the utility of LLMs for differential diagnosis in languages other than English have shown promise, but a large-scale assessment on the relative performance of these models in a variety of European and non-European languages on a comprehensive corpus of challenging rare-disease cases is lacking. We created 4917 clinical vignettes using structured data captured with Human Phenotype Ontology (HPO) terms with the Global Alliance for Genomics and Health (GA4GH) Phenopacket Schema. These clinical vignettes span a total of 360 distinct genetic diseases with 2525 associated phenotypic features. We used translations of the Human Phenotype Ontology together with language-specific templates to generate prompts in English, Chinese, Czech, Dutch, French, German, Italian, Japanese, Spanish, and Turkish. We applied GPT-4o, version gpt-4o-2024-08-06, and the medically fine-tuned Meditron3-70B to the task of delivering a ranked differential diagnosis using a zero-shot prompt. An ontology-based approach with the Mondo disease ontology was used to map synonyms and to map disease subtypes to clinical diagnoses in order to automate evaluation of LLM responses. For English, GPT-4o placed the correct diagnosis at the first rank 19.9% and within the top-3 ranks 27.0% of the time. In comparison, for the nine non-English languages tested here the correct diagnosis was placed at rank 1 between 16.9% and 20.6%, within top-3 between 25.4% and 28.6% of cases. The Meditron3 model placed the correct diagnosis within the first 3 ranks for 20.9% of cases in English and between 19.9% and 24.0% for the other nine languages. The differential diagnostic performance of LLMs across a comprehensive corpus of rare-disease cases was largely consistent across the ten languages tested. This suggests that the utility of LLMs in clinical settings may extend to non-English clinical settings. NHGRI 5U24HG011449, 5RM1HG010860, R01HD103805 and R24OD011883. P.N.R. was supported by a Professorship of the Alexander von Humboldt Foundation; P.L. was supported by a National Grant (PMP21/00063 ONTOPREC-ISCIII, Fondos FEDER). C.M., J.R. and J.H.C. were supported in part by the Director, Office of Science, Office of Basic Energy Sciences, of the US Department of Energy (Contract No. DE-AC0205CH11231).",
      "authors": "Chimirri Leonardo; Caufield J Harry; Bridges Yasemin; Matentzoglu Nicolas; Gargano Michael; Cazalla Mario; Chen Shihan; Danis Daniel; Dingemans Alexander J M; Gehle Klara; Gehle Petra; Graefe Adam S L; Gu Weihong; Ladewig Markus S; Lapunzina Pablo; Nevado Julián; Niyonkuru Enock; Ogishima Soichi; Seelow Dominik; Tenorio Castaño Jair A; Turnovec Marek; de Vries Bert B A; Wang Kai; Wissink Kyran; Yüksel Zafer; Zucca Gabriele; Haendel Melissa A; Mungall Christopher J; Reese Justin; Robinson Peter N",
      "year": "2025",
      "month": "Nov",
      "journal": "EBioMedicine",
      "source": "pubmed"
    },
    {
      "pmid": "41091734",
      "doi": "10.1371/journal.pcbi.1013567",
      "title": "CASynergy: A causal attention model for interpretable prediction of cancer drug synergy.",
      "abstract": "Cancer drug combination therapies offer a promising strategy to overcome resistance and improve treatment efficacy, but identifying synergistic drug pairs is challenging due to complex biological interactions and tumor heterogeneity. Current machine learning algorithms for drug synergy prediction primarily rely on large-scale, multimodal datasets, yet suffer from critical limitations including poor interpretability, difficulty distinguishing causative biological relationships from correlations, and inadequate modeling of cancer-specific molecular interactions. To address these challenges, we propose CASynergy (Causal Attention and Cross-attention Synergy), a novel deep learning model for predicting cancer drug synergy that addresses limitations of prior approaches in accuracy and interpretability. CASynergy introduces a causal attention mechanism to distinguish true causal genomic features from spurious correlations, cell line-specific gene network construction to capture the unique molecular context of each cancer cell line, and a cross-attention module to integrate drug molecular features with cell line gene expression profiles. These improvements allow CASynergy to clearly identify significant drug-gene interactions and provides interpretable insights into why a combination is predicted to be synergistic. Experiments on two benchmark datasets (DrugCombDB and Oncology-Screen) suggests that CASynergy outperformed five state-of-the-art models. CASynergy offers a better and more reliable way to predict effective drug combinations. It works well across different cancer types and is easier to understand, which is important for personalized cancer treatment and finding new drugs.",
      "authors": "Li Haitao; Zheng Long; Li Lei; Chen Yiwei; Li Junjie; Zheng Chunhou; Su Yansen",
      "year": "2025",
      "month": "Oct",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    },
    {
      "pmid": "41088266",
      "doi": "10.1186/s13058-025-02129-z",
      "title": "Multimodal deep learning model for prediction of breast cancer recurrence risk and correlation with oncotype DX.",
      "abstract": "Proper stratification of recurrence risk in breast cancer is crucial for guiding treatment decisions. This study aims to predict the recurrence risk of breast cancer patients using a multimodal deep learning model that integrates multiple sequence MRI imaging features with clinicopathologic characteristics. In this retrospective study, we enrolled 574 patients with non-metastatic invasive breast cancer from two Chinese institutions between September 2012 and July 2019. We developed a multimodal deep learning (MDL) model by constructing a multi-instance learning framework based on convolutional neural networks. We integrated imaging features from T2WI, DWI, and DCE-MRI sequences with clinicopathologic features for breast cancer recurrence risk stratification. Subsequently, the performance of the MDL model was evaluated using receiver operating characteristic (ROC) curves, the Hosmer-Lemeshow test, calibration curves, and decision curve analysis (DCA). Survival analysis was conducted with Kaplan-Meier survival curves to stratify breast cancer patients into high and low-recurrence risk groups. Time-dependent ROC curves were used to assess 3-year, 5-year, and 7-year recurrence-free survival (RFS) for breast cancer patients. Additionally, we performed differential and enrichment analyses on Oncotype DX genes. We correlated these genes with clinicopathologic features and deep-learning radiographic features using univariate Cox regression and Pearson correlation analysis. The MDL model demonstrated good performance in predicting breast cancer recurrence risk and accurately differentiated between high- and low-recurrence risk groups, with an AUC as high as 0.915 (95% CI 0.8448-0.9856). The C-index of prediction models was 0.803 in the testing cohort. The AUCs for 5-year and 7-year RFS were 0.936 (95% CI 0.876-0.997) and 0.956 (95% CI 0.902-1.000) in the validation cohort. In the testing cohort, these AUCs were 0.836 (95% CI 0.763-0.909) and 0.783 (95% CI 0.676-0.891). This study found a significant correlation between Oncotype DX gene expression, clinicopathologic features, and deep-learning radiographic features (p < 0.05). This study validated the robust predictive accuracy of the MDL model in identifying high- and low-risk groups for recurrence. The correlations identified between Oncotype DX genes, clinicopathologic features, and deep-learning radiographic features offer novel insights for future biomarker research in breast cancer.",
      "authors": "Zhang Ruixin; Wang Kaiting; Wang Shiwei; Wang Chunjie; Cao Tingting; Ci Ce; Xu Maosheng; Ge Min",
      "year": "2025",
      "month": "Oct",
      "journal": "Breast cancer research : BCR",
      "source": "pubmed"
    },
    {
      "pmid": "41083998",
      "doi": "10.1186/s13059-025-03819-9",
      "title": "iPro-MP: a BERT-based model to predict multiple prokaryotic promoters.",
      "abstract": "Promoters, as essential cis-regulatory elements in prokaryotes, govern gene expression by mediating RNA polymerase binding through core motifs and long-range regulatory interactions, playing a pivotal role in cell metabolism and environmental adaptation. Hence, accurate identification of prokaryotic promoters is vital for understanding their biological functions. However, the existing tools for predicting prokaryotic promoters are mainly concentrated on individual model organisms, and their prediction accuracy needs to be further improved. To address these gaps, we develop iPro-MP, a transformer-based prokaryotic promoter prediction framework that we systematically evaluate across 23 phylogenetically diverse species, including both model and non-model organisms. iPro-MP utilizes a multi-head attention mechanism to capture textual information in DNA sequences and effectively learns the hidden patterns. Cross-species prediction demonstrates the necessity of constructing species-specific models. Through a series of experiments, iPro-MP shows outstanding performance, with the AUC exceeding 0.9 in 18 out of 23 species. Our novel approach to predicting prokaryotic promoters, iPro-MP, provides the superiority to other existing tools, especially in predicting non-model organisms. Finally, for the convenience of other researchers, the source code and datasets of iPro-MP are freely available at https://github.com/Jackie-Suv/iPro-MP .",
      "authors": "Su Wei; Yang Yuhe; Zhao Yafei; Yuan Shishi; Xie Xueqin; Hao Yuduo; Zhang Hongqi; Ye Dongxin; Lyu Hao; Lin Hao",
      "year": "2025",
      "month": "Oct",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "41057892",
      "doi": "10.1186/s13040-025-00487-0",
      "title": "An intelligent healthcare system for rare disease diagnosis utilizing electronic health records based on a knowledge-guided multimodal transformer framework.",
      "abstract": "Rare diseases are a common problem with millions of patients globally, but their diagnosis is difficult because of varied clinical presentations, small sample size, and disparate biomedical data sources. Current diagnostic tools are not able to combine multimodal information effectively, which results in a timely or wrong diagnosis. To fill this gap, this paper suggests a smart multimodal healthcare framework integrating electronic health records (EHRs), genomic sequences, and medical imaging to improve the detection of rare diseases. The framework uses Swin Transformer to extract hierarchical visual features in radiographic scans, Med-BERT and Transformer-XL to learn semantic and long-term temporal relations in longitudinal electronic health record narratives, and a Graph Neural Network (GNN)-based encoder to learn functional and structural relations in genomic sequences. The alignment of the cross-modal representation is further boosted with a Knowledge-Guided Contrastive Learning (KGCL) mechanism, which takes advantage of rare disease ontologies in Orphanet to improve the interpretability of the model and infusion of knowledge. To achieve strong performance, the Nutcracker Optimization Algorithm (NOA) is proposed to optimize hyperparameters, calibrate attention mechanisms, and enhance multimodal fusion. Experimental results on MIMIC-IV (EHR), ClinVar (genomics), and CheXpert (imaging) datasets show that the proposed framework significantly outperforms the state-of-the-art multimodal baselines in terms of accuracy and robustness of early rare disease diagnosis. This paper presents the opportunity to integrate hierarchical vision transformers, domain-specific language models, graph-based genomic encoders, and knowledge-directed optimization to make explainable, accurate, and clinically applicable healthcare decisions in rare disease settings.",
      "authors": "Abugabah Ahed; Shukla Prashant Kumar; Shukla Piyush Kumar; Pandey Ankur",
      "year": "2025",
      "month": "Oct",
      "journal": "BioData mining",
      "source": "pubmed"
    },
    {
      "pmid": "41052279",
      "doi": "10.1093/bib/bbaf533",
      "title": "Computational toxicology in drug discovery: applications of artificial intelligence in ADMET and toxicity prediction.",
      "abstract": "Toxicity risk assessment plays a crucial role in determining the clinical success and market potential of drug candidates. Traditional animal-based testing is costly, time-consuming, and ethically controversial, which has led to the rapid development of computational toxicology. This review surveys over 20 ADMET prediction platforms, categorizing them into rule/statistical-based methods, machine learning (ML) methods, and graph-based methods. We also summarize major toxicological databases into four types: chemical toxicity, environmental toxicology, alternative toxicology, and biological toxin databases, highlighting their roles in model training and validation. Furthermore, we review recent advancements in ML and artificial intelligence (AI) applied to toxicity prediction, covering acute toxicity, organ-specific toxicities, and carcinogenicity. The field is transitioning from single-endpoint predictions to multi-endpoint joint modeling, incorporating multimodal features. We also explore the application of generative modeling techniques and interpretability frameworks to improve the accuracy and credibility of predictions. Additionally, we discuss the use of network toxicology in evaluating the safety of traditional Chinese medicines (TCMs) and the potential of large language models (LLMs) in literature mining, knowledge integration, and molecular toxicity prediction. Finally, we address current challenges, including data quality, model interpretability, and causal inference, and propose future directions such as multi-omics integration, interpretable AI models, and domain-specific LLMs, aiming to provide more efficient and precise technical support for preclinical toxicity assessments in drug development.",
      "authors": "Zhang Jiangyan; Li Haolin; Zhang Yuncong; Huang Junyang; Ren Liping; Zhang Chuantao; Zou Quan; Zhang Yang",
      "year": "2025",
      "month": "Aug",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41050110",
      "doi": "10.1016/j.jpha.2025.101315",
      "title": "DTLCDR: A target-based multimodal fusion deep learning framework for cancer drug response prediction.",
      "abstract": "Accurate prediction of drug responses in cancer cell lines (CCLs) and transferable prediction of clinical drug responses using CCLs are two major tasks in personalized medicine. Despite the rapid advancements in existing computational methods for preclinical and clinical cancer drug response (CDR) prediction, challenges remain regarding the generalization of new drugs that are unseen in the training set. Herein, we propose a multimodal fusion deep learning (DL) model called drug-target and single-cell language based CDR (DTLCDR) to predict preclinical and clinical CDRs. The model integrates chemical descriptors, molecular graph representations, predicted protein target profiles of drugs, and cell line expression profiles with general knowledge from single cells. Among these features, a well-trained drug-target interaction (DTI) prediction model is used to generate target profiles of drugs, and a pretrained single-cell language model is integrated to provide general genomic knowledge. Comparison experiments on the cell line drug sensitivity dataset demonstrated that DTLCDR exhibited improved generalizability and robustness in predicting unseen drugs compared with previous state-of-the-art baseline methods. Further ablation studies verified the effectiveness of each component of our model, highlighting the significant contribution of target information to generalizability. Subsequently, the ability of DTLCDR to predict novel molecules was validated through ",
      "authors": "Yu Jie; Shi Cheng; Zhou Yiran; Liu Ningfeng; Zong Xiaolin; Liu Zhenming; Zhang Liangren",
      "year": "2025",
      "month": "Aug",
      "journal": "Journal of pharmaceutical analysis",
      "source": "pubmed"
    },
    {
      "pmid": "41041579",
      "doi": "10.21203/rs.3.rs-7657076/v1",
      "title": "Q RadFusion: Hybrid Quantum Classical Radiogenomic Framework for Breast Cancer Diagnosis.",
      "abstract": "Breast cancer remains the most common cancer in women worldwide, with early and accurate diagnosis critical for patient survival. Radiogenomics integrates imaging phenotypes with genomic profiles, offering a pathway to precision diagnostics. However, existing classical machine learning models often struggle with the high dimensionality and heterogeneity of multimodal data, leading to issues in calibration and reproducibility. This study presents Q RadFusion, a hybrid quantum-classical framework designed to enhance breast cancer diagnosis by fusing mammography and genomics data. Q RadFusion was implemented on two publicly available datasets: CBIS-DDSM (2,600 curated mammography cases, TCIA) and TCGA-BRCA (1,000 genomic profiles, GDC). Imaging preprocessing included bias-field correction, segmentation, and harmonization, while genomic data underwent normalization and imputation. Feature selection was performed using the Quantum Approximate Optimization Algorithm (QAOA), and features were mapped into a quantum Hilbert space using Variational Quantum Circuits (VQC). For multimodal fusion, ResNet encoded mammography features, and a Transformer encoded genomic features. Patient-level and site-held-out splits were used for evaluation. Q RadFusion achieved an AUC of 0.96 and accuracy of 94%, outperforming baselines including CNN-LSTM, ResNet + XGBoost, and multimodal Transformers. Ablation studies confirmed the contribution of quantum components, with optimal performance observed at circuit depth  Q RadFusion demonstrates that hybrid quantum-classical radiogenomic integration can deliver accurate, reproducible, and clinically meaningful diagnostic support for breast cancer, with strong potential for future clinical translation.",
      "authors": "C Padmaja; S Sivaneasan Bala Krishnan; S Ramacharan; Chakrabarti Prasun",
      "year": "2025",
      "month": "Sep",
      "journal": "Research square",
      "source": "pubmed"
    },
    {
      "pmid": "41041318",
      "doi": "10.3389/fimmu.2025.1630781",
      "title": "Correlation does not equal causation: the imperative of causal inference in machine learning models for immunotherapy.",
      "abstract": "Machine learning (ML) has played a crucial role in advancing precision immunotherapy by integrating multi-omics data to identify biomarkers and predict therapeutic responses. However, a prevalent methodological flaw persists in immunological studies-an overreliance on correlation-based analysis while neglecting causal inference. Traditional ML models struggle to capture the intricate dynamics of immune interactions and often function as \"black boxes.\" A systematic review of 90 studies on immune checkpoint inhibitors revealed that despite employing ML or deep learning techniques, none incorporated causal inference. Similarly, all 36 retrospective studies modeling melanoma exhibited the same limitation. This \"knowledge-practice gap\" highlights a disconnect: although researchers acknowledge that correlation does not imply causation, causal inference is often omitted in practice. Recent advances in causal ML, like Targeted-BEHRT, CIMLA, and CURE, offer promising solutions. These models can distinguish genuine causal relationships from spurious correlations, integrate multimodal data-including imaging, genomics, and clinical records-and control for unmeasured confounders, thereby enhancing model interpretability and clinical applicability. Nevertheless, practical implementation still faces major challenges, including poor data quality, algorithmic opacity, methodological complexity, and interdisciplinary communication barriers. To bridge these gaps, future efforts must focus on advancing research in causal ML, developing platforms such as the Perturbation Cell Atlas and federated causal learning frameworks, and fostering interdisciplinary training programs. These efforts will be essential to translating causal ML from theoretical innovation to clinical reality in the next 5-10 years-representing not only a methodological upgrade, but also a paradigm shift in immunotherapy research and clinical decision-making.",
      "authors": "Wang Jia-Wen; Meng Meng; Dai Mu-Wei; Liang Ping; Hou Juan",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in immunology",
      "source": "pubmed"
    },
    {
      "pmid": "41036838",
      "doi": "10.1161/CIRCULATIONAHA.125.074971",
      "title": "Characterizing the Immune Response in Pig-to-Human Heart Xenografts Using a Multimodal Diagnostic System.",
      "abstract": "Porcine genome editing has revolutionized xenotransplantation, recently enabling the first pig-to-human heart xenotransplants. However, the xenoimmune response in heart xenografts remains largely unexplored. This study aimed to precisely characterize the xenoimmune response and injury in 2 heart xenografts transplanted from 10-gene-edited pigs into brain-dead human recipients. We analyzed xenograft biopsy specimens 66 hours after reperfusion using a multimodal phenotyping approach combining morphological evaluation, immunophenotyping, ultrastructural assessment, automated quantification of multiplex immunofluorescence staining, and gene expression profiling. Xenografts before implantation and wild-type pig hearts with and without ischemia/reperfusion injury and brain death were used as controls. Both xenografts showed evidence of endothelial activation and mild microvascular inflammation without capillary C4d deposition. Immune infiltrates were mainly composed of CD15+ and CD68+ innate immune cells. Ultrastructural assessment showed endothelial swelling with occasional intravascular leucocytes. Deep learning-based automated multiplex immunofluorescence analysis confirmed that microvascular inflammation was primarily associated with CD15+ and CD68+ innate immune cells. Both xenografts showed increased expression of genes and pathways associated with monocyte/macrophage activation, neutrophil activation, interferon-gamma response, natural killer cell burden, endothelial activation, apoptosis, and injury repair. This phenotype was absent in all control pig hearts independent of ischemia/reperfusion injury and brain death. Multimodal phenotyping of pig-to-human heart xenografts revealed early signs of xenoimmune response, characterized by mild innate microvascular inflammation, endothelial activation, and a molecular signature characteristic of antibody-mediated rejection. Developing such a precision diagnostic system could improve graft monitoring in future clinical settings.",
      "authors": "Giarraputo Alessia; Morgand Erwan; Stern Jeffrey; Mezine Fariza; Coutance Guillaume; Goutaudier Valentin; Sannier Aurelie; Certain Anais; Hauet Thierry; Giraud Sebastien; Kerforne Thomas; Allain Geraldine; Ayares David; Khalil Karen; Kim Jacqueline; Mehta Sapna; Narula Navneet; Reyentovich Alex; Smith Deane; Tissier Renaud; Saraon Tajinderpal; Kadosh Bernard; Divita Michael; Goldberg Randal; Pass Harvey; Mangiola Massimo; Bruneval Patrick; Griesemer Adam; Moazami Nader; Montgomery Robert A; Loupy Alexandre",
      "year": "2025",
      "month": "Dec",
      "journal": "Circulation",
      "source": "pubmed"
    },
    {
      "pmid": "41031875",
      "doi": "10.1093/bib/bbaf521",
      "title": "SurvBoard: standardized benchmarking for multi-omics cancer survival models.",
      "abstract": "Multi-omics data, which include genomic, transcriptomic, epigenetic, and proteomic data, are gaining increasing importance for determining the clinical outcomes of cancer patients. Several recent studies have evaluated various multimodal integration strategies for cancer survival prediction, highlighting the need for standardizing model performance results. Addressing this issue, we introduce SurvBoard, a benchmark framework that standardizes key experimental design choices. SurvBoard enables comparisons between single-cancer and pan-cancer data models and assesses the benefits of using patient data with missing modalities. We also address common pitfalls in preprocessing and validating multi-omics cancer survival models. We apply SurvBoard to several exemplary use cases, further confirming that statistical models tend to outperform deep learning methods, especially for metrics measuring survival function calibration. Moreover, most models exhibit better performance when trained in a pan-cancer context and can benefit from leveraging samples for which data of some omics modalities are missing. We provide a web service for model evaluation and to make our benchmark results easily accessible and viewable: https://www.survboard.science/. All code is available on GitHub: https://github.com/BoevaLab/survboard/. All benchmark outputs are available on Zenodo: 10.5281/zenodo.11066226. A video tutorial on how to use the Survboard leaderboard is available on YouTube at https://youtu.be/HJrdpJP8Vvk.",
      "authors": "Wissel David; Janakarajan Nikita; Grover Aayush; Toniato Enrico; Martínez Maria Rodríguez; Boeva Valentina",
      "year": "2025",
      "month": "Aug",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "41023606",
      "doi": "10.1186/s12864-025-12089-5",
      "title": "Identification of key genes for fish adaptation to freshwater and seawater based on attention mechanism.",
      "abstract": "The evolutionary divergence of freshwater and marine fish reflects their adaptation to distinct ecological environments, with differences evident in their morphological traits, physiological functions, and genomic structures. Traditional molecular methods often fail to uncover the intricate regulatory relationships among genes under environmental stress. This study proposes the weighted attention gene analysis (WAGA) model, a novel approach that integrates natural language processing (NLP) for protein-coding gene feature representation with deep learning and self-attention (SA) mechanisms. WAGA effectively identifies key genes associated with sensory functions, osmoregulation, and growth and development on the basis of attention weights. The experimental results highlight its effectiveness in revealing genes crucial for ecological adaptation and evolution. This approach is essential for elucidating the mechanisms of ecological adaptability and evolutionary processes, while also offering novel insights and tools to support targeted breeding in aquaculture and fish genomics research.",
      "authors": "Qian Songping; Zhao Youjie; Liu Fangrong; Liu Lei; Zhou Qingyang; Zhang Shunrong; Cao Yong",
      "year": "2025",
      "month": "Sep",
      "journal": "BMC genomics",
      "source": "pubmed"
    },
    {
      "pmid": "41020875",
      "doi": "10.3390/cimb47090753",
      "title": "Interpretable Transfer Learning for Cancer Drug Resistance: Candidate Target Identification.",
      "abstract": "Tumor drug resistance exhibits substantial heterogeneity across cancer types, reflecting distinct molecular mechanisms in each malignancy. To characterize this complexity, we developed a pan-cancer transfer learning framework that integrates bulk RNA-seq data with a residual variational autoencoder (Res VAE) backbone. Five models were trained on the Genomics of Drug Sensitivity in Cancer (GDSC) dataset, which includes drug response profiles for 72 chemotherapeutic agents. Among them, three models are specially designed by incorporating variational autoencoders and large pretrained models (LLMs): the LLM large VAE (VAE_LL), the LLM small VAE (VAE_LS), and the LLM distillation VAE (VAE_LD). Random Forest (RF) and eXtreme Gradient Boosting (XGB) were included as ensemble learning baselines. After internal cross-validation, the top four models (VAE_LL, VAE_LD, XGB, and RF) were applied to five representative TCGA cohorts comprising 1,836 patients. For each cancer type, resistance to nine clinically relevant first-line drugs was modeled, resulting in 180 drug-cancer prediction tasks. Among all models, VAE_LD achieved the best overall performance, with a mean AUC of 0.81 and an F1 score of 0.92 on the GDSC benchmark, and maintained strong predictive power in the clinical validation phase. Interpretation analyses identified tumor-specific resistance biomarkers with clinical significance. In lung adenocarcinoma, elevated expression of ",
      "authors": "Zhang Wenjie; Wu Xisong; Chen Liang; Wan Xinyue",
      "year": "2025",
      "month": "Sep",
      "journal": "Current issues in molecular biology",
      "source": "pubmed"
    },
    {
      "pmid": "41009571",
      "doi": "10.3390/ijms26189004",
      "title": "SenolyticSynergy: An Attention-Based Network for Discovering Novel Senolytic Combinations via Human Aging Genomics.",
      "abstract": "Senolytics, a category of drugs targeting aging processes, have garnered significant attention since their emergence in 2015. Unlike traditional drug development approaches that rely on randomized screening, research on aging-related pharmaceuticals has employed mechanism-based strategies, resulting in the discovery of the pioneering combination therapy of dasatinib (D) and quercetin (Q). Although preliminary studies with senolytic drug combinations have shown promising outcomes, the predictive capabilities of the research in this field remain limited by the extensive experimental data requirements. In this study, we employed differential gene expression analysis and machine learning techniques to investigate the combinatorial effects of senolytic drugs. We identified 1624 core aging-related genes and used this dataset to retrain a multimodal attention mechanism model, creating a specialized framework, SenolyticSynergy, for predicting effective senolytic drug combinations. We then utilized 63 established senolytic compounds as starting points for combination testing, developing a comprehensive dataset of 1953 potential drug combinations for aging interventions. Following rigorous filtration, we identified 190 high-confidence drug combinations and predicted their synergistic scores. Among these combinations, ten demonstrated exceptionally high synergistic scores, exceeding 8. The combination of temsirolimus and nitazoxanide ranked first and may be the most promising candidate. The analysis of the literature data and computational studies of molecular structures using 3D modeling validated the accuracy of these predictions. This framework paves the way for large-scale research into anti-aging drug combinations, advancing research capabilities in this field.",
      "authors": "Ye Yaowen; Su Ting; Gao Jiayi; Ming Dengming",
      "year": "2025",
      "month": "Sep",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "41007283",
      "doi": "10.3390/biology14091137",
      "title": "Biological Sequence Representation Methods and Recent Advances: A Review.",
      "abstract": "Biological-sequence representation methods are pivotal for advancing machine learning in computational biology, transforming nucleotide and protein sequences into formats that enhance predictive modeling and downstream task performance. This review categorizes these methods into three developmental stages: computational-based, word embedding-based, and large language model (LLM)-based, detailing their principles, applications, and limitations. Computational-based methods, such as k-mer counting and position-specific scoring matrices (PSSM), extract statistical and evolutionary patterns to support tasks like motif discovery and protein-protein interaction prediction. Word embedding-based approaches, including Word2Vec and GloVe, capture contextual relationships, enabling robust sequence classification and regulatory element identification. Advanced LLM-based methods, leveraging Transformer architectures like ESM3 and RNAErnie, model long-range dependencies for RNA structure prediction and cross-modal analysis, achieving superior accuracy. However, challenges persist, including computational complexity, sensitivity to data quality, and limited interpretability of high-dimensional embeddings. Future directions prioritize integrating multimodal data (e.g., sequences, structures, and functional annotations), employing sparse attention mechanisms to enhance efficiency, and leveraging explainable AI to bridge embeddings with biological insights. These advancements promise transformative applications in drug discovery, disease prediction, and genomics, empowering computational biology with robust, interpretable tools.",
      "authors": "Zhang Hongwei; Shi Yan; Wang Yapeng; Yang Xu; Li Kefeng; Im Sio-Kei; Han Yu",
      "year": "2025",
      "month": "Aug",
      "journal": "Biology",
      "source": "pubmed"
    },
    {
      "pmid": "41007223",
      "doi": "10.3390/bioengineering12090979",
      "title": "From Anatomy to Genomics Using a Multi-Task Deep Learning Approach for Comprehensive Glioma Profiling.",
      "abstract": "Gliomas are among the most complex and lethal primary brain tumors, necessitating precise evaluation of both anatomical subregions and molecular alterations for effective clinical management. To find a solution to the disconnected nature of current bioimage analysis pipelines, where anatomical segmentation based on MRI and molecular biomarker prediction are done as separate tasks, we use here Molecular-Genomic and Multi-Task (MGMT-Net), a one deep learning scheme that carries out the task of the multi-modal MRI data without any conversion. MGMT-Net incorporates a novel Cross-Modality Attention Fusion (CMAF) module that dynamically integrates diverse imaging sequences and pairs them with a hybrid Transformer-Convolutional Neural Network (CNN) encoder to capture both global context and local anatomical detail. This architecture supports dual-task decoders, enabling concurrent voxel-wise tumor delineation and subject-level classification of key genomic markers, including the IDH gene mutation, the 1p/19q co-deletion, and the TERT gene promoter mutation. Extensive validation on the Brain Tumor Segmentation (BraTS 2024) dataset and the combined Cancer Genome Atlas/Erasmus Glioma Database (TCGA/EGD) datasets demonstrated high segmentation accuracy and robust biomarker classification performance, with strong generalizability across external institutional cohorts. Ablation studies further confirmed the importance of each architectural component in achieving overall robustness. MGMT-Net presents a scalable and clinically relevant solution that bridges radiological imaging and genomic insights, potentially reducing diagnostic latency and enhancing precision in neuro-oncology decision-making. By integrating spatial and genetic analysis within a single model, this work represents a significant step toward comprehensive, AI-driven glioma assessment.",
      "authors": "Abdusalomov Akmalbek; Umirzakova Sabina; Bekmirzaev Obidjon; Dauletov Adilbek; Buriboev Abror; Kutlimuratov Alpamis; Nishanov Akhram; Nasimov Rashid; Oh Ryumduck",
      "year": "2025",
      "month": "Sep",
      "journal": "Bioengineering (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "41002412",
      "doi": "10.3390/cells14181449",
      "title": "Sequence-Based Protein-Protein Interaction Prediction and Its Applications in Drug Discovery.",
      "abstract": "Aberrant protein-protein interactions (PPIs) underpin a plethora of human diseases, and disruption of these harmful interactions constitute a compelling treatment avenue. Advances in computational approaches to PPI prediction have closely followed progress in deep learning and natural language processing. In this review, we outline the state-of-the-art methods for sequence-based PPI prediction and explore their impact on target identification and drug discovery. We begin with an overview of commonly used training data sources and techniques used to curate these data to enhance the quality of the training set. Subsequently, we survey various PPI predictor types, including traditional similarity-based approaches, and deep learning-based approaches with a particular emphasis on transformer architecture. Finally, we provide examples of PPI prediction in system-level proteomics analyses, target identification, and designs of therapeutic peptides and antibodies. This review sheds light on sequence-based PPI prediction, a broadly applicable alternative to structure-based methods, from a unique perspective that emphasizes their roles in the drug discovery process and rigorous model assessment.",
      "authors": "Charih François; Green James R; Biggar Kyle K",
      "year": "2025",
      "month": "Sep",
      "journal": "Cells",
      "source": "pubmed"
    },
    {
      "pmid": "41000926",
      "doi": "10.1101/2025.09.21.677619",
      "title": "Predicting functional constraints across evolutionary timescales with phylogeny-informed genomic language models.",
      "abstract": "Genomic language models (gLMs) have emerged as a powerful approach for learning genome-wide functional constraints directly from DNA sequences. However, standard gLMs adapted from natural language processing often require extremely large model sizes and computational resources, yet still fall short of classical evolutionary models in predictive tasks. Here, we introduce GPN-Star (Genomic Pretrained Network with Species Tree and Alignment Representation), a biologically grounded gLM featuring a phylogeny-aware architecture that leverages whole-genome alignments and species trees to model evolutionary relationships explicitly. Trained on alignments spanning vertebrate, mammalian, and primate evolutionary timescales, GPN-Star achieves state-of-the-art performance across a wide range of variant effect prediction tasks in both coding and non-coding regions of the human genome. Analyses across timescales reveal task-dependent advantages of modeling more recent versus deeper evolution. To demonstrate its potential to advance human genetics, we show that GPN-Star substantially outperforms prior methods in prioritizing pathogenic and fine-mapped GWAS variants; yields unprecedented enrichments of complex trait heritability; and improves power in rare variant association testing. Extending beyond humans, we train GPN-Star for five model organisms - ",
      "authors": "Ye Chengzhong; Benegas Gonzalo; Albors Carlos; Li Jianan Canal; Prillo Sebastian; Fields Peter D; Clarke Brian; Song Yun S",
      "year": "2025",
      "month": "Sep",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41000812",
      "doi": "10.1101/2025.09.19.677475",
      "title": "Predicting dynamic expression patterns in budding yeast with a fungal DNA language model.",
      "abstract": "Predicting gene expression from DNA sequence remains challenging due to complex regulatory codes. We introduce a masked DNA language model pretrained on 165 fungal genomes closely related to budding yeast that captures conserved regulatory grammar. Fine-tuning the LM on yeast RNA-seq data-including high-resolution transcriptional regulator induction time courses generated in this study-yielded Shorkie, a model that substantially improves gene expression prediction compared to baselines trained without self-supervision. Shorkie identified canonical transcription factor (TF) binding motifs and tracked their usage across induction experiments. Furthermore, Shorkie accurately predicted variant effects, outperforming leading sequence-to-expression models in ",
      "authors": "Chao Kuan-Hao; Magzoub Majed Mohamed; Stoops Emily; Hackett Sean; Linder Johannes; Kelley David R",
      "year": "2025",
      "month": "Sep",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "41000745",
      "doi": "10.1101/2025.09.12.675662",
      "title": "Predicting the unseen: a diffusion-based debiasing framework for transcriptional response prediction at single-cell resolution.",
      "abstract": "Predicting cellular responses to genetic perturbations is critical for advancing our understanding of gene regulation. While single-cell CRISPR perturbation assays such as Perturb-seq provide direct measurements of gene function, the scale of these experiments is limited by cost and feasibility. This motivates the development of computational approaches that can accurately infer responses to unmeasured perturbations from related experimental data. We introduce dbDiffusion, a generative framework that integrates diffusion models with classifier-free guidance derived from perturbation information, operating in latent space through a variational autoencoder (VAE). Diffusion models are probabilistic generative models that approximate data distributions by reversing a Markovian diffusion process, progressively denoising Gaussian noise into structured outputs. By exploiting biological similarities in gene expression profiles and relationships among perturbations, dbDiffusion enables the conditional generation of gene expressions for previously unobserved perturbations. In contrast to competing approaches, dbDiffusion does not rely on LLM or foundation models, which have been found to yield unsatisfactory results. Rather, it leverages embeddings derived from measured perturbations to generalize to unseen perturbations, effectively transferring information across related experimental conditions. In benchmarking against state-of-the-art methods on Perturb-seq datasets, dbDiffusion demonstrates superior accuracy in predicting perturbation responses. A methodological innovation of dbDiffusion is the integration of prediction-powered inference, which corrects for biases inherent in generative models and enables statistically rigorous downstream tasks, including identification of differentially expressed genes. By combining deep generative modeling with principled inference, dbDiffusion establishes a scalable computational framework for predicting and analyzing transcriptomic perturbation responses, significantly extending the utility of Perturb-seq experiments.",
      "authors": "Shang Ergan; Wei Yuting; Roeder Kathryn",
      "year": "2025",
      "month": "Sep",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40984701",
      "doi": "10.1093/bib/bbaf492",
      "title": "Benchmarking large language models for genomic knowledge with GeneTuring.",
      "abstract": "Large language models (LLMs) show promise in biomedical research, but their effectiveness for genomic inquiry remains unclear. We developed GeneTuring, a benchmark consisting of 16 genomics tasks with 1600 curated questions, and manually evaluated 48 000 answers from 10 LLM configurations, including GPT-4o (via API, ChatGPT with web access, and a custom Generative Pretrained Transformer (GPT) setup), GPT-3.5, Claude 3.5, Gemini Advanced, GeneGPT (both slim and full), BioGPT, and BioMedLM. A custom GPT-4o configuration integrated with National Center for Biotechnology Information (NCBI) Application Programming Interfaces (APIs), developed in this study as SeqSnap, achieved the best overall performance. GPT-4o with web access and GeneGPT demonstrated complementary strengths. Our findings highlight both the promise and current limitations of LLMs in genomics, and emphasize the value of combining LLMs with domain-specific tools for robust genomic intelligence. GeneTuring offers a key resource for benchmarking and improving LLMs in biomedical research.",
      "authors": "Shang Xinyi; Liao Xu; Ji Zhicheng; Hou Wenpin",
      "year": "2025",
      "month": "Aug",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40980765",
      "doi": "",
      "title": "Advancing Digital Precision Medicine for Chronic Fatigue Syndrome through Longitudinal Large-Scale Multi-Modal Biological Omics Modeling with Machine Learning and Artificial Intelligence.",
      "abstract": "Myalgic Encephalomyelitis/Chronic Fatigue Syndrome (ME/CFS) is a complex debilitating disorder manifesting as severe fatigue and post-exertional malaise. The etiology of ME/CFS remains elusive. Here in chapter one, we present a deep metagenomic analysis of stool combined with plasma metabolomics and clinical phenotyping of two ME/CFS cohorts with short (<4y, n=75) or long-term disease (>10y, n=79) compared to healthy controls (n=79). First, we describe microbial and metabolomic dysbiosis in ME/CFS patients. Short-term patients showed significant microbial dysbiosis, while long-term patients had largely resolved microbial dysbiosis but had metabolic and clinical aberrations. Second, we identified phenotypic, microbial, and metabolic biomarkers specific to patient cohorts. These revealed potential functional mechanisms underlying disease onset and duration, including reduced microbial butyrate biosynthesis together with a reduction in plasma butyrate, bile acids, and benzoate. In addition to the insights derived, our data represent an important resource to facilitate mechanistic hypotheses of host-microbiome interactions in ME/CFS. We then studied a more generalized question in chapter two: chronic diseases like ME/CFS and long COVID exhibit high heterogeneity with multifactorial etiology and progression, complicating diagnosis and treatment. To address this, we developed BioMapAI, an explainable Deep Learning framework using the richest longitudinal multi- 'omics dataset for ME/CFS to date. This dataset includes gut metagenomics, plasma metabolome, immune profiling, blood labs, and clinical symptoms. By connecting multi- 'omics to a symptom matrix, BioMapAI identified both disease- and symptom-specific biomarkers, reconstructed symptoms, and achieved state-of-the-art precision in disease classification. We also created the first connectivity map of these 'omics in both healthy and disease states and revealed how microbiome-immune-metabolome crosstalk shifted from healthy to ME/CFS. Thus, we proposed several innovative mechanistic hypotheses for ME/CFS: Disrupted microbial functions - SCFA (butyrate), BCAA (amino acid), tryptophan, benzoate - lost connection with plasma lipids and bile acids, and activated inflammatory and mucosal immune cells (MAIT, ",
      "authors": "Xiong Ruoyun",
      "year": "2025",
      "month": "Jun",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "40979439",
      "doi": "10.3389/frai.2025.1496948",
      "title": "Global reform population health management as stewarded by Higher Expert Medical Science Safety (HEMSS).",
      "abstract": "As described in a Memorandum of Understanding (MoU) on AI infrastructure, global human phenotype ontology (HPO) is a priority for the US and the UK. The UK NHS Act of 1946 and the Medicare and Medicaid Act of 1965 classify using genomics as primary care, supporting international HPO aims for Population Health Management (PHM). The Higher Expert Medical Science Safety (HEMSS) proposes the NHS England, Genomics, and Biobank agile group developers. The HEMSS strategy executes the PHM of the HPO through digital records, pilot citizen predictor pre-eXams, and precise eXam intercept classifications, continuously improving public safety. PHM reform includes biobank opportunities for Value-Based Care (VBC) stratifying genomic and socio-environmental factors that risk HPO in disease segmentation. The author evaluated a standard approach to PHM for HPO with mature and advanced interoperable standards. A reform toolkit aligns adversarial, neural, and transformer models for Generative AI by utilizing multimodal data nuanced for fairness in Quantum Intelligence. The recommendations include HEMSS steps from well-being evaluations to the PHM strategy for HPO in the UK-US. Concepts involve piloting the scaling up of neighborhood clinics and federal centers through reform classification. Plans for citizen privacy facilitate data use with access to reference biobanks, ensuring DNA democratization and national cybersecurity. The UK NHSE corporate governance and US federal authorities monitor and reform the Integrated Care Board assessments and the Centers for Medicare and Medicaid Services surveys using agile methods. The UK-US MoU for AI safety is an international ideal for PHM, creating a safe space for HPO adherence to predictive and interceptive adoption for health and socioeconomic growth. HEMSS Agile Group Development impacts ethical and societal primary care debates. HEMSS discussions on global public health inclusiveness and national engagement aim to govern the classification phases for adherence. Therefore, debates on UK-US accreditation or regulation on the future of Artificial General Intelligence follow. The author concludes in support of the Population Health Management Expert Medical Science Safety Agile Group Development Program. The UK and US governments would benefit from this proposition, and international goals for well-being and socioeconomic growth would also be supported.",
      "authors": "Henry James Andrew",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in artificial intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "40973591",
      "doi": "10.1016/j.alit.2025.08.005",
      "title": "RNA velocity and beyond: Current advances in modeling single-cell transcriptional dynamics.",
      "abstract": "Single-cell RNA sequencing (scRNA-seq) has revolutionized biology through high-throughput quantification of gene expression at individual cell resolution. However, standard scRNA-seq provides only static cellular snapshots, obscuring dynamic processes that unfold temporally, such as differentiation, reprogramming, and disease progression. RNA Velocity, introduced in 2018, offers a groundbreaking solution. By leveraging unspliced pre-mRNA and spliced mRNA information, RNA Velocity models infer instantaneous gene expression change rates and effectively predict future transcriptional states over hour-long timescales. This review charts the evolution of this powerful concept, beginning with foundational principles and mathematical models of transcriptional dynamics. We explore Velocyto's pioneering implementation, discuss successes and limitations, and then examine second-generation advanced computational tools that generalize the framework, including scVelo, dynamo, and CellRank. A dedicated section highlights growing applications in allergy and immunology research, where these methods reveal novel disease mechanisms in asthma, atopic dermatitis, and chronic inflammation by analyzing immune cell differentiation and state transitions. We explored modern frontiers, including RNA Velocity integration with spatial and multimodal data, and the latest deep learning-based methods. Finally, we addressed the current challenges and remaining limitations of RNA Velocity analysis, offering insights into best practices and future directions. Throughout, we emphasize applications to allergic and immune-mediated diseases-including asthma, atopic dermatitis, and prurigo nodularis-to guide researchers and clinicians in allergy and immunology. RNA Velocity is becoming indispensable for navigating the complex, dynamic cellular world and transforming our understanding of temporal biological processes from static observations to predictive, dynamic insights that illuminate cellular fate decisions and disease mechanisms.",
      "authors": "Shimamura Teppei",
      "year": "2025",
      "month": "Oct",
      "journal": "Allergology international : official journal of the Japanese Society of Allergology",
      "source": "pubmed"
    },
    {
      "pmid": "40968257",
      "doi": "10.1038/s41698-025-01092-4",
      "title": "Multi-modal characterization of metabolic and immune gene clusters in adrenocortical carcinoma treatment.",
      "abstract": "Adrenocortical carcinoma (ACC) is an uncommon and aggressive endocrine malignancy, characterized by limited therapeutic options and considerable variability in patient outcomes. The challenge is to combine the complex information of ACC with artificial intelligence (AI) and clinical and pathology data to achieve precision medicine and improve patient prognosis. We developed the Steroid-related Immune Score (SIS) using multi-modal analysis of genomics, digital pathology, and artificial intelligence and validated it in external datasets. In addition, we conducted single-cell RNA sequencing (scRNA-seq) of small samples and in vitro functional experiments. SIS delivered a stable performance with an AUC of 0.8 ± 0.01 in the ResNet50 and Vision Transformer-B16 models. We validated the best model in external ACC cohorts. Using Class Activation Maps (CAMs) technology revealed that SIS was associated with lymphocyte infiltration, establishing it as a new feature in addition to the Weiss scoring system. Patients in the high SIS group responded well to immunotherapy, while the low SIS group showed adaptability to hormone inhibition therapy. Single-cell RNA sequencing data revealed the relationship between the tumor microenvironment and drug resistance in ACC. In vitro functional assays demonstrated that elevated DHCR7 gene expression correlated with unfavorable prognosis and treatment sensitivity, identifying it as a prospective therapeutic target. Furthermore, there are similarities between the metabolic characteristics of ACC and schizophrenia, such as calcium and iron ion levels. Our multi-modal analysis comprehensively characterizes the immune microenvironment of ACC, emphasizing the synergistic regulation of metabolic and immune gene clusters that influence ACC patients' responses to immune and hormone therapies.",
      "authors": "Hao Wenjun; Yao Luhan; Wang Yanlong; Wan Jiayu; Zhu Yuyan; Dai Zhihong; Sun Xu; Fan Bo; Wang Yuchao; Xiang Hao; Gao Xiang; Liang Peng; Zhao Haolin; Wang Liang; Wang Ying; Wang Hongyu; Yang Deyong; Liu Zhiyu",
      "year": "2025",
      "month": "Sep",
      "journal": "NPJ precision oncology",
      "source": "pubmed"
    },
    {
      "pmid": "40967225",
      "doi": "10.1016/j.xgen.2025.101007",
      "title": "Single-nucleus transcriptome atlas of orbitofrontal cortex in ALS with a deep learning-based decoding of alternative polyadenylation mechanisms.",
      "abstract": "Amyotrophic lateral sclerosis (ALS) and frontotemporal lobar degeneration (FTLD) are fatal neurodegenerative diseases sharing clinical and pathological features. Both involve complex neuron-glia interactions, but cell-type-specific alterations remain poorly defined. We performed single-nucleus RNA sequencing of the frontal cortex from C9orf72-related ALS (with and without FTLD) and sporadic ALS (sALS). Neurons showed prominent changes in mitochondrial function, protein homeostasis, and chromatin remodeling. Comparison with independent datasets from other cortical regions revealed consistent pathway alterations, including upregulation of STMN2 and NEFL across brain regions and subtypes. We further examined dysregulation of alternative polyadenylation (APA), an understudied post-transcriptional mechanism, uncovering cell-type-specific APA patterns. To investigate its regulation, we developed the alternative polyadenylation network (APA-Net), a multi-modal deep learning model integrating transcript sequences and RNA-binding protein (RBP) expression profiles to predict APA. This atlas advances our understanding of ALS/FTLD molecular pathology and provides a valuable resource for future mechanistic studies.",
      "authors": "McKeever Paul M; Sababi Aiden M; Sharma Raghav; Xu Zhiyu; Xiao Shangxi; McGoldrick Philip; Ketela Troy; Sato Christine; Moreno Danielle; Visanji Naomi; Kovacs Gabor G; Keith Julia; Zinman Lorne; Rogaeva Ekaterina; Goodarzi Hani; Bader Gary D; Robertson Janice",
      "year": "2025",
      "month": "Dec",
      "journal": "Cell genomics",
      "source": "pubmed"
    },
    {
      "pmid": "40966644",
      "doi": "10.1093/bib/bbaf467",
      "title": "Graph-based deep learning for integrating single-cell and bulk transcriptomic data to identify clinical cancer subtypes.",
      "abstract": "The integration of single-cell RNA sequencing (scRNA-seq) and bulk transcriptomic data has become essential for deciphering the complex heterogeneity of cancer and identifying clinical cancer subtypes. However, the inherent challenges posed by the high dimensionality, sparsity, and noise characteristics of scRNA-seq data have significantly hindered its widespread clinical translation. To address these limitations, we introduce single-cell and bulk transcriptomic graph deep learning, a graph-based deep learning method that synergistically integrates scRNA-seq and bulk transcriptomic data to precisely identify cancer subtypes and predict clinical outcomes. scBGDL constructs sample-specific gene graphs modeling complex gene-gene interactions and cellular relationships. The architecture employs Graph Attention Networks for feature aggregation, MinCutPool layers for dimensionality reduction, and Transformer modules to capture high-order biological dependencies. Independently validated in each of 16 distinct The Cancer Genome Atlas cancer types, scBGDL significantly outperformed existing methods in prognostic accuracy (mean C-index: 0.7060 versus 0.6709 max competitor), demonstrating robustness and generalizability to diverse transcriptional architectures. To demonstrate clinical versatility, we further evaluated scBGDL in three therapeutic contexts using multicenter cohorts: lung adenocarcinoma survival prediction (n = 1099), epithelial ovarian cancer platinum-based chemotherapy response (n = 762), skin cutaneous melanoma immunotherapy outcome (n = 305). scBGDL consistently delivered robust risk stratification (log-rank P < 0.05 across cohorts), identified key driver edges, and uncovered clinically relevant biological interpretations. By enabling multimodal data integration and interpretable biological insights, scBGDL advances precision oncology for prognosis prediction, therapy optimization, and biomarker discovery. The source code for scBGDL model is available online (https://github.com/NEFLab/scBGDL).",
      "authors": "Liu Yixin; Zhang Dandan; Liu Tianyu; Wang Ao; Wang Guohua; Zhao Yuming",
      "year": "2025",
      "month": "Aug",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40962325",
      "doi": "10.5483/BMBRep.2025-0020",
      "title": "Deep learning application for genomic data analysis.",
      "abstract": "Modern genomic sequencing techniques have advanced rapidly, thereby improving data production rates and dimensionality. With this accelerated growth, machine learning, especially deep learning, has been leveraged to analyze complex data and complement conventional bioinformatics methods. Deep learning approaches have been successfully applied in genomics, leading to the development of state-of-the-art models and significantly improved interpretation of genomic data. Here, we review deep learning models in four genomic domains: variant calling, gene expression regulation, motif finding, and 3D chromatin interactions. We summarize the key aspects of model development, such as training and generalization, that enable the efficient application of deep learning models in genomic research. Real-world applications have demonstrated the reliability and efficiency of these models for predicting genomic profiles. Finally, we highlight the future directions of deep learning approaches in genomics by discussing the challenges related to genome tokenization and multi-omics data integration. [BMB Reports 2026; 59(1): 60-68].",
      "authors": "Jeong Chang Beom; Cho Hyein; Park Daechan",
      "year": "2026",
      "month": "Jan",
      "journal": "BMB reports",
      "source": "pubmed"
    },
    {
      "pmid": "40961977",
      "doi": "10.1088/1741-2552/ae087d",
      "title": "An interpretable generative multimodal neuroimaging-genomics framework for decoding Alzheimer's disease.",
      "abstract": "",
      "authors": "Dolci Giorgio; Cruciani Federica; Abdur Rahaman Md; Abrol Anees; Chen Jiayu; Fu Zening; Boscolo Galazzo Ilaria; Menegaz Gloria; Calhoun Vince D",
      "year": "2025",
      "month": "Sep",
      "journal": "Journal of neural engineering",
      "source": "pubmed"
    },
    {
      "pmid": "40950234",
      "doi": "10.1101/2025.08.21.671434",
      "title": "STARNet enables spatially resolved inference of gene regulatory networks from spatial multi-omics data.",
      "abstract": "Biological tissues are composed of distinct microenvironments that spatially orchestrate gene expression and cell identity. However, the regulatory principles governing domain-specific cellular functions remain poorly understood due to the lack of effective methods for mapping gene regulatory networks (GRNs) ",
      "authors": "Hu Lei; Zhang Shichen; Zhang Xuting; Luo Yihai; Gu Haoteng; Liu Peng; Mao Sheng; Chen Li; Xia Yuhao; Yang Minghao; Zhang Sai; Min Yaosen; Li Han; Wang Peizhuo; Yu Hongtao; Zeng Jianyang",
      "year": "2025",
      "month": "Sep",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40950025",
      "doi": "10.1101/2025.08.27.672609",
      "title": "PlantCAD2: A Long-Context DNA Language Model for Cross-Species Functional Annotation in Angiosperms.",
      "abstract": "Understanding how DNA sequence encodes biological function remains a fundamental challenge in biology. Flowering plants (angiosperms), the dominant terrestrial clade, exhibit maximal biochemical complexity, extraordinary species diversity (over 100,000 species), relatively recent origins (~160 million years), ~200-fold variation in genome size and relative compact coding regions compared with other eukaryotes. These features present both a unique challenge and opportunity for pre-training DNA language models to understand plant-specific evolutionary conservation, regulatory architectures and genomic functions. Here, we introduce PlantCAD2, a long-context, plant-specific DNA language model with single-nucleotide resolution, pre-trained on 65 angiosperm genomes, together with a series of public benchmarks for evaluation. Comprehensive zero-shot testing shows that PlantCAD2 (676 million parameters) efficiently captures evolutionary conservation, surpassing the 7-billion-parameter Evo2 model in 10 of 12 tasks. With parameter-efficient fine-tuning, PlantCAD2 also outperforms the 1-billion-parameter AgroNT across seven cross-species tasks including chromatin accessible region, gene expression and protein translation. Moreover, its 8,192bp context window substantially improves accessible chromatin prediction in large genomes such as maize (AUPRC increasing from 0.587 to 0.711), underscoring the importance of long-range context for modeling distal regulation. Together, these results establish PlantCAD2 as a powerful, efficient, and versatile foundation model for plant genomics, enabling accurate genome annotation across diverse species.",
      "authors": "Zhai Jingjing; Gokaslan Aaron; Hsu Sheng-Kai; Chen Szu-Ping; Liu Zong-Yan; Marroquin Edgar; Czech Eric; Cannon Betsy; Berthel Ana; Romay M Cinta; Pennell Matt; Kuleshov Volodymyr; Buckler Edward S",
      "year": "2025",
      "month": "Dec",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40948833",
      "doi": "10.21037/tlcr-2025-187",
      "title": "Deep learning enhances precision diagnosis and treatment of non-small cell lung cancer: future prospects.",
      "abstract": "Non-small cell lung cancer (NSCLC), a major form of pulmonary malignancy and a leading global cause of cancer-related mortality, highlights the urgent need for advanced precision treatment approaches. This article comprehensively reviews the significant progress and future directions of deep learning techniques in revolutionizing the precise diagnosis and therapeutic management of NSCLC. It demonstrates how deep learning methods have the potential to surpass traditional tumor treatment paradigms, significantly enhancing diagnostic accuracy, personalizing treatment selection, and predicting patient outcomes with greater precision. The article traces the evolution of deep learning models in this field, from basic analyses relying on single data modalities, such as imaging or genomics alone, to more sophisticated architectures capable of multimodal data fusion. It emphasizes the crucial role of integrating radiological, pathological, genomic, and clinical data in uncovering deeper biological insights. Furthermore, it outlines the typical workflow involved in developing and deploying deep learning applications for NSCLC and lists some currently used models, including convolutional neural networks for image analysis and complex architectures for multi-omics data integration. These models show considerable potential for improving diagnostic accuracy and optimizing therapeutic interventions. However, translating these computational tools into routine clinical practice faces several challenges. The review candidly addresses key issues, including the need for large-scale, high-quality, and standardized datasets; the \"black box\" nature of complex models, which requires improved interpretability to gain clinicians' trust and provide actionable insights; and profound ethical considerations regarding data privacy, algorithmic bias, and equitable access. Despite these obstacles, deep learning has emerged as a powerful instrument in the oncological arsenal, significantly enhancing the precision and efficiency of NSCLC care. Finally, the article offers a dialectical perspective on the future of deep learning in NSCLC, exploring emerging trends and providing recommendations to overcome current limitations, with the goal of maximizing its potential to improve patient survival and quality of life.",
      "authors": "Zhang Xinran; Liu Jia; Zhou Wen; Lu Junfei; Wu Liqin; Li Yan; Wang Yiyuan; Wang Zhichao; Cai Jun",
      "year": "2025",
      "month": "Aug",
      "journal": "Translational lung cancer research",
      "source": "pubmed"
    },
    {
      "pmid": "40940727",
      "doi": "10.3390/cells14171315",
      "title": "Artificial Intelligence in Ocular Transcriptomics: Applications of Unsupervised and Supervised Learning.",
      "abstract": "Transcriptomic profiling is a powerful tool for dissecting the cellular and molecular complexity of ocular tissues, providing insights into retinal development, corneal disease, macular degeneration, and glaucoma. With the expansion of microarray, bulk RNA sequencing (RNA-seq), and single-cell RNA-seq technologies, artificial intelligence (AI) has emerged as a key strategy for analyzing high-dimensional gene expression data. This review synthesizes AI-enabled transcriptomic studies in ophthalmology from 2019 to 2025, highlighting how supervised and unsupervised machine learning (ML) methods have advanced biomarker discovery, cell type classification, and eye development and ocular disease modeling. Here, we discuss unsupervised techniques, such as principal component analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE), uniform manifold approximation and projection (UMAP), and weighted gene co-expression network analysis (WGCNA), now the standard in single-cell workflows. Supervised approaches are also discussed, including the least absolute shrinkage and selection operator (LASSO), support vector machines (SVMs), and random forests (RFs), and their utility in identifying diagnostic and prognostic markers in age-related macular degeneration (AMD), diabetic retinopathy (DR), glaucoma, keratoconus, thyroid eye disease, and posterior capsule opacification (PCO), as well as deep learning frameworks, such as variational autoencoders and neural networks that support multi-omics integration. Despite challenges in interpretability and standardization, explainable AI and multimodal approaches offer promising avenues for advancing precision ophthalmology.",
      "authors": "Lalman Catherine; Yang Yimin; Walker Janice L",
      "year": "2025",
      "month": "Aug",
      "journal": "Cells",
      "source": "pubmed"
    },
    {
      "pmid": "40940333",
      "doi": "10.1038/s41467-025-63688-5",
      "title": "Flexynesis: A deep learning toolkit for bulk multi-omics data integration for precision oncology and beyond.",
      "abstract": "Accurate decision making in precision oncology depends on integration of multimodal molecular information, for which various deep learning methods have been developed. However, most deep learning-based bulk multi-omics integration methods lack transparency, modularity, deployability, and are limited to narrow tasks. To address these limitations, we introduce Flexynesis, which streamlines data processing, feature selection, hyperparameter tuning, and marker discovery. Users can choose from deep learning architectures or classical supervised machine learning methods with a standardized input interface for single/multi-task training and evaluation for regression, classification, and survival modeling. We showcase the tool's capability across diverse use-cases in precision oncology. To maximize accessibility, Flexynesis is available on PyPi, Guix, Bioconda, and the Galaxy Server ( https://usegalaxy.eu/ ). This toolset makes deep-learning based bulk multi-omics data integration in clinical/pre-clinical research more accessible to users with or without deep-learning experience. Flexynesis is available at https://github.com/BIMSBbioinfo/flexynesis .",
      "authors": "Uyar Bora; Savchyn Taras; Naghsh Nilchi Amirhossein; Sarigun Ahmet; Wurmus Ricardo; Shaik Mohammed Maqsood; Grüning Björn; Franke Vedran; Akalin Altuna",
      "year": "2025",
      "month": "Sep",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "40927964",
      "doi": "10.1002/cam4.71224",
      "title": "A Review on Biomarker-Enhanced Machine Learning for Early Diagnosis and Outcome Prediction in Ovarian Cancer Management.",
      "abstract": "Ovarian cancer (OC) remains the most lethal gynecological malignancy, largely due to its late-stage diagnosis and nonspecific early symptoms. Advances in biomarker identification and machine learning offer promising avenues for improving early detection and prognosis. This review evaluates the role of biomarker-driven ML models in enhancing the early detection, risk stratification, and treatment planning of OC. We analyzed literature spanning clinical, biomarker, and ML studies, emphasizing key diagnostic and prognostic biomarkers (e.g., CA-125, HE4) and ML techniques (e.g., Random Forest, XGBoost, Neural Networks). The review synthesizes findings from 17 investigations that integrate multi-modal data, including tumor markers, inflammatory, metabolic, and hematologic parameters, to assess ML model performance. Biomarker-driven ML models significantly outperform traditional statistical methods, achieving AUC values exceeding 0.90 in diagnosing OC and distinguishing malignant from benign tumors. Ensemble methods (e.g., Random Forest, XGBoost) and deep learning approaches (e.g., RNNs) excel in classification accuracy (up to 99.82%), survival prediction (AUC up to 0.866), and treatment response forecasting. Combining CA-125 and HE4 with additional markers like CRP and NLR enhances specificity and sensitivity. However, limitations such as small sample sizes, lack of external validation, and exclusion of imaging/genomic data hinder clinical adoption. Biomarker-driven ML represents a transformative approach for OC management, improving diagnostic precision and personalized care. Future research should prioritize multi-center validation, multi-omics integration, and explainable AI to overcome current challenges and enable real-world implementation, potentially reducing OC mortality through earlier detection and optimized treatment.",
      "authors": "Hormaty Somayyeh; Seiwan Anwar Nather; Rasheed Bushra H; Parvaz Hanieh; Gharahzadeh Ali; Ghaznavi Hamid",
      "year": "2025",
      "month": "Sep",
      "journal": "Cancer medicine",
      "source": "pubmed"
    },
    {
      "pmid": "40919912",
      "doi": "10.1093/bib/bbaf457",
      "title": "Predicting nucleic acid binding sites by attention map-guided graph convolutional network with protein language embeddings and physicochemical information.",
      "abstract": "Protein-nucleic acid binding sites play a crucial role in biological processes such as gene expression, signal transduction, replication, and transcription. In recent years, with the development of artificial intelligence, protein language models, graph neural networks, and transformer architectures have been adopted to develop both structure-based and sequence-based predictive models. Structure-based methods benefit from the spatial relationship between residues and have shown promising performance. However, structure-based information requires 3D protein structures, which is a challenge for large-scale protein sequence spaces. To address this limitation, researchers have attempted to use predicted protein structure information to guide binding site prediction. While this strategy has improved accuracy, it still depends on the quality of structure predictions. Thus, some studies have returned to prediction methods based solely on protein sequences, particularly those using protein language models, which have greatly enhanced the prediction accuracy. This paper proposes a novel protein-nucleic acid binding site prediction framework, ATtention Maps and Graph convolutional neural networks to predict nucleic acid-protein Binding sites (ATMGBs), which first fuses protein language embeddings with physicochemical properties to obtain multiview information, then leverages the attention map of a protein language model to simulate the relationship between residues, and then utilizes graph convolutional networks for enhancing the feature representations for final prediction. ATMGBs was evaluated on several different independent test sets. The results indicate that the proposed approach significantly improves sequence-based prediction performance, even achieving prediction accuracy comparable to structure-based frameworks. The dataset and code used in this study are available at https://github.com/lixiangli01/ATMGBs.",
      "authors": "Li Xiang; Peng Wei; Zhu Xiaolei",
      "year": "2025",
      "month": "Aug",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40917653",
      "doi": "10.1093/bioadv/vbaf196",
      "title": "A foundation model for learning genetic associations from brain imaging phenotypes.",
      "abstract": "Due to the intricate etiology of neurological disorders, finding interpretable associations between multiomics features can be challenging using standard approaches. We propose COMICAL, a contrastive learning approach using multiomics data to generate associations between genetic markers and brain imaging-derived phenotypes. COMICAL jointly learns omics representations utilizing transformer-based encoders with custom tokenizers. Our modality-agnostic approach uniquely identifies many-to-many associations via self-supervised learning schemes and cross-modal attention encoders. COMICAL discovered several significant associations between genetic markers and imaging-derived phenotypes for a variety of neurological disorders in the UK Biobank, as well as prediction of diseases and unseen clinical outcomes from learned representations. The source code of COMICAL along with pretrained weights, enabling transfer learning, is available at https://github.com/IBM/comical.",
      "authors": "Machado Reyes Diego; Burch Myson; Parida Laxmi; Bose Aritra",
      "year": "2025",
      "month": "",
      "journal": "Bioinformatics advances",
      "source": "pubmed"
    },
    {
      "pmid": "40917099",
      "doi": "10.1177/11779322251358314",
      "title": "Language Modelling Techniques for Analysing the Impact of Human Genetic Variation.",
      "abstract": "Interpreting the effects of variants within the human genome and proteome is essential for analysing disease risk, predicting medication response, and developing personalised health interventions. Due to the intrinsic similarities between the structure of natural languages and genetic sequences, natural language processing techniques have demonstrated great applicability in computational variant effect prediction. In particular, the advent of the Transformer has led to significant advancements in the field. However, transformer-based models are not without their limitations, and a number of extensions and alternatives have been developed to improve results and enhance computational efficiency. This systematic review investigates over 50 different language modelling approaches to computational variant effect prediction over the past decade, analysing the main architectures, and identifying key trends and future directions. Benchmarking of the reviewed models remains unachievable at present, primarily due to the lack of shared evaluation frameworks and data sets.",
      "authors": "Hegde Megha; Nebel Jean-Christophe; Rahman Farzana",
      "year": "2025",
      "month": "",
      "journal": "Bioinformatics and biology insights",
      "source": "pubmed"
    },
    {
      "pmid": "40917001",
      "doi": "10.1002/advs.202509247",
      "title": "Dynamic Synthesis of Multi-Modal Representations for CITE-seq Data Integration and Analysis.",
      "abstract": "Single-cell multi-omics technologies are pivotal for deciphering the complexities of biological systems, with Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq) emerging as a particularly valuable approach. The dual-modality capability makes CITE-seq particularly advantageous for dissecting cellular heterogeneity and understanding the dynamic interplay between transcriptomic and proteomic landscapes. However, existing computational models for integrating these two modalities often struggle to capture the complex, non-linear interactions between RNA and antibody-derived tags (ADTs), and are computationally intensive. To address these issues, scMHVA, a novel and lightweight framework designed to integrate the diverse modalities of CITE-seq data, is proposed. scMHVA utilizes an adaptive dynamic synthesis module to generate consolidated yet heterogeneous embeddings from RNA and ADT modalities. Subsequently, scMHVA enhances inter-modality correlations within the joint representation by applying a multi-head self-attention mechanism, effectively capturing the intricate mapping relationships between mRNA expression levels and protein abundance. Extensive experiments demonstrate that scMHVA consistently outperformed existing single-modal and multi-modal clustering methods across CITE-seq datasets of varying scales, exhibiting linear runtime scalability and effectively eliminating batch effects, thereby establishing it as a robust tool for large-scale CITE-seq data analysis. Additionally, it is demonstrated that scMHVA successfully annotates different cell types in a published mouse thymocyte dataset and reveals dynamics of immune cell development.",
      "authors": "Shi Yinan; Su Yanchi; Cheng Yue; Wong Ka-Chun; Wang Yunhe; Li Xiangtao",
      "year": "2025",
      "month": "Nov",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "40914154",
      "doi": "10.1016/j.crmeth.2025.101167",
      "title": "SuperGLUE facilitates an explainable training framework for multi-modal data analysis.",
      "abstract": "Single-cell multi-modal data integration has been an area of active research in recent years. However, it is difficult to unify the integration process of different omics in a pipeline and evaluate the contributions of data integration. In this article, we revisit the definition and contributions of multi-modal data integration and propose a strong and scalable method based on probabilistic deep learning with an explainable framework powered by statistical modeling to extract meaningful information after data integration. Our proposed method is capable of integrating different types of omics and sensing data. It offers an approach to discovering important relationships among biological features or cell states. We demonstrate that our method outperforms other baseline models in preserving both local and global structures and perform a comprehensive analysis for mining structural relationships in complex biological systems, including inference of gene regulatory networks, extraction of significant biological linkages, and analysis of differentially regulatory relationships.",
      "authors": "Liu Tianyu; Zhao Jia; Zhao Hongyu",
      "year": "2025",
      "month": "Sep",
      "journal": "Cell reports methods",
      "source": "pubmed"
    },
    {
      "pmid": "40910005",
      "doi": "10.3389/fphar.2025.1609079",
      "title": "Multimodal integration strategies for clinical application in oncology.",
      "abstract": "In clinical practice, a variety of techniques are employed to generate diverse data types for each cancer patient. These data types, spanning clinical, genomics, imaging, and other modalities, exhibit significant differences and possess distinct data structures. Therefore, most current analyses focus on a single data modality, limiting the potential of fully utilizing all available data and providing comprehensive insights. Artificial intelligence (AI) methods, adept at handling complex data structures, offer a powerful approach to efficiently integrate multimodal data. The insights derived from such models may ultimately expedite advancements in patient diagnosis, prognosis, and treatment responses. Here, we provide an overview of current advanced multimodal integration strategies and the related clinical potential in oncology field. We start from the key processing methods for single data modalities such as multi-omics, imaging data, and clinical notes. We then include diverse AI methods, covering traditional machine learning, representation learning, and vision language model, tailored to each distinct data modality. We further elaborate on popular multimodal integration strategies and discuss the related strength and weakness. Finally, we explore potential clinical applications including early detection/diagnosis, biomarker discovery, and prediction of clinical outcome. Additionally, we discuss ongoing challenges and outline potential future directions in the field.",
      "authors": "Zhang Baoyi; Wan Zhuoya; Luo Yige; Zhao Xi; Samayoa Josue; Zhao Weilong; Wu Si",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in pharmacology",
      "source": "pubmed"
    },
    {
      "pmid": "40909977",
      "doi": "10.3389/fonc.2025.1597969",
      "title": "Diagnosis methods for pancreatic cancer with the technique of deep learning: a review and a meta-analysis.",
      "abstract": "Early diagnosis can significantly improve survival rate of Pancreatic ductal adenocarcinoma (PDAC), but due to the insidious and non-specific early symptoms, most patients are not suitable for surgery when diagnosed. Traditional imaging techniques and an increasing number of non-imaging diagnostic methods have been used for the early diagnosis of pancreatic cancer (PC) through deep learning (DL). This review summarizes diagnosis methods for pancreatic cancer with the technique of deep learning and looks forward to the future development directions of deep learning for early diagnosis of pancreatic cancer. This study follows the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines, retrieving studies on deep learning for early pancreatic cancer diagnosis from PubMed, Embase, Web of Science, IEEE, and Cochrane Library over the past 5 years. Inclusion criteria were studies involving PDAC patients, using deep learning algorithms for diagnosis evaluation, using histopathological results as the reference standard, and having sufficient data. Two reviewers independently screened and extracted data. Quality was assessed using QUADAS-2, with StataMP 17 for meta-analysis. In this study, 422 articles were retrieved, and 7 were finally included for meta-analysis. The analysis showed that the accuracy of deep learning in the early diagnosis of pancreatic cancer was 80%-98.9%, and the combined sensitivity, specificity and AUC were 0.92 (95% CI: 0.85-0.96), 0.92 (95% CI: 0.85-0.96), and 0.97 (95% CI: 0.95-0.98). The positive and negative likelihood ratio were 11.52 (95% CI, 6.15-21.55) and 0.09 (95% CI, 0.04-0.17). Endoscopic ultrasound (EUS) and Contrast-Enhanced Computed Tomography (CE-CT) were the main diagnostic methods. Non-imaging diagnostic methods such as deep learning urine markers, disease trajectory also performed good diagnostic potential. Artificial intelligence (AI) technology holds promise for clinical guidance in pancreatic cancer risk prediction and diagnosis. Future research may focus on leveraging diverse data sources like genomics and biomarkers through deep learning; utilizing multi - center or international samples; tackling the challenge of early diagnosis for small pancreatic cancers; enhancing the explainability of AI models and multi-modal approaches.",
      "authors": "Bi Yuanbo; Li Dongrui; Pang Ruochen; Du Chengxv; Li Da; Zhao Xiaoyv; Lv Haitao",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in oncology",
      "source": "pubmed"
    },
    {
      "pmid": "40907572",
      "doi": "10.4143/crt.2025.707",
      "title": "Deep Learning-Based Multimodal Prediction of NAC Response in LARC by Integrating MRI and Proteomics.",
      "abstract": "Locally advanced rectal cancer (LARC) exhibits significant heterogeneity in response to neoadjuvant chemotherapy (NAC), with poor responders facing delayed treatment and unnecessary toxicity. Although MRI provides spatial pathophysiological information and proteomics reveals molecular mechanisms, current single-modal approaches cannot integrate these complementary perspectives, resulting in limited predictive accuracy and biological insight. This retrospective study developed a multimodal deep learning framework using a cohort of 274 LARC patients treated with NAC (2012-2021). Graph neural networks analyzed proteomic profiles from FFPE tissues, incorporating KEGG/GO pathways and PPI networks, while a spatially enhanced 3D ResNet152 processed T2WI. A LightGBM classifier integrated both modalities with clinical features using zero-imputation for missing data. Model performance was assessed through AUC-ROC, decision curve analysis, and interpretability techniques (SHAP and Grad-CAM). The integrated model achieved superior NAC response prediction (test AUC 0.828, sensitivity 0.875, specificity 0.750), significantly outperforming single-modal approaches (MRI ΔAUC +0.109; proteomics ΔAUC +0.125). SHAP analysis revealed MRI-derived features contributed 57.7% of predictive power, primarily through peritumoral stromal heterogeneity quantification. Proteomics identified 10 key chemoresistance proteins, including CYBA, GUSB, ATP6AP2, DYNC1I2, DAD1, ACOX1, COPG1, FBP1, DHRS7, and SSR3. Decision curve analysis confirmed clinical utility across threshold probabilities (0-0.75). Our study established a novel MRI-proteomics integration framework for NAC response prediction, with MRI defining spatial resistance patterns and proteomics deciphering molecular drivers, enabling early organ preservation strategies. The zero-imputation design ensured deplorability in diverse clinical settings.",
      "authors": "Li Yan; Ding Jiaxuan; Du Fenqi; Wang Zhongxing; Liu Zeyuan; Liu Yanlong; Zhou Yang; Zhang Qiuju",
      "year": "2025",
      "month": "Sep",
      "journal": "Cancer research and treatment",
      "source": "pubmed"
    },
    {
      "pmid": "40904504",
      "doi": "10.3389/fonc.2025.1630628",
      "title": "Artificial intelligence in advanced gastric cancer: a comprehensive review of applications in precision oncology.",
      "abstract": "Gastric cancer (GC) remains a major global health challenge, particularly in its advanced stages where prognosis is poor, and treatment responses are heterogeneous. Precision oncology aims to tailor therapies, but current biomarkers have limitations. Artificial Intelligence (AI), encompassing machine learning (ML) and deep learning (DL), offers powerful tools to analyze complex, multi-dimensional data from advanced GC patients, including clinical records, genomics, imaging (radiomics), and digital pathology (pathomics). This review synthesizes the current state of AI applications in unresectable, advanced GC. AI models demonstrate significant potential in refining diagnosis and staging, predicting treatment efficacy for chemotherapy, immunotherapy, and targeted therapies, and assessing prognosis. Multi-modal AI approaches, integrating data from diverse sources, consistently show improved predictive performance over single-modality models, better reflecting the complexity of the disease. Key challenges remain, including data quality and standardization, model generalizability and interpretability, and the need for rigorous prospective validation. Future directions emphasize multi-center collaborations, development of robust and explainable AI (XAI), and seamless integration into clinical workflows. Overcoming these hurdles will be crucial to translate AI's potential into tangible clinical benefits, enabling truly personalized and effective management for patients with advanced gastric cancer.",
      "authors": "Fu Min; Xu Jialing; Lv Yingying; Jin Baijun",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in oncology",
      "source": "pubmed"
    },
    {
      "pmid": "40900876",
      "doi": "10.5662/wjm.v15.i4.105516",
      "title": "Artificial intelligence for early diagnosis and risk prediction of periodontal-systemic interactions: Clinical utility and future directions.",
      "abstract": "Artificial intelligence (AI) is transforming healthcare by improving diagnostic accuracy and predictive analytics. Periodontal diseases are recognized as risk factors for systemic conditions, including type 2 diabetes mellitus, cardiovascular disease, Alzheimer's disease, polycystic ovary syndrome, thyroid dysfunction, and post-coronavirus disease 2019 complications. These conditions exhibit complex bidirectional interactions, underscoring the importance of early detection and risk stratification. Current diagnostic tools often fail to capture these interactions at an early stage, limiting timely intervention. This study hypothesizes that AI-driven approaches can significantly improve early diagnosis and risk prediction of periodontal-systemic interactions, enhancing clinical outcomes. To evaluate AI's role in diagnosing and predicting periodontal-systemic interactions in studies from 2010 to 2024. This systematic review followed PRISMA guidelines (2009) and included peer-reviewed articles from PubMed, Scopus, and Embase. Studies with large sample sizes (≥ 500 participants) were selected, focusing on AI models integrating multi-omics data and advanced imaging techniques such as cone beam computed tomography and magnetic resonance imaging. Machine learning models processed structured clinical data, deep learning models combined imaging and clinical data, and natural language processing models extracted insights from clinical notes. AI applications significantly enhanced diagnostic and predictive accuracy, reducing diagnostic time by 40% and improving predictive accuracy by 25% in periodontal patients with type 2 diabetes mellitus. Studies with sample sizes of 1000-1500 participants reported diagnostic accuracy improvements up to 92%, with specificity and sensitivity rates of 94% and 90%, respectively. Increasing sample sizes over the years reflected advancements in AI, data collection, and model training, reinforcing model reliability. AI's integration of multi-omics and imaging data has transformed early diagnosis and risk prediction in periodontal-systemic interactions, improving clinical outcomes and decision-making.",
      "authors": "Das Neelam; Gade Keertana R; Addanki Pavan K",
      "year": "2025",
      "month": "Dec",
      "journal": "World journal of methodology",
      "source": "pubmed"
    },
    {
      "pmid": "40898302",
      "doi": "10.1186/s13073-025-01526-5",
      "title": "Deep learning-based histomorphological subtyping and risk stratification of small cell lung cancer from hematoxylin and eosin-stained whole slide images.",
      "abstract": "Accurate subtyping and risk stratification are imperative for prognostication and clinical decision-making in small cell lung cancer (SCLC). However, traditional molecular subtyping is resource-intensive and challenging to translate into clinical practice. A total of 517 SCLC patients and their corresponding hematoxylin and eosin (H&E)-stained whole slide images (WSIs) from three independent medical institutions were analyzed. A hybrid clustering-based unsupervised deep representation learning model was developed to identify histomorphological phenotypes (HIPO) and characterize tumor ecosystem diversity. Consensus clustering and a deep learning-based stratification system were used to define histomorphological subtypes (HIPOS) based on patient-level HIPO features. Survival analysis and Cox proportional hazards regression models were used to assess the clinical significance of HIPOS. An integrated analysis of pathomics, proteomics, and immunohistochemistry was conducted to explore the biological and microenvironmental correlates of HIPOS. We performed histomorphological phenotyping of SCLC using unsupervised deep representation learning from WSIs and identified 15 HIPOs. Unsupervised clustering of HIPO profiles stratified SCLCs into two reproducible image-based subtypes: HIPOS-I and HIPOS-II. Patients in the HIPOS-I group had better overall survival and disease-free survival compared to those in HIPOS-II, independent of clinical features and molecular subtypes. Multimodal analyses revealed that HIPOS-I tumors were characterized by enriched immune infiltration and immune activation, whereas HIPOS-II tumors displayed increased fibrosis, cellular pleomorphism, and dysregulated oxidative metabolism. Additionally, we developed a simplified deep-learning model to predict HIPOS subtypes to enhance clinical applications and validated the prognostic value of these subtypes in independent cohorts. This study demonstrates the potential of a deep learning-based histomorphological subtyping system to improve patient stratification and prognosis prediction in SCLC. The HIPOS offers a promising and clinically applicable tool for personalized management using routine H&E-stained WSIs.",
      "authors": "Zhang Yibo; Liu Shilong; Chen Jun; Chen Ruanqi; Yang Zijian; Sheng Ruyu; Li Xin; Wang Taolue; Liu Hongyu; Yang Fan; Ying Jianming; Yang Lin; Sun Jie; Zhou Meng",
      "year": "2025",
      "month": "Sep",
      "journal": "Genome medicine",
      "source": "pubmed"
    },
    {
      "pmid": "40894641",
      "doi": "10.1101/2025.02.26.640468",
      "title": "Pre-training Genomic Language Model with Variants for Better Modeling Functional Genomics.",
      "abstract": "Sequence-to-function models can predict gene expression from sequence data and be used to link genetic information with transcriptomics data to understand regulatory processes and their effects on complex phenotypes. The genomic language models are pre-trained with large-scale DNA sequences and can generate robust representations of these sequences by learning the genomic context. However, few studies can estimate the predictability of gene expression levels and bridge these two classes of models together to explore individualized gene expression prediction. In this manuscript, we propose UKBioBERT as a DNA language model pre-trained with genetic variants from UK BioBank. We demonstrate that UKBioBERT generates informative embeddings capable of identifying gene functions, and improving gene expression prediction in cell lines, thereby enhancing our understanding of gene expression predictability. Building upon these embeddings, we combine UKBioBERT with state-of-the-art sequence-to-function architectures, Enformer and Borzoi, to create UKBioFormer and UKBioZoi. These models exhibit better performance in predicting highly predictable gene expression levels and can be generalized across different cohorts. Furthermore, UKBioFormer effectively captures the relationship between genetic variants and expression variations, enabling in-silico mutation analyses and eQTL identification. Collectively, our findings underscore the value of integrating genomic language models and sequence-to-function approaches for advancing functional genomics research.",
      "authors": "Liu Tianyu; Zhang Xiangyu; Lin Jiecong; Pinello Luca; Ying Rex; Zhao Hongyu",
      "year": "2025",
      "month": "Aug",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40894586",
      "doi": "10.1101/2023.12.07.569910",
      "title": "scELMo: Embeddings from Language Models are Good Learners for Single-cell Data Analysis.",
      "abstract": "Various Foundation Models (FMs) have been built based on the pre-training and fine-tuning framework to analyze single-cell data with different degrees of success. In this manuscript, we propose a method named scELMo (Single-cell Embedding from Language Models), to analyze single-cell data that utilizes Large Language Models (LLMs) as a generator for both the description of metadata information and the embeddings for such descriptions. We combine the embeddings from LLMs with the raw data under the zero-shot learning framework to further extend its function by using the fine-tuning framework to handle different tasks. We demonstrate that scELMo is capable of cell clustering, batch effect correction, and cell-type annotation without training a new model. Moreover, the fine-tuning framework of scELMo can help with more challenging tasks including in-silico treatment analysis or modeling perturbation. scELMo has a lighter structure and lower requirements for resources. Our method also outperforms recent large-scale FMs (such as scGPT [1], Geneformer [2]) and other LLM-based single-cell data analysis pipelines (such as GenePT [3] and GPTCelltype [4]) based on our evaluations, suggesting a promising path for developing domain-specific FMs.",
      "authors": "Liu Tianyu; Chen Tianqi; Zheng Wangjie; Luo Xiao; Chen Yiqun; Zhao Hongyu",
      "year": "2025",
      "month": "Aug",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40894134",
      "doi": "10.1101/2025.08.18.25333844",
      "title": "Integrating Imaging-Derived Clinical Endotypes with Plasma Proteomics and External Polygenic Risk Scores Enhances Coronary Microvascular Disease Risk Prediction.",
      "abstract": "Coronary microvascular disease (CMVD) is an underdiagnosed but significant contributor to the burden of ischemic heart disease, characterized by angina and myocardial infarction. The development of risk prediction models such as polygenic risk scores (PRS) for CMVD has been limited by a lack of large-scale genome-wide association studies (GWAS). However, there is significant overlap between CMVD and enrollment criteria for coronary artery disease (CAD) GWAS. In this study, we developed CMVD PRS models by selecting variants identified in a CMVD GWAS and applying weights from an external CAD GWAS, using CMVD-associated loci as proxies for the genetic risk. We integrated plasma proteomics, clinical measures from perfusion PET imaging, and PRS to evaluate their contributions to CMVD risk prediction in comprehensive machine and deep learning models. We then developed a novel unsupervised endotyping framework for CMVD from perfusion PET-derived myocardial blood flow data, revealing distinct patient subgroups beyond traditional case-control definitions. This imaging-based stratification substantially improved classification performance alongside plasma proteomics and PRS, achieving AUROCs between 0.65 and 0.73 per class, significantly outperforming binary classifiers and existing clinical models, highlighting the potential of this stratification approach to enable more precise and personalized diagnosis by capturing the underlying heterogeneity of CMVD. This work represents the first application of imaging-based endotyping and the integration of genetic and proteomic data for CMVD risk prediction, establishing a framework for multimodal modeling in complex diseases.",
      "authors": "Venkatesh Rasika; Cherlin Tess; Ritchie Marylyn D; Guerraty Marie A; Verma Shefali S",
      "year": "2025",
      "month": "Aug",
      "journal": "medRxiv : the preprint server for health sciences",
      "source": "pubmed"
    },
    {
      "pmid": "40893475",
      "doi": "10.1016/j.aopr.2025.07.002",
      "title": "Multimodal data-driven approaches in retinal vein occlusion: A narrative review integrating machine learning and bioinformatics.",
      "abstract": "Retinal vein occlusion (RVO) is a leading cause of visual impairment on a global scale. Its pathological mechanisms involve a complex interplay of vascular obstruction, ischemia, and secondary inflammatory responses. Recent interdisciplinary advances, underpinned by the integration of multimodal data, have established a new paradigm for unraveling the pathophysiological mechanisms of RVO, enabling early diagnosis and personalized treatment strategies. This review critically synthesizes recent progress at the intersection of machine learning, bioinformatics, and clinical medicine, focusing on developing predictive models and deep analysis, exploring molecular mechanisms, and identifying markers associated with RVO. By bridging technological innovation with clinical needs, this review underscores the potential of data-driven strategies to advance RVO research and optimize patient care. Machine learning-bioinformatics integration has revolutionised RVO research through predictive modelling and mechanistic insights, particularly via deep learning-enhanced retinal imaging and multi-omics networks. Despite progress, clinical translation requires resolving data standardisation inconsistencies and model generalizability limitations. Establishing multicentre validation frameworks and interpretable AI tools, coupled with patient-focused data platforms through cross-disciplinary collaboration, could enable precision interventions to optimally preserve vision.",
      "authors": "Liang Chunlan; Liu Lian; Zhong Jingxiang",
      "year": "2025",
      "month": "",
      "journal": "Advances in ophthalmology practice and research",
      "source": "pubmed"
    },
    {
      "pmid": "40879746",
      "doi": "10.1007/s00018-025-05837-z",
      "title": "Deep learning in chromatin organization: from super-resolution microscopy to clinical applications.",
      "abstract": "The 3D organization of the genome plays a critical role in regulating gene expression, maintaining cellular identity, and mediating responses to environmental cues. Advances in super-resolution microscopy and genomic technologies have enabled unprecedented insights into chromatin architecture at nanoscale resolution. However, the complexity and volume of data generated by these techniques necessitate innovative computational strategies for effective analysis and interpretation. In this review, we explore the transformative role of deep learning in the analysis of 3D genome organization, highlighting how deep learning models are being leveraged to enhance image reconstruction, segmentation, and dynamic tracking in chromatin research. We provide an overview of deep learning-enhanced methodologies that significantly improve spatial and temporal resolution of images, with a special focus on single-molecule localization microscopy. Furthermore, we discuss deep learning's contribution to segmentation accuracy, and its application in single-particle tracking for dissecting chromatin dynamics at the single-cell level. These advances are complemented by frameworks that enable multimodal integration and interpretability, pushing the boundaries of chromatin biology into clinical diagnostics and personalized medicine. Finally, we discuss emerging clinical applications where deep learning models, based on chromatin imaging, aid in disease stratification, drug response prediction, and early cancer detection. We also address the challenges of data sparsity, model interpretability and propose future directions to decode genome function with higher precision and impact.",
      "authors": "Rotkevich Mikhail; Viana Carlotta; Neguembor Maria Victoria; Cosma Maria Pia",
      "year": "2025",
      "month": "Aug",
      "journal": "Cellular and molecular life sciences : CMLS",
      "source": "pubmed"
    },
    {
      "pmid": "40874816",
      "doi": "10.1093/bib/bbaf405",
      "title": "MuST: multiple-modality structure transformation for single-cell spatial transcriptomics.",
      "abstract": "Spatial transcriptomics (ST) technologies have revolutionized the study of gene expression patterns in tissues by providing multimodal data, including transcriptomic (Tra.), spatial, and morphological modalities, thereby offering new opportunities to understand tissue biology beyond traditional Tra. However, we identify the modality bias phenomenon in ST data species, i.e. the inconsistent contribution of different modalities to the labels leads to a tendency for the analysis methods to retain the information of the dominant modality. How to mitigate the adverse effects of modality bias to satisfy various downstream tasks remains a fundamental challenge. This paper introduces Multiple-modality Structure Transformation, named MuST, a novel methodology to tackle the challenge. MuST integrates the multi-modality information contained in the ST data effectively into a uniform latent space to provide a foundation for all the downstream tasks. It learns intrinsic local structures by topology discovery strategy and topology fusion loss function to solve the inconsistencies among different modalities. Thus, these topology-based and deep learning techniques provide a solid foundation for a variety of analytical tasks while coordinating different modalities. The effectiveness of MuST is assessed by performance metrics and biological significance. The results show that it outperforms existing state-of-the-art methods with clear advantages in the precision of identifying and preserving structures of tissues and biomarkers. MuST offers a versatile toolkit for the intricate analysis of complex biological systems.",
      "authors": "Zang Zelin; Li Liangyu; Xu Yongjie; Duan Chenrui; Shen Yue; Sun Yi; Lei Zhen; Li Stan Z",
      "year": "2025",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40868397",
      "doi": "10.3390/bioengineering12080884",
      "title": "scOTM: A Deep Learning Framework for Predicting Single-Cell Perturbation Responses with Large Language Models.",
      "abstract": "Modeling drug-induced transcriptional responses at the single-cell level is essential for advancing human healthcare, particularly in understanding disease mechanisms, assessing therapeutic efficacy, and anticipating adverse effects. However, existing approaches often impose a rigid constraint by enforcing pointwise alignment of latent representations to a standard normal prior, which limits expressiveness and results in biologically uninformative embeddings, especially in complex biological systems. Additionally, many methods inadequately address the challenges of unpaired data, typically relying on naive averaging strategies that ignore cell-type specificity and intercellular heterogeneity. To overcome these limitations, we propose scOTM, a deep learning framework designed to predict single-cell perturbation responses from unpaired data, focusing on generalization to unseen cell types. scOTM integrates prior biological knowledge of perturbations and cellular states, derived from large language models specialized for molecular and single-cell corpora. These informative representations are incorporated into a variational autoencoder with maximum mean discrepancy regularization, allowing flexible modeling of transcriptional shifts without imposing a strict constraint of alignment to a standard normal prior. scOTM further employs optimal transport to establish an efficient and interpretable mapping between control and perturbed distributions, effectively capturing the transcriptional shifts underlying response variation. Extensive experiments demonstrate that scOTM outperforms existing methods in predicting whole-transcriptome responses and identifying top differentially expressed genes. Furthermore, scOTM exhibits superior robustness in data-limited settings and strong generalization capabilities across cell types.",
      "authors": "Wang Yuchen; Lu Tianchi; Chen Xingjian; Yao Zhongyu; Wong Ka-Chun",
      "year": "2025",
      "month": "Aug",
      "journal": "Bioengineering (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "40856916",
      "doi": "10.1007/s12672-025-03307-3",
      "title": "Application of artificial intelligence in medical imaging for tumor diagnosis and treatment: a comprehensive approach.",
      "abstract": "This narrative review provides a comprehensive and structured overview of recent advances in the application of artificial intelligence (AI) to medical imaging for tumor diagnosis and treatment. By synthesizing evidence from recent literature and clinical reports, we highlight the capabilities, limitations, and translational potential of AI techniques across key imaging modalities such as CT, MRI, and PET. Deep learning (DL) and radiomics have facilitated automated lesion detection, tumour segmentation, and prognostic assessments, improving early cancer detection across various malignancies, including breast, lung, and prostate cancers. AI-driven multi-modal imaging fusion integrates radiomics, genomics, and clinical data, refining precision oncology strategies. Additionally, AI-assisted radiotherapy planning and adaptive dose optimisation have enhanced therapeutic efficacy while minimising toxicity. However, challenges persist regarding data heterogeneity, model generalisability, regulatory constraints, and ethical concerns. The lack of standardised datasets and explainable AI (XAI) frameworks hinders clinical adoption. Future research should focus on improving AI interpretability, fostering multi-centre dataset interoperability, and integrating AI with molecular imaging and real-time clinical decision support. Addressing these challenges will ensure AI's seamless integration into clinical oncology, optimising cancer diagnosis, prognosis, and treatment outcomes.",
      "authors": "Huang Junyan; Xiang Yizhen; Gan Shengqi; Wu Linrong; Yan Jiangyu; Ye Dong; Zhang Junjun",
      "year": "2025",
      "month": "Aug",
      "journal": "Discover oncology",
      "source": "pubmed"
    },
    {
      "pmid": "40848288",
      "doi": "10.1093/bioinformatics/btaf469",
      "title": "TRAFICA: an open chromatin language model to improve transcription factor binding affinity prediction.",
      "abstract": "In silico transcription factor and DNA (TF-DNA) binding affinity prediction plays a vital role in examining TF binding preferences and understanding gene regulation. The existing tools employ TF-DNA binding profiles from in vitro high-throughput technologies to predict TF-DNA binding affinity. However, TFs tend to bind to sequences in open chromatin regions in vivo, such TF binding preference is seldomly considered by these existing tools. In this study, we developed TRAFICA, an open chromatin language model to predict TF-DNA binding affinity by integrating sequence characteristics of open chromatin regions from ATAC-seq experiments and in vitro TF-DNA binding profiles from high-throughput technologies. We pretrained TRAFICA on over 2.8 million nucleotide sequences in open chromatin regions derived from 197 ATAC-seq experiments (115 cell lines) to learn in vivo TF binding preferences. We further fine-tuned TRAFICA using low-rank adaptation (LoRA) on PBM and HT-SELEX TF-DNA binding profiles to learn intrinsic binding preferences for specific TFs. We systematically evaluated TRAFICA and compared its predictive performance with existing prediction tools and advanced DNA language models. The experimental results demonstrated that TRAFICA significantly outperformed the others in predicting in vitro and in vivo TF-DNA binding affinity, achieving state-of-the-art performance. These findings indicate that considering the sequence characteristics from open chromatin regions could significantly improve TF-DNA binding affinity prediction. The source code of TRAFICA and detailed tutorials are available at https://github.com/ericcombiolab/TRAFICA.",
      "authors": "Xu Yu; Wang Chonghao; Xu Ke; Ding Yi; Lyu Aiping; Zhang Lu",
      "year": "2025",
      "month": "Nov",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "40843339",
      "doi": "10.1016/j.patter.2025.101326",
      "title": "BioLLM: A standardized framework for integrating and benchmarking single-cell foundation models.",
      "abstract": "The application and evaluation of single-cell foundation models (scFMs) present significant challenges due to heterogeneous architectures and coding standards. To address this, we introduce BioLLM (biological large language model), a unified framework for integrating and applying scFMs to single-cell RNA sequencing analysis. BioLLM provides a unified interface that integrates diverse scFMs, eliminating architectural and coding inconsistencies to enable streamlined model access. With standardized APIs and comprehensive documentation, BioLLM supports streamlined model switching and consistent benchmarking. Our comprehensive evaluation of scFMs revealed distinct strengths and limitations, highlighting scGPT's robust performance across all tasks, including zero shot and fine-tuning. Geneformer and scFoundation demonstrated strong capabilities in gene-level tasks, benefiting from effective pretraining strategies. In contrast, scBERT lagged behind, likely due to its smaller model size and limited training data. Ultimately, BioLLM aims to empower the scientific community to leverage the full potential of foundational models, advancing our understanding of complex biological systems through enhanced single-cell analysis.",
      "authors": "Qiu Ping; Chen Qianqian; Qin Hua; Fang Shuangsang; Zhang Yilin; Zhang Yanlin; Xia Tianyi; Cao Lei; Zhang Yong; Fang Xiaodong; Li Yuxiang; Hu Luni",
      "year": "2025",
      "month": "Aug",
      "journal": "Patterns (New York, N.Y.)",
      "source": "pubmed"
    },
    {
      "pmid": "40838787",
      "doi": "10.1093/bib/bbaf433",
      "title": "SpaICL: image-guided curriculum strategy-based graph contrastive learning for spatial transcriptomics clustering.",
      "abstract": "Spatial transcriptomics, by capturing both gene expression and spatial information, holds great promise for unraveling the complex organization of tissues. In this study, we introduce SpaICL, an image-guided curriculum strategy-based graph contrastive learning framework for spatial transcriptomics clustering. SpaICL integrates gene expression, spatial coordinates, and histological image features to construct a low-dimensional latent representation that enhances the de-lineation of spatial functional domains. The model employs a complementary masking strategy and a shared graph neural network encoder to generate dual embeddings, while a dual cross-attention mechanism aligns local and global features across multiple modalities. Additionally, the curriculum learning module further facilitates the gradual integration of neighborhood information, effectively mitigating the over-smoothing issues associated with fixed adjacency matrices. We evaluated the performance of SpaICL on five benchmark spatial transcriptomics datasets, achieving superior results compared to existing baseline methods. Moreover, SpaICL demonstrates significant potential in downstream analytical applications. The code of SpaICL is available at https://github.com/wenwenmin/SpaICL.",
      "authors": "Zhao Jingcheng; Min Wenwen",
      "year": "2025",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40835718",
      "doi": "10.1038/s41746-025-01942-2",
      "title": "A novel sequence-based transformer model architecture for integrating multi-omics data in preterm birth risk prediction.",
      "abstract": "Preterm birth (PTB) significantly contributes to maternal and perinatal mortality and lifelong morbidity. While large language models (LLM) offer considerable potential for disease risk prediction and early detection, their application to PTB prediction using multi-omics data remains limited. We developed a novel transformer-based architecture for integrating cell free (cfDNA) and cfRNA sequencing data for PTB risk prediction. In the test set, the cfDNA LLM model achieved an AUC of 0.822, and the cfRNA LLM model achieved 0.851. Integrating cfDNA and cfRNA data within the transformer-based framework outperformed both, reaching an AUC of 0.890, a significant improvement over single-modality models. Additionally, we explored cfRNA and cfDNA integration using RNA editing and achieved an AUC of 0.82. This underscores the potential of multi-omics data fusion, with transformer-based architectures providing a powerful framework for disease risk assessment, and demonstrates the potential of AI-driven multi-omics for broader applications in precision obstetrics and biomedicine.",
      "authors": "Zhou Si; Guan Chenchen; Deng Siwei; Zhu Yibing; Yang Wenzhi; Zhang Xiao; Wang Xinrui; Yang Jinying; Zhu Shida; Jiang Hui; Zhang Jianguo; Jin Yongcheng; Cheng Danling; Sun Hai-Xi; Zhao Lijian; Huang Hefeng",
      "year": "2025",
      "month": "Aug",
      "journal": "NPJ digital medicine",
      "source": "pubmed"
    },
    {
      "pmid": "40832322",
      "doi": "10.1101/2025.08.17.670761",
      "title": "Multimodal learning decodes the global binding landscape of chromatin-associated proteins.",
      "abstract": "Chromatin-associated proteins (CAPs), including over 1,600 transcription factors, bind directly or indirectly to the genomic DNA to regulate gene expression and determine a myriad of cell types. Mapping their genome-wide binding and co-binding landscape is essential towards a mechanistic understanding of their functions in gene regulation and resulting cellular phenotypes. However, due to the lack of techniques that effectively scale across proteins and biological samples, their genome-wide binding profiles remain challenging to obtain, particularly in primary cells. Here we present Chromnitron, a multimodal foundation model that accurately predicts CAP binding landscapes across hundreds of proteins in unseen cell types. Via ",
      "authors": "Tan Jimin; Fu Xi; Ling Xinyu; Mo Shentong; Bai Jiangshan; Rabadán Raúl; Fenyö David; Boeke Jef D; Tsirigos Aristotelis; Xia Bo",
      "year": "2025",
      "month": "Aug",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40832178",
      "doi": "10.1101/2025.08.08.669387",
      "title": "CART-GPT: A T Cell-Informed AI Linguistic Framework for Interpreting Neurotoxicity and Therapeutic Outcomes in CAR-T Therapy.",
      "abstract": "Chimeric antigen receptor (CAR) T cell therapy holds transformative potential for hematologic malignancies, yet predicting patient-specific treatment efficacy and neurotoxicity remains a major clinical challenge due to the complex and heterogeneous nature of the infused CAR-T cell populations. Here, we introduce CART-GPT, a transformer-based model fine-tuned on a curated atlas of 1.12 million CAR-T single-cell RNA-seq profiles annotated with clinical outcomes. CART-GPT is the first AI model developed for CAR-T therapy that predicts both treatment response and the risk of immune effector cell-associated neurotoxicity syndrome (ICANS), achieving state-of-the-art performance (AUC ~0.8) and marking a significant advance in the field. The model provides interpretable insights, revealing that neither therapeutic efficacy nor neurotoxicity is driven by individual cell types alone, but by the combined influence of discrete, distinct subsets across diverse T cell states and transcriptional programs. A novel cell aggregation strategy links single-cell predictions to patient-level metrics, enhancing both accuracy and biological relevance. As a contribution to this ever-evolving field, we also release a comprehensive, annotated single-cell CAR-T atlas as a community resource to facilitate future research in immunotherapy. These advances demonstrate the potential of foundation models in single-cell biology to inform precision CAR-T treatment planning and facilitate the rational design of next-generation cell therapies.",
      "authors": "Mao Tiantian; Shao Xiaojian; Guo Wei; Jiang Zhiwu; Jing Rui; Li Xin; Zhu Yiran; Jin Tony; Ma Tao; Lu Yong; Jin Guangxu",
      "year": "2025",
      "month": "Aug",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40826123",
      "doi": "10.1186/s13073-025-01521-w",
      "title": "Improving automated deep phenotyping through large language models using retrieval-augmented generation.",
      "abstract": "Diagnosing rare genetic disorders relies on precise phenotypic and genotypic analysis, with the Human Phenotype Ontology (HPO) providing a standardized language for capturing clinical phenotypes. Rule-based HPO extraction tools use concept recognition to automatically identify phenotypes, but they often struggle with incomplete phenotype assignment, requiring significant manual review. While large language models (LLMs) hold promise for more context-driven phenotype extraction, they are prone to errors and \"hallucinations,\" making them less reliable without further refinement. We present RAG-HPO, a Python-based tool that leverages retrieval-augmented generation (RAG) to elevate accuracy of HPO term assignment by LLM. This approach bypasses the limitations of baseline models and eliminates the need for time- and resource-intensive fine-tuning. RAG-HPO integrates a dynamic vector database, containing > 54,000 phenotypic phrases mapped to HPO IDs, which allows real-time retrieval and contextual matching. The RAG-HPO workflow begins by extracting phenotypic phrases from clinical text via an LLM and then matching them via semantic similarity to entries within the database. The best term matches are returned to the LLM as context for final HPO term assignment of each phrase. Performance was benchmarked on 112 published case reports with 1792 manually assigned HPO terms and compared to Doc2HPO, ClinPhen, and FastHPOCR. In evaluations, RAG-HPO + LLaMa-3.1 70B achieved a mean precision of 0.81, recall of 0.76, and an F1 score of 0.78-significantly surpassing conventional tools (p < 0.00001). RAG-HPO returned 1648 terms, of which 19.1% (315) were false positives that did not exactly match our manually annotated standard. Among these, < 1% (1/315) represented hallucinations, and 1.3% (4/315) represented terms with no ontological relationship to the desired target; the remaining false positives (95.2%, 300/315) were broader ancestor terms of the target term, which may still be relevant to users in many contexts. RAG-HPO is a user-friendly, adaptable tool designed for secure evaluation of clinical text and outperforms standard HPO-matching tools in precision, recall, and F1. Its enhanced precision and recall represent a substantial advancement in phenotypic analysis, accelerating the identification of genetic mechanisms underlying rare diseases and driving progress in genetic research and clinical genomics. RAG-HPO is available at https://github.com/PoseyPod/RAG-HPO .",
      "authors": "Garcia Brandon T; Westerfield Lauren; Yelemali Priya; Gogate Nikhita; Rivera-Munoz E Andres; Du Haowei; Dawood Moez; Jolly Angad; Lupski James R; Posey Jennifer E",
      "year": "2025",
      "month": "Aug",
      "journal": "Genome medicine",
      "source": "pubmed"
    },
    {
      "pmid": "40826008",
      "doi": "10.1186/s12864-025-11941-y",
      "title": "A hybrid adversarial autoencoder-graph network model with dynamic fusion for robust scRNA-seq clustering.",
      "abstract": "Single-cell RNA sequencing (scRNA-seq) allows the exploration of biological heterogeneity among different cell types within tissues at a single-cell resolution. Cell clustering serves as a foundation for scRNA-seq data analysis and provides new insights into the heterogeneity of cells within complex tissues. However, the inherent features of scRNA-seq data, such as heterogeneity, sparsity, and high dimensionality, pose significant technical challenges for effective cell clustering. Here, we present a novel deep clustering method, scCAGN, based on an adversarial autoencoder (AAE) and a cross-attention graph convolutional network (GCN), to address the above challenges in scRNA-seq data analysis. Specifically, to enhance data reconstruction, scCAGN utilizes adversarial autoencoders to augment encoder capabilities. Graph feature representations obtained via a GCN were integrated using a dynamic information fusion mechanism, yielding enhanced feature representations. In addition, scCAGN combines three different loss functions to optimize clustering performance through a joint clustering approach. By leveraging a unique information fusion and joint mechanism, scCAGN extracts deep cell features without labeled information, thus improving cell classification efficiency. Our findings show that scCAGN surpasses the existing methods in clustering performance across eight typical scRNA-seq datasets, achieving a maximum Normalized Mutual Information (NMI) improvement of 11.94%, notably reaching an NMI of 0.9732 in the QS_diaphragm dataset. It showed an average NMI improvement of 13% across the eight benchmark datasets, surpassing the lowest-performing method. Further ablation and hyperparameter analyses validated the robustness of the proposed method. The code is available at: http://github.com/gladex/scCAGN . scCAGN integrates AAE and cross-attention GCN with dynamic fusion, achieving state-of-the-art scRNA-seq clustering (0.9732 NMI, 13% average gain) across eight datasets. Validated via ablation and hyperparameter tests, it advances label-free cell discovery and enables further multimodal integration to dissect cellular heterogeneity.",
      "authors": "Tang Binhua; Feng Yingying; Gao Xinyu",
      "year": "2025",
      "month": "Aug",
      "journal": "BMC genomics",
      "source": "pubmed"
    },
    {
      "pmid": "40825239",
      "doi": "10.1093/bib/bbaf418",
      "title": "Protein language model pseudolikelihoods capture features of in vivo B cell selection and evolution.",
      "abstract": "B cell selection and evolution play crucial roles in dictating successful immune responses. Recent advancements in sequencing technologies and deep-learning strategies have paved the way for generating and exploiting an ever-growing wealth of antibody repertoire data. The self-supervised nature of protein language models (PLMs) has demonstrated the ability to learn complex representations of antibody sequences and has been leveraged for a wide range of applications including diagnostics, structural modeling, and antigen-specificity predictions. PLM-derived likelihoods have been used to improve antibody affinities in vitro, raising the question of whether PLMs can capture and predict features of B cell selection in vivo. Here, we explore how general and antibody-specific PLM-generated sequence pseudolikelihoods (SPs) relate to features of in vivo B cell selection such as expansion, isotype usage, and somatic hypermutation (SHM) at single-cell resolution. Our results demonstrate that the type of PLM and the region of the antibody input sequence significantly affect the generated SP. Contrary to previous in vitro reports, we observe a negative correlation between SPs and binding affinity, whereas repertoire features such as SHM and isotype usage were strongly correlated with SPs. By constructing evolutionary lineage trees of B cell clones from human and mouse repertoires, we observe that SHMs are routinely among the most likely mutations suggested by PLMs and that mutating residues have lower absolute likelihoods than conserved residues. Our findings highlight the potential of PLMs to predict features of antibody selection and further suggest their potential to assist in antibody discovery and engineering.",
      "authors": "van Ginneken Daphne; Samant Anamay; Daga-Krumins Karlis; Glänzer Wiona; Agrafiotis Andreas; Kladis Evgenios; Reddy Sai T; Yermanos Alexander",
      "year": "2025",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40821715",
      "doi": "10.1016/j.csbj.2025.07.038",
      "title": "Tokenization and deep learning architectures in genomics: A comprehensive review.",
      "abstract": "The development of modern DNA sequencing technologies has resulted in the rapid growth of genomic data. Alongside the collection of this data, there is an increasing need for the development of modern computational tools leveraging this data for tasks including but not limited to antimicrobial resistance and gene annotation. Current deep learning architectures and tokenization techniques have been explored for the extraction of meaningful underlying information contained within this sequencing data. We aim to survey current and foundational literature surrounding the area of deep learning architectures and tokenization techniques in the field of genomics. Our survey of the literature outlines that significant work remains in developing efficient tokenization techniques that can capture or model underlying motifs within DNA sequences. While deep learning models have become more efficient, many current tokenization methods either reduce scalability through naive sequence representation, incorrectly model motifs or are borrowed directly from NLP tasks for use with biological sequences. Current and future model architectures should seek to implement and support more advanced, and biologically relevant, tokenization techniques to more effectively model the underlying information in biological sequencing data.",
      "authors": "Testagrose Conrad; Boucher Christina",
      "year": "2025",
      "month": "",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "40819118",
      "doi": "10.1038/s43856-025-01034-y",
      "title": "Achieving inclusive healthcare through integrating education and research with AI and personalized curricula.",
      "abstract": "Precision medicine promises significant health benefits but faces challenges such as complex data management and analytics, interdisciplinary collaboration, and education of researchers, healthcare professionals, and participants. Addressing these needs requires the integration of computational experts, engineers, designers, and healthcare professionals to develop user-friendly systems and shared terminologies. The widespread adoption of large language models (LLMs) such as Generative Pretrained Transformer (GPT) and Claude highlights the importance of making complex data accessible to non-specialists. We evaluated the Stanford Data Ocean (SDO) precision medicine training program's learning outcomes, AI Tutor performance, and learner satisfaction by assessing self-rated competency on key learning objectives through pre- and post-learning surveys, along with formative and summative assessment completion rates. We also analyzed AI Tutor accuracy and learners' self-reported satisfaction, and post-program academic and career impacts. Additionally, we demonstrated the capabilities of the AI Data Visualization tool. SDO demonstrates the ability to improve learning outcomes for learners from broad educational and socioeconomic backgrounds with the support of the AI Tutor. The AI Data Visualization tool enables learners to interpret multi-omics and wearable data and replicate research findings. SDO strives to mitigate challenges in precision medicine through a scalable, cloud-based platform that supports data management for various data types, advanced research, and personalized learning. SDO provides AI Tutors and AI-powered data visualization tools to enhance educational and research outcomes and make data analysis accessible to users from broad educational backgrounds. By extending engagement and cutting-edge research capabilities globally, SDO particularly benefits economically disadvantaged and historically marginalized communities, fostering interdisciplinary biomedical research and bridging the gap between education and practical application in the biomedical field.",
      "authors": "Bahmani Amir; Cha Kexin; Alavi Arash; Dixit Amit; Ross Antony; Park Ryan; Goncalves Francesca; Ma Shirley; Saxman Paul; Nair Ramesh; Akhavan-Sarraf Ramin; Zhou Xin; Wang Meng; Contrepois Kévin; Li-Pook-Than Jennifer; Monte Emma; Rodriguez David Jose Florez; Lai Jaslene; Babu Mohan; Tondar Abtin; Schüssler-Fiorenza Rose Sophia Miryam; Akbari Ilya; Zhang Xinyue; Yegnashankaran Kritika; Yracheta Joseph; Dale Kali; Miller Alison Derbenwick; Edmiston Scott; McGhee Eva M; Nebeker Camille; Wu Joseph C; Kundaje Anshul; Snyder Michael",
      "year": "2025",
      "month": "Aug",
      "journal": "Communications medicine",
      "source": "pubmed"
    },
    {
      "pmid": "40806487",
      "doi": "10.3390/ijms26157358",
      "title": "Self-Normalizing Multi-Omics Neural Network for Pan-Cancer Prognostication.",
      "abstract": "Prognostic markers such as overall survival (OS) and tertiary lymphoid structure (TLS) ratios, alongside diagnostic signatures like primary cancer-type classification, provide critical information for treatment selection, risk stratification, and longitudinal care planning across the oncology continuum. However, extracting these signals solely from sparse, high-dimensional multi-omics data remains a major challenge due to heterogeneity and frequent missingness in patient profiles. To address this challenge, we present SeNMo, a self-normalizing deep neural network trained on five heterogeneous omics layers-gene expression, DNA methylation, miRNA abundance, somatic mutations, and protein expression-along with the clinical variables, that learns a unified representation robust to missing modalities. Trained on more than 10,000 patient profiles across 32 tumor types from The Cancer Genome Atlas (TCGA), SeNMo provides a baseline that can be readily fine-tuned for diverse downstream tasks. On a held-out TCGA test set, the model achieved a concordance index of 0.758 for OS prediction, while external evaluation yielded 0.73 on the CPTAC lung squamous cell carcinoma cohort and 0.66 on an independent 108-patient Moffitt Cancer Center cohort. Furthermore, on Moffitt's cohort, baseline SeNMo fine-tuned for TLS ratio prediction aligned with expert annotations (",
      "authors": "Waqas Asim; Tripathi Aakash; Ahmed Sabeen; Mukund Ashwin; Farooq Hamza; Johnson Joseph O; Stewart Paul A; Naeini Mia; Schabath Matthew B; Rasool Ghulam",
      "year": "2025",
      "month": "Jul",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "40799808",
      "doi": "",
      "title": "Progress and new challenges in image-based profiling.",
      "abstract": "For over two decades, image-based profiling has revolutionized cellular phenotype analysis. Image-based profiling processes rich, high-throughput, microscopy data into unbiased measurements that reveal phenotypic patterns powerful for drug discovery, functional genomics, and cell state classification. Here, we review the evolving computational landscape of image-based profiling, detailing current procedures, discussing limitations, and highlighting future development directions. Deep learning has fundamentally reshaped image-based profiling, improving feature extraction, scalability, and multimodal data integration. Methodological advancements such as single-cell analysis and batch effect correction, drawing inspiration from single-cell transcriptomics, have enhanced analytical precision. The growth of open-source software ecosystems and the development of community-driven standards have further democratized access to image-based profiling, fostering reproducibility and collaboration across research groups. Despite these advancements, the field still faces significant challenges requiring innovative solutions. By focusing on the technical evolution of image-based profiling rather than the wide-ranging biological applications, our aim with this review is to provide researchers with a roadmap for navigating the progress and new challenges in this rapidly advancing domain.",
      "authors": "Serrano Erik; Peters John; Wagner Jesko; Graham Rebecca E; Chen Zhenghao; Feng Brian; Miranda Gisele; Kalinin Alexandr A; Vulliard Loan; Tomkinson Jenna; Mattson Cameron; Lippincott Michael J; Kang Ziqi; Sitani Divya; Bunten Dave; Seal Srijit; Carragher Neil O; Carpenter Anne E; Singh Shantanu; Marin Zapata Paula A; Caicedo Juan C; Way Gregory P",
      "year": "2025",
      "month": "Aug",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "40799805",
      "doi": "",
      "title": "DART-Eval: A Comprehensive DNA Language Model Evaluation Benchmark on Regulatory DNA.",
      "abstract": "Recent advances in self-supervised models for natural language, vision, and protein sequences have catalyzed the development of genomic DNA language models (DNALMs). These models aim to learn generalizable representations of diverse DNA elements, potentially enabling various downstream genomic prediction, interpretation and design tasks. However, existing benchmarks do not adequately assess the capabilities of DNALMs on an important class of non-coding DNA elements critical for regulating gene activity. Here, we introduce DART-Eval, a suite of representative benchmarks focused on regulatory DNA to evaluate performance of DNALMs across zero-shot, probed, and fine-tuned settings against contemporary ",
      "authors": "Patel Aman; Singhal Arpita; Wang Austin; Pampari Anusri; Kasowski Maya; Kundaje Anshul",
      "year": "2025",
      "month": "Aug",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "40794872",
      "doi": "10.1093/nar/gkaf748",
      "title": "Base-resolution binding profile prediction of proteins on RNAs with deep learning.",
      "abstract": "RNA-binding proteins play crucial roles in various RNA-associated biological processes, which are closely linked to cellular function and disease. Based on CLIP-seq data, the existing deep learning methods are developed to predict protein-RNA interactions. However, CLIP-seq relies on gene expression, which varies significantly across cells. Existing methods are typically trained on peak-associated binding sites and implicitly defined non-binding sites, without considering the cell-specific expression profiles. Given the dynamic nature of protein-RNA interactions, these methods struggle to accurately predict the binding nucleotides and strength of proteins on RNAs across cell lines. Therefore, this study proposes a novel deep learning-based method, iDeepB, designed to predict the proteins binding profile on RNAs at base resolution by integrating cell-line-specific gene expression profiles. iDeepB first constructs expression-aware benchmark datasets based on cell-specific RNA-seq and eCLIP-seq data, which is used to train a hybrid deep network with multi-head attention, enabling the prediction of protein binding profiles, analysis of binding motif syntax composition, and quantification of functional effects of genome mutations related to human diseases. Comprehensive evaluation on the newly developed benchmark datasets demonstrates that iDeepB outperforms existing methods in predicting protein binding profile on RNAs.",
      "authors": "Liu Xiaojian; Zhu Weimin; Ding Xiaohan; Fang Yi; Wang Shengfan; Zhu Lin; Shen Hong-Bin; Pan Xiaoyong",
      "year": "2025",
      "month": "Jul",
      "journal": "Nucleic acids research",
      "source": "pubmed"
    },
    {
      "pmid": "40791911",
      "doi": "10.3389/fneur.2025.1615523",
      "title": "Harnessing artificial intelligence for brain disease: advances in diagnosis, drug discovery, and closed-loop therapeutics.",
      "abstract": "Brain diseases pose a significant global health challenge due to their complexity and the limitations of traditional medical strategies. Recent advancements in artificial intelligence (AI), especially deep learning models like Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Graph Neural Networks (GNNs), offer powerful new tools for analysis. These neural networks are effective at extracting complex patterns from high-dimensional data. By integrating diverse data sources-such as neuroimaging, multi-omics, and clinical information-multimodal AI provides the comprehensive view needed to understand intricate disease mechanisms. This review outlines how these technologies enhance precision drug development and enable closed-loop treatment systems for brain disorders. Key applications include improving diagnostic accuracy, identifying novel biomarkers, accelerating drug discovery through target identification and virtual screening, and predicting patient-specific treatment responses. These AI-driven methods have the potential to shift medicine from a one-size-fits-all model to a personalized approach, with diagnostics and therapies tailored to individual profiles. However, realizing this potential requires addressing significant challenges related to data access, model interpretability, clinical validation, and practical integration.",
      "authors": "Fang Su-Jun; Yin Zhao-di; Cai Qi; Li Li-Fan; Zheng Peng-Fei; Chen Li-Zhen",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in neurology",
      "source": "pubmed"
    },
    {
      "pmid": "40791437",
      "doi": "10.1101/2025.07.11.664399",
      "title": "mamp-ml: A deep learning approach to epitope immunogenicity in plants.",
      "abstract": "Eukaryotes detect biomolecules through surface-localized receptors, key signaling components. A subset of receptors survey for pathogens, induce immunity, and restrict pathogen growth. Comparative genomics of both hosts and pathogens has unveiled vast sequence variation in receptors and potential ligands, creating an experimental bottleneck. We have developed mamp-ml, a machine learning framework for predicting plant receptor-ligand interactions. We leveraged existing functional data from over two decades of foundational research, together with the large protein language model ESM-2, to build a pipeline and model that predicts immunogenic outcomes using a combination of receptor-ligand features. Our model achieves 73% prediction accuracy on a held-out test set, even when an experimental structure is lacking. Our approach enables high-throughput screening of LRR receptor-ligand combinations and provides a computational framework for engineering plant immune systems.",
      "authors": "Stevens Danielle M; Yang David; Liang Tatiana J; Li Tianrun; Vega Brandon; Coaker Gitta L; Krasileva Ksenia",
      "year": "2025",
      "month": "Jul",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40777394",
      "doi": "10.1101/2025.07.23.665976",
      "title": "CellFuse Enables Multi-modal Integration of Single-cell and Spatial Proteomics data.",
      "abstract": "Single-cell and spatial proteomic technologies capture complementary biological information, yet no single platform can measure all modalities within the same cell. Most existing integration methods are optimized for transcriptomic data and rely on a large set of shared, strongly linked features, an assumption that often fails for low-dimensional proteomic modalities. We present CellFuse, a deep learning-based, modality-agnostic integration framework designed specifically for settings with limited feature overlap. CellFuse leverages supervised contrastive learning to learn a shared embedding space, enabling accurate cell type prediction and seamless integration across modalities and experimental conditions. Across a range of datasets including healthy PBMCs, bone marrow, CAR-T-treated lymphoma, and healthy and tumor tissues-CellFuse consistently outperforms existing methods in both integration quality and runtime efficiency. It maintains high accuracy even in the presence of missing markers and rare cell types, and performs robustly in cross-dataset comparisons, making it a powerful tool for scalable and high-fidelity single-cell data integration in basic and translational research.",
      "authors": "Koladiya Abhishek; Good Zinaida; Varra Sricharan Reddy; Bendall Sean C; Davis Kara L",
      "year": "2025",
      "month": "Jul",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40775734",
      "doi": "10.1186/s13073-025-01502-z",
      "title": "Building digital histology models of transcriptional tumor programs with generative deep learning for pathology-based precision medicine.",
      "abstract": "Precision oncology depends on identifying the biological vulnerabilities of a tumor. Molecular assays, like transcriptomics, provide an information-rich view of the tumor that can be leveraged to inform therapeutic selection. However, the costs of such assays can be prohibitive for clinical translation at scale. Histology-based imaging remains a predominant means of diagnosis that is widely accessible. To more broadly leverage limited molecular datasets, models have been trained to use histology to infer the expression of individual genes or pathways, with varying levels of accuracy and explainability. Our approach detects expression of transcriptional programs from tumor histology and interprets the image features supporting program detection. Specifically, we used RNA-seq data from squamous cell carcinoma (SCC) patients to infer cohesive expression patterns of multiple genes. Then, we used deep learning techniques to train a computational model to predict the activity levels of the transcriptional programs directly from histology images. We exploited that predictive capability to generate synthetic digital models of the cellular histology of each transcriptional program, using generative adversarial networks to isolate image features supporting specific transcriptional predictions and pathologist review to interpret the images. Applying our histologically integrated latent space analysis to SCCs revealed sets of genes associated with both pathologist-interpretable image features and clinically relevant processes, including immune response, collagen remodeling, and fibrosis, going beyond predictions of individual molecular features. Our results demonstrate an approach for discovering clinically interpretable histological features that indicate molecular, potentially treatment-informing, biological processes. These features are detectable in widely available histology slides, allowing a standard microscope to deliver complex, patient-specific molecular information.",
      "authors": "Hieromnimon Hanna M; Dolezal James; Doytcheva Kristina; Howard Frederick M; Kochanny Sara; Zhang Zhenyu; Grossman Robert L; Tanager Kevin; Wang Cindy; Kather Jakob Nikolas; Izumchenko Evgeny; Cipriani Nicole A; Fertig Elana J; Pearson Alexander T; Riesenfeld Samantha J",
      "year": "2025",
      "month": "Aug",
      "journal": "Genome medicine",
      "source": "pubmed"
    },
    {
      "pmid": "40771972",
      "doi": "10.3389/fneur.2025.1607924",
      "title": "Artificial intelligence in neurodegenerative diseases research: a bibliometric analysis since 2000.",
      "abstract": "This bibliometric review examines the evolving landscape of artificial intelligence (AI) in neurodegenerative diseases research from 2000 to March 16, 2025, utilizing data from 1,402 publications (1,159 articles, 243 reviews) indexed in the Web of Science Core Collection. Through advanced tools - VOSviewer, CiteSpace, and Bibliometrix R - the study maps collaboration networks, keyword trends, and knowledge trajectories. Results reveal exponential growth post-2017, driven by advancements in deep learning and multimodal data integration. The United States (25.96%) and China (24.11%) dominate publication volume, while the UK exhibits the highest collaboration centrality (0.24) and average citations per publication (31.68). Core journals like ",
      "authors": "Zhang Yabin; Yu Lei; Lv Yuting; Yang Tiantian; Guo Qi",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in neurology",
      "source": "pubmed"
    },
    {
      "pmid": "40766228",
      "doi": "10.21203/rs.3.rs-7108570/v1",
      "title": "Cross-level Cross-Scale Inference and Imputation of Single-cell Spatial Proteomics.",
      "abstract": "High-throughput single-cell and spatial omics technologies have transformed biological research. Despite these advances, reliably identifying the molecular drivers and their interplays across biological levels and scales remains a significant challenge. Current experimental methods are limited by batch effects, the lack of simultaneous multi-modal measurements in individual cells, limited coverage of measured proteins, poor generalization to unseen conditions, and insufficient spatial context at a single-cell resolution. To overcome these challenges, we introduce scProSpatial, a unified, multi-modal, multi-scale deep learning framework designed to infer and impute high fidelity single-cell spatial proteomics from scRNA-seqs. Through comprehensive evaluations, scProSpatial accurately predicts spatial abundances of proteins in the absence of shared transcriptomics features, expands protein coverages by 50 times, and generalizes robustly to out-of-distribution scenarios. A case study in metastatic breast cancer further illustrates its utility, demonstrating scProSpatial's potential to drive cross-level, cross-scale multi-omics integration and analysis and reveal deeper insights into complex biological systems.",
      "authors": "Wu You; Xie Lei",
      "year": "2025",
      "month": "Jul",
      "journal": "Research square",
      "source": "pubmed"
    },
    {
      "pmid": "40748323",
      "doi": "10.1093/bib/bbaf355",
      "title": "A technical review of multi-omics data integration methods: from classical statistical to deep generative approaches.",
      "abstract": "The rapid advancement of high-throughput sequencing and other assay technologies has resulted in the generation of large and complex multi-omics datasets, offering unprecedented opportunities for advancing precision medicine. However, multi-omics data integration remains challenging due to the high-dimensionality, heterogeneity, and frequency of missing values across data types. Computational methods leveraging statistical and machine learning approaches have been developed to address these issues and uncover complex biological patterns, improving our understanding of disease mechanisms. Here, we comprehensively review state-of-the-art multi-omics integration methods with a focus on deep generative models, particularly variational autoencoders (VAEs) that have been widely used for data imputation, augmentation, and batch effect correction. We explore the technical aspects of VAE loss functions and regularisation techniques, including adversarial training, disentanglement, and contrastive learning. Moreover, we highlight recent advancements in foundation models and multimodal data integration, outlining future directions in precision medicine research.",
      "authors": "Baião Ana R; Cai Zhaoxiang; Poulos Rebecca C; Robinson Phillip J; Reddel Roger R; Zhong Qing; Vinga Susana; Gonçalves Emanuel",
      "year": "2025",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40747416",
      "doi": "10.1101/2025.07.07.663529",
      "title": "Benchmarking Large Language Models for Predictive Modeling in Biomedical Research With a Focus on Reproductive Health.",
      "abstract": "Generative AI, particularly large language models (LLMs), is increasingly being used in computational biology to support code generation for data analysis. In this study, we evaluated the ability of LLMs to generate functional R and Python code for predictive modeling tasks, leveraging standardized molecular datasets from several recent DREAM (Dialogue for Reverse Engineering Assessments and Methods) Challenges focused on reproductive health. We assessed LLM performance across four predictive tasks derived from three DREAM challenges: gestational age regression from gene expression, gestational age regression from DNA methylation profiles, and classification of preterm birth and early preterm birth from microbiome data. LLMs were prompted with task descriptions, data locations, and target outcomes. LLM-generated code was then run to fit and apply prediction models and generate graphics, and they were ranked based on their success in completing the tasks and achieving strong test set performance. Among the eight LLMs tested, o3-mini-high, 4o, DeepseekR1 and Gemini 2.0 completed at least one task without error. Overall, R code generation was more successful (14/16 tasks) than Python (7/16), attributed to the utility of Bioconductor packages for querying Gene Expression Omnibus data. OpenAI's o3-mini-high outperformed others, completing 7/8 tasks. Test set performance of the top LLM matched or exceeded top-performing teams from the original DREAM challenges. These findings underscore the potential of LLMs to enhance exploratory analysis and democratize access to predictive modeling in omics by automating key components of analysis pipelines, and highlight the potential to increase research output when conducting analyses of standardized datasets from public repositories.",
      "authors": "Sarwal Reuben; Tarca Victor; Dubin Claire; Kalavros Nikolas; Bhatti Gaurav; Bhattacharya Sanchita; Butte Atul; Romero Roberto; Stolovitzky Gustavo; Oskotsky Tomiko T; Tarca Adi L; Sirota Marina",
      "year": "2025",
      "month": "Jul",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40731310",
      "doi": "10.1186/s12859-025-06236-8",
      "title": "PuMA: PubMed gene/cell type-relation Atlas.",
      "abstract": "Rapid extraction and visualization of cell-specific gene expression is important for automatic cell type annotation, e.g. in single cell analysis. There is an emerging field in which tools such as curated databases or machine learning methods are used to support cell type annotation. However, complementing approaches to efficiently incorporate the latest knowledge of free-text articles from literature databases, such as PubMed, are understudied. This work introduces the PubMed Gene/Cell type-Relation Atlas (PuMA) which provides a local, easy-to-use web-interface to facilitate literature-driven cell type annotation. It utilizes a pretrained machine learning based named entity recognition model in order to extract gene and cell type concepts from PubMed, links biomedical ontologies, and suggests gene to cell type relations based on a ranking score. It includes a search tool for genes and cell types, additionally providing an interactive graph visualization for exploring cross-relations. Each result is fully traceable by linking the relevant PubMed articles. This work enables researchers to analyse and automatize cell type annotation based on PubMed articles. It complements manual curated marker gene databases and enables interactive visualizations. The evaluation shows that PuMA is competitive against an extensive manual curated database across three gold standard datasets and two species-mouse and human. The software framework is freely available and enables regular article imports for incremental knowledge updates.GitLab: https://imigitlab.uni-muenster.de/published/PuMA/.",
      "authors": "Bickmann Lucas; Sandmann Sarah; Walter Carolin; Varghese Julian",
      "year": "2025",
      "month": "Jul",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40728934",
      "doi": "10.1093/bioinformatics/btaf417",
      "title": "2OMe-LM: predicting 2'-O-methylation sites in human RNA using a pre-trained RNA language model.",
      "abstract": "2'-O-methylation (2OMe) is a common post-transcriptional modification in RNA that plays a crucial role in regulating gene expression and is implicated in various biological processes and diseases. Computational methods offer an efficient alternative to the time-consuming and costly experimental identification of 2OMe sites. Recent advancements in RNA pre-trained language models have revolutionized RNA bioinformatics. However, there remains a gap in their application specifically for predicting 2OMe sites. In the study, we propose a novel deep learning framework, 2OMe-LM, for predicting 2OMe sites in RNA. 2OMe-LM integrates RNA sequence features derived from RNA pre-trained language models with those obtained from the word2vec technique. Then, 2OMe-LM employs fully connected layers and a bidirectional long short-term memory network to process the two types of features separately, followed by a feature fusion module for the final prediction. Additionally, an attention block is incorporated to provide the interpretability of the prediction results. The results demonstrate that 2OMe-LM significantly outperforms existing state-of-the-art predictors, with features from RNA pre-trained language models proving to be critical. Motif analysis further demonstrates 2OMe-LM's potential for discovering 2OMe-related motifs. The 2OMe-LM web server is available at https://csuligroup.com:9200/2OMe-LM. The source code can be obtained from https://github.com/CSUBioGroup/2OMe-LM.",
      "authors": "Liu Qianpei; Zeng Min; Li Yiming; Lu Chengqian; Kan Shichao; Guo Fei; Li Min",
      "year": "2025",
      "month": "Aug",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "40723331",
      "doi": "10.3390/biology14070771",
      "title": "Integrating Deep Learning and Transcriptomics to Assess Livestock Aggression: A Scoping Review.",
      "abstract": "The presence of aggressive behavior in livestock creates major difficulties for animal welfare, farm safety, economic performance and selective breeding. The two innovative tools of deep learning-based video analysis and transcriptomic profiling have recently appeared to aid the understanding and monitoring of such behaviors. This scoping review assesses the current use of these two methods for aggression research across livestock species and identifies trends while revealing unaddressed gaps in existing literature. A scoping literature search was performed through the PubMed, Scopus and Web of Science databases to identify articles from 2014 to April 2025. The research included 268 original studies which were divided into 250 AI-driven behavioral phenotyping papers and 18 transcriptomic investigations without any studies combining both approaches. Most research focused on economically significant species, including pigs and cattle, yet poultry and small ruminants, along with camels and fish and other species, received limited attention. The main developments include convolutional neural network (CNN)-based object detection and pose estimation systems, together with the transcriptomic identification of molecular pathways that link to aggression and stress. The main barriers to progress in the field include inconsistent behavioral annotation and insufficient real-farm validation together with limited cross-modal integration. Standardized behavior definitions, together with multimodal datasets and integrated pipelines that link phenotypic and molecular data, should be developed according to our proposal. These innovations will speed up the advancement of livestock welfare alongside precision breeding and sustainable animal production.",
      "authors": "Juhos Roland; Kusza Szilvia; Bilicki Vilmos; Bagi Zoltán",
      "year": "2025",
      "month": "Jun",
      "journal": "Biology",
      "source": "pubmed"
    },
    {
      "pmid": "40709098",
      "doi": "10.1038/s42256-025-01052-4",
      "title": "Integrating multimodal cancer data using deep latent variable path modelling.",
      "abstract": "Cancers are commonly characterized by a complex pathology encompassing genetic, microscopic and macroscopic features, which can be probed individually using imaging and omics technologies. Integrating these data to obtain a full understanding of pathology remains challenging. We introduce a method called deep latent variable path modelling, which combines the representational power of deep learning with the capacity of path modelling to identify relationships between interacting elements in a complex system. To evaluate the capabilities of deep latent variable path modelling, we initially trained a model to map dependencies between single-nucleotide variant, methylation profiles, microRNA sequencing, RNA sequencing and histological data using breast cancer data from The Cancer Genome Atlas. This method exhibited superior performance in mapping associations between data types compared with classical path modelling. We additionally performed successful applications of the model to stratify single-cell data, identify synthetic lethal interactions using CRISPR-Cas9 screens derived from cell lines and detect histologic-transcriptional associations using spatial transcriptomic data. Results from each of these data types can then be understood with reference to the same holistic model of illness.",
      "authors": "Ing Alex; Andrades Alvaro; Cosenza Marco Raffaele; Korbel Jan O",
      "year": "2025",
      "month": "",
      "journal": "Nature machine intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "40699869",
      "doi": "10.3390/cimb47060470",
      "title": "Integrating Artificial Intelligence in Next-Generation Sequencing: Advances, Challenges, and Future Directions.",
      "abstract": "The integration of artificial intelligence (AI) into next-generation sequencing (NGS) has revolutionized genomics, offering unprecedented advancements in data analysis, accuracy, and scalability. This review explores the synergistic relationship between AI and NGS, highlighting its transformative impact across genomic research and clinical applications. AI-driven tools, including machine learning and deep learning, enhance every aspect of NGS workflows-from experimental design and wet-lab automation to bioinformatics analysis of the generated raw data. Key applications of AI integration in NGS include variant calling, epigenomic profiling, transcriptomics, and single-cell sequencing, where AI models such as CNNs, RNNs, and hybrid architectures outperform traditional methods. In cancer research, AI enables precise tumor subtyping, biomarker discovery, and personalized therapy prediction, while in drug discovery, it accelerates target identification and repurposing. Despite these advancements, challenges persist, including data heterogeneity, model interpretability, and ethical concerns. This review also discusses the emerging role of AI in third-generation sequencing (TGS), addressing long-read-specific challenges, like fast and accurate basecalling, as well as epigenetic modification detection. Future directions should focus on implementing federated learning to address data privacy, advancing interpretable AI to improve clinical trust and developing unified frameworks for seamless integration of multi-modal omics data. By fostering interdisciplinary collaboration, AI promises to unlock new frontiers in precision medicine, making genomic insights more actionable and scalable.",
      "authors": "Athanasopoulou Konstantina; Michalopoulou Vasiliki-Ioanna; Scorilas Andreas; Adamopoulos Panagiotis G",
      "year": "2025",
      "month": "Jun",
      "journal": "Current issues in molecular biology",
      "source": "pubmed"
    },
    {
      "pmid": "40697660",
      "doi": "10.3389/fphar.2025.1597351",
      "title": "Application of artificial intelligence large language models in drug target discovery.",
      "abstract": "Drug target discovery is a fundamental aspect of contemporary drug research and development. However, the use of conventional biochemical screening, omics analysis, and related approaches is constrained by substantial technical complexity and significant resource requirements. With the advancement of artificial intelligence-based large language models, notable progress has been achieved in drug target identification. During target mining, large language models with natural language comprehension capabilities can efficiently integrate literature data resources and systematically analyze disease-associated biological pathways and potential targets. Notably, models specifically designed for biomolecular \"language\" have demonstrated advantages across multiple aspects. The genomics-focused large language model has significantly enhanced the accuracy of pathogenic gene variant identification and gene expression prediction. In transcriptomics, large language models enable comprehensive reconstruction of gene regulatory networks. In proteomics, advancements have been made in protein structure analysis, function prediction, and interaction inference. Additionally, the single-cell multi-omics large language model facilitates data integration across different omics technologies. These technological advancements provide multi-dimensional biological evidence supporting drug target discovery and contribute to a more efficient screening process for candidate targets. The development of these models is generally based on deep neural networks of Transformer architecture, and powerful representation capabilities are obtained through large-scale unsupervised pre-training (such as mask language modeling, autoregressive prediction) combined with task-specific supervised fine-tuning. This review systematically examines recent advancements in the application of large language models in drug target discovery, emphasizing existing technical challenges and potential future research directions.",
      "authors": "Liu Xinyu; Zhang Jia; Wang Xiaoran; Teng Maoda; Wang Guoying; Zhou Xiaoming",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in pharmacology",
      "source": "pubmed"
    },
    {
      "pmid": "40672207",
      "doi": "10.1101/2025.07.04.663250",
      "title": "GAME: Genomic API for Model Evaluation.",
      "abstract": "The rapid expansion of genomics datasets and the application of machine learning has produced sequence-to-activity genomics models with ever-expanding capabilities. However, benchmarking these models on practical applications has been challenging because individual projects evaluate their models in ad hoc ways, and there is substantial heterogeneity of both model architectures and benchmarking tasks. To address this challenge, we have created GAME, a system for large-scale, community-led standardized model benchmarking on user-defined evaluation tasks. We borrow concepts from the Application Programming Interface (API) paradigm to allow for seamless communication between pre-trained models and benchmarking tasks, ensuring consistent evaluation protocols. Because all models and benchmarks are inherently compatible in this framework, the continual addition of new models and new benchmarks is easy. We also developed a Matcher module powered by a large language model (LLM) to automate ambiguous task alignment between benchmarks and models. Containerization of these modules enhances reproducibility and facilitates the deployment of models and benchmarks across computing platforms. By focusing on predicting underlying biochemical phenomena (e.g. gene expression, open chromatin, DNA binding), we ensure that tasks remain technology-independent. We provide examples of benchmarks and models implementing this framework, and anticipate that the community will contribute their own, leading to an ever-expanding and evolving set of models and evaluation tasks. This resource will accelerate genomics research by illuminating the best models for a given task, motivating novel functional genomic benchmarks, and providing a more nuanced understanding of model abilities.",
      "authors": "Luthra Ishika; Priyadarshi Satyam; Guo Rui; Mahieu Lukas; Kempynck Niklas; Dooley Damion; Penzar Dmitry; Vorontsov Ilya; Sheng Yilun; Tu Xinming; Klie Adam; Drusinsky Shiron; Floren Alexander; Armand Ethan; Alasoo Kaur; Seelig Georg; Tewhey Ryan; Koo Peter; Agarwal Vikram; Gosai Sager; Pinello Luca; White Michael A; Lal Avantika; Zeitlinger Julia; Pollard Katherine S; Libbrecht Maxwell; Carter Hannah; Mostafavi Sara; Kulakovskiy Ivan; Hsiao Will; Aerts Stein; Zhou Jian; de Boer Carl G",
      "year": "2025",
      "month": "Jul",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40671942",
      "doi": "",
      "title": "Spatia: Multimodal Model for Prediction and Generation of Spatial Cell Phenotypes.",
      "abstract": "Understanding how cellular morphology, gene expression, and spatial organization jointly shape tissue function is a central challenge in biology. Image-based spatial transcriptomics technologies now provide high-resolution measurements of cell images and gene expression profiles, but machine learning methods typically analyze these modalities in isolation or at limited resolution. We address the problem of learning unified, spatially aware representations that integrate cell morphology, gene expression, and spatial context across biological scales. This requires models that can operate at single-cell resolution, reason across spatial neighborhoods, and generalize to whole-slide tissue organization. Here, we introduce Spatia, a multi-scale generative and predictive model for spatial transcriptomics. Spatia learns cell-level embeddings by fusing image-derived morphological tokens and transcriptomic vector tokens using cross-attention and then aggregates them at niche and tissue levels using transformer modules to capture spatial dependencies. Spatia incorporates token merging in its generative diffusion decoder to synthesize high-resolution cell images conditioned on gene expression. We assembled a multi-scale dataset consisting of 17 million cell-gene pairs, 1 million niche-gene pairs, and 10, 000 tissue-gene pairs across 49 donors, 17 tissue types, and 12 disease states. We benchmark Spatia against 13 existing models across 12 individual tasks, which span several categories including cell annotation, cell clustering, gene imputation, cross-modal prediction, and image generation. Spatia achieves improved performance over all baselines and generates realistic cell morphologies that reflect transcriptomic perturbations.",
      "authors": "Kong Zhenglun; Qiu Mufan; Boesen John; Lin Xiang; Yun Sukwon; Chen Tianlong; Kellis Manolis; Zitnik Marinka",
      "year": "2025",
      "month": "Jul",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "40667082",
      "doi": "10.1101/2025.06.17.659751",
      "title": "A generalized and efficient approach for complete mRNA design improves translation, stability and specificity.",
      "abstract": "End-to-end, machine-learning based design of mRNA molecules offers a powerful means to tailor their properties for specific tasks. mRNA expression level, immunogenicity, tissue specificity, stability, and localization, among others strongly depend on sequence, thus providing a rich set of properties amenable to optimization. Despite this potential, the various components of mRNA are governed by distinct grammatical and functional rules that hinder the development of a unified algorithmic approach for complete mRNA design. While machine learning and generative AI techniques demonstrate substantial benefits for individual sequence design tasks, adapting these tools to new domains or out-of-distribution tasks remains challenging. In this work, we describe a simple and powerful alteration to integrated gradients (",
      "authors": "Riley Aidan T; Vlasity McKayla; Huang Joey Zhuoying; Becicka Wyatt M; Wong Wilson W; Grinstaff Mark W; Green Alexander A",
      "year": "2025",
      "month": "Jun",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40666922",
      "doi": "10.1101/2025.06.16.659949",
      "title": "JASMINE: A powerful representation learning method for enhanced analysis of incomplete multi-omics data.",
      "abstract": "Integrative analysis of multi-omics data provides a more comprehensive and nuanced view of a subject's biological state. However, high-dimensionality and ubiquitous modality missingness present significant analytical challenges. Existing methods for incomplete multi-omics data are scarce, do not fully leverage both modality-specific and shared information, and produce task-biased representations. We propose JASMINE, a self-supervised representation learning method for incomplete multi-omics data that preserves both modality-specific and joint information and enhances sample similarity structure. JASMINE produces embeddings that achieve superior performance across multiple tasks for two different incomplete multi-omics datasets while requiring only a single round of training per dataset.",
      "authors": "Ballard Jenna L; Dai Zongyu; Shen Li; Long Qi",
      "year": "2025",
      "month": "Sep",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40664732",
      "doi": "10.1038/s41598-025-09869-0",
      "title": "Decision level scheme for fusing multiomics and histology slide images using deep neural network for tumor prognosis prediction.",
      "abstract": "Molecular biostatistical workflows in oncology often rely on predictive models that use multimodal data. Advances in deep learning and artificial intelligence technologies have enabled the multimodal fusion of large volumes of multimodal data. Here, we presented a decision level multimodal data fusion framework for integrating multiomics and pathological tissue slide images for prognosis prediction. Our approach established the spatial map of instances by connecting the neighboring nuclei in space and calculated the characteristic tensor via graph convolution layers for the input pathological tissue slide images. Global Average Pooling was applied to align and normalize the feature tensors from pathological images and the multiomics data, enabling seamless integration. We tested our proposed approach using Breast Invasive Carcinoma data and Non-Small Cell Lung Cancer data from the Cancer Genome Atlas, which contains paired whole-slide images, transcriptome data, genotype, epienetic, and survival information. In a 10-fold cross-validation, the comparison results demonstrated that the multimodal fusion paradigm improves outcome predictions from single modal data alone with the average C-index increasing from 0.61 to 0.52 to 0.75 and 0.67 for breast cancer and non-small cell lung cancer cohort, respectively. The proposed decision level multimodal data fusion framework is expected to provide insights and technical methodologies for the follow-up studies.",
      "authors": "Zhao Tingting; Ren Yongyong; Lu Hui; Kong Yan",
      "year": "2025",
      "month": "Jul",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "40662829",
      "doi": "10.1093/bioinformatics/btaf229",
      "title": "MutBERT: probabilistic genome representation improves genomics foundation models.",
      "abstract": "Understanding the genomic foundation of human diversity and disease requires models that effectively capture sequence variation, such as single nucleotide polymorphisms (SNPs). While recent genomic foundation models have scaled to larger datasets and multi-species inputs, they often fail to account for the sparsity and redundancy inherent in human population data, such as those in the 1000 Genomes Project. SNPs are rare in humans, and current masked language models (MLMs) trained directly on whole-genome sequences may struggle to efficiently learn these variations. Additionally, training on the entire dataset without prioritizing regions of genetic variation results in inefficiencies and negligible gains in performance. We present MutBERT, a probabilistic genome-based masked language model that efficiently utilizes SNP information from population-scale genomic data. By representing the entire genome as a probabilistic distribution over observed allele frequencies, MutBERT focuses on informative genomic variations while maintaining computational efficiency. We evaluated MutBERT against DNABERT-2, various versions of Nucleotide Transformer, and modified versions of MutBERT across multiple downstream prediction tasks. MutBERT consistently ranked as one of the top-performing models, demonstrating that this novel representation strategy enables better utilization of biobank-scale genomic data in building pretrained genomic foundation models. https://github.com/ai4nucleome/mutBERT.",
      "authors": "Long Weicai; Su Houcheng; Xiong Jiaqi; Zhang Yanlin",
      "year": "2025",
      "month": "Jul",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "40661489",
      "doi": "10.1101/2025.06.11.656869",
      "title": "Spatial multi-omics and deep learning reveal fingerprints of immunotherapy response and resistance in hepatocellular carcinoma.",
      "abstract": "Despite advances in immunotherapy treatment, nonresponse rates remain high, and mechanisms of resistance to checkpoint inhibition remain unclear. To address this gap, we performed spatial transcriptomic and proteomic profiling on human hepatocellular carcinoma tissues collected before and after immunotherapy. We developed an interpretable, multimodal deep learning framework to extract key cellular and molecular signatures from these data. Our graph neural network approach based on spatial proteomic inputs achieved outstanding performance (ROC-AUC > 0.9) in predicting patient treatment response. Key predictive features and associated spatial transcriptomic profiles revealed the multi-omic landscape of immunotherapy response and resistance. One such feature was an interface niche expressing restrictive extracellular matrix factors that physically separates tumor tissue and lymphoid aggregates in nonresponders. We integrate this and other spatially-resolved signatures into SPARC, a multi-omic \"fingerprint\" comprising scores for immunotherapy response and resistance mechanisms. This study lays groundwork for future patient stratification and treatment strategies in cancer immunotherapy.",
      "authors": "Wu Zhenqin; Boen Joseph; Jindal Sonali; Basu Sreyashi; Bieniosek Matthew; He Siyu; LaPelusa Michael; Mayer Aaron T; Kaseb Ahmed O; Zou James; Sharma Padmanee; Trevino Alexandro E",
      "year": "2025",
      "month": "Jun",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40660356",
      "doi": "10.1186/s13059-025-03674-8",
      "title": "Evaluating the representational power of pre-trained DNA language models for regulatory genomics.",
      "abstract": "The emergence of genomic language models (gLMs) offers an unsupervised approach to learning a wide diversity of cis-regulatory patterns in the non-coding genome without requiring labels of functional activity generated by wet-lab experiments. Previous evaluations have shown that pre-trained gLMs can be leveraged to improve predictive performance across a broad range of regulatory genomics tasks, albeit using relatively simple benchmark datasets and baseline models. Since the gLMs in these studies were tested upon fine-tuning their weights for each downstream task, determining whether gLM representations embody a foundational understanding of cis-regulatory biology remains an open question. Here, we evaluate the representational power of pre-trained gLMs to predict and interpret cell-type-specific functional genomics data that span DNA and RNA regulation for six major functional genomics prediction tasks. Our findings suggest that probing the representations of current pre-trained gLMs do not offer substantial advantages over conventional machine learning approaches that use one-hot encoded sequences. Nevertheless, highly tuned supervised models trained from scratch using one-hot encoded sequences can achieve performance competitive with or better than pre-trained models across the datasets explored in this study. This work highlights a major gap with current gLMs, raising potential issues in conventional pre-training strategies for the non-coding genome.",
      "authors": "Tang Ziqi; Somia Nirali; Yu Yiyang; Koo Peter K",
      "year": "2025",
      "month": "Jul",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "40654940",
      "doi": "10.1101/2025.05.07.648613",
      "title": "Transfer learning framework via Bayesian group factor analysis incorporating feature-wise dependencies.",
      "abstract": "Transfer learning considers distinct but related tasks defined over heterogeneous domains and aims to improve generalization and performance through knowledge transfer between tasks. This approach can be especially advantageous in biomedical contexts with insufficient labeled training data, where joint learning across domains can enable inference in otherwise underpowered datasets. High-dimensional biomedical data is characterized with redundancy, rendering non-linear dependencies among features. Existing models often fail to leverage such feature dependencies during inference, limiting their ability to model complex biological systems. We present a Bayesian group factor analysis transfer learning framework that supports multitask, multi-modal learning. Our approach learns a shared latent space within each domain, simultaneously across multiple domains, and uses a feature-wise prior to model complex relationships. We evaluate our framework using controlled synthetic data experiments and four disjoint patient cancer datasets from acute myeloid leukemia and neuroblastoma. We show that our method improves drug response prediction and more readily recapitulates consensus biomarkers of drug response. Similarly, our approach improves tumor purity prediction and identifies a robust gene signature associated with it. Our framework is scalable, interpretable, and adaptable across target phenotypes, offering a robust solution for a wide range of heterogeneous multi-omics problems.",
      "authors": "Thirumalaisamy Dharani; Black Natasha; Gönen Mehmet; Nikolova Olga",
      "year": "2025",
      "month": "May",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40644951",
      "doi": "10.1016/j.ijfoodmicro.2025.111335",
      "title": "Genomic diversity of Cronobacter sakazakii across the food system to consumers at the global scale.",
      "abstract": "Understanding how foodborne pathogens adapt to changing environments is essential for improving food safety monitoring and control. Cronobacter sakazakii, a persistent opportunistic pathogen associated with powdered infant formula outbreaks, poses critical health risks to neonates and other vulnerable populations. This study tested the hypothesis that genetic variation in C. sakazakii correlates with specific isolation sources and geographic origins across the global food system. We conducted a pangenomics meta-analysis of C. sakazakii derived from food, environmental, and clinical sources spanning North America, Asia, and Europe. A robust fine-tuned Generative Pre-trained Transformer (GPT) model was developed to standardize the categorization of isolate metadata descriptors. C. sakazakii genome assemblies (n = 748) were used to build and annotate the pangenome, and genome size and accessory gene profiles were found to be significantly associated with source type and continent of origin. Isolates from powdered foods, compared to those sourced from alternative foods, had larger genomes and were enriched in functions annotated to Clusters of Orthologous Genes (COG) category L for DNA replication, recombination and repair (e.g., transposase, integrase), among other features. Random forest models using both accessory genes and the subset of virulence factor homologs accurately predicted source attributions, identifying type VI secretion system and heavy metal response genes as key indicators of isolate origins. Several antimicrobial resistance genes associated with efflux (i.e., arlR, facT, oprZ) also exhibited patterns for biogeography. Overall, this study uncovered the distribution of key accessory genetic elements of C. sakazakii throughout the food system, revealing putative adaptations for its persistence and transmission. Our reproducible and automated workflow has potential applications in molecular surveillance for emerging food safety concerns.",
      "authors": "Gao Mairui; Pradhan Abani K; Blaustein Ryan A",
      "year": "2025",
      "month": "Oct",
      "journal": "International journal of food microbiology",
      "source": "pubmed"
    },
    {
      "pmid": "40636005",
      "doi": "10.3389/fpls.2025.1626539",
      "title": "Identification of DNA N6-methyladenine modifications in the rice genome with a fine-tuned large language model.",
      "abstract": "DNA N6-methyladenine (6mA) plays a significant role in various biological processes. In the rice genome, 6mA is involved in important processes such as growth and development, influencing gene expression. Therefore, identifying the 6mA locus in rice is crucial for understanding its complex gene expression regulatory system. Although several useful prediction models have been proposed, there is still room for improvement. To address this, we propose an architecture named iRice6mA-LMXGB that integrates a fine-tuned large language model to identify the 6mA locus in rice. Specifically, our method consists of two main components: (1) a BERT model for feature extraction and (2) an XGBoost module for 6mA classification. We utilize a pre-trained DNABERT-2 model to initialize the parameters of the BERT component. Through transfer learning, we fine-tune the model on the rice 6mA recognition task, converting raw DNA sequences into high-dimensional feature vectors. These features are then processed by an XGBoost algorithm to generate predictions. To further validate the effectiveness of our fine-tuning strategy, we employ UMAP(Uniform Manifold Approximation and Projection) visualization. Our approach achieves a validation accuracy of 0.9903 in a five-fold cross-validation setting and produces a receiver operating characteristic (ROC) curve with an area under the curve (AUC) of 0.9994. Compared to existing predictors trained on the same dataset, our method demonstrates superior performance. This study provides a powerful tool for advancing research in rice 6mA epigenetics.",
      "authors": "Zhang Yichi; Chen Hao; Xiang Shicheng; Lv Zhibin",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in plant science",
      "source": "pubmed"
    },
    {
      "pmid": "40632498",
      "doi": "10.1093/bib/bbaf332",
      "title": "Multimodal zero-shot learning of previously unseen epitranscriptomes from RNA-seq data.",
      "abstract": "Precise identification of condition-specific epitranscriptomes is of critical importance for investigating the dynamics and versatile functions of RNA modification under various biological contexts. Existing approaches for predicting condition-specific RNA modification are usually trained on epitranscriptome data obtained from the same condition, which limited their usage, as such data are available only for a small number of conditions due to the technical difficulties and high expenses of epitranscriptome profiling technologies. We present ExpressRM, a multimodal zero-shot learning framework for predicting condition-specific RNA modification sites in previously unseen contexts from genome and RNA-seq data. Different from existing in-condition learning approaches, this method does not rely on matched epitranscriptome data for training, which greatly expands its applicability. On a benchmark dataset comprising epitranscriptomes and matched transcriptomes of 37 human tissues, we demonstrate that ExpressRM can accurately predict epitranscriptomes of previously unseen conditions from their transcriptomes only, and the performance is comparable to existing in-condition learning algorithms that require epitranscriptome data from the same condition. Additionally, the method has the capability of differentiating highly dynamic RNA methylation sites from more static (or house-keeping) ones. With a case study, we show that ExpressRM can uncover N6-methyladenosine RNA methylation sites in glioblastoma using only its RNA-seq data, and unveils novel and previously validated pathological insights. Together, these results suggest that the proposed multimodal zero-shot learning framework can effectively leverage transcriptome knowledge to explore the dynamic roles of RNA modifications in previously unseen experimental setups, providing valuable insights into vast biological contexts where RNA-seq is routinely used but epitranscriptome profiling has not yet been covered.",
      "authors": "Song Yiyou; Song Bowen; Huang Daiyun; Nguyen Anh; Hu Lihong; Meng Jia; Wang Yue",
      "year": "2025",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40631230",
      "doi": "10.1101/2025.04.22.649977",
      "title": "spRefine Denoises and Imputes Spatial Transcriptomics with a Reference-Free Framework Powered by Genomic Language Model.",
      "abstract": "The analysis of spatial transcriptomics is hindered by high noise levels and missing gene measurements, challenges that are further compounded by the higher cost of spatial data compared to traditional single-cell data. To overcome this challenge, we introduce ",
      "authors": "Liu Tianyu; Huang Tinglin; Jin Wengong; Chu Tinyi; Ying Rex; Zhao Hongyu",
      "year": "2025",
      "month": "Jul",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40618351",
      "doi": "10.1093/bib/bbaf317",
      "title": "Spatial histology and gene-expression representation and generative learning via online self-distillation contrastive learning.",
      "abstract": "Spatial transcriptomics quantifies spatial molecular profiles alongside histology, enabling computational prediction of spatial gene expression distribution directly from whole slide images. Inspired by image-to-text alignment and generation, we introduce Magic, a self-training contrastive learning model designed for histology-to-gene expression prediction. Magic (i) employs contrastive learning to derive shared embeddings for histology and gene expression while utilizing a momentum-based module to generate pseudo-targets to reduce the impact of noise; and (ii) leverages a transformer-based decoder to predict the expression of 300 genes based on histological features. Trained on 75 760 spots from 56 breast cancer slices and validated on 11 026 spots from five independent slices, Magic outperforms existing methods in aligning and generating histology-gene expression data, achieving a 10% improvement over the second-best approach. Furthermore, Magic demonstrates robust generalization, effectively predicting gene expression in colorectal cancer samples and The Cancer Genome Atlas (TCGA) datasets through zero-shot learning. Notably, Magic's predicted gene expression captures interpatient differences, highlighting its strong potential for clinical applications.",
      "authors": "Yan Qianyi; Li Xuan; Cui Jiangnan; Rong Jianming; Zhang Jingsong; Gao Pingting; Xu Yaochen; Qiu Fufang; Zuo Chunman",
      "year": "2025",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40616534",
      "doi": "10.4103/jcrt.jcrt_2524_24",
      "title": "Precision prediction of cervical cancer outcomes: A machine learning approach to recurrence and survival analysis.",
      "abstract": "Cervical cancer remains a significant global health challenge, with high rates of recurrence and mortality, particularly in low-resource regions. Effective prediction of recurrence and survival is crucial for optimizing treatment and improving patient outcomes. Recently, artificial intelligence (AI) has emerged as a transformative tool in oncology, providing advanced methodologies for analyzing large-scale medical data and offering predictive insights into patient outcomes. This review comprehensively explores the role of AI in predicting cervical cancer recurrence and survival, focusing on techniques such as machine learning, deep learning, and natural language processing. The integration of AI with medical imaging, genomics, and clinical data is discussed, along with the associated challenges and limitations. Future directions and the potential impact of AI on personalized medicine in cervical cancer care are also examined.",
      "authors": "Saini Surendra Kumar; Sharma Daya Nand; Chauhan Sapna; Srivastava Shelly; Gopishankar N; Subramani V",
      "year": "2025",
      "month": "Apr",
      "journal": "Journal of cancer research and therapeutics",
      "source": "pubmed"
    },
    {
      "pmid": "40608008",
      "doi": "10.1093/bib/bbaf304",
      "title": "spaLLM: enhancing spatial domain analysis in multi-omics data through large language model integration.",
      "abstract": "Spatial multi-omics technologies provide valuable data on gene expression from various omics in the same tissue section while preserving spatial information. However, deciphering spatial domains within spatial omics data remains challenging due to the sparse gene expression. We propose spaLLM, the first multi-omics spatial domain analysis method that integrates large language models to enhance data representation. Our method combines a pre-trained single-cell language model (scGPT) with graph neural networks and multi-view attention mechanisms to compensate for limited gene expression information in spatial omics while improving sensitivity and resolution within modalities. SpaLLM processes multiple spatial modalities, including RNA, chromatin, and protein data, potentially adapting to emerging technologies and accommodating additional modalities. Benchmarking against eight state-of-the-art methods across four different datasets and platforms demonstrates that our model consistently outperforms other advanced methods across multiple supervised evaluation metrics. The source code for spaLLM is freely available at https://github.com/liiilongyi/spaLLM.",
      "authors": "Li Longyi; Dong Liyan; Zhang Hao; Xu Dong; Li Yongli",
      "year": "2025",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40606969",
      "doi": "10.3389/fonc.2025.1480384",
      "title": "Leveraging a foundation model zoo for cell similarity search in oncological microscopy across devices.",
      "abstract": "Cellular imaging analysis using the traditional retrospective approach is extremely time-consuming and labor-intensive. Although AI-based solutions are available, these approaches rely heavily on supervised learning techniques that require high quality, large labeled datasets from the same microscope to be reliable. In addition, primary patient samples are often heterogeneous cell populations and need to be stained to distinguish the cellular subsets. The resulting imaging data is analyzed and labeled manually by experts. Therefore, a method to distinguish cell populations across imaging devices without the need for staining and extensive manual labeling would help immensely to gain real-time insights into cell population dynamics. This especially holds true for recognizing specific cell types and states in response to treatments. We aim to develop an unsupervised approach using general vision foundation models trained on diverse and extensive imaging datasets to extract rich visual features for cell-analysis across devices, including both stained and unstained live cells. Our method, Entropy-guided Weighted Combinational FAISS (EWC-FAISS), uses these models purely in an inference-only mode without task-specific retraining on the cellular data. Combining the generated embeddings in an efficient and adaptive k-nearest neighbor search allows for automated, cross device identification of cell types and states, providing a strong basis for AI-assisted cancer therapy. We utilized two publicly available datasets. The WBC dataset includes 14,424 images of stained white blood cell samples from patients with acute myeloid and lymphoid leukemia, as well as those without leukemic pathology. The LISC dataset comprises 257 images of white blood cell samples from healthy individuals. We generated four in-house datasets utilizing the JIMT-1 breast cancer cell line, as well as Jurkat and K562 (leukemic cell lines). These datasets were acquired using the Nanolive 3D Cell Explorer-fluo (CX-A) holotomographic microscope and the BioTek Lionheart FX automated brightfield microscope. The images from the in-house datasets were manually annotated using Roboflow software. To generate the embeddings, we used and optimized a concatenated combination of SAM, DINO, ConvNeXT, SWIN, CLIP and ViTMAE. The combined embeddings were used as input for the adaptive k-nearest neighbor search, building an approximate Hierarchical Navigable Small World FAISS index. We compared EWC-FAISS to fully fined-tuned ViT-Classifiers with DINO-, and SWIN-backbones, a ConvNeXT architecture, as well as to NMTune as a lightweight domain-adaptation method with frozen backbone. EWC-FAISS performed competitively with the baselines on the original datasets in terms of macro accuracy. Macro accuracy is the average of class-specific accuracies, treating all classes equally by averaging their individual accuracies. EWC-FAISS ranked second for the WBC dataset (macro accuracy: 97.6 ± 0.2), first for cell state classification from Nanolive (macro accuracy: 90 ± 0), and performed comparably for cell type classification from Lionheart (macro accuracy: 87 ± 0). For the transfer to out-of-distribution (OOD) datasets, which the model had not seen during training, EWC-FAISS consistently outperformed the other baselines. For the LISC dataset, EWC-FAISS achieved a macro accuracy of 78.5 ± 0.3, compared to DINO FT's 17 ± 1, SWIN FT's 44 ± 14, ConvNeXT FT's 45 ± 9, and NMTune's 52 ± 10. For the cell state classification from Lionheart, EWC-FAISS had a macro accuracy of 86 ± 1, while DINO FT, SWIN FT, and ConvNeXT FT achieved 65 ± 11, 68 ± 16, and 81 ± 1, respectively, and NMTune 81 ± 7. For the transfer of cell type classification from Nanolive, EWC-FAISS attained a macro accuracy of 85 ± 0, compared to DINO FT's 24.5 ± 0.9, SWIN FT's 57 ± 6, ConvNeXT FT's 54 ± 4, and NMTune's 63 ± 4. Additionally, building EWC-FAISS after embedding generation was significantly faster than training DINO FT (∼ 6 minutes compared to  We present a novel approach to identify various cell lines and primary cells based on their identity and state using images acquired across various imaging platforms which vary in resolution, magnification and image quality. Despite these differences, we could show that our efficient, adaptive k-nearest neighbor search pipeline can be applied on a large image dataset containing different cell types and effectively differentiate between the cells and their states such as live, apoptotic or necrotic. There are several applications, particularly in distinguishing various cell populations in patient samples or monitoring therapy.",
      "authors": "Kalweit Gabriel; Klett Anusha; Silvestrini Paula; Rahnfeld Jens; Naouar Mehdi; Vogt Yannick; Infante Diana; Berger Rebecca; Duque-Afonso Jesús; Hartmann Tanja Nicole; Follo Marie; Bodurova-Spassova Elitsa; Lübbert Michael; Mertelsmann Roland; Boedecker Joschka; Ullrich Evelyn; Kalweit Maria",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in oncology",
      "source": "pubmed"
    },
    {
      "pmid": "40585839",
      "doi": "10.5306/wjco.v16.i6.107646",
      "title": "Advances and challenges in pathomics for liver cancer: From diagnosis to prognostic stratification.",
      "abstract": "Hepatocellular carcinoma (HCC), a leading cause of cancer mortality, faces diagnostic and therapeutic challenges due to its histopathological complexity and clinical heterogeneity. Pathomics, an emerging discipline that integrates artificial intelligence (AI) with quantitative pathology image analysis, aims to decode disease heterogeneity by extracting high-dimensional features from histopathological specimens. This review highlights how AI-driven pathomics has revolutionized liver cancer management through automated analysis of whole-slide images. Pathomics integrates deep learning with histopathological features to enable precise tumour classification (",
      "authors": "Peng Ming-Hui; Zhang Kai-Lun; Guan Shi-Wei; Lin Quan; Yu Hai-Bo",
      "year": "2025",
      "month": "Jun",
      "journal": "World journal of clinical oncology",
      "source": "pubmed"
    },
    {
      "pmid": "40585083",
      "doi": "10.1101/2025.01.02.25319880",
      "title": "Integrating GWAS and Transcriptomic Data Using PrediXcan and Multimodal Deep Learning Reveals Genetic Basis and Drug Repositioning Opportunities for Alzheimer's Disease.",
      "abstract": "Alzheimer's disease (AD), the leading cause of dementia, imposes a significant societal and economic burden; however, its complex molecular mechanisms remain unclear. This study integrates multi-omics data with advanced artificial intelligence (AI) methods to uncover the molecular basis underlying AD phenotype regulation and explore personalized drug repositioning strategies based on individual genetic backgrounds. First, we applied the PrediXcan method to identify candidate genes closely associated with AD cognitive diagnosis, selecting from 61 brain-related traits. We validated these findings through individual-level analysis using gene expression and genotype data from 553 dorsolateral prefrontal cortex samples in the ROSMAP database. Simultaneously, we constructed a deep, multi-layer information fusion model (AD-MIF) by integrating genotype and gene expression data and employing autoencoders as well as graph autoencoders for multi-modal feature extraction. The results revealed a 10-20% improvement in the Area Under the Curve (AUC) for predicting AD-related phenotypes. Both approaches showed high consistency across cellular structures, brain regions, and neurobiological pathways, demonstrating their complementary advantages. Gene enrichment analysis indicated that APOE and its interacting gene APOC1 play a central role in cholesterol metabolism, lipid transport, and immune regulation, while genes such as SCIMP and KAT8 are involved in immune signaling, epigenetic regulation, and neuroprotection. After incorporating attention mechanisms, AD-MIF highlighted the importance of key genes, such as POLR2C and TRAPPC4, in regulating neuronal function. Based on predictive results and enrichment analysis, we further identified candidate drugs, including sirolimus, dasatinib, and MGCD-265. In vivo experiments confirmed that MGCD-265, also known as Glesatinib, and dasatinib significantly improve cognitive deficits in the SAMP8 AD model mice by inhibiting neuroinflammation, pathological tau phosphorylation, and Aβ deposition. This study demonstrates the complementary advantages of bioinformatics pipelines and AI-based multi-modal fusion methods in elucidating the complex pathological mechanisms of AD and enhancing phenotype prediction accuracy. It also provides new theoretical support for personalized drug interventions based on individual genetic characteristics, laying a solid foundation for optimizing early screening, prediction, and personalized treatment strategies.",
      "authors": "Tian Xuecong; Su Ying; Zhang Sizhe; Chen Chen; Ma Yaolei; Sun Haiqing; Chen Cheng; Zhou Wei; Gao Yue; Zhou Luyu; Lv Xiaoyi; Roussos Panos; Zhang Wen",
      "year": "2025",
      "month": "Jun",
      "journal": "medRxiv : the preprint server for health sciences",
      "source": "pubmed"
    },
    {
      "pmid": "40564042",
      "doi": "10.3390/biomedicines13061323",
      "title": "A Deep Learning Methodology for Screening New Natural Therapeutic Candidates for Pharmacological Cardioversion and Anticoagulation in the Treatment and Management of Atrial Fibrillation.",
      "abstract": "",
      "authors": "Dong Tim; Llewellyn Rhys D; Hezzell Melanie; Angelini Gianni D",
      "year": "2025",
      "month": "May",
      "journal": "Biomedicines",
      "source": "pubmed"
    },
    {
      "pmid": "40563902",
      "doi": "10.3390/biology14060651",
      "title": "AI-Driven Transcriptome Prediction in Human Pathology: From Molecular Insights to Clinical Applications.",
      "abstract": "Gene expression regulation underpins cellular function and disease progression, yet its complexity and the limitations of conventional detection methods hinder clinical translation. In this review, we define \"predict\" as the AI-driven inference of gene expression levels and regulatory mechanisms from non-invasive multimodal data (e.g., histopathology images, genomic sequences, and electronic health records) instead of direct molecular assays. We systematically examine and analyze the current approaches for predicting gene expression and diagnosing diseases, highlighting their respective advantages and limitations. Machine learning algorithms and deep learning models excel in extracting meaningful features from diverse biomedical modalities, enabling tools like PathChat and Prov-GigaPath to improve cancer subtyping, therapy response prediction, and biomarker discovery. Despite significant progress, persistent challenges-such as data heterogeneity, noise, and ethical issues including privacy and algorithmic bias-still limit broad clinical adoption. Emerging solutions like cross-modal pretraining frameworks, federated learning, and fairness-aware model design aim to overcome these barriers. Case studies in precision oncology illustrate AI's ability to decode tumor ecosystems and predict treatment outcomes. By harmonizing multimodal data and advancing ethical AI practices, this field holds immense potential to propel personalized medicine forward, although further innovation is needed to address the issues of scalability, interpretability, and equitable deployment.",
      "authors": "Chen Xiaoya; Xu Huinan; Yu Shengjie; Hu Wan; Zhang Zhongjin; Wang Xue; Yuan Yue; Wang Mingyue; Chen Liang; Lin Xiumei; Hu Yinlei; Cai Pengfei",
      "year": "2025",
      "month": "Jun",
      "journal": "Biology",
      "source": "pubmed"
    },
    {
      "pmid": "40551770",
      "doi": "10.3389/fpls.2025.1618174",
      "title": "A BERT-based rice enhancer identification model combined with sequence-representation differential entropy interpretation.",
      "abstract": "Rice is a crucial food crop, and research into its gene expression regulation holds significant importance for molecular breeding and yield improvement. Enhancers, as key elements regulating the spatiotemporal-specific expression of genes, represent a core challenge in functional genomics due to their precise identification requirements. Current deep learning-based methods for rice enhancer identification face limitations primarily in feature extraction efficiency and the generalization capabilities of model architectures. In response, this study introduces a novel model architecture, RiceEN-BERT-SVM, which integrates DNABERT-2 as a feature extraction tool, alongside Support Vector Machine (SVM) for enhancer sequence classification. The mechanism underlying the optimization of model performance is elucidated through differential entropy analysis of feature representations. Experimental results demonstrate the high precision of this approach, achieving an accuracy of 88.05% in 5-fold cross-validation and 87.55% in independent testing. These metrics surpass current state-of-the-art (SOTA) models by margins ranging from 1.47% to 6.87% on the same dataset. Further refinement through fine-tuning enhances RiceEN-BERT-SVM's performance, increasing its accuracy by an additional 6.95%, resulting in a final accuracy of 93.63%. The study employs differential entropy analysis of sequence feature representations to explain the performance enhancements observed with increased fine-tuning iterations. As the number of iterations rises, the differential entropy distributions of positive and negative sample features gradually separate from their initial overlapping state, corresponding with the model's progressive improvement in performance. At six fine-tuning iterations, the separation between positive and negative sample entropy reaches its peak, achieving optimal model performance. Beyond this point, the distributions begin to overlap again, leading to a decline in performance. This novel approach not only offers an efficient tool for rice enhancer identification but also introduces a visually interpretable framework based on differential entropy, providing a new perspective for optimizing biological sequence analysis models.",
      "authors": "Pu Yajing; Hao Xintong; Zheng Zhaoqi; Ma Huiyan; Lv Zhibin",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in plant science",
      "source": "pubmed"
    },
    {
      "pmid": "40551237",
      "doi": "10.1186/s13062-025-00661-8",
      "title": "Multimodal deep learning for predicting neoadjuvant treatment outcomes in breast cancer: a systematic review.",
      "abstract": "Pathological complete response (pCR) to neoadjuvant systemic therapy (NAST) is an established prognostic marker in breast cancer (BC). Multimodal deep learning (DL), integrating diverse data sources (radiology, pathology, omics, clinical), holds promise for improving pCR prediction accuracy. This systematic review synthesizes evidence on multimodal DL for pCR prediction and compares its performance against unimodal DL. Following PRISMA, we searched PubMed, Embase, and Web of Science (January 2015-April 2025) for studies applying DL to predict pCR in BC patients receiving NAST, using data from radiology, digital pathology (DP), multi-omics, and/or clinical records, and reporting AUC. Data on study design, DL architectures, and performance (AUC) were extracted. A narrative synthesis was conducted due to heterogeneity. Fifty-one studies, mostly retrospective (90.2%, median cohort 281), were included. Magnetic resonance imaging and DP were common primary modalities. Multimodal approaches were used in 52.9% of studies, often combining imaging with clinical data. Convolutional neural networks were the dominant architecture (88.2%). Longitudinal imaging improved prediction over baseline-only (median AUC 0.91 vs. 0.82). Overall, the median AUC across studies was 0.88, with 35.3% achieving AUC ≥ 0.90. Multimodal models showed a modest but consistent improvement over unimodal approaches (median AUC 0.88 vs. 0.83). Omics and clinical text were rarely primary DL inputs. DL models demonstrate promising accuracy for pCR prediction, especially when integrating multiple modalities and longitudinal imaging. However, significant methodological heterogeneity, reliance on retrospective data, and limited external validation hinder clinical translation. Future research should prioritize prospective validation, integration underutilized data (multi-omics, clinical), and explainable AI to advance DL predictors to the clinical setting.",
      "authors": "Krasniqi Eriseld; Filomeno Lorena; Arcuri Teresa; Ferretti Gianluigi; Gasparro Simona; Fulvi Alberto; Roselli Arianna; D'Onofrio Loretta; Pizzuti Laura; Barba Maddalena; Maugeri-Saccà Marcello; Botti Claudio; Graziano Franco; Puccica Ilaria; Cappelli Sonia; Pelle Fabio; Cavicchi Flavia; Villanucci Amedeo; Paris Ida; Calabrò Fabio; Rea Sandra; Costantini Maurizio; Perracchio Letizia; Sanguineti Giuseppe; Takanen Silvia; Marucci Laura; Greco Laura; Kayal Rami; Moscetti Luca; Marchesini Elisa; Calonaci Nicola; Blandino Giovanni; Caravagna Giulio; Vici Patrizia",
      "year": "2025",
      "month": "Jun",
      "journal": "Biology direct",
      "source": "pubmed"
    },
    {
      "pmid": "40536817",
      "doi": "10.1093/bib/bbaf289",
      "title": "A novel deep learning framework with dynamic tokenization for identifying chromatin interactions along with motif importance investigation.",
      "abstract": "A comprehensive understanding of chromatin interaction networks is crucial for unraveling the regulatory mechanisms of gene expression. While various computational methods have been developed to predict chromatin interactions and address the limitations and high costs of high-throughput experimental techniques, their performance is often overestimated due to the specificity of chromatin interaction data. In this study, we proposed Inter-Chrom, a novel deep learning model integrating dynamic tokenization, DNABERT's word embedding, and the efficient channel attention mechanism to identify chromatin interactions using sequence and genomic features, leveraging a newly curated dataset. Experimental results demonstrate that Inter-Chrom outperforms existing methods on three cell line datasets. Additionally, we proposed a novel method for calculating motif importance and analyzed the motifs with high importance scores identified through this method, including those that have been extensively studied and others that have received limited attention to date. Inter-Chrom's robustness for input variations and superior ability to leverage sequence features position it as a powerful tool for advancing chromatin interaction research. The source code of Inter-Chrom is freely available at https://github.com/HaoWuLab-Bioinformatics/Inter-Chrom.",
      "authors": "Li Liangcan; Li Xin; Wu Hao",
      "year": "2025",
      "month": "May",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40530265",
      "doi": "10.3389/fpls.2025.1611992",
      "title": "Foundation models in plant molecular biology: advances, challenges, and future directions.",
      "abstract": "A foundation model (FM) is a neural network trained on large-scale data using unsupervised or self-supervised learning, capable of adapting to a wide range of downstream tasks. This review provides a comprehensive overview of FMs in plant molecular biology, emphasizing recent advances and future directions. It begins by tracing the evolution of biological FMs across the DNA, RNA, protein, and single-cell levels, from tools inspired by natural language processing (NLP) to transformative models for decoding complex biological sequences. The review then focuses on plant-specific FMs such as GPN, AgroNT, PDLLMs, PlantCaduceus, and PlantRNA-FM, which address challenges that are widespread among plant genomes, including polyploidy, high repetitive sequence content, and environment-responsive regulatory elements, alongside universal FMs like GENERator and Evo 2, which leverage extensive cross-species training data for sequence design and prediction of mutation effects. Key opportunities and challenges in plant molecular biology FM development are further outlined, such as data heterogeneity, biologically informed architectures, cross-species generalization, and computational efficiency. Future research should prioritize improvements in model generalization, multi-modal data integration, and computational optimization to overcome existing limitations and unlock the potential of FMs in plant science. This review serves as an essential resource for plant molecular biologists and offers a clear snapshot of the current state and future potential of FMs in the field.",
      "authors": "Xu Feng; Wu Tianhao; Cheng Qian; Wang Xiangfeng; Yan Jun",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in plant science",
      "source": "pubmed"
    },
    {
      "pmid": "40526743",
      "doi": "10.1371/journal.pcbi.1013012",
      "title": "Multimodal CustOmics: A unified and interpretable multi-task deep learning framework for multimodal integrative data analysis in oncology.",
      "abstract": "Characterizing cancer presents a delicate challenge as it involves deciphering complex biological interactions within the tumor's microenvironment. Clinical trials often provide histology images and molecular profiling of tumors, which can help understand these interactions. Despite recent advances in representing multimodal data for weakly supervised tasks in the medical domain, achieving a coherent and interpretable fusion of whole slide images and multi-omics data is still a challenge. Each modality operates at distinct biological levels, introducing substantial correlations between and within data sources. In response to these challenges, we propose a novel deep-learning-based approach designed to represent multi-omics & histopathology data for precision medicine in a readily interpretable manner. While our approach demonstrates superior performance compared to state-of-the-art methods across multiple test cases, it also deals with incomplete and missing data in a robust manner. It extracts various scores characterizing the activity of each modality and their interactions at the pathway and gene levels. The strength of our method lies in its capacity to unravel pathway activation through multimodal relationships and to extend enrichment analysis to spatial data for supervised tasks. We showcase its predictive capacity and interpretation scores by extensively exploring multiple TCGA datasets and validation cohorts. The method opens new perspectives in understanding the complex relationships between multimodal pathological genomic data in different cancer types and is publicly available on Github.",
      "authors": "Benkirane Hakim; Vakalopoulou Maria; Planchard David; Adam Julien; Olaussen Ken; Michiels Stefan; Cournède Paul-Henry",
      "year": "2025",
      "month": "Jun",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    },
    {
      "pmid": "40517171",
      "doi": "10.1038/s41698-025-00979-6",
      "title": "A multimodal fusion system predicting survival benefits of immune checkpoint inhibitors in unresectable hepatocellular carcinoma.",
      "abstract": "Early identification of unresectable hepatocellular carcinoma (HCC) patients who may benefit from immune checkpoint inhibitors (ICIs) is crucial for optimizing outcomes. Here, we developed a multimodal fusion (MMF) system integrating CT-derived deep learning features and clinical data to predict overall survival (OS) and progression-free survival (PFS). Using retrospective multicenter data (n = 859), the MMF combining an ensemble deep learning (Ensemble-DL) model with clinical variables achieved strong external validation performance (C-index: OS = 0.74, PFS = 0.69), outperforming radiomics (29.8% OS improvement), mRECIST (27.6% OS improvement), clinical benchmarks (C-index: OS = 0.67, p = 0.0011; PFS = 0.65, p = 0.033), and Ensemble-DL (C-index: OS = 0.69, p = 0.0028; PFS = 0.66, p = 0.044). The MMF system effectively stratified patients across clinical subgroups and demonstrated interpretability through activation maps and radiomic correlations. Differential gene expression analysis revealed enrichment of the PI3K/Akt pathway in patients identified by the MMF system. The MMF system provides an interpretable, clinically applicable approach to guide personalized ICI treatment in unresectable HCC.",
      "authors": "Xu Jun; Wang Tengfei; Li Junjun; Wang Yong; Zhu Zhangxiang; Fu Xiao; Wang Junjie; Zhang Zhenglin; Cai Wei; Song Ruipeng; Hou Changlong; Yang Li-Zhuang; Wang Hongzhi; Wong Stephen T C; Li Hai",
      "year": "2025",
      "month": "Jun",
      "journal": "NPJ precision oncology",
      "source": "pubmed"
    },
    {
      "pmid": "40511682",
      "doi": "10.7554/eLife.98469",
      "title": "Artificial intelligence approaches for tumor phenotype stratification from single-cell transcriptomic data.",
      "abstract": "Single-cell RNA-sequencing (scRNA-seq) coupled with robust computational analysis facilitates the characterization of phenotypic heterogeneity within tumors. Current scRNA-seq analysis pipelines are capable of identifying a myriad of malignant and non-malignant cell subtypes from single-cell profiling of tumors. However, given the extent of intra-tumoral heterogeneity, it is challenging to assess the risk associated with individual cell subpopulations, primarily due to the complexity of the cancer phenotype space and the lack of clinical annotations associated with tumor scRNA-seq studies. To this end, we introduce SCellBOW, a scRNA-seq analysis framework inspired by document embedding techniques from the domain of Natural Language Processing (NLP). SCellBOW is a novel computational approach that facilitates effective identification and high-quality visualization of single-cell subpopulations. We compared SCellBOW with existing best practice methods for its ability to precisely represent phenotypically divergent cell types across multiple scRNA-seq datasets, including our in-house generated human splenocyte and matched peripheral blood mononuclear cell (PBMC) dataset. For tumor cells, SCellBOW estimates the relative risk associated with each cluster and stratifies them based on their aggressiveness. This is achieved by simulating how the presence or absence of a specific cell subpopulation influences disease prognosis. Using SCellBOW, we identified a hitherto unknown and pervasive AR-/NE",
      "authors": "Bhattacharya Namrata; Rockstroh Anja; Deshpande Sanket Suhas; Thomas Sam Koshy; Yadav Anunay; Goswami Chitrita; Chawla Smriti; Solomon Pierre; Fourgeux Cynthia; Ahuja Gaurav; Hollier Brett; Kumar Himanshu; Roquilly Antoine; Poschmann Jeremie; Lehman Melanie; Nelson Colleen C; Sengupta Debarka",
      "year": "2025",
      "month": "Jun",
      "journal": "eLife",
      "source": "pubmed"
    },
    {
      "pmid": "40508136",
      "doi": "10.3390/ijms26115324",
      "title": "Artificial Intelligence-Assisted Breeding for Plant Disease Resistance.",
      "abstract": "Harnessing state-of-the-art technologies to improve disease resistance is a critical objective in modern plant breeding. Artificial intelligence (AI), particularly deep learning and big model (large language model and large multi-modal model), has emerged as a transformative tool to enhance disease detection and omics prediction in plant science. This paper provides a comprehensive review of AI-driven advancements in plant disease detection, highlighting convolutional neural networks and their linked methods and technologies through bibliometric analysis from recent research. We further discuss the groundbreaking potential of large language models and multi-modal models in interpreting complex disease patterns via heterogeneous data. Additionally, we summarize how AI accelerates genomic and phenomic selection by enabling high-throughput analysis of resistance-associated traits, and explore AI's role in harmonizing multi-omics data to predict plant disease-resistant phenotypes. Finally, we propose some challenges and future directions in terms of data, model, and privacy facets. We also provide our perspectives on integrating federated learning with a large language model for plant disease detection and resistance prediction. This review provides a comprehensive guide for integrating AI into plant breeding programs, facilitating the translation of computational advances into disease-resistant crop breeding.",
      "authors": "Ma Juan; Cheng Zeqiang; Cao Yanyong",
      "year": "2025",
      "month": "Jun",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "40501975",
      "doi": "10.1101/2025.06.06.658309",
      "title": "Integrative analysis of mRNA stability regulation uncovers a metastasis-suppressive program in breast cancer.",
      "abstract": "Heterogeneity in cancer gene expression is typically linked to genetic and epigenetic alterations, yet post-transcriptional regulation likely influences these patterns as well. However, the quantitative contribution of post-transcriptional mechanisms to cancer transcriptome dynamics remains unclear. Here, we systematically measured mRNA dynamics across diverse breast cancer models, revealing that mRNA stability significantly shapes gene expression variability. To decipher the regulatory grammar underlying these dynamics, we developed GreyHound, an interpretable multimodal deep-learning framework integrating RNA sequence features and RNA-binding protein (RBP) expression. GreyHound identified an extensive network of RBPs and their regulons underlying variations in mRNA stability. Among these, we uncovered a metastasis-suppressive regulatory axis centered on the RNA-binding protein RBMS3 and its post-transcriptional control of the redox regulator TXNIP. Functional and molecular analyses revealed that RBMS3 depletion resulted in targeted transcript destabilization, which was associated with poor clinical outcomes and enhanced metastatic potential in xenograft models. Using in vivo epistasis studies, we confirmed that RBMS3 regulation of TXNIP mRNA stability drives this metastasis-suppressive program. These findings position the RBMS3-TXNIP regulatory axis as a key post-transcriptional mechanism in breast cancer and illustrate how interpretable models of RNA dynamics can uncover hidden regulatory programs in disease.",
      "authors": "Karner Heather; Mittmann Tabea; Chen Vicky W; Borah Ashir A; Langen Andreas; Yousefi Hassan; Fish Lisa; Zaro Balyn W; Navickas Albertas; Goodarzi Hani",
      "year": "2025",
      "month": "Jun",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40501921",
      "doi": "10.1101/2025.01.28.635153",
      "title": "sciLaMA: A Single-Cell Representation Learning Framework to Leverage Prior Knowledge from Large Language Models.",
      "abstract": "Single-cell RNA sequencing (scRNA-seq) enables high-resolution exploration of cellular diversity and gene regulation, yet analyzing such data remains challenging due to technical and methodological limitations. Existing task-specific deep generative models like Variational Auto-Encoder (VAE) and its variants struggle to incorporate external biological knowledge, while transformer-based foundational large Language Models (LLMs or large LaMs) face limitations in computational cost and applicability to tabular gene expression data. Here, we introduce sciLaMA (single-cell interpretable Language Model Adapter), a novel representation learning framework that bridges these gaps by integrating static gene embeddings from multimodal LLMs with scRNA-seq tabular data through a paired-VAE architecture. Our approach generates context-aware representations for both cells and genes and outperforms state-of-the-art methods in key single-cell downstream tasks, including batch effect correction, cell clustering, and cell-state-specific gene marker and module identification, while maintaining computational efficiency. sciLaMA offers a computationally efficient, unified framework for comprehensive single-cell data analysis and biologically interpretable gene module discovery. Source code is available at https://github.com/microsoft/sciLaMA.",
      "authors": "Hu Hongru; Zhang Shuwen; Choi Yongin; Malladi Venkat S; Quon Gerald",
      "year": "2025",
      "month": "May",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40501071",
      "doi": "10.1093/bib/bbaf268",
      "title": "scATD: a high-throughput and interpretable framework for single-cell cancer drug resistance prediction and biomarker identification.",
      "abstract": "Transfer learning has been widely applied to drug sensitivity prediction based on single-cell RNA sequencing, leveraging knowledge from large datasets of cancer cell lines or other sources to improve the prediction of drug responses. However, previous studies require model fine-tuning for different patient single-cell datasets, limiting their ability to meet the clinical need for high-throughput rapid prediction. In this research, we introduce single-cell Adaptive Transfer and Distillation model (scATD), a transfer learning framework leveraging large language models for high-throughput drug sensitivity prediction. Based on different large language models (scFoundation and Geneformer) and transfer strategies, scATD includes three distinct sub-models: scATD-sf, scATD-gf, and scATD-sf-dist. scATD-sf and scATD-gf employs an important bidirectional style transfer to enable predictions for new patients without model parameter training. Additionally, scATD-sf-dist uses knowledge distillation from large models to enhance prediction performance, improve efficiency, and reduce resource requirements. Benchmarking across more diverse datasets demonstrates scATD's superior accuracy, generalization and efficiency. Besides, by rigorously selecting reference background samples for feature attribution algorithms, scATD also provides more meaningful insights into the relationship between gene expression and drug resistance mechanisms. Making scATD more interpretability for addressing critical challenges in precision oncology.",
      "authors": "Zhou Murong; Luo Zeyu; Yin Yu-Hang; Liu Qiaoming; Wang Guohua; Zhao Yuming",
      "year": "2025",
      "month": "May",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40496817",
      "doi": "10.1016/j.omtn.2025.102546",
      "title": "Generative artificial intelligence, integrative bioinformatics, and single-cell analysis reveal Alzheimer's genetic and immune landscape.",
      "abstract": "The research aims to understand Alzheimer's genetic and immune landscapes using the amalgamation of three technologies: artificial intelligence (GenAI), integrative bioinformatics, and single-cell analysis. First, the study aims to identify and characterize the significant genes associated with Alzheimer's disease (AD) using three GenAI models (GPT‑4o, Gemini model, and DeepSeek). After the genes were accumulated from GenAI models, 27 genes associated with AD were recoded. Furthermore, they were analyzed using integrative bioinformatics methods. Similarly, the immune landscape of AD using single-cell analysis was also explored, which reveals a high percentage of effector CD8",
      "authors": "Das Arpita; Bhattacharya Manojit; Abdelhameed Ali Saber; Lee Sang-Soo; Chakraborty Chiranjib",
      "year": "2025",
      "month": "Jun",
      "journal": "Molecular therapy. Nucleic acids",
      "source": "pubmed"
    },
    {
      "pmid": "40492244",
      "doi": "",
      "title": "Prompting Decision Transformers for Zero-Shot Reach-Avoid Policies.",
      "abstract": "Offline goal-conditioned reinforcement learning methods have shown promise for reach-avoid tasks, where an agent must reach a target state while avoiding undesirable regions of the state space. Existing approaches typically encode avoid-region information into an augmented state space and cost function, which prevents flexible, dynamic specification of novel avoid-region information at evaluation time. They also rely heavily on well-designed reward and cost functions, limiting scalability to complex or poorly structured environments. We introduce RADT, a decision transformer model for offline, reward-free, goal-conditioned, avoid region-conditioned RL. RADT encodes goals and avoid regions directly as prompt tokens, allowing any number of avoid regions of arbitrary size to be specified at evaluation time. Using only suboptimal offline trajectories from a random policy, RADT learns reach-avoid behavior through a novel combination of goal and avoid-region hindsight relabeling. We benchmark RADT against 3 existing offline goal-conditioned RL models across 11 tasks, environments, and experimental settings. RADT generalizes in a zero-shot manner to out-of-distribution avoid region sizes and counts, outperforming baselines that require retraining. In one such zero-shot setting, RADT achieves 35.7% improvement in normalized cost over the best retrained baseline while maintaining high goal-reaching success. We apply RADT to cell reprogramming in biology, where it reduces visits to undesirable intermediate gene expression states during trajectories to desired target states, despite stochastic transitions and discrete, structured state dynamics.",
      "authors": "Li Kevin; Zitnik Marinka",
      "year": "2025",
      "month": "May",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "40489624",
      "doi": "10.1073/pnas.2421738122",
      "title": "Cross-species modeling of plant genomes at single-nucleotide resolution using a pretrained DNA language model.",
      "abstract": "Interpreting function and fitness effects in diverse plant genomes requires transferable models. Language models (LMs) pretrained on large-scale biological sequences can capture evolutionary conservation and offer cross-species prediction better than supervised models through fine-tuning limited labeled data. We introduce PlantCaduceus, a plant DNA LM that learns evolutionary conservation patterns in 16 angiosperm genomes by modeling both DNA strands simultaneously. When fine-tuned on a small set of labeled ",
      "authors": "Zhai Jingjing; Gokaslan Aaron; Schiff Yair; Berthel Ana; Liu Zong-Yan; Lai Wei-Yun; Miller Zachary R; Scheben Armin; Stitzer Michelle C; Romay M Cinta; Buckler Edward S; Kuleshov Volodymyr",
      "year": "2025",
      "month": "Jun",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "source": "pubmed"
    },
    {
      "pmid": "40483546",
      "doi": "10.1093/bib/bbaf263",
      "title": "Artificial intelligence-driven circRNA vaccine development: multimodal collaborative optimization and a new paradigm for biomedical applications.",
      "abstract": "Circular RNA (circRNA) vaccines have emerged as a groundbreaking innovation in infectious disease prevention and cancer immunotherapy, offering superior stability and reduced immunogenicity compared to conventional linear messenger RNA (mRNA) vaccines. While linear mRNA vaccines are prone to degradation and can trigger strong innate immune responses, covalently closed circRNA vaccines leverage their unique circular structure to enhance molecular stability and minimize innate immune activation, positioning them as a next-generation platform for vaccine development. Artificial intelligence (AI) is revolutionizing circRNA vaccine design and optimization. Deep learning models, such as convolutional neural networks (CNNs) and Transformers, integrate multi-omics data to refine antigen prediction, RNA secondary structure modeling, and lipid nanoparticle delivery system formulation, surpassing traditional bioinformatics approaches in both accuracy and efficiency. While AI-driven bioinformatics enhances antigen screening and delivery system modeling, generative AI accelerates literature synthesis and experimental planning-though the risk of fabricated references and limited biological interpretability hinders its reliability. Despite these advancements, challenges such as the \"black-box\" nature of AI algorithms, unreliable literature retrieval, and insufficient integration of biological mechanisms underscore the necessity for a hybrid \"AI-traditional-experimental\" paradigm. This approach integrates explainable AI frameworks, multi-omics validation, and ethical oversight to ensure clinical translatability. Future research should prioritize mechanism-driven AI models, real-time experimental feedback, and rigorous ethical standards to fully unlock the potential of circRNA vaccines in precision oncology and global health.",
      "authors": "Zhao Yan; Wang Huaiyu",
      "year": "2025",
      "month": "May",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40475298",
      "doi": "10.1177/20552076251348834",
      "title": "Global trends in the use of artificial intelligence for urological tumor histopathology: A 20-year bibliometric analysis.",
      "abstract": "The field of urological tumor histopathology has long relied on subjective pathologist expertise, leading to diagnostic variability. Recent advances in digital pathology and artificial intelligence (AI) offer transformative potential by standardizing diagnoses, improving accuracy, and bridging healthcare disparities. This study conducted a 20-year bibliometric analysis to map global research trends and innovations in AI-driven urological pathology. For this bibliometric analysis, literature from 2004 to 2024 was retrieved from the Web of Science Core Collection. CiteSpace, VOSviewer, and Microsoft Excel were used to visualize coauthorship, cocitation, and co-occurrence analyses of countries/regions, institutions, authors, references, and keywords in the field of AI for urological tumor histopathology. A total of 199 papers were included. Research on AI-driven urological tumor pathology has steadily increased since 2005, with a significant surge between 2020 and 2023. The United States made the largest contribution in terms of publications (131), citations (4725), and collaborations. The most productive institution was the University of Southern California, while Patel et al. and Epstein et al. were identified as the most active and most cocited authors, respectively. European Urology led in both publication volume and impact. Keyword analysis identified \"machine learning,\" \"prostate cancer,\" \"deep learning,\" and \"diagnosis\" as major research foci. The integration of AI into urological tumor pathology demonstrates transformative potential, significantly enhancing diagnostic accuracy and efficiency through automated analysis of whole-slide imaging and Gleason grading, comparable to pathologist-level performance. However, clinical translation encounters critical challenges, including data bias, model interpretability (\"black-box\" limitations), and regulatory-ethical complexities. Future advancements hinge on developing explainable AI frameworks, multimodal systems integrating histopathology, radiomics, and genomics and establishing global collaborative networks to address resource disparities. Prioritizing standardized data protocols, fairness-aware algorithms, and dynamic regulatory guidelines will be essential to ensure equitable, reliable, and clinically actionable AI solutions, ultimately advancing precision oncology in urological malignancies.",
      "authors": "Dai Fazhong; He Yifeng; Duan Juan; Lin Kangjian; Lv Qian; Zhao Zhongxiang; Zou Yesong; Jiang Jianhong; Zheng Zongtai; Qiu Xiaofu",
      "year": "2025",
      "month": "",
      "journal": "Digital health",
      "source": "pubmed"
    },
    {
      "pmid": "40452145",
      "doi": "10.1093/bib/bbaf249",
      "title": "EDS-Kcr: deep supervision based on large language model for identifying protein lysine crotonylation sites across multiple species.",
      "abstract": "With the rapid advancement of proteomics, post-translational modifications, particularly lysine crotonylation (Kcr), have gained significant attention in basic research, drug development, and disease treatment. However, current methods for identifying these modifications are often complex, costly, and time-consuming. To address these challenges, we have proposed EDS-Kcr, a novel bioinformatics tool that integrates the state-of-the-art protein language model ESM2 with deep supervision to improve the efficiency and accuracy of Kcr site prediction. EDS-Kcr demonstrated outstanding performance across various species datasets, proving its applicability to a wide range of proteins, including those from humans, plants, animals, and microbes. Compared to existing Kcr site prediction models, our model excelled in multiple key performance indicators, showcasing superior predictive power and robustness. Furthermore, we enhanced the transparency and interpretability of EDS-Kcr through visualization techniques and attention mechanisms. In conclusion, the EDS-Kcr model provides an efficient and reliable predictive tool suitable for disease diagnosis and drug development. We have also established a freely accessible web server for EDS-Kcr at http://eds-kcr.lin-group.cn/.",
      "authors": "Zhang Hong-Qi; Lin Xin-Ran; Wang Yan-Ting; Pei Wen-Fang; Ma Guang-Ji; Zhou Ze-Xu; Deng Ke-Jun; Yan Dan; Liu Tian-Yuan",
      "year": "2025",
      "month": "May",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40447924",
      "doi": "10.1007/s12672-025-02771-1",
      "title": "A review of enhanced biosignature immunotherapy tools for predicting lung cancer immune phenotypes using deep learning.",
      "abstract": "Cancer has increasingly been recognized as a genetic disease, influenced by lifestyle changes, dietary patterns, and environmental pollutants. Lung cancer remains one of the most lethal malignancies worldwide, necessitating precise diagnostic and therapeutic approaches. Among these types, lung cancer is the third most common cancer, which affects all over the population. Lung cancer is a cancer that forms in tissues of the lung, usually in the cells that line the air passages. There are two main types of lung cancer: small cell and non-small cell lung cancer. These two types grow differently and are treated differently. This review explores the application of advanced deep learning (DL) techniques in enhancing biosignature immunotherapy tools for the prediction of immune phenotypes in lung cancer patients. The study systematically analyses recent research integrating multi-modal biomedical data, such as radiomics, genomics, transcriptomics, and histopathological images, to develop robust DL-based predictive models. A well-defined literature search strategy, inclusion/exclusion criteria, and a PRISMA-guided screening process ensure transparency and reproducibility. Emphasis is placed on identifying key predictive biomarkers, including Programmed Death-Ligand 1 (PD-L1) expression, Tumor Mutational Burden (TMB), Microsatellite Instability (MSI), and APOBEC mutational signatures, which are vital for personalizing immunotherapy. The review also incorporates a quality assessment framework to evaluate the methodological rigor of the included studies. Enhanced technical details, such as model architecture, validation strategies, hyperparameter tuning, and standardized performance metrics like AUC-ROC and Harrell's C-index, are presented to facilitate cross-study comparisons. This review underscores the transformative role of DL in precision oncology and highlights the potential for integrating biosignatures into clinical workflows to improve immunotherapy outcomes in lung cancer.",
      "authors": "Oliver A Sheryl; Sayeed Md Shohel; Razak Siti Fatimah Abdul",
      "year": "2025",
      "month": "May",
      "journal": "Discover oncology",
      "source": "pubmed"
    },
    {
      "pmid": "40433986",
      "doi": "10.1093/iob/obae036",
      "title": "Opportunities and Challenges in Applying AI to Evolutionary Morphology.",
      "abstract": "Artificial intelligence (AI) is poised to revolutionize many aspects of science, including the study of evolutionary morphology. While classical AI methods such as principal component analysis and cluster analysis have been commonplace in the study of evolutionary morphology for decades, recent years have seen increasing application of deep learning to ecology and evolutionary biology. As digitized specimen databases become increasingly prevalent and openly available, AI is offering vast new potential to circumvent long-standing barriers to rapid, big data analysis of phenotypes. Here, we review the current state of AI methods available for the study of evolutionary morphology, which are most developed in the area of data acquisition and processing. We introduce the main available AI techniques, categorizing them into 3 stages based on their order of appearance: (1) machine learning, (2) deep learning, and (3) the most recent advancements in large-scale models and multimodal learning. Next, we present case studies of existing approaches using AI for evolutionary morphology, including image capture and segmentation, feature recognition, morphometrics, and phylogenetics. We then discuss the prospectus for near-term advances in specific areas of inquiry within this field, including the potential of new AI methods that have not yet been applied to the study of morphological evolution. In particular, we note key areas where AI remains underutilized and could be used to enhance studies of evolutionary morphology. This combination of current methods and potential developments has the capacity to transform the evolutionary analysis of the organismal phenotype into evolutionary phenomics, leading to an era of \"big data\" that aligns the study of phenotypes with genomics and other areas of bioinformatics.",
      "authors": "He Y; Mulqueeney J M; Watt E C; Salili-James A; Barber N S; Camaiti M; Hunt E S E; Kippax-Chui O; Knapp A; Lanzetti A; Rangel-de Lázaro G; McMinn J K; Minus J; Mohan A V; Roberts L E; Adhami D; Grisan E; Gu Q; Herridge V; Poon S T S; West T; Goswami A",
      "year": "2024",
      "month": "",
      "journal": "Integrative organismal biology (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "40430173",
      "doi": "10.3390/life15050745",
      "title": "Role of Artificial Intelligence and Personalized Medicine in Enhancing HIV Management and Treatment Outcomes.",
      "abstract": "The integration of artificial intelligence and personalized medicine is transforming HIV management by enhancing diagnostics, treatment optimization, and disease monitoring. Advances in machine learning, deep neural networks, and multi-omics data analysis enable precise prognostication, tailored antiretroviral therapy, and early detection of drug resistance. AI-driven models analyze vast genomic, proteomic, and clinical datasets to refine treatment strategies, predict disease progression, and pre-empt therapy failures. Additionally, AI-powered diagnostic tools, including deep learning imaging and natural language processing, improve screening accuracy, particularly in resource-limited settings. Despite these innovations, challenges such as data privacy, algorithmic bias, and the need for clinical validation remain. Successful integration of AI into HIV care requires robust regulatory frameworks, interdisciplinary collaboration, and equitable technology access. This review explores both the potential and limitations of AI in HIV management, emphasizing the need for ethical implementation and expanded research to maximize its impact. AI-driven approaches hold great promise for a more personalized, efficient, and effective future in HIV treatment and care.",
      "authors": "Sah Ashok Kumar; Elshaikh Rabab H; Shalabi Manar G; Abbas Anass M; Prabhakar Pranav Kumar; Babker Asaad M A; Choudhary Ranjay Kumar; Gaur Vikash; Choudhary Ajab Singh; Agarwal Shagun",
      "year": "2025",
      "month": "May",
      "journal": "Life (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "40429619",
      "doi": "10.3390/ijms26104473",
      "title": "Artificial Intelligence in Glaucoma: Advances in Diagnosis, Progression Forecasting, and Surgical Outcome Prediction.",
      "abstract": "Glaucoma is a leading cause of irreversible blindness, with challenges persisting in early diagnosis, disease progression, and surgical outcome prediction. Recent advances in artificial intelligence have enabled significant progress by extracting clinically relevant patterns from structural, functional, and molecular data. This review outlines the current applications of artificial intelligence in glaucoma care, including early detection using fundus photography and OCT and disease progression prediction using deep learning architectures such as convolutional neural networks, recurrent neural networks, transformer models, generative adversarial networks, and autoencoders. Surgical outcome forecasting has been enhanced through multimodal models that integrate electronic health records and imaging data. We also highlight emerging AI applications in omics analysis, including transcriptomics and metabolomics, for biomarker discovery and individualized risk stratification. Despite these advances, key challenges remain in interpretability, integration of heterogeneous data, and the lack of personalized surgical timing guidance. Future work should focus on transparent, generalizable, and multimodal AI models, supported by large, well-curated datasets, to advance precision medicine in glaucoma.",
      "authors": "Lan Chiao-Hsin; Chiu Ta-Hung; Yen Wei-Ting; Lu Da-Wen",
      "year": "2025",
      "month": "May",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "40426849",
      "doi": "10.3390/biomedicines13051019",
      "title": "Hearts, Data, and Artificial Intelligence Wizardry: From Imitation to Innovation in Cardiovascular Care.",
      "abstract": "Artificial intelligence (AI) is transforming cardiovascular medicine by enabling the analysis of high-dimensional biomedical data with unprecedented precision. Initially employed to automate human tasks such as electrocardiogram (ECG) interpretation and imaging segmentation, AI's true potential lies in uncovering hidden disease data patterns, predicting long-term cardiovascular risk, and personalizing treatments. Unlike human cognition, which excels in certain tasks but is limited by memory and processing constraints, AI integrates multimodal data sources-including ECG, echocardiography, cardiac magnetic resonance (CMR) imaging, genomics, and wearable sensor data-to generate novel clinical insights. AI models have demonstrated remarkable success in early dis-ease detection, such as predicting heart failure from standard ECGs before symptom on-set, distinguishing genetic cardiomyopathies, and forecasting arrhythmic events. However, several challenges persist, including AI's lack of contextual understanding in most of these tasks, its \"black-box\" nature, and biases in training datasets that may contribute to disparities in healthcare delivery. Ethical considerations and regulatory frameworks are evolving, with governing bodies establishing guidelines for AI-driven medical applications. To fully harness the potential of AI, interdisciplinary collaboration among clinicians, data scientists, and engineers is essential, alongside open science initiatives to promote data accessibility and reproducibility. Future AI models must go beyond task automation, focusing instead on augmenting human expertise to enable proactive, precision-driven cardiovascular care. By embracing AI's computational strengths while addressing its limitations, cardiology is poised to enter an era of transformative innovation beyond traditional diagnostic and therapeutic paradigms.",
      "authors": "Pantelidis Panteleimon; Dilaveris Polychronis; Ruipérez-Campillo Samuel; Goliopoulou Athina; Giannakodimos Alexios; Theofilis Panagiotis; De Lucia Raffaele; Katsarou Ourania; Zisimos Konstantinos; Kalogeras Konstantinos; Oikonomou Evangelos; Siasos Gerasimos",
      "year": "2025",
      "month": "Apr",
      "journal": "Biomedicines",
      "source": "pubmed"
    },
    {
      "pmid": "40408481",
      "doi": "10.1126/sciadv.adu2151",
      "title": "Single-cell multimodal analysis reveals tumor microenvironment predictive of treatment response in non-small cell lung cancer.",
      "abstract": "Non-small cell lung cancer (NSCLC) constitutes over 80% of lung cancer cases and remains a leading cause of cancer-related mortality worldwide. Despite the advent of immune checkpoint inhibitors, their efficacy is limited to 27 to 45% of patients. Identifying likely treatment responders is essential for optimizing healthcare and improving quality of life. We generated multiplex immunofluorescence (mIF) images, histopathology, and RNA sequencing data from human NSCLC tissues. Through the analysis of mIF images, we characterized the spatial organization of 1.5 million cells based on the expression levels for 33 biomarkers. To enable large-scale characterization of tumor microenvironments, we developed NucSegAI, a deep learning model for automated nuclear segmentation and cellular classification in histology images. With this model, we analyzed the morphological, textural, and topological phenotypes of 45.6 million cells across 119 whole-slide images. Through unsupervised phenotype discovery, we identified specific lymphocyte phenotypes predictive of immunotherapy response. Our findings can improve patient stratification and guide selection of effective therapeutic regimens.",
      "authors": "Zheng Yuanning; Sadée Christoph; Ozawa Michael; Howitt Brooke E; Gevaert Olivier",
      "year": "2025",
      "month": "May",
      "journal": "Science advances",
      "source": "pubmed"
    },
    {
      "pmid": "40407404",
      "doi": "10.1177/10732748251343245",
      "title": "Perceptions, Attitudes, and Concerns on Artificial Intelligence Applications in Patients with Cancer.",
      "abstract": "IntroductionThe use of artificial intelligence (AI) in oncology has increased rapidly, transforming various healthcare areas such as pathology, radiology, diagnostics, prognosis, genomics, treatment planning, and clinical trials. However, perspectives, comfort levels, and concerns about AI in cancer care remain largely unexplored.Materials and MethodsThis prospective, descriptive cross-sectional survey study was conducted between May 20, 2024 and October 22, 2024, among 363 patients with cancer from two different hospitals affiliated with Ankara University, a tertiary care center in Türkiye. The survey included three distinct sections: (1) Perceptions: Patients' general views on AI's impact in oncology; (2) Attitudes: Comfort level with AI performing medical tasks; (3) Concerns: Specific fears related to AI implementation (eg, diagnostic errors, data privacy, healthcare costs). Survey responses were summarized descriptively, and differences by age, gender, and education were analyzed using chi-square tests.ResultsA majority (50.7%) believed AI would somewhat (32%) or significantly (18.7%) improve healthcare. However, one-third of patients (33.1%) were very uncomfortable with AI diagnosing cancer, with higher discomfort among less-educated participants (",
      "authors": "Erul Enes; Aktekin Yusuf; Danışman Furkan Berk; Gümüştaş Şükrü Armanç; Aktekin Büşra Saraç; Yekedüz Emre; Ürün Yüksel",
      "year": "2025",
      "month": "",
      "journal": "Cancer control : journal of the Moffitt Cancer Center",
      "source": "pubmed"
    },
    {
      "pmid": "40407386",
      "doi": "10.1093/bib/bbaf210",
      "title": "StereoMM: a graph fusion model for integrating spatial transcriptomic data and pathological images.",
      "abstract": "Spatial omics technologies, generating high-throughput and multimodal data, have necessitated the development of advanced data integration methods to facilitate comprehensive biological and clinical treatment discoveries. Based on the cross-attention concept, we developed an AI learning based toolchain called StereoMM, a graph based fusion model that can incorporate omics data such as gene expression, histological images, and spatial location. StereoMM uses an attention module for omics data interaction and a graph autoencoder to integrate spatial positions and omics data in a self-supervised manner. Applying StereoMM across various cancer types and platforms has demonstrated its robust capability. StereoMM outperforms competitors in identifying spatial regions reflecting tumour progression and shows promise in classifying colorectal cancer patients into deficient mismatch repair and proficient mismatch repair groups. The comprehensive inter-modal integration and efficiency of StereoMM enable researchers to construct spatial views of integrated multimodal features efficiently, advancing thorough tissue and patient characterization.",
      "authors": "Luo Bingying; Teng Fei; Tang Guo; Cen Weixuan; Liu Xing; Chen Jinmiao; Qu Chi; Liu Xuanzhu; Liu Xin; Jiang Wenyan; Huang Huaqiang; Feng Yu; Zhang Xue; Jian Min; Li Mei; Xi Feng; Li Guibo; Liao Sha; Chen Ao; Yu Weimiao; Xu Xun; Zhang Jiajun",
      "year": "2025",
      "month": "May",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40391010",
      "doi": "10.3389/fendo.2025.1506729",
      "title": "Beyond genomics: artificial intelligence-powered diagnostics for indeterminate thyroid nodules-a systematic review and meta-analysis.",
      "abstract": "In recent years, artificial intelligence (AI) tools have become widely studied for thyroid ultrasonography (USG) classification. The real-world applicability of these developed tools as pre-operative diagnostic aids is limited due to model overfitting, clinician trust, and a lack of gold standard surgical histology as ground truth class label. The ongoing dilemma within clinical thyroidology is surgical decision making for indeterminate thyroid nodules (ITN). Genomic sequencing classifiers (GSC) have been utilised for this purpose; however, costs and availability preclude universal adoption creating an inequity gap. We conducted this review to analyse the current evidence of AI in ITN diagnosis without the use of GSC. English language articles evaluating the diagnostic accuracy of AI for ITNs were identified. A systematic search of PubMed, Google Scholar, and Scopus from inception to 18 February 2025 was performed using comprehensive search strategies incorporating MeSH headings and keywords relating to AI, indeterminate thyroid nodules, and pre-operative diagnosis. This systematic review and meta-analysis was conducted in accordance with methods recommended by the Cochrane Collaboration (PROSPERO ID CRD42023438011). The search strategy yielded 134 records after the removal of duplicates. A total of 20 models were presented in the seven studies included, five of which were radiological driven, one utilised natural language processing, and one focused on cytology. The pooled meta-analysis incorporated 16 area under the curve (AUC) results derived from 15 models across three studies yielding a combined estimate of 0.82 (95% CI: 0.81-0.84) indicating moderate-to-good classification performance across machine learning (ML) and deep learning (DL) architectures. However, substantial heterogeneity was observed, particularly among DL models (I² = 99.7%, pooled AUC = 0.85, 95% CI: 0.85-0.86). Minimal heterogeneity was observed among ML models (I² = 0.7%), with a pooled AUC of 0.75 (95% CI: 0.70-0.81). Meta-regression analysis performed suggests potential publication bias or systematic differences in model architectures, dataset composition, and validation methodologies. This review demonstrated the burgeoning potential of AI to be of clinical value in surgical decision making for ITNs; however, study-developed models were unsuitable for clinical implementation based on performance alone at their current states or lacked robust independent external validation. There is substantial capacity for further development in this field. https://www.crd.york.ac.uk/PROSPERO/, identifier CRD42023438011.",
      "authors": "Jassal Karishma; Edwards Melissa; Koohestani Afsaneh; Brown Wendy; Serpell Jonathan W; Lee James C",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in endocrinology",
      "source": "pubmed"
    },
    {
      "pmid": "40386420",
      "doi": "10.21203/rs.3.rs-6443303/v1",
      "title": "IBDome: An integrated molecular, histopathological, and clinical atlas of inflammatory bowel diseases.",
      "abstract": "Multi-omic and multimodal datasets with detailed clinical annotations offer significant potential to advance our understanding of inflammatory bowel diseases (IBD), refine diagnostics, and enable personalized therapeutic strategies. In this multi-cohort study, we performed an extensive multi-omic and multimodal analysis of 1,002 clinically annotated patients with IBD and non-IBD controls, incorporating whole-exome and RNA sequencing of normal and inflamed gut tissues, serum proteomics, and histopathological assessments from images of H&E-stained tissue sections. Transcriptomic profiles of normal and inflamed tissues revealed distinct site-specific inflammatory signatures in Crohn's disease (CD) and ulcerative colitis (UC). Leveraging serum proteomics, we developed an inflammatory protein severity signature that reflects underlying intestinal molecular inflammation. Furthermore, foundation model-based deep learning accurately predicted histologic disease activity scores from images of H&Estained intestinal tissue sections, offering a robust tool for clinical evaluation. Our integrative analysis highlights the potential of combining multi-omics and advanced computational approaches to improve our understanding and management of IBD.",
      "authors": "Trajanoski Zlatko; Plattner Christina; Sturm Gregor; Kühl Anja; Atreya Raja; Carollo Sandro; Gronauer Raphael; Rieder Dietmar; Günther Michael; Ormanns Steffen; Manzl Claudia; Wirtz Stefan; Meneghetti Asier; Hegazy Ahmed; Patankar Jay; Carrero Zunamys; Neurath Markus; Kather Jakob; Becker Christoph; Siegmund Britta",
      "year": "2025",
      "month": "May",
      "journal": "Research square",
      "source": "pubmed"
    },
    {
      "pmid": "40382355",
      "doi": "10.1038/s41467-025-59780-5",
      "title": "CREATE: cell-type-specific cis-regulatory element identification via discrete embedding.",
      "abstract": "Cis-regulatory elements (CREs), including enhancers, silencers, promoters and insulators, play pivotal roles in orchestrating gene regulatory mechanisms that drive complex biological traits. However, current approaches for CRE identification are predominantly sequence-based and typically focus on individual CRE types, limiting insights into their cell-type-specific functions and regulatory dynamics. Here, we present CREATE, a multimodal deep learning framework based on Vector Quantized Variational AutoEncoder, tailored for comprehensive CRE identification and characterization. CREATE integrates genomic sequences, chromatin accessibility, and chromatin interaction data to generate discrete CRE embeddings, enabling accurate multi-class classification and robust characterization of CREs. CREATE excels in identifying cell-type-specific CREs, and provides quantitative and interpretable insights into CRE-specific features, uncovering the underlying regulatory codes. By facilitating large-scale prediction of CREs in specific cell types, CREATE enhances the recognition of disease- or phenotype-associated biological variabilities of CREs, thus advancing our understanding of gene regulatory landscapes and their roles in health and disease.",
      "authors": "Cui Xuejian; Yin Qijin; Gao Zijing; Li Zhen; Chen Xiaoyang; Lv Hairong; Chen Shengquan; Liu Qiao; Zeng Wanwen; Jiang Rui",
      "year": "2025",
      "month": "May",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "40382312",
      "doi": "10.1038/s41467-025-59592-7",
      "title": "Extensible Immunofluorescence (ExIF) accessibly generates high-plexity datasets by integrating standard 4-plex imaging data.",
      "abstract": "Standard immunofluorescence imaging captures just ~4 molecular markers (4-plex) per cell, limiting dissection of complex biology. Inspired by multimodal omics-based data integration approaches, we propose an Extensible Immunofluorescence (ExIF) framework that transforms carefully designed but easily produced panels of 4-plex immunofluorescence into a unified dataset with theoretically unlimited marker plexity, using generative deep learning-based virtual labelling. ExIF enables integrated analyses of complex cell biology, exemplified here through interrogation of the epithelial-mesenchymal transition (EMT), driving significant improvements in downstream quantitative analyses usually reserved for omics data, including: classification of cell phenotypes; manifold learning of cell phenotype heterogeneity; and pseudotemporal inference of molecular marker dynamics. Introducing data integration concepts from omics to microscopy, ExIF empowers life scientists to use routine 4-plex fluorescence microscopy to quantitatively interrogate complex, multimolecular single-cell processes in a manner that approaches the performance of multiplexed labelling methods whose uptake remains limited.",
      "authors": "Gunawan Ihuan; Kohane Felix V; Dey Moumitha; Nguyen Kathy; Zheng Ye; Neumann Daniel P; Vafaee Fatemeh; Meijering Erik; Lock John G",
      "year": "2025",
      "month": "May",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "40381695",
      "doi": "10.1016/j.jbc.2025.110242",
      "title": "Machine learning-based multimodal radiomics and transcriptomics models for predicting radiotherapy sensitivity and prognosis in esophageal cancer.",
      "abstract": "Radiotherapy plays a critical role in treating esophageal cancer, but individual responses vary significantly, impacting patient outcomes. This study integrates machine learning-driven multimodal radiomics and transcriptomics to develop predictive models for radiotherapy sensitivity and prognosis in esophageal cancer. We applied the SEResNet101 deep learning model to imaging and transcriptomic data from the UCSC Xena and TCGA databases, identifying prognosis-associated genes such as STUB1, PEX12, and HEXIM2. Using Lasso regression and Cox analysis, we constructed a prognostic risk model that accurately stratifies patients based on survival probability. Notably, STUB1, an E3 ubiquitin ligase, enhances radiotherapy sensitivity by promoting the ubiquitination and degradation of SRC, a key oncogenic protein. In vitro and in vivo experiments confirmed that STUB1 overexpression or SRC silencing significantly improves radiotherapy response in esophageal cancer models. These findings highlight the predictive power of multimodal data integration for individualized radiotherapy planning and underscore STUB1 as a promising therapeutic target for enhancing radiotherapy efficacy in esophageal cancer.",
      "authors": "Ye Chengyu; Zhang Hao; Chi Zhou; Xu Zhina; Cai Yujie; Xu Yajing; Tong Xiangmin",
      "year": "2025",
      "month": "Jul",
      "journal": "The Journal of biological chemistry",
      "source": "pubmed"
    },
    {
      "pmid": "40358524",
      "doi": "10.1093/bioinformatics/btaf302",
      "title": "CrossAttOmics: multiomics data integration with cross-attention.",
      "abstract": "Advances in high throughput technologies enabled large access to various types of omics. Each omics provides a partial view of the underlying biological process. Integrating multiple omics layers would help have a more accurate diagnosis. However, the complexity of omics data requires approaches that can capture complex relationships. One way to accomplish this is by exploiting the known regulatory links between the different omics, which could help in constructing a better multimodal representation. In this article, we propose CrossAttOmics, a new deep-learning architecture based on the cross-attention mechanism for multiomics integration. Each modality is projected in a lower dimensional space with its specific encoder. Interactions between modalities with known regulatory links are computed in the feature representation space with cross-attention. The results of different experiments carried out in this article show that our model can accurately predict the types of cancer by exploiting the interactions between multiple modalities. CrossAttOmics outperforms other methods when there are few paired training examples. Our approach can be combined with attribution methods like LRP to identify which interactions are the most important. The code is available at https://github.com/Sanofi-Public/CrossAttOmics and https://doi.org/10.5281/zenodo.15065928. TCGA data can be downloaded from the Genomic Data Commons Data Portal. CCLE data can be downloaded from the depmap portal.",
      "authors": "Beaude Aurélien; Augé Franck; Zehraoui Farida; Hanczar Blaise",
      "year": "2025",
      "month": "Jun",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "40345352",
      "doi": "10.1016/j.phrs.2025.107765",
      "title": "MRI-based multimodal AI model enables prediction of recurrence risk and adjuvant therapy in breast cancer.",
      "abstract": "Timely intervention and improved prognosis for breast cancer patients rely on early metastasis risk detection and accurate treatment predictions. This study introduces an advanced multimodal MRI and AI-driven 3D deep learning model, termed the 3D-MMR-model, designed to predict recurrence risk in non-metastatic breast cancer patients. We conducted a multicenter study involving 1199 non-metastatic breast cancer patients from four institutions in China, with comprehensive MRI and clinical data retrospectively collected. Our model employed multimodal-data fusion, utilizing contrast-enhanced T1-weighted imaging (T1 + C) and T2-weighted imaging (T2WI) volumes, processed through a modified 3D-UNet for tumor segmentation and a DenseNet121-based architecture for disease-free survival (DFS) prediction. Additionally, we performed RNA-seq analysis to delve further into the relationship between concentrated hotspots within the tumor region and the tumor microenvironment. The 3D-MR-model demonstrated superior predictive performance, with time-dependent ROC analysis yielding AUC values of 0.90, 0.89, and 0.88 for 2-, 3-, and 4-year DFS predictions, respectively, in the training cohort. External validation cohorts corroborated these findings, highlighting the model's robustness across diverse clinical settings. Integration of clinicopathological features further enhanced the model's accuracy, with a multimodal approach significantly improving risk stratification and decision-making in clinical practice. Visualization techniques provided insights into the decision-making process, correlating predictions with tumor microenvironment characteristics. In summary, the 3D-MMR-model represents a significant advancement in breast cancer prognosis, combining cutting-edge AI technology with multimodal imaging to deliver precise and clinically relevant predictions of recurrence risk. This innovative approach holds promise for enhancing patient outcomes and guiding individualized treatment plans in breast cancer care.",
      "authors": "Yu Yunfang; Ren Wei; Mao Luhui; Ouyang Wenhao; Hu Qiugen; Yao Qinyue; Tan Yujie; He Zifan; Ban Xiaohua; Hu Huijun; Lin Ruichong; Wang Zehua; Chen Yongjian; Wu Zhuo; Chen Kai; Ouyang Jie; Li Tang; Zhang Zebang; Liu Guoying; Chen Xiuxing; Li Zhuo; Duan Xiaohui; Wang Jin; Yao Herui",
      "year": "2025",
      "month": "Jun",
      "journal": "Pharmacological research",
      "source": "pubmed"
    },
    {
      "pmid": "40329800",
      "doi": "10.1002/advs.202414507",
      "title": "De Novo Reconstruction of 3D Human Facial Images from DNA Sequence.",
      "abstract": "Facial morphology is a distinctive biometric marker, offering invaluable insights into personal identity, especially in forensic science. In the context of high-throughput sequencing, the reconstruction of 3D human facial images from DNA is becoming a revolutionary approach for identifying individuals based on unknown biological specimens. Inspired by artificial intelligence techniques in text-to-image synthesis, it proposes Difface, a multi-modality model designed to reconstruct 3D facial images only from DNA. Specifically, Difface first utilizes a transformer and a spiral convolution network to map high-dimensional Single Nucleotide Polymorphisms and 3D facial images to the same low-dimensional features, respectively, while establishing the association between both modalities in the latent features in a contrastive manner; and then incorporates a diffusion model to reconstruct facial structures from the characteristics of SNPs. Applying Difface to the Han Chinese database with 9,674 paired SNP phenotypes and 3D facial images demonstrates excellent performance in DNA-to-3D image alignment and reconstruction and characterizes the individual genomics. Also, including phenotype information in Difface further improves the quality of 3D reconstruction, i.e. Difface can generate 3D facial images of individuals solely from their DNA data, projecting their appearance at various future ages. This work represents pioneer research in de novo generating human facial images from individual genomics information.",
      "authors": "Jiao Mingqi; Li Jiarui; Zhong Bingxu; Du Siyuan; Li Shuning; Zhang Manfei; Zhang Qibin; Liang Zhongming; Liu Fan; Zuo Chunman; Wang Sijia; Chen Luonan",
      "year": "2025",
      "month": "Aug",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "40328890",
      "doi": "10.1038/s42004-025-01540-z",
      "title": "Leveraging pretrained deep protein language model to predict peptide collision cross section.",
      "abstract": "Collision cross section (CCS) of peptide ions provides an important separation dimension in liquid chromatography/tandem mass spectrometry-based proteomics that incorporates ion mobility spectrometry (IMS), and its accurate prediction is the basis for advanced proteomics workflows. This paper describes experimental data and a prediction model for challenging CCS prediction tasks including longer peptides that tend to have higher charge states. The proposed model is based on a pretrained deep protein language model. While the conventional prediction model requires training from scratch, the proposed model enables training with less amount of time owing to the use of the pretrained model as a feature extractor. Results of experiments with the novel experimental data show that the proposed model succeeds in drastically reducing the training time while maintaining the same or even better prediction performance compared with the conventional method. Our approach presents the possibility of prediction on the basis of \"greener\" manner training of various peptide properties in proteomic liquid chromatography/tandem mass spectrometry experiments.",
      "authors": "Nakai-Kasai Ayano; Ogata Kosuke; Ishihama Yasushi; Tanaka Toshiyuki",
      "year": "2025",
      "month": "May",
      "journal": "Communications chemistry",
      "source": "pubmed"
    },
    {
      "pmid": "40321941",
      "doi": "",
      "title": "The Dissipation Theory of Aging: A Quantitative Analysis Using a Cellular Aging Map.",
      "abstract": "We propose a new theory for aging based on dynamical systems and provide a data-driven computational method to quantify the changes at the cellular level. We use ergodic theory to decompose the dynamics of changes during aging and show that aging is fundamentally a dissipative process within biological systems, akin to dynamical systems where dissipation occurs due to non-conservative forces. To quantify the dissipation dynamics, we employ a transformer-based machine learning algorithm to analyze gene expression data, incorporating age as a token to assess how age-related dissipation is reflected in the embedding space. By evaluating the dynamics of gene and age embeddings, we provide a cellular aging map (CAM) and identify patterns indicative of divergence in gene embedding space, nonlinear transitions, and entropy variations during aging for various tissues and cell types. Our results provide a novel perspective on aging as a dissipative process and introduce a computational framework that enables measuring age-related changes with molecular resolution.",
      "authors": "Khodaee Farhan; Zandie Rohola; Xia Yufan; Edelman Elazer R",
      "year": "2025",
      "month": "Apr",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "40313967",
      "doi": "10.3389/fimmu.2025.1531930",
      "title": "Comprehensive molecular analyses of an autoimmune-related gene predictive model and immune infiltrations using machine learning methods in intracranial aneurysma.",
      "abstract": "Increasing evidence indicates a connection between intracranial aneurysm (intracranial aneurysm, IA) and autoimmune diseases. However, the molecular mechanisms from a genetic perspective remain unclear. This study aims to elucidate the potential roles of autoimmune-related genes (ARGs) in the pathogenesis of IA. Three transcription profiles (GSE13353, GSE26969, and GSE75436) for intracranial aneurysm (IA) were obtained from GEO databases. Autoimmune-related genes (ARGs) were sourced from the Genecards databases. Differentially expressed ARGs (DEARGs) were identified using the \"limma\" R package. GO, KEGG and GSEA analyses were performed to uncover underlying molecular functions. Three machine learning methods-LASSO logistic regression, random forest (RF), and XGBoost-were employed to identify key genes. An artificial neural network was used to develop an autoimmune-related signature predictive model for IA. Immune characteristics, including immune cell infiltration, immune responses, and HLA gene expression in IA, were investigated using ssGSEA. Additionally, the miRNA-gene regulatory network and potential therapeutic drugs for hub genes were predicted. In certain sections of the written content of this manuscript, the authors have utilized text generated by an AI technology. The specific name, version, model, and source of the generative AI technology used are as follows: Generative AI Technology Name: ChatGPT, Version: 4.0, Model: GPT-4, Source: OpenAI. A total of 39 differentially expressed ARGs (DEARGs) were identified across the GSE13353, GSE26969, and GSE75436 datasets. From these, two key diagnostic genes were identified using three machine learning algorithms: ADIPOQ and IL21R. A predictive neural network model was developed based on these genes, exhibiting strong diagnostic capability with a ROC value of 0.944, and further validated using a nomogram approach. The study focused on intracranial aneurysm (IA), revealing significant insights into the underlying genetic mechanisms. The results of bioinformatics analysis in our study elucidated the mechanism of intracranial aneurysm (IA), identifying two key differential genes. Our research highlights the significant roles of immune infiltration and the regulatory networks between genes, miRNAs, and drugs in IA. These findings not only enhance our understanding of the pathogenesis of IA but also suggest potential new avenues for its treatment.",
      "authors": "Zhang Minxue; Zhou Lin; Zhao Yuying; Wang Yanling; Zhang Zhuobo; Liu Zhan",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in immunology",
      "source": "pubmed"
    },
    {
      "pmid": "40303920",
      "doi": "10.3389/fphar.2025.1541509",
      "title": "Artificial intelligence in traditional Chinese medicine: advances in multi-metabolite multi-target interaction modeling.",
      "abstract": "Traditional Chinese Medicine (TCM) utilizes multi-metabolite and multi-target interventions to address complex diseases, providing advantages over single-target therapies. However, the active metabolites, therapeutic targets, and especially the combination mechanisms remain unclear. The integration of advanced data analysis and nonlinear modeling capabilities of artificial intelligence (AI) is driving the transformation of TCM into precision medicine. This review concentrates on the application of AI in TCM target prediction, including multi-omics techniques, TCM-specialized databases, machine learning (ML), deep learning (DL), and cross-modal fusion strategies. It also critically analyzes persistent challenges such as data heterogeneity, limited model interpretability, causal confounding, and insufficient robustness validation in practical applications. To enhance the reliability and scalability of AI in TCM target prediction, future research should prioritize continuous optimization of the AI algorithms using zero-shot learning, end-to-end architectures, and self-supervised contrastive learning.",
      "authors": "Li Yu; Liu Xiangjun; Zhou Jingwen; Li Fengjiao; Wang Yuting; Liu Qingzhong",
      "year": "2025",
      "month": "",
      "journal": "Frontiers in pharmacology",
      "source": "pubmed"
    },
    {
      "pmid": "40291692",
      "doi": "10.1101/2025.03.26.645544",
      "title": "IBDome: An integrated molecular, histopathological, and clinical atlas of inflammatory bowel diseases.",
      "abstract": "Multi-omic and multimodal datasets with detailed clinical annotations offer significant potential to advance our understanding of inflammatory bowel diseases (IBD), refine diagnostics, and enable personalized therapeutic strategies. In this multi-cohort study, we performed an extensive multi-omic and multimodal analysis of 1,002 clinically annotated patients with IBD and non-IBD controls, incorporating whole-exome and RNA sequencing of normal and inflamed gut tissues, serum proteomics, and histopathological assessments from images of H&E-stained tissue sections. Transcriptomic profiles of normal and inflamed tissues revealed distinct site-specific inflammatory signatures in Crohn's disease (CD) and ulcerative colitis (UC). Leveraging serum proteomics, we developed an inflammatory protein severity signature that reflects underlying intestinal molecular inflammation. Furthermore, foundation model-based deep learning accurately predicted histologic disease activity scores from images of H&E-stained intestinal tissue sections, offering a robust tool for clinical evaluation. Our integrative analysis highlights the potential of combining multi-omics and advanced computational approaches to improve our understanding and management of IBD.",
      "authors": "Plattner Christina; Sturm Gregor; Kühl Anja A; Atreya Raja; Carollo Sandro; Gronauer Raphael; Rieder Dietmar; Günther Michael; Ormanns Steffen; Manzl Claudia; Wirtz Stefan; Meneghetti Asier Rabasco; Hegazy Ahmed N; Patankar Jay V; Carrero Zunamys I; Neurath Markus F; Kather Jakob Nikolas; Becker Christoph; Siegmund Britta; Trajanoski Zlatko",
      "year": "2025",
      "month": "Apr",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40273431",
      "doi": "10.1093/bib/bbaf197",
      "title": "Carmna: classification and regression models for nitrogenase activity based on a pretrained large protein language model.",
      "abstract": "Nitrogen-fixing microorganisms play a critical role in the global nitrogen cycle by converting atmospheric nitrogen into ammonia through the action of nitrogenase (EC 1.18.6.1). In this study, we employed six machine learning algorithms to model the classification and regression of nitrogenase activity (Carmna). Carmna utilized the pretrained large-scale model ProtT5 for feature extraction from nitrogenase sequences and incorporated additional features, such as gene expression and codon preference, for model training. The optimal classification model, based on XGBoost, achieved an average area under receiver operating characteristic curve of 0.9365 and an F1 score of 0.85 in five-fold cross-validation. For regression, the best-performing model was a stacking approach based on support vector regression, with an average R2 of 0.5572 and a mean absolute error of 0.3351. Further interpretability analysis of the optimal regression model revealed that not only the proportion and codon preferences of standard amino acids, but also the expression levels and spatial distance of nitrogenase genes were associated with nitrogenase activity. We also obtained the minimum nitrogen-fixing nif cluster. This study deepens our understanding of the complex mechanisms regulating nitrogenase activity and contributes to the development of efficient bio-fertilizers.",
      "authors": "Ye Anqiang; Zhang Ji-Yun; Xu Qian; Guo Hai-Xia; Liao Zhen; Cui Hongtu; Zhang Dongdong; Guo Feng-Biao",
      "year": "2025",
      "month": "Mar",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40258830",
      "doi": "10.1038/s41467-025-58079-9",
      "title": "Stereopy: modeling comparative and spatiotemporal cellular heterogeneity via multi-sample spatial transcriptomics.",
      "abstract": "Understanding complex biological systems requires tracing cellular dynamic changes across conditions, time, and space. However, integrating multi-sample data in a unified way to explore cellular heterogeneity remains challenging. Here, we present Stereopy, a flexible framework for modeling and dissecting comparative and spatiotemporal patterns in multi-sample spatial transcriptomics with interactive data visualization. To optimize this framework, we devise a universal container, a scope controller, and an integrative transformer tailored for multi-sample multimodal data storage, management, and processing. Stereopy showcases three representative applications: investigating specific cell communities and genes responsible for pathological changes, detecting spatiotemporal gene patterns by considering spatial and temporal features, and inferring three-dimensional niche-based cell-gene interaction network that bridges intercellular communications and intracellular regulations. Stereopy serves as both a comprehensive bioinformatics toolbox and an extensible framework that empowers researchers with enhanced data interpretation abilities and new perspectives for mining multi-sample spatial transcriptomics data.",
      "authors": "Fang Shuangsang; Xu Mengyang; Cao Lei; Liu Xiaobin; Bezulj Marija; Tan Liwei; Yuan Zhiyuan; Li Yao; Xia Tianyi; Guo Longyu; Kovacevic Vladimir; Hui Junhou; Guo Lidong; Liu Chao; Cheng Mengnan; Lin Li'ang; Wen Zhenbin; Josic Bojana; Milicevic Nikola; Qiu Ping; Lu Qin; Li Yumei; Wang Leying; Hu Luni; Zhang Chao; Kang Qiang; Chen Fengzhen; Deng Ziqing; Li Junhua; Li Mei; Li Shengkang; Zhao Yi; Fan Guangyi; Zhang Yong; Chen Ao; Li Yuxiang; Xu Xun",
      "year": "2025",
      "month": "Apr",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "40245359",
      "doi": "10.1146/annurev-biodatasci-103123-095406",
      "title": "Biomedical Natural Language Processing in the Era of Large Language Models.",
      "abstract": "Biomedicine has rapidly digitized over recent decades, from genomic sequencing to electronic medical records. Now, the rise of large language models (LLMs) is driving a generative artificial intelligence (AI) revolution in natural language processing (NLP). Together, these trends create unprecedented possibilities to optimize patient care and accelerate biomedical discovery. Biomedical NLP already boosts productivity by automating labor-intensive tasks such as knowledge extraction and medical abstraction. Emerging approaches promise creativity gain, surpassing standard healthcare practices and uncovering emergent capabilities through Web-scale biomedical knowledge and population-level patient data. However, LLMs remain prone to hallucinations and omissions, and ensuring compliance and safety is vital in order to do no harm. Incorporating diverse modalities such as imaging and genomics is also essential for comprehensive solutions. We review these challenges and opportunities in biomedical NLP, offering historical context, surveying the current state of the art, and exploring frontiers for AI researchers and biomedical practitioners.",
      "authors": "Usuyama Naoto; Wong Cliff; Zhang Sheng; Naumann Tristan; Poon Hoifung",
      "year": "2025",
      "month": "Aug",
      "journal": "Annual review of biomedical data science",
      "source": "pubmed"
    },
    {
      "pmid": "40224145",
      "doi": "10.1016/j.mex.2025.103276",
      "title": "Liver Tumor Prediction using Attention-Guided Convolutional Neural Networks and Genomic Feature Analysis.",
      "abstract": "The task of predicting liver tumors is critical as part of medical image analysis and genomics area since diagnosis and prognosis are important in making correct medical decisions. Silent characteristics of liver tumors and interactions between genomic and imaging features are also the main sources of challenges toward reliable predictions. To overcome these hurdles, this study presents two integrated approaches namely, - Attention-Guided Convolutional Neural Networks (AG-CNNs), and Genomic Feature Analysis Module (GFAM). Spatial and channel attention mechanisms in AG-CNN enable accurate tumor segmentation from CT images while providing detailed morphological profiling. Evaluation with three control databases TCIA, LiTS, and CRLM shows that our model produces more accurate output than relevant literature with an accuracy of 94.5%, a Dice Similarity Coefficient of 91.9%, and an F1-Score of 96.2% for the Dataset 3. More considerably, the proposed methods outperform all the other methods in different datasets in terms of recall, precision, and Specificity by up to 10 percent than all other methods including CELM, CAGS, DM-ML, and so on.•Utilization of Attention-Guided Convolutional Neural Networks (AG-CNN) enhances tumor region focus and segmentation accuracy.•Integration of Genomic Feature Analysis (GFAM) identifies molecular markers for subtype-specific tumor classification.",
      "authors": "Edwin Raja S; Sutha J; Elamparithi P; Jaya Deepthi K; Lalitha S D",
      "year": "2025",
      "month": "Jun",
      "journal": "MethodsX",
      "source": "pubmed"
    },
    {
      "pmid": "40220759",
      "doi": "10.1016/j.crmeth.2025.101026",
      "title": "Inferring gene regulatory networks by hypergraph generative model.",
      "abstract": "We present hypergraph variational autoencoder (HyperG-VAE), a Bayesian deep generative model that leverages hypergraph representation to model single-cell RNA sequencing (scRNA-seq) data. The model features a cell encoder with a structural equation model to account for cellular heterogeneity and construct gene regulatory networks (GRNs) alongside a gene encoder using hypergraph self-attention to identify gene modules. The synergistic optimization of encoders via a decoder improves GRN inference, single-cell clustering, and data visualization, as validated by benchmarks. HyperG-VAE effectively uncovers gene regulation patterns and demonstrates robustness in downstream analyses, as shown in B cell development data from bone marrow. Gene set enrichment analysis of overlapping genes in predicted GRNs confirms the gene encoder's role in refining GRN inference. Offering an efficient solution for scRNA-seq analysis and GRN construction, HyperG-VAE also holds the potential for extending GRN modeling to temporal and multimodal single-cell omics.",
      "authors": "Su Guangxin; Wang Hanchen; Zhang Ying; Wilkins Marc R; Canete Pablo F; Yu Di; Yang Yang; Zhang Wenjie",
      "year": "2025",
      "month": "Apr",
      "journal": "Cell reports methods",
      "source": "pubmed"
    },
    {
      "pmid": "40205054",
      "doi": "10.1038/s41586-025-08878-3",
      "title": "Multimodal cell maps as a foundation for structural and functional genomics.",
      "abstract": "Human cells consist of a complex hierarchy of components, many of which remain unexplored",
      "authors": "Schaffer Leah V; Hu Mengzhou; Qian Gege; Moon Kyung-Mee; Pal Abantika; Soni Neelesh; Latham Andrew P; Pontano Vaites Laura; Tsai Dorothy; Mattson Nicole M; Licon Katherine; Bachelder Robin; Cesnik Anthony; Gaur Ishan; Le Trang; Leineweber William; Palar Aji; Pulido Ernst; Qin Yue; Zhao Xiaoyu; Churas Christopher; Lenkiewicz Joanna; Chen Jing; Ono Keiichiro; Pratt Dexter; Zage Peter; Echeverria Ignacia; Sali Andrej; Harper J Wade; Gygi Steven P; Foster Leonard J; Huttlin Edward L; Lundberg Emma; Ideker Trey",
      "year": "2025",
      "month": "Jun",
      "journal": "Nature",
      "source": "pubmed"
    },
    {
      "pmid": "40203028",
      "doi": "10.1371/journal.pone.0320085",
      "title": "Utilizing a deep learning model based on BERT for identifying enhancers and their strength.",
      "abstract": "An enhancer is a specific DNA sequence typically located within a gene at upstream or downstream position and serves as a pivotal element in the regulation of eukaryotic gene transcription. Therefore, the recognition of enhancers is highly significant for comprehending gene expression regulatory systems. While some useful predictive models have been proposed, there are still deficiencies in these models. To address current limitations, we propose a model, DNABERT2-Enhancer, based on transformer architecture and deep learning, designed for the recognition of enhancers (classified as either enhancer or non-enhancer) and the identification of their activity (strong or weak enhancers). More specifically, DNABERT2-Enhancer is composed of a BERT model for extracting features and a CNN model for enhancers classification. Parameters of the BERT model are initialized by a pre-training DNABERT-2 language model. The enhancer recognition task is then fine-tuned through transfer learning to convert the original sequence into feature vectors. Subsequently, the CNN network is employed to learn the feature vector generated by BERT and produce the prediction results. In comparison with existing predictors utilizing the identical dataset, our approach demonstrates superior performance. This suggests that the model will be a useful instrument for academic research on the enhancer recognition.",
      "authors": "Wang Tong; Gao Mengqi",
      "year": "2025",
      "month": "",
      "journal": "PloS one",
      "source": "pubmed"
    },
    {
      "pmid": "40200293",
      "doi": "10.1186/s13059-025-03530-9",
      "title": "MIDAA: deep archetypal analysis for interpretable multi-omic data integration based on biological principles.",
      "abstract": "High-throughput multi-omic molecular profiling allows the probing of biological systems at unprecedented resolution. However, integrating and interpreting high-dimensional, sparse, and noisy multimodal datasets remains challenging. Deriving new biological insights with current methods is difficult because they are not rooted in biological principles but prioritise tasks like dimensionality reduction. Here, we introduce a framework that combines archetypal analysis, an approach grounded in biological principles, with deep learning. Using archetypes based on evolutionary trade-offs and Pareto optimality, MIDAA finds extreme data points that define the geometry of the latent space, preserving the complexity of biological interactions while retaining an interpretable output. We demonstrate that these extreme points represent cellular programmes reflecting the underlying biology. Moreover, we show that, compared to alternative methods, MIDAA can identify parsimonious, interpretable, and biologically relevant patterns from real and simulated multi-omics.",
      "authors": "Milite Salvatore; Caravagna Giulio; Sottoriva Andrea",
      "year": "2025",
      "month": "Apr",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "40166250",
      "doi": "10.1101/2025.03.18.644040",
      "title": "Genomic Language Model for Predicting Enhancers and Their Allele-Specific Activity in the Human Genome.",
      "abstract": "Predicting and deciphering the regulatory logic of enhancers is a challenging problem, due to the intricate sequence features and lack of consistent genetic or epigenetic signatures that can accurately discriminate enhancers from other genomic regions. Recent machine-learning based methods have spotlighted the importance of extracting nucleotide composition of enhancers but failed to learn the sequence context and perform suboptimally. Motivated by advances in genomic language models, we developed DNABERT-Enhancer, a novel enhancer prediction method, by applying DNABERT pre-trained language model on the human genome. We trained two different models, using large collection of enhancers curated from the ENCODE registry of candidate cis-Regulatory Elements. The best fine-tuned model achieved 88.05% accuracy with Matthews correlation coefficient of 76% on independent set aside data. Further, we present the analysis of the predicted enhancers for all chromosomes of the human genome by comparing with the enhancer regions reported in publicly available databases. Finally, we applied DNABERT-Enhancer along with other DNABERT based regulatory genomic region prediction models to predict candidate SNPs with allele-specific enhancer and transcription factor binding activity. The genome-wide enhancer annotations and candidate loss-of-function genetic variants predicted by DNABERT-Enhancer provide valuable resources for genome interpretation in functional and clinical genomics studies.",
      "authors": "Sathian Rekha; Dutta Pratik; Ay Ferhat; Davuluri Ramana V",
      "year": "2025",
      "month": "Mar",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40163820",
      "doi": "10.1093/bib/bbaf129",
      "title": "Kolmogorov-Arnold networks for genomic tasks.",
      "abstract": "Kolmogorov-Arnold networks (KANs) emerged as a promising alternative for multilayer perceptrons (MLPs) in dense fully connected networks. Multiple attempts have been made to integrate KANs into various deep learning architectures in the domains of computer vision and natural language processing. Integrating KANs into deep learning models for genomic tasks has not been explored. Here, we tested linear KANs (LKANs) and convolutional KANs (CKANs) as a replacement for MLP in baseline deep learning architectures for classification and generation of genomic sequences. We used three genomic benchmark datasets: Genomic Benchmarks, Genome Understanding Evaluation, and Flipon Benchmark. We demonstrated that LKANs outperformed both baseline and CKANs on almost all datasets. CKANs can achieve comparable results but struggle with scaling over large number of parameters. Ablation analysis demonstrated that the number of KAN layers correlates with the model performance. Overall, linear KANs show promising results in improving the performance of deep learning models with relatively small number of parameters. Unleashing KAN potential in different state-of-the-art deep learning architectures currently used in genomics requires further research.",
      "authors": "Cherednichenko Oleksandr; Poptsova Maria",
      "year": "2025",
      "month": "Mar",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40161713",
      "doi": "10.1101/2025.03.14.642461",
      "title": "HIPPIE: A Multimodal Deep Learning Model for Electrophysiological Classification of Neurons.",
      "abstract": "Extracellular electrophysiological recordings present unique computational challenges for neuronal classification due to noise, technical variability, and batch effects across experimental systems. We introduce HIPPIE (High-dimensional Interpretation of Physiological Patterns In Extracellular recordings), a deep learning framework that combines self-supervised pretraining on unlabeled datasets with supervised fine-tuning to classify neurons from extracellular recordings. Using conditional convolutional joint autoencoders, HIPPIE learns robust, technology-adjusted representations of waveforms and spiking dynamics. This model can be applied to electrophysiological classification and clustering across diverse biological cultures and technologies. We validated HIPPIE on both ",
      "authors": "Gonzalez-Ferrer Jesus; Lehrer Julian; Schweiger Hunter E; Geng Jinghui; Hernandez Sebastian; Reyes Francisco; Sevetson Jess L; Salama Sofie R; Teodorescu Mircea; Haussler David; Mostajo-Radji Mohammed A",
      "year": "2025",
      "month": "Mar",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40160857",
      "doi": "10.1016/j.csbj.2025.03.007",
      "title": "Benchmarking DNA large language models on quadruplexes.",
      "abstract": "Large language models (LLMs) in genomics have successfully predicted various functional genomic elements. While their performance is typically evaluated using genomic benchmark datasets, it remains unclear which LLM is best suited for specific downstream tasks, particularly for generating whole-genome annotations. Current LLMs in genomics fall into three main categories: transformer-based models, long convolution-based models, and state-space models (SSMs). In this study, we benchmarked three different types of LLM architectures for generating whole-genome maps of G-quadruplexes (GQ), a type of flipons, or non-B DNA structures, characterized by distinctive patterns and functional roles in diverse regulatory contexts. Although GQ forms from folding guanosine residues into tetrads, the computational task is challenging as the bases involved may be on different strands, separated by a large number of nucleotides, or made from RNA rather than DNA. All LLMs performed comparably well, with DNABERT-2 and HyenaDNA achieving superior results based on F1 and MCC. Analysis of whole-genome annotations revealed that HyenaDNA recovered more quadruplexes in distal enhancers and intronic regions. The models were better suited to detecting large GQ arrays that likely contribute to the nuclear condensates involved in gene transcription and chromosomal scaffolds. HyenaDNA and Caduceus formed a separate grouping in the generated de novo quadruplexes, while transformer-based models clustered together. Overall, our findings suggest that different types of LLMs complement each other. Genomic architectures with varying context lengths can detect distinct functional regulatory elements, underscoring the importance of selecting the appropriate model based on the specific genomic task. The code and data underlying this article are available at https://github.com/powidla/G4s-FMs.",
      "authors": "Cherednichenko Oleksandr; Herbert Alan; Poptsova Maria",
      "year": "2025",
      "month": "",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "40149941",
      "doi": "10.3390/biom15030405",
      "title": "GramSeq-DTA: A Grammar-Based Drug-Target Affinity Prediction Approach Fusing Gene Expression Information.",
      "abstract": "Drug-target affinity (DTA) prediction is a critical aspect of drug discovery. The meaningful representation of drugs and targets is crucial for accurate prediction. Using 1D string-based representations for drugs and targets is a common approach that has demonstrated good results in drug-target affinity prediction. However, these approach lacks information on the relative position of the atoms and bonds. To address this limitation, graph-based representations have been used to some extent. However, solely considering the structural aspect of drugs and targets may be insufficient for accurate DTA prediction. Integrating the functional aspect of these drugs at the genetic level can enhance the prediction capability of the models. To fill this gap, we propose GramSeq-DTA, which integrates chemical perturbation information with the structural information of drugs and targets. We applied a Grammar Variational Autoencoder (GVAE) for drug feature extraction and utilized two different approaches for protein feature extraction as follows: a Convolutional Neural Network (CNN) and a Recurrent Neural Network (RNN). The chemical perturbation data are obtained from the L1000 project, which provides information on the up-regulation and down-regulation of genes caused by selected drugs. This chemical perturbation information is processed, and a compact dataset is prepared, serving as the functional feature set of the drugs. By integrating the drug, gene, and target features in the model, our approach outperforms the current state-of-the-art DTA prediction models when validated on widely used DTA datasets (BindingDB, Davis, and KIBA). This work provides a novel and practical approach to DTA prediction by merging the structural and functional aspects of biological entities, and it encourages further research in multi-modal DTA prediction.",
      "authors": "Debnath Kusal; Rana Pratip; Ghosh Preetam",
      "year": "2025",
      "month": "Mar",
      "journal": "Biomolecules",
      "source": "pubmed"
    },
    {
      "pmid": "40121304",
      "doi": "10.1038/s41746-025-01560-y",
      "title": "Predicting response to neoadjuvant chemotherapy in muscle-invasive bladder cancer via interpretable multimodal deep learning.",
      "abstract": "Building accurate prediction models and identifying predictive biomarkers for treatment response in Muscle-Invasive Bladder Cancer (MIBC) are essential for improving patient survival but remain challenging due to tumor heterogeneity, despite numerous related studies. To address this unmet need, we developed an interpretable Graph-based Multimodal Late Fusion (GMLF) deep learning framework. Integrating histopathology and cell type data from standard H&E images with gene expression profiles derived from RNA sequencing from the SWOG S1314-COXEN clinical trial (ClinicalTrials.gov NCT02177695 2014-06-25), GMLF uncovered new histopathological, cellular, and molecular determinants of response to neoadjuvant chemotherapy. Specifically, we identified key gene signatures that drive the predictive power of our model, including alterations in TP63, CCL5, and DCN. Our discovery can optimize treatment strategies for patients with MIBC, e.g., improving clinical outcomes, avoiding unnecessary treatment, and ultimately, bladder preservation. Additionally, our approach could be used to uncover predictors for other cancers.",
      "authors": "Bai Zilong; Osman Mohamed; Brendel Matthew; Tangen Catherine M; Flaig Thomas W; Thompson Ian M; Plets Melissa; Scott Lucia M; Theodorescu Dan; Gustafson Daniel; Daneshmand Siamak; Meeks Joshua J; Choi Woonyoung; Dinney Colin P N; Elemento Olivier; Lerner Seth P; McConkey David J; Faltas Bishoy M; Wang Fei",
      "year": "2025",
      "month": "Mar",
      "journal": "NPJ digital medicine",
      "source": "pubmed"
    },
    {
      "pmid": "40107149",
      "doi": "10.1016/j.compmedimag.2025.102526",
      "title": "A multimodal framework for assessing the link between pathomics, transcriptomics, and pancreatic cancer mutations.",
      "abstract": "In Pancreatic Ductal Adenocarcinoma (PDAC), predicting genetic mutations directly from histopathological images using Deep Learning can provide valuable insights. The combination of several omics can provide further knowledge on mechanisms underlying tumor biology. This study aimed at developing an explainable multimodal pipeline to predict genetic mutations for the KRAS, TP53, SMAD4, and CDKN2A genes, integrating pathomic features with transcriptomics from two independent datasets, the TCGA-PAAD, assumed as training set, and the CPTAC-PDA, as external validation set. Large and small configurations of CLAM (Clustering-constrained Attention Multiple Instance Learning) models were evaluated with three different feature extractors (ResNet50, UNI, and CONCH). RNA-seq data were pre-processed both conventionally and using three autoencoder architectures. The processed transcript panels were input into machine learning (ML) models for mutation classification. Attention maps and SHAP were employed, highlighting significant features from both data modalities. A fusion layer or a voting mechanism combined the outputs from pathomic and transcriptomic models, obtaining a multimodal prediction. Performance comparisons were assessed by Area Under Receiver Operating Characteristic (AUROC) and Precision-Recall (AUPRC) curves. On the validation set, for KRAS, multimodal ML achieved 0.92 of AUROC and 0.98 of AUPRC. For TP53, the multimodal voting model achieved 0.75 of AUROC and 0.85 of AUPRC. For SMAD4 and CDKN2A, transcriptomic ML models achieved AUROC of 0.71 and 0.65, while multimodal ML showed AUPRC of 0.39 and 0.37, respectively. This approach demonstrated the potential of combining pathomics with transcriptomics, offering an interpretable framework for predicting key genetic mutations in PDAC.",
      "authors": "Berloco Francesco; Zaccaria Gian Maria; Altini Nicola; Colucci Simona; Bevilacqua Vitoantonio",
      "year": "2025",
      "month": "Jul",
      "journal": "Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society",
      "source": "pubmed"
    },
    {
      "pmid": "40091193",
      "doi": "10.1093/bib/bbaf109",
      "title": "Graph neural networks for single-cell omics data: a review of approaches and applications.",
      "abstract": "Rapid advancement of sequencing technologies now allows for the utilization of precise signals at single-cell resolution in various omics studies. However, the massive volume, ultra-high dimensionality, and high sparsity nature of single-cell data have introduced substantial difficulties to traditional computational methods. The intricate non-Euclidean networks of intracellular and intercellular signaling molecules within single-cell datasets, coupled with the complex, multimodal structures arising from multi-omics joint analysis, pose significant challenges to conventional deep learning operations reliant on Euclidean geometries. Graph neural networks (GNNs) have extended deep learning to non-Euclidean data, allowing cells and their features in single-cell datasets to be modeled as nodes within a graph structure. GNNs have been successfully applied across a broad range of tasks in single-cell data analysis. In this survey, we systematically review 107 successful applications of GNNs and their six variants in various single-cell omics tasks. We begin by outlining the fundamental principles of GNNs and their six variants, followed by a systematic review of GNN-based models applied in single-cell epigenomics, transcriptomics, spatial transcriptomics, proteomics, and multi-omics. In each section dedicated to a specific omics type, we have summarized the publicly available single-cell datasets commonly utilized in the articles reviewed in that section, totaling 77 datasets. Finally, we summarize the potential shortcomings of current research and explore directions for future studies. We anticipate that this review will serve as a guiding resource for researchers to deepen the application of GNNs in single-cell omics.",
      "authors": "Li Sijie; Hua Heyang; Chen Shengquan",
      "year": "2025",
      "month": "Mar",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40078374",
      "doi": "10.1093/nsr/nwaf028",
      "title": "Foundation models in bioinformatics.",
      "abstract": "With the adoption of foundation models (FMs), artificial intelligence (AI) has become increasingly significant in bioinformatics and has successfully addressed many historical challenges, such as pre-training frameworks, model evaluation and interpretability. FMs demonstrate notable proficiency in managing large-scale, unlabeled datasets, because experimental procedures are costly and labor intensive. In various downstream tasks, FMs have consistently achieved noteworthy results, demonstrating high levels of accuracy in representing biological entities. A new era in computational biology has been ushered in by the application of FMs, focusing on both general and specific biological issues. In this review, we introduce recent advancements in bioinformatics FMs employed in a variety of downstream tasks, including genomics, transcriptomics, proteomics, drug discovery and single-cell analysis. Our aim is to assist scientists in selecting appropriate FMs in bioinformatics, according to four model types: language FMs, vision FMs, graph FMs and multimodal FMs. In addition to understanding molecular landscapes, AI technology can establish the theoretical and practical foundation for continued innovation in molecular biology.",
      "authors": "Guo Fei; Guan Renchu; Li Yaohang; Liu Qi; Wang Xiaowo; Yang Can; Wang Jianxin",
      "year": "2025",
      "month": "Apr",
      "journal": "National science review",
      "source": "pubmed"
    },
    {
      "pmid": "40063929",
      "doi": "10.2196/59792",
      "title": "Generative AI Models in Time-Varying Biomedical Data: Scoping Review.",
      "abstract": "Trajectory modeling is a long-standing challenge in the application of computational methods to health care. In the age of big data, traditional statistical and machine learning methods do not achieve satisfactory results as they often fail to capture the complex underlying distributions of multimodal health data and long-term dependencies throughout medical histories. Recent advances in generative artificial intelligence (AI) have provided powerful tools to represent complex distributions and patterns with minimal underlying assumptions, with major impact in fields such as finance and environmental sciences, prompting researchers to apply these methods for disease modeling in health care. While AI methods have proven powerful, their application in clinical practice remains limited due to their highly complex nature. The proliferation of AI algorithms also poses a significant challenge for nondevelopers to track and incorporate these advances into clinical research and application. In this paper, we introduce basic concepts in generative AI and discuss current algorithms and how they can be applied to health care for practitioners with little background in computer science. We surveyed peer-reviewed papers on generative AI models with specific applications to time-series health data. Our search included single- and multimodal generative AI models that operated over structured and unstructured data, physiological waveforms, medical imaging, and multi-omics data. We introduce current generative AI methods, review their applications, and discuss their limitations and future directions in each data modality. We followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines and reviewed 155 articles on generative AI applications to time-series health care data across modalities. Furthermore, we offer a systematic framework for clinicians to easily identify suitable AI methods for their data and task at hand. We reviewed and critiqued existing applications of generative AI to time-series health data with the aim of bridging the gap between computational methods and clinical application. We also identified the shortcomings of existing approaches and highlighted recent advances in generative AI that represent promising directions for health care modeling.",
      "authors": "He Rosemary; Sarwal Varuni; Qiu Xinru; Zhuang Yongwen; Zhang Le; Liu Yue; Chiang Jeffrey",
      "year": "2025",
      "month": "Mar",
      "journal": "Journal of medical Internet research",
      "source": "pubmed"
    },
    {
      "pmid": "40062615",
      "doi": "10.1093/bib/bbaf088",
      "title": "A novel integrative multimodal classifier to enhance the diagnosis of Parkinson's disease.",
      "abstract": "Parkinson's disease (PD) is a complex, progressive neurodegenerative disorder with high heterogeneity, making early diagnosis difficult. Early detection and intervention are crucial for slowing PD progression. Understanding PD's diverse pathways and mechanisms is key to advancing knowledge. Recent advances in noninvasive imaging and multi-omics technologies have provided valuable insights into PD's underlying causes and biological processes. However, integrating these diverse data sources remains challenging, especially when deriving meaningful low-level features that can serve as diagnostic indicators. This study developed and validated a novel integrative, multimodal predictive model for detecting PD based on features derived from multimodal data, including hematological information, proteomics, RNA sequencing, metabolomics, and dopamine transporter scan imaging, sourced from the Parkinson's Progression Markers Initiative. Several model architectures were investigated and evaluated, including support vector machine, eXtreme Gradient Boosting, fully connected neural networks with concatenation and joint modeling (FCNN_C and FCNN_JM), and a multimodal encoder-based model with multi-head cross-attention (MMT_CA). The MMT_CA model demonstrated superior predictive performance, achieving a balanced classification accuracy of 97.7%, thus highlighting its ability to capture and leverage cross-modality inter-dependencies to aid predictive analytics. Furthermore, feature importance analysis using SHapley Additive exPlanations not only identified crucial diagnostic biomarkers to inform the predictive models in this study but also holds potential for future research aimed at integrated functional analyses of PD from a multi-omics perspective, ultimately revealing targets required for precision medicine approaches to aid treatment of PD aimed at slowing down its progression.",
      "authors": "Zhou Xiaoyan; Parisi Luca; Huang Wentao; Zhang Yihan; Huang Xiaoqun; Youseffi Mansour; Javid Farideh; Ma Renfei",
      "year": "2025",
      "month": "Mar",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "40061308",
      "doi": "10.1101/2025.02.26.25322769",
      "title": "Consistent Performance of GPT-4o in Rare Disease Diagnosis Across Nine Languages and 4967 Cases.",
      "abstract": "Large language models (LLMs) are increasingly used in the medical field for diverse applications including differential diagnostic support. The estimated training data used to create LLMs such as the Generative Pretrained Transformer (GPT) predominantly consist of English-language texts, but LLMs could be used across the globe to support diagnostics if language barriers could be overcome. Initial pilot studies on the utility of LLMs for differential diagnosis in languages other than English have shown promise, but a large-scale assessment on the relative performance of these models in a variety of European and non-European languages on a comprehensive corpus of challenging rare-disease cases is lacking. We created 4967 clinical vignettes using structured data captured with Human Phenotype Ontology (HPO) terms with the Global Alliance for Genomics and Health (GA4GH) Phenopacket Schema. These clinical vignettes span a total of 378 distinct genetic diseases with 2618 associated phenotypic features. We used translations of the Human Phenotype Ontology together with language-specific templates to generate prompts in English, Chinese, Czech, Dutch, German, Italian, Japanese, Spanish, and Turkish. We applied GPT-4o, version gpt-4o-2024-08-06, to the task of delivering a ranked differential diagnosis using a zero-shot prompt. An ontology-based approach with the Mondo disease ontology was used to map synonyms and to map disease subtypes to clinical diagnoses in order to automate evaluation of LLM responses. For English, GPT-4o placed the correct diagnosis at the first rank 19·8% and within the top-3 ranks 27·0% of the time. In comparison, for the eight non-English languages tested here the correct diagnosis was placed at rank 1 between 16·9% and 20·5%, within top-3 between 25·3% and 27·7% of cases. The differential diagnostic performance of GPT-4o across a comprehensive corpus of rare-disease cases was consistent across the nine languages tested. This suggests that LLMs such as GPT-4o may have utility in non-English clinical settings. NHGRI 5U24HG011449 and 5RM1HG010860. P.N.R. was supported by a Professorship of the Alexander von Humboldt Foundation; P.L. was supported by a National Grant (PMP21/00063 ONTOPRECISC-III, Fondos FEDER).",
      "authors": "Chimirri Leonardo; Caufield J Harry; Bridges Yasemin; Matentzoglu Nicolas; Gargano Michael; Cazalla Mario; Chen Shihan; Danis Daniel; Dingemans Alexander Jm; Gehle Petra; Graefe Adam S L; Gu Weihong; Ladewig Markus S; Lapunzina Pablo; Nevado Julián; Niyonkuru Enock; Ogishima Soichi; Seelow Dominik; Castaño Jair A Tenorio; Turnovec Marek; de Vries Bert Ba; Wang Kai; Wissink Kyran; Yüksel Zafer; Zucca Gabriele; Haendel Melissa A; Mungall Christopher J; Reese Justin; Robinson Peter N",
      "year": "2025",
      "month": "Feb",
      "journal": "medRxiv : the preprint server for health sciences",
      "source": "pubmed"
    },
    {
      "pmid": "40060567",
      "doi": "10.1101/2025.02.27.640661",
      "title": "SensitiveCancerGPT: Leveraging Generative Large Language Model on Structured Omics Data to Optimize Drug Sensitivity Prediction.",
      "abstract": "The fast accumulation of vast pharmacogenomics data of cancer cell lines provide unprecedented opportunities for drug sensitivity prediction (DSP), a crucial prerequisite for the advancement of precision oncology. Recently, Generative Large Language Models (LLM) have demonstrated performance and generalization prowess across diverse tasks in the field of natural language processing (NLP). However, the structured format of the pharmacogenomics data poses challenge for the utility of LLM in DSP. Therefore, the objective of this study is multi-fold: to adapt prompt engineering for structured pharmacogenomics data toward optimizing LLM's DSP performance, to evaluate LLM's generalization in real-world DSP scenarios, and to compare LLM's DSP performance against that of state-of-the-science baselines. We systematically investigated the capability of the Generative Pre-trained Transformer (GPT) as a DSP model on four publicly available benchmark pharmacogenomics datasets, which are stratified by five cancer tissue types of cell lines and encompass both oncology and non-oncology drugs. Essentially, the predictive landscape of GPT is assessed for effectiveness on the DSP task via four learning paradigms: zero-shot learning, few-shot learning, fine-tuning and clustering pretrained embeddings. To facilitate GPT in seamlessly processing the structured pharmacogenomics data, domain-specific novel prompt engineering is employed by implementing three prompt templates (i.e., Instruction, Instruction-Prefix, Cloze) and integrating pharmacogenomics-related features into the prompt. We validated GPT's performance in diverse real-world DSP scenarios: cross-tissue generalization, blind tests, and analyses of drug-pathway associations and top sensitive/resistant cell lines. Furthermore, we conducted a comparative evaluation of GPT against multiple Transformer-based pretrained models and existing DSP baselines. Extensive experiments on the pharmacogenomics datasets across the five tissue cohorts demonstrate that fine-tuning GPT yields the best DSP performance (28% F1 increase, p-value= 0.0003) followed by clustering pretrained GPT embeddings (26% F1 increase, p-value= 0.0005), outperforming GPT in-context learning (i.e., few-shot). However, GPT in the zero-shot setting had a big F1 gap, resulting in the worst performance. Within the scope of prompt engineering, performance enhancement was achieved by directly instructing GPT about the DSP task and resorting to a concise context format (i.e., instruction-prefix), leading to F1 performance gain of 22% (p-value=0.02); while incorporation of drug-cell line prompt context derived from genomics and/or molecular features further boosted F1 score by 2%. Compared to state-of-the-science DSP baselines, GPT significantly asserted superior mean F1 performance (16% gain, p-value<0.05) on the GDSC dataset. In the cross-tissue analysis, GPT showcased comparable generalizability to the within-tissue performances on the GDSC and PRISM datasets, while statistically significant F1 performance improvements on the CCLE (8%, p-value=0.001) and DrugComb (19%, p-value=0.009) datasets. Evaluation on the challenging blind tests suggests GPT's competitiveness on the CCLE and DrugComb datasets compared to random splitting. Furthermore, analyses of the drug-pathway associations and log probabilities provided valuable insights that align with previous DSP findings. The diverse experiment setups and in-depth analysis underscore the importance of generative LLM, such as GPT, as a viable in silico approach to guide precision oncology. https://github.com/bioIKEA/SensitiveCancerGPT.",
      "authors": "Chowdhury Shaika; Rajaganapathy Sivaraman; Sun Lichao; Wang Liewei; Yang Ping; Cerhan James R; Zong Nansu",
      "year": "2025",
      "month": "Mar",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40060426",
      "doi": "10.1101/2025.02.19.638723",
      "title": "MolGene-E: Inverse Molecular Design to Modulate Single Cell Transcriptomics.",
      "abstract": "Designing drugs that can restore a diseased cell to its healthy state is an emerging approach in systems pharmacology to address medical needs that conventional target-based drug discovery paradigms have failed to meet. Single-cell transcriptomics can comprehensively map the differences between diseased and healthy cellular states, making it a valuable technique for systems pharmacology. However, single-cell omics data is noisy, heterogeneous, scarce, and high-dimensional. As a result, no machine learning methods currently exist to use single-cell omics data to design new drug molecules. We have developed a new deep generative framework named MolGene-E to tackle this challenge. MolGene-E combines two novel models: 1) a cross-modal model that can harmonize and denoise chemical-perturbed bulk and single-cell transcriptomics data, and 2) a contrastive learning-based generative model that can generate new molecules based on the transcriptomics data. MolGene-E consistently outperforms baseline methods in generating high-quality, hit-like molecules from gene expression profiles obtained from single-cell datasets as validated by target knock-out experiments using CRISPR. This superior performance is demonstrated across diverse ",
      "authors": "Ohlan Rahul; Murugan Raswanth; Xie Li; Mottaqi Mohammedsadeq; Zhang Shuo; Xie Lei",
      "year": "2025",
      "month": "Feb",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "40047372",
      "doi": "10.1002/advs.202412402",
      "title": "A Knowledge-Guided Graph Learning Approach Bridging Phenotype- and Target-Based Drug Discovery.",
      "abstract": "Discovering therapeutic molecules requires the integration of both phenotype-based drug discovery (PDD) and target-based drug discovery (TDD). However, this integration remains challenging due to the inherent heterogeneity, noise, and bias present in biomedical data. In this study, Knowledge-Guided Drug Relational Predictor (KGDRP), a graph representation learning approach is developed that effectively integrates multimodal biomedical data, including network data containing biological system information, gene expression data, and sequence data that incorporates chemical molecular structures, all within a heterogeneous graph (HG) structure. By incorporating biomedical HG (BioHG) into a heterogeneous graph neural network (HGNN)-based architecture, KGDRP exhibits a remarkable 12% improvement compared to previous methods in real-world screening scenarios. Notably, the biology-informed representation, derived from KGDRP, significantly enhance target prioritization by 26% in drug target discovery. Furthermore, zero-shot evaluation on COVID-19 exhibited a notably higher success rate in identifying diverse potential drugs. The utilization of BioHG facilitates a unique KGDRP-based analysis of cell-target-drug interactions, thereby enabling the elucidation of drug mechanisms. Overall, KGDRP provides a robust infrastructure for the seamlessly integration of multimodal data and biomedical networks, effectively accelerating PDD, guiding therapeutic target discovery, and ultimately expediting therapeutic molecule discovery.",
      "authors": "Ye Qing; Zeng Yundian; Jiang Linlong; Kang Yu; Pan Peichen; Chen Jiming; Deng Yafeng; Zhao Haitao; He Shibo; Hou Tingjun; Hsieh Chang-Yu",
      "year": "2025",
      "month": "Apr",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "40042114",
      "doi": "10.1002/advs.202415808",
      "title": "Multimodal Nanoplasmonic and Fluorescence Imaging for Simultaneous Monitoring of Single-Cell Secretory and Intracellular Dynamics.",
      "abstract": "Current imaging technologies are limited in their capability to simultaneously capture intracellular and extracellular dynamics in a spatially and temporally resolved manner. This study presents a multimodal imaging system that integrates nanoplasmonic sensing with multichannel fluorescence imaging to concomitantly analyze intracellular and extracellular processes in space and time at the single-cell level. Utilizing a highly sensitive gold nanohole array biosensor, the system provides label-free and real-time monitoring of extracellular secretion, while implementing nanoplasmonic-compatible multichannel fluorescence microscopy enables to visualize the interconnected intracellular activities. Combined with deep-learning-assisted image processing, this integrated approach allows multiparametric and simultaneous study of various cellular constituents in hundreds of individual cells with subcellular spatial and minute-level temporal resolution over extended periods of up to 20 h. The system's utility is demonstrated by characterizing a range of secreted biomolecules and fluorescence toolkits across three distinct applications: visualization of secretory behaviors along with subcellular organelles and metabolic processes, concurrent monitoring of protein expression and secretion, and assessment of cell cycle phases alongside their corresponding secretory profiles. By offering comprehensive insights, the multifunctional approach is expected to enhance holistic readouts of biological systems, facilitating new discoveries in both fundamental and translational sciences.",
      "authors": "Ansaryan Saeid; Chiang Yung-Cheng; Liu Yen-Cheng; Reichenbach Patrick; Irving Melita; Altug Hatice",
      "year": "2025",
      "month": "Apr",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "40037709",
      "doi": "10.1093/nar/gkaf138",
      "title": "Deep learning-based cell-specific gene regulatory networks inferred from single-cell multiome data.",
      "abstract": "Gene regulatory networks (GRNs) provide a global representation of how genetic/genomic information is transferred in living systems and are a key component in understanding genome regulation. Single-cell multiome data provide unprecedented opportunities to reconstruct GRNs at fine-grained resolution. However, the inference of GRNs is hindered by insufficient single omic profiles due to the characteristic high loss rate of single-cell sequencing data. In this study, we developed scMultiomeGRN, a deep learning framework to infer transcription factor (TF) regulatory networks via unique integration of single-cell genomic (single-cell RNA sequencing) and epigenomic (single-cell ATAC sequencing) data. We create scMultiomeGRN to elucidate these networks by conceptualizing TF network graph structures. Specifically, we build modality-specific neighbor aggregators and cross-modal attention modules to learn latent representations of TFs from single-cell multi-omics. We demonstrate that scMultiomeGRN outperforms state-of-the-art models on multiple benchmark datasets involved in diseases and health. Via scMultiomeGRN, we identified Alzheimer's disease-relevant regulatory network of SPI1 and RUNX1 for microglia. In summary, scMultiomeGRN offers a deep learning framework to identify cell type-specific gene regulatory network from single-cell multiome data.",
      "authors": "Xu Junlin; Lu Changcheng; Jin Shuting; Meng Yajie; Fu Xiangzheng; Zeng Xiangxiang; Nussinov Ruth; Cheng Feixiong",
      "year": "2025",
      "month": "Feb",
      "journal": "Nucleic acids research",
      "source": "pubmed"
    },
    {
      "pmid": "40037540",
      "doi": "10.1093/neuonc/noaf058",
      "title": "Applications of artificial intelligence and advanced imaging in pediatric diffuse midline glioma.",
      "abstract": "Diffuse midline glioma (DMG) is a rare, aggressive, and fatal tumor that largely occurs in the pediatric population. To improve outcomes, it is important to characterize DMGs, which can be performed via magnetic resonance imaging (MRI) assessment. Recently, artificial intelligence (AI) and advanced imaging have demonstrated their potential to improve the evaluation of various brain tumors, gleaning more information from imaging data than is possible without these methods. This narrative review compiles the existing literature on the intersection of MRI-based AI use and DMG tumors. The applications of AI in DMG revolve around classification and diagnosis, segmentation, radiogenomics, and prognosis/survival prediction. Currently published articles have utilized a wide spectrum of AI algorithms, from traditional machine learning and radiomics to neural networks. Challenges include the lack of cohorts of DMG patients with publicly available, multi-institutional, multimodal imaging and genomics datasets as well as the overall rarity of the disease. As an adjunct to AI, advanced MRI techniques, including diffusion-weighted imaging, perfusion-weighted imaging, and Magnetic Resonance Spectroscopy (MRS), as well as positron emission tomography (PET), provide additional insights into DMGs. Establishing AI models in conjunction with advanced imaging modalities has the potential to push clinical practice toward precision medicine.",
      "authors": "Haddadi Avval Atlas; Banerjee Suneel; Zielke John; Kann Benjamin H; Mueller Sabine; Rauschecker Andreas M",
      "year": "2025",
      "month": "Jul",
      "journal": "Neuro-oncology",
      "source": "pubmed"
    },
    {
      "pmid": "39995150",
      "doi": "10.1002/2211-5463.70003",
      "title": "Beyond digital twins: the role of foundation models in enhancing the interpretability of multiomics modalities in precision medicine.",
      "abstract": "Medical digital twins (MDTs) are virtual representations of patients that simulate the biological, physiological, and clinical processes of individuals to enable personalized medicine. With the increasing complexity of omics data, particularly multiomics, there is a growing need for advanced computational frameworks to interpret these data effectively. Foundation models (FMs), large-scale machine learning models pretrained on diverse data types, have recently emerged as powerful tools for improving data interpretability and decision-making in precision medicine. This review discusses the integration of FMs into MDT systems, particularly their role in enhancing the interpretability of multiomics data. We examine current challenges, recent advancements, and future opportunities in leveraging FMs for multiomics analysis in MDTs, with a focus on their application in precision medicine.",
      "authors": "Alsaedi Sakhaa; Gao Xin; Gojobori Takashi",
      "year": "2025",
      "month": "Aug",
      "journal": "FEBS open bio",
      "source": "pubmed"
    },
    {
      "pmid": "39990095",
      "doi": "10.34133/bdr.0059",
      "title": "Multiomics Research: Principles and Challenges in Integrated Analysis.",
      "abstract": "Multiomics research is a transformative approach in the biological sciences that integrates data from genomics, transcriptomics, proteomics, metabolomics, and other omics technologies to provide a comprehensive understanding of biological systems. This review elucidates the fundamental principles of multiomics, emphasizing the necessity of data integration to uncover the complex interactions and regulatory mechanisms underlying various biological processes. We explore the latest advances in computational methodologies, including deep learning, graph neural networks (GNNs), and generative adversarial networks (GANs), which facilitate the effective synthesis and interpretation of multiomics data. Additionally, this review addresses the critical challenges in this field, such as data heterogeneity, scalability, and the need for robust, interpretable models. We highlight the potential of large language models to enhance multiomics analysis through automated feature extraction, natural language generation, and knowledge integration. Despite the important promise of multiomics, the review acknowledges the substantial computational resources required and the complexity of model tuning, underscoring the need for ongoing innovation and collaboration in the field. This comprehensive analysis aims to guide researchers in navigating the principles and challenges of multiomics research to foster advances in integrative biological analysis.",
      "authors": "Luo Yunqing; Zhao Chengjun; Chen Fei",
      "year": "2024",
      "month": "",
      "journal": "Biodesign research",
      "source": "pubmed"
    },
    {
      "pmid": "39987496",
      "doi": "10.1093/bib/bbaf066",
      "title": "ESM-BBB-Pred: a fine-tuned ESM 2.0 and deep neural networks for the identification of blood-brain barrier peptides.",
      "abstract": "Blood-brain barrier peptides (BBBP) could significantly improve the delivery of drugs to the brain, paving the way for new treatments for central nervous system (CNS) disorders. The primary challenge in treating CNS disorders lies in the difficulty pharmaceutical agent's face in crossing the BBB. Almost 98% of small molecule drugs and nearly all large molecule drugs fail to penetrate the BBB effectively. Thus, identifying these peptides is vital for advancements in healthcare. This study introduces an enhanced intelligent computational model called BBB-PEP- Evolutionary Scale Modeling (ESM), designed to identify BBBP. The relative positions, reverse position and statistical moment-based features have been utilized on the existing benchmark dataset. For classification purpose, six deep classifiers such as fully connected networks, convolutional neural network, simple recurrent neural networks, long short-term memory (LSTM), bidirectional LSTM, and gated recurrent unit have been utilized. In addition to harnessing the effectiveness of the pre-trained model, a protein language model ESM 2.0 has been fine-tuned on a benchmark dataset for BBBP classification. Three tests such as self-consistency, independent set testing, and five-fold cross-validation have been utilized for evaluation purposes with evaluation metrics includes accuracy, specificity, sensitivity, and Matthews correlation coefficient. The fine-tuned model ESM 2.0 has shown superior results as compared to employed classifiers and surpasses the existing benchmark studies. This system will support future research and the scientific community in the computational identification of BBBP.",
      "authors": "Naseem Ansar; Alturise Fahad; Alkhalifah Tamim; Khan Yaser Daanial",
      "year": "2024",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39968174",
      "doi": "10.1016/j.csbj.2025.01.011",
      "title": "Identifying somatic driver mutations in cancer with a language model of the human genome.",
      "abstract": "Somatic driver mutations play important roles in cancer and must be precisely identified to advance our understanding of tumorigenesis and its promotion and progression. However, identifying somatic driver mutations remains challenging in Homo sapiens genomics due to the random nature of mutations and the high cost of qualitative experiments. Building on the powerful sequence interpretation capabilities of language models, we propose a self-attention-based contextualized pretrained language model for somatic driver mutation identification. We pretrained the model with the Homo sapiens reference genome to equip it with the ability to understand genome sequences and then fine-tuned it for oncogene and tumor suppressor gene prediction tasks, enabling it to extract features related to driver genes from the original genome sequence. The fine-tuned model was used to obtain the mutations' carcinogenic effect characteristics to further identify whether the mutation is a driver or a passenger. Compared with other computational algorithms, our method achieved excellent somatic driver mutation identification performance on the test set, with an absolute improvement of 4.31% in AUROC over the best comparison method. The strong performance of our method indicates that it can provide new insights into the discovery of cancer drivers.",
      "authors": "Zeng Guangjian; Zhao Chengzhi; Li Guanpeng; Huang Zhengyang; Zhuang Jinhu; Liang Xiaohua; Yu Xiaxia; Fang Shenying",
      "year": "2025",
      "month": "",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "39922065",
      "doi": "10.1016/j.breast.2025.103892",
      "title": "Multimodal data integration in early-stage breast cancer.",
      "abstract": "The use of biomarkers in breast cancer has significantly improved patient outcomes through targeted therapies, such as hormone therapy anti-Her2 therapy and CDK4/6 or PARP inhibitors. However, existing knowledge does not fully encompass the diverse nature of breast cancer, particularly in triple-negative tumors. The integration of multi-omics and multimodal data has the potential to provide new insights into biological processes, to improve breast cancer patient stratification, enhance prognosis and response prediction, and identify new biomarkers. This review presents a comprehensive overview of the state-of-the-art multimodal (including molecular and image) data integration algorithms developed and with applicability to breast cancer stratification, prognosis, or biomarker identification. We examined the primary challenges and opportunities of these multimodal data integration algorithms, including their advantages, limitations, and critical considerations for future research. We aimed to describe models that are not only academically and preclinically relevant, but also applicable to clinical settings.",
      "authors": "Llinas-Bertran Arnau; Butjosa-Espín Maria; Barberi Vittoria; Seoane Jose A",
      "year": "2025",
      "month": "Apr",
      "journal": "Breast (Edinburgh, Scotland)",
      "source": "pubmed"
    },
    {
      "pmid": "39918957",
      "doi": "10.1016/j.celrep.2025.115270",
      "title": "scCamAge: A context-aware prediction engine for cellular age, aging-associated bioactivities, and morphometrics.",
      "abstract": "Current deep-learning-based image-analysis solutions exhibit limitations in holistically capturing spatiotemporal cellular changes, particularly during aging. We present scCamAge, an advanced context-aware multimodal prediction engine that co-leverages image-based cellular spatiotemporal features at single-cell resolution alongside cellular morphometrics and aging-associated bioactivities such as genomic instability, mitochondrial dysfunction, vacuolar dynamics, reactive oxygen species levels, and epigenetic and proteasomal dysfunctions. scCamAge employed heterogeneous datasets comprising ∼1 million single yeast cells and was validated using pro-longevity drugs, genetic mutants, and stress-induced models. scCamAge also predicted a pro-longevity response in yeast cells under iterative thermal stress, confirmed using integrative omics analyses. Interestingly, scCamAge, trained solely on yeast images, without additional learning, surpasses generic models in predicting chemical and replication-induced senescence in human fibroblasts, indicating evolutionary conservation of aging-related morphometrics. Finally, we enhanced the generalizability of scCamAge by retraining it on human fibroblast senescence datasets, which improved its ability to predict senescent cells.",
      "authors": "Gautam Vishakha; Duari Subhadeep; Solanki Saveena; Gupta Mudit; Mittal Aayushi; Arora Sakshi; Aggarwal Anmol; Sharma Anmol Kumar; Tyagi Sarthak; Pankajbhai Rathod Kunal; Sharma Arushi; Chauhan Sonam; Satija Shiva; Kumar Suvendu; Mohanty Sanjay Kumar; Tayal Juhi; Dixit Nilesh Kumar; Sengupta Debarka; Mehta Anurag; Ahuja Gaurav",
      "year": "2025",
      "month": "Feb",
      "journal": "Cell reports",
      "source": "pubmed"
    },
    {
      "pmid": "39913621",
      "doi": "10.1093/bib/bbaf003",
      "title": "A multi-modal fusion model with enhanced feature representation for chronic kidney disease progression prediction.",
      "abstract": "Artificial intelligence (AI)-based multi-modal fusion algorithms are pivotal in emulating clinical practice by integrating data from diverse sources. However, most of the existing multi-modal models focus on designing new modal fusion methods, ignoring critical role of feature representation. Enhancing feature representativeness can address the noise caused by modal heterogeneity at the source, enabling high performance even with small datasets and simple architectures. Here, we introduce DeepOmix-FLEX (Fusion with Learning Enhanced feature representation for X-modal or FLEX in short), a multi-modal fusion model that integrates clinical data, proteomic data, metabolomic data, and pathology images across different scales and modalities, with a focus on advanced feature learning and representation. FLEX contains a Feature Encoding Trainer structure that can train feature encoding, thus achieving fusion of inter-feature and inter-modal. FLEX achieves a mean AUC of 0.887 for prediction of chronic kidney disease progression on an internal dataset, exceeding the mean AUC of 0.727 using conventional clinical variables. Following external validation and interpretability analyses, our model demonstrated favorable generalizability and validity, as well as the ability to exploit markers. In summary, FLEX highlights the potential of AI algorithms to integrate multi-modal data and optimize the allocation of healthcare resources through accurate prediction.",
      "authors": "Qiao Yixuan; Zhou Hong; Liu Yang; Chen Ruixuan; Zhang Xiaodong; Nie Sheng; Hou Fan Fan; Zhao Yi; Xu Xin; Zhao Lianhe",
      "year": "2024",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39910777",
      "doi": "10.1093/bib/bbaf045",
      "title": "Steering veridical large language model analyses by correcting and enriching generated database queries: first steps toward ChatGPT bioinformatics.",
      "abstract": "Large language models (LLMs) leverage factual knowledge from pretraining. Yet this knowledge remains incomplete and sometimes challenging to retrieve-especially in scientific domains not extensively covered in pretraining datasets and where information is still evolving. Here, we focus on genomics and bioinformatics. We confirm and expand upon issues with plain ChatGPT functioning as a bioinformatics assistant. Poor data retrieval and hallucination lead ChatGPT to err, as do incorrect sequence manipulations. To address this, we propose a system basing LLM outputs on up-to-date, authoritative facts and facilitating LLM-guided data analysis. Specifically, we introduce NagGPT, a middleware tool to insert between LLMs and databases, designed to bridge gaps in LLM knowledge and usage of database application programming interfaces. NagGPT proxies LLM-generated database queries, with special handling of incorrect queries. It acts as a gatekeeper between query responses and the LLM prompt, redirecting large responses to files but providing a synthesized snippet and injecting comments to steer the LLM. A companion OpenAI custom GPT, Genomics Fetcher-Analyzer, connects ChatGPT with NagGPT. It steers ChatGPT to generate and run Python code, performing bioinformatics tasks on data dynamically retrieved from a dozen common genomics databases (e.g. NCBI, Ensembl, UniProt, WormBase, and FlyBase). We implement partial mitigations for encountered challenges: detrimental interactions between code generation style and data analysis, confusion between database identifiers, and hallucination of both data and actions taken. Our results identify avenues to augment ChatGPT as a bioinformatics assistant and, more broadly, to improve factual accuracy and instruction following of unmodified LLMs.",
      "authors": "Cinquin Olivier",
      "year": "2024",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39894532",
      "doi": "10.1253/circj.CJ-24-0865",
      "title": "Digitalomics: Towards Artificial Intelligence / Machine Learning-Based Precision Cardiovascular Medicine.",
      "abstract": "Recent advances in traditional \"-omics\" technologies have provided deeper insights into cardiovascular diseases through comprehensive molecular profiling. Accordingly, digitalomics has emerged as a novel transdisciplinary concept that integrates multimodal information with digitized physiological data, medical imaging, environmental data, electronic health records, environmental records, and biometric data from wearables. This digitalomics-driven augmented multiomics approach can provide more precise personalized health risk assessments and optimization when combined with conventional multiomics approaches. Artificial intelligence and machine learning (AI/ML) technologies, alongside statistical methods, serve as key comprehensive analytical tools in realizing this comprehensive framework. This review focuses on two promising AI/ML applications in cardiovascular medicine: digital phonocardiography (PCG) and AI text generators. Digital PCG uses AI/ML models to objectively analyze heart sounds and predict clinical parameters, potentially surpassing traditional auscultation capabilities. In addition, large language models, such as generative pretrained transformer, have demonstrated remarkable performance in assessing medical knowledge, achieving accuracy rates exceeding 80% in medical licensing examinations, although there are issues regarding knowledge accuracy and safety. Current challenges to the implementation of these technologies include maintaining up-to-date medical knowledge and ensuring consistent accuracy of outputs, but ongoing developments in fine-tuning and retrieval-augmented generation show promise in addressing these challenges. Integration of AI/ML technologies in clinical practice, guided by appropriate validation and implementation strategies, may notably advance precision cardiovascular medicine through the digitalomics framework.",
      "authors": "Nomura Akihiro; Takeji Yasuaki; Shimojima Masaya; Takamura Masayuki",
      "year": "2025",
      "month": "Jan",
      "journal": "Circulation journal : official journal of the Japanese Circulation Society",
      "source": "pubmed"
    },
    {
      "pmid": "39888214",
      "doi": "10.1002/advs.202413571",
      "title": "Epigenetic Impacts of Non-Coding Mutations Deciphered Through Pre-Trained DNA Language Model at Single-Cell Resolution.",
      "abstract": "DNA methylation plays a critical role in gene regulation, affecting cellular differentiation and disease progression, particularly in non-coding regions. However, predicting the epigenetic consequences of non-coding mutations at single-cell resolution remains a challenge. Existing tools have limited prediction capacity and struggle to capture dynamic, cell-type-specific regulatory changes that are crucial for understanding disease mechanisms. Here, Methven, a deep learning framework designed is presented to predict the effects of non-coding mutations on DNA methylation at single-cell resolution. Methven integrates DNA sequence with single-cell ATAC-seq data and models SNP-CpG interactions over 100 kbp genomic distances. By using a divide-and-conquer approach, Methven accurately predicts both short- and long-range regulatory interactions and leverages the pre-trained DNA language model for enhanced precision in classification and regression tasks. Methven outperforms existing methods and demonstrates robust generalizability to monocyte datasets. Importantly, it identifies CpG sites associated with rheumatoid arthritis, revealing key pathways involved in immune regulation and disease progression. Methven's ability to detect progressive epigenetic changes provides crucial insights into gene regulation in complex diseases. These findings demonstrate Methven's potential as a powerful tool for basic research and clinical applications, advancing this understanding of non-coding mutations and their role in disease, while offering new opportunities for personalized medicine.",
      "authors": "Liu Zhe; Gu An; Bao Yihang; Lin Guan Ning",
      "year": "2025",
      "month": "Mar",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "39884279",
      "doi": "10.1016/j.xgen.2025.100762",
      "title": "A multi-modal transformer for cell type-agnostic regulatory predictions.",
      "abstract": "Sequence-based deep learning models have emerged as powerful tools for deciphering the cis-regulatory grammar of the human genome but cannot generalize to unobserved cellular contexts. Here, we present EpiBERT, a multi-modal transformer that learns generalizable representations of genomic sequence and cell type-specific chromatin accessibility through a masked accessibility-based pre-training objective. Following pre-training, EpiBERT can be fine-tuned for gene expression prediction, achieving accuracy comparable to the sequence-only Enformer model, while also being able to generalize to unobserved cell states. The learned representations are interpretable and useful for predicting chromatin accessibility quantitative trait loci (caQTLs), regulatory motifs, and enhancer-gene links. Our work represents a step toward improving the generalization of sequence-based deep neural networks in regulatory genomics.",
      "authors": "Javed Nauman; Weingarten Thomas; Sehanobish Arijit; Roberts Adam; Dubey Avinava; Choromanski Krzysztof; Bernstein Bradley E",
      "year": "2025",
      "month": "Feb",
      "journal": "Cell genomics",
      "source": "pubmed"
    },
    {
      "pmid": "39870633",
      "doi": "10.1038/s41467-025-56276-0",
      "title": "STAIG: Spatial transcriptomics analysis via image-aided graph contrastive learning for domain exploration and alignment-free integration.",
      "abstract": "Spatial transcriptomics is an essential application for investigating cellular structures and interactions and requires multimodal information to precisely study spatial domains. Here, we propose STAIG, a deep-learning model that integrates gene expression, spatial coordinates, and histological images using graph-contrastive learning coupled with high-performance feature extraction. STAIG can integrate tissue slices without prealignment and remove batch effects. Moreover, it is designed to accept data acquired from various platforms, with or without histological images. By performing extensive benchmarks, we demonstrate the capability of STAIG to recognize spatial regions with high precision and uncover new insights into tumor microenvironments, highlighting its promising potential in deciphering spatial biological intricates.",
      "authors": "Yang Yitao; Cui Yang; Zeng Xin; Zhang Yubo; Loza Martin; Park Sung-Joon; Nakai Kenta",
      "year": "2025",
      "month": "Jan",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "39863682",
      "doi": "10.1038/s41698-025-00808-w",
      "title": "Histopathology and proteomics are synergistic for high-grade serous ovarian cancer platinum response prediction.",
      "abstract": "Patients with High-Grade Serous Ovarian Cancer (HGSOC) exhibit varied responses to treatment, with 20-30% showing de novo resistance to platinum-based chemotherapy. While hematoxylin-eosin (H&E)-stained pathological slides are used for routine diagnosis of cancer type, they may also contain diagnostically useful information about treatment response. Our study demonstrates that combining H&E-stained whole slide images (WSIs) with proteomic signatures using a multimodal deep learning framework significantly improves the prediction of platinum response in both discovery and validation cohorts. This method outperforms the Homologous Recombination Deficiency (HRD) score in predicting platinum response and overall patient survival. Our study suggests that histology and proteomics contain complementary information about biological processes determining response to first line platinum treatment in HGSOC. This integrative approach has the potential to improve personalized treatment and provide insights into the therapeutic vulnerabilities of HGSOC.",
      "authors": "Kilim Oz; Olar Alex; Biricz András; Madaras Lilla; Pollner Péter; Szállási Zoltán; Sztupinszki Zsofia; Csabai István",
      "year": "2025",
      "month": "Jan",
      "journal": "NPJ precision oncology",
      "source": "pubmed"
    },
    {
      "pmid": "39851073",
      "doi": "10.1093/bib/bbaf010",
      "title": "scMMAE: masked cross-attention network for single-cell multimodal omics fusion to enhance unimodal omics.",
      "abstract": "Multimodal omics provide deeper insight into the biological processes and cellular functions, especially transcriptomics and proteomics. Computational methods have been proposed for the integration of single-cell multimodal omics of transcriptomics and proteomics. However, existing methods primarily concentrate on the alignment of different omics, overlooking the unique information inherent in each omics type. Moreover, as the majority of single-cell cohorts only encompass one omics, it becomes critical to transfer the knowledge learnt from multimodal omics to enhance unimodal omics analysis. Therefore, we proposed a novel framework that leverages masked autoencoder with cross-attention mechanism, called scMMAE (single-cell multimodal masked autoencoder), to fuse multimodal omics and enhance unimodal omics analysis. scMMAE simultaneously captures both the shared features and the distinctive information of two single-cell omics modalities and transfers the knowledge to enhance single-cell transcriptome data. Comparative evaluations against benchmarking methods across various cohorts revealed a notable improvement, with an increase of up to 21% in the adjusted Rand index and up to 12% in normalized mutual information in the context of multimodal fusion. In the realm of unimodal omics, scMMAE demonstrated an overall enhancement of approximately 20% in the adjusted Rand index and nearly 10% in normalized mutual information. Other nine metrics, including the Fowlkes-Mallows index and silhouette coefficient, further underscored the high performance of scMMAE. Significantly, scMMAE exhibits an elevated level of proficiency in distinguishing between different cell types, particularly on CD4 and CD8 T cells. Availability and implementation: scMMAE source code at https://github.com/DM0815/scMMAE/.",
      "authors": "Meng Dian; Feng Yu; Yuan Kaishen; Yu Zitong; Cao Qin; Cheng Lixin; Zheng Xubin",
      "year": "2024",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39846423",
      "doi": "10.1049/syb2.70000",
      "title": "SpaGraphCCI: Spatial cell-cell communication inference through GAT-based co-convolutional feature integration.",
      "abstract": "Spatially resolved transcriptomics technologies potentially provide the extra spatial position information and tissue image to better infer spatial cell-cell interactions (CCIs) in processes such as tissue homeostasis, development, and disease progression. However, methods for effectively integrating spatial multimodal data to infer CCIs are still lacking. Here, the authors propose a deep learning method for integrating features through co-convolution, called SpaGraphCCI, to effectively integrate data from different modalities of SRT by projecting gene expression and image feature into a low-dimensional space. SpaGraphCCI can achieve significant performance on datasets from multiple platforms including single-cell resolution datasets (AUC reaches 0.860-0.907) and spot resolution datasets (AUC ranges from 0.880 to 0.965). SpaGraphCCI shows better performance by comparing with the existing deep learning-based spatial cell communication inference methods. SpaGraphCCI is robust to high noise and can effectively improve the inference of CCIs. We test on a human breast cancer dataset and show that SpaGraphCCI can not only identify proximal cell communication but also infer new distal interactions. In summary, SpaGraphCCI provides a practical tool that enables researchers to decipher spatially resolved cell-cell communication based on spatial transcriptome data.",
      "authors": "Zhang Han; Cui Ting; Xu Xiaoqiang; Sui Guangyu; Fang Qiaoli; Yang Guanghao; Gong Yizhen; Yang Sanqiao; Lv Yufei; Shang Desi",
      "year": "2025",
      "month": "",
      "journal": "IET systems biology",
      "source": "pubmed"
    },
    {
      "pmid": "39841593",
      "doi": "10.1093/bib/bbaf021",
      "title": "Spatially aligned graph transfer learning for characterizing spatial regulatory heterogeneity.",
      "abstract": "Spatially resolved transcriptomics (SRT) technologies facilitate the exploration of cell fates or states within tissue microenvironments. Despite these advances, the field has not adequately addressed the regulatory heterogeneity influenced by microenvironmental factors. Here, we propose a novel Spatially Aligned Graph Transfer Learning (SpaGTL), pretrained on a large-scale multi-modal SRT data of about 100 million cells/spots to enable inference of context-specific spatial gene regulatory networks across multiple scales in data-limited settings. As a novel cross-dimensional transfer learning architecture, SpaGTL aligns spatial graph representations across gene-level graph transformers and cell/spot-level manifold-dominated variational autoencoder. This alignment facilitates the exploration of microenvironmental variations in cell types and functional domains from a molecular regulatory perspective, all within a self-supervised framework. We verified SpaGTL's precision, robustness, and speed over existing state-of-the-art algorithms and show SpaGTL's potential that facilitates the discovery of novel regulatory programs that exhibit strong associations with tissue functional regions and cell types. Importantly, SpaGTL could be extended to process multi-slice SRT data and map molecular regulatory landscape associated with three-dimensional spatial-temporal changes during development.",
      "authors": "Huang Wendong; Hu Yaofeng; Wang Lequn; Wu Guangsheng; Zhang Chuanchao; Shi Qianqian",
      "year": "2024",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39838298",
      "doi": "10.1186/s12859-024-06015-x",
      "title": "A graph neural network approach for hierarchical mapping of breast cancer protein communities.",
      "abstract": "Comprehensively mapping the hierarchical structure of breast cancer protein communities and identifying potential biomarkers from them is a promising way for breast cancer research. Existing approaches are subjective and fail to take information from protein sequences into consideration. Deep learning can automatically learn features from protein sequences and protein-protein interactions for hierarchical clustering. Using a large amount of publicly available proteomics data, we created a hierarchical tree for breast cancer protein communities using a novel hierarchical graph neural network, with the supervision of gene ontology terms and assistance of a pre-trained deep contextual language model. Then, a group-lasso algorithm was applied to identify protein communities that are under both mutation burden and survival burden, undergo significant alterations when targeted by specific drug molecules, and show cancer-dependent perturbations. The resulting hierarchical map of protein communities shows how gene-level mutations and survival information converge on protein communities at different scales. Internal validity of the model was established through the convergence on BRCA2 as a breast cancer hotspot. Further overlaps with breast cancer cell dependencies revealed SUPT6H and RAD21, along with their respective protein systems, HOST:37 and HOST:861, as potential biomarkers. Using gene-level perturbation data of the HOST:37 and HOST:861 gene sets, three FDA-approved drugs with high therapeutic value were selected as potential treatments to be further evaluated. These drugs include mercaptopurine, pioglitazone, and colchicine. The proposed graph neural network approach to analyzing breast cancer protein communities in a hierarchical structure provides a novel perspective on breast cancer prognosis and treatment. By targeting entire gene sets, we were able to evaluate the prognostic and therapeutic value of genes (or gene sets) at different levels, from gene-level to system-level biology. Cancer-specific gene dependencies provide additional context for pinpointing cancer-related systems and drug-induced alterations can highlight potential therapeutic targets. These identified protein communities, in conjunction with other protein communities under strong mutation and survival burdens, can potentially be used as clinical biomarkers for breast cancer.",
      "authors": "Zhang Xiao; Liu Qian",
      "year": "2025",
      "month": "Jan",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39817513",
      "doi": "10.1093/nar/gkae1310",
      "title": "GENA-LM: a family of open-source foundational DNA language models for long sequences.",
      "abstract": "Recent advancements in genomics, propelled by artificial intelligence, have unlocked unprecedented capabilities in interpreting genomic sequences, mitigating the need for exhaustive experimental analysis of complex, intertwined molecular processes inherent in DNA function. A significant challenge, however, resides in accurately decoding genomic sequences, which inherently involves comprehending rich contextual information dispersed across thousands of nucleotides. To address this need, we introduce GENA language model (GENA-LM), a suite of transformer-based foundational DNA language models capable of handling input lengths up to 36 000 base pairs. Notably, integrating the newly developed recurrent memory mechanism allows these models to process even larger DNA segments. We provide pre-trained versions of GENA-LM, including multispecies and taxon-specific models, demonstrating their capability for fine-tuning and addressing a spectrum of complex biological tasks with modest computational demands. While language models have already achieved significant breakthroughs in protein biology, GENA-LM showcases a similarly promising potential for reshaping the landscape of genomics and multi-omics data analysis. All models are publicly available on GitHub (https://github.com/AIRI-Institute/GENA_LM) and on HuggingFace (https://huggingface.co/AIRI-Institute). In addition, we provide a web service (https://dnalm.airi.net/) allowing user-friendly DNA annotation with GENA-LM models.",
      "authors": "Fishman Veniamin; Kuratov Yuri; Shmelev Aleksei; Petrov Maxim; Penzar Dmitry; Shepelin Denis; Chekanov Nikolay; Kardymon Olga; Burtsev Mikhail",
      "year": "2025",
      "month": "Jan",
      "journal": "Nucleic acids research",
      "source": "pubmed"
    },
    {
      "pmid": "39816158",
      "doi": "10.1364/BOE.541570",
      "title": "MulitDeepsurv: survival analysis of gastric cancer based on deep learning multimodal fusion models.",
      "abstract": "Gastric cancer is a leading cause of cancer-related deaths globally. As mortality rates continue to rise, predicting cancer survival using multimodal data-including histopathological images, genomic data, and clinical information-has become increasingly crucial. However, extracting effective predictive features from this complex data has posed challenges for survival analysis due to the high dimensionality and heterogeneity of histopathology images and genomic data. Furthermore, existing methods often lack sufficient interaction between intra- and inter-modal features, significantly impacting model performance. To address these challenges, we developed a deep learning-based multimodal feature fusion model, MultiDeepsurv, designed to predict the survival of gastric cancer patients by integrating histopathological images, clinical data, and gene expression data. Our approach includes a two-branch hybrid network, GLFUnet, which leverages the attention mechanism for enhanced pathology image representation learning. Additionally, we employ a graph convolutional neural network (GCN) to extract features from gene expression data and clinical information. To capture the correlations between different modalities, we utilize the SFusion fusion strategy that employs a self-attention mechanism to learn potential correlations across modalities. Finally, these deeply processed features are fed into Cox regression models for an end-to-end survival analysis. Comprehensive experiments and analyses conducted on a gastric cancer cohort from The Cancer Genome Atlas (TCGA) demonstrate that our proposed MultiDeepsurv model outperforms other methods in terms of prognostic accuracy, with a C-index of 0.806 and an AUC of 0.842.",
      "authors": "Mao Songren; Liu Jie",
      "year": "2025",
      "month": "Jan",
      "journal": "Biomedical optics express",
      "source": "pubmed"
    },
    {
      "pmid": "39800876",
      "doi": "10.1093/bib/bbae719",
      "title": "Deep learning in integrating spatial transcriptomics with other modalities.",
      "abstract": "Spatial transcriptomics technologies have been extensively applied in biological research, enabling the study of transcriptome while preserving the spatial context of tissues. Paired with spatial transcriptomics data, platforms often provide histology and (or) chromatin images, which capture cellular morphology and chromatin organization. Additionally, single-cell RNA sequencing (scRNA-seq) data from matching tissues often accompany spatial data, offering a transcriptome-wide gene expression profile of individual cells. Integrating such additional data from other modalities can effectively enhance spatial transcriptomics data, and, conversely, spatial transcriptomics data can supplement scRNA-seq with spatial information. Moreover, the rapid development of spatial multi-omics technology has spurred the demand for the integration of spatial multi-omics data to present a more detailed molecular landscape within tissues. Numerous deep learning (DL) methods have been developed for integrating spatial transcriptomics with other modalities. However, a comprehensive review of DL approaches for integrating spatial transcriptomics data with other modalities remains absent. In this study, we systematically review the applications of DL in integrating spatial transcriptomics data with other modalities. We first delineate the DL techniques applied in this integration and the key tasks involved. Next, we detail these methods and categorize them based on integrated modality and key task. Furthermore, we summarize the integration strategies of these integration methods. Finally, we discuss the challenges and future directions in integrating spatial transcriptomics with other modalities, aiming to facilitate the development of robust computational methods that more comprehensively exploit multimodal information.",
      "authors": "Luo Jiajian; Fu Jiye; Lu Zuhong; Tu Jing",
      "year": "2024",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39792954",
      "doi": "10.1371/journal.pcbi.1012755",
      "title": "The role of chromatin state in intron retention: A case study in leveraging large scale deep learning models.",
      "abstract": "Complex deep learning models trained on very large datasets have become key enabling tools for current research in natural language processing and computer vision. By providing pre-trained models that can be fine-tuned for specific applications, they enable researchers to create accurate models with minimal effort and computational resources. Large scale genomics deep learning models come in two flavors: the first are large language models of DNA sequences trained in a self-supervised fashion, similar to the corresponding natural language models; the second are supervised learning models that leverage large scale genomics datasets from ENCODE and other sources. We argue that these models are the equivalent of foundation models in natural language processing in their utility, as they encode within them chromatin state in its different aspects, providing useful representations that allow quick deployment of accurate models of gene regulation. We demonstrate this premise by leveraging the recently created Sei model to develop simple, interpretable models of intron retention, and demonstrate their advantage over models based on the DNA language model DNABERT-2. Our work also demonstrates the impact of chromatin state on the regulation of intron retention. Using representations learned by Sei, our model is able to discover the involvement of transcription factors and chromatin marks in regulating intron retention, providing better accuracy than a recently published custom model developed for this purpose.",
      "authors": "Daoud Ahmed; Ben-Hur Asa",
      "year": "2025",
      "month": "Jan",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    },
    {
      "pmid": "39786428",
      "doi": "10.1093/bioinformatics/btae759",
      "title": "SampleExplorer: using language models to discover relevant transcriptome data.",
      "abstract": "Over the last two decades, transcriptomics has become a standard technique in biomedical research. We now have large databases of RNA-seq data, accompanied by valuable metadata detailing scientific objectives and the experimental procedures used. The metadata is crucial in understanding and replicating published studies, but so far has been underutilized in helping researchers to discover existing datasets. We present SampleExplorer, a tool allowing researchers to search for relevant data using both text and gene set queries. SampleExplorer embeds sample metadata and uses a transformer-based language model to retrieve similar datasets. Extensive benchmarking (see Supplementary Materials and Methods) using the ARCHS4 database demonstrates that SampleExplorer provides an effective approach for retrieving biologically relevant samples from large-scale transcriptomicdata. This tool provides an efficient approach for discovering relevant gene expression datasets in large public repositories. It improves sample and dataset identification across diverse experimental contexts, helping researchers leverage existing transcriptomic data for potential replication or verification studies. Availability and implementation: SampleExplorer is available as a Python package compatible with versions 3.9 to 3.11, available for installation via the Python Package Index (PyPI). The codebase and documentation are accessible at https://github.com/wlchin/SampleExplorer. Supplementary data (Supplementary Materials and Methods) provides detailed methodological information, including an algorithmic description of the retrieval process and data preparation steps.",
      "authors": "Chin Wee Loong; Lassmann Timo",
      "year": "2024",
      "month": "Dec",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "39781179",
      "doi": "10.7759/cureus.75389",
      "title": "Comparing the Artificial Intelligence Detection Models to Standard Diagnostic Methods and Alternative Models in Identifying Alzheimer's Disease in At-Risk or Early Symptomatic Individuals: A Scoping Review.",
      "abstract": "Alzheimer's disease (AD) and other neurodegenerative illnesses place a heavy strain on the world's healthcare systems, particularly among the aging population. With a focus on research from January 2022 to September 2023, this scoping review, which adheres to Preferred Reporting Items for Systematic Reviews and Meta-Analysis extension for Scoping Reviews (PRISMA-Scr) criteria, examines the changing landscape of artificial intelligence (AI) applications for early AD detection and diagnosis. Forty-four carefully chosen articles were selected from a pool of 2,966 articles for the qualitative synthesis. The research reveals impressive advancements in AI-driven approaches, including neuroimaging, genomics, cognitive tests, and blood-based biomarkers. Notably, AI models focusing on deep learning (DL) algorithms demonstrate outstanding accuracy in early AD identification, often even before the onset of clinical symptoms. Multimodal approaches, which combine information from various sources, including neuroimaging and clinical assessments, provide comprehensive insights into the complex nature of AD. The study also emphasizes the critical role that blood-based and genetic biomarkers play in strengthening AD diagnosis and risk assessment. When combined with clinical or imaging data, genetic variations and polygenic risk scores help to improve prediction models. In a similar vein, blood-based biomarkers provide non-invasive instruments for detecting metabolic changes linked to AD. Cognitive and functional evaluations, which include neuropsychological examinations and assessments of daily living activities, serve as essential benchmarks for monitoring the course of AD and directing treatment interventions. When these evaluations are included in machine learning models, the diagnosis accuracy is improved, and treatment monitoring is made more accessible. In addition, including methods that support model interpretability and explainability helps in the thorough understanding and valuable implementation of AI-driven insights in clinical contexts. This review further identifies several gaps in the research landscape, including the need for diverse, high-quality datasets to address data heterogeneity and improve model generalizability. Practical implementation challenges, such as integrating AI systems into clinical workflows and clinician adoption, are highlighted as critical barriers to real-world application. Moreover, ethical considerations, particularly surrounding data privacy and informed consent, must be prioritized as AI adoption in healthcare accelerates. Performance metrics (e.g., sensitivity, specificity, and area under the curve (AUC)) for AI-based approaches are discussed, with a need for clearer reporting and comparative analyses. Addressing these limitations, alongside methodological clarity and critical evaluation of biases, would strengthen the credibility of AI applications in AD detection. By expanding its scope, this study highlights areas for improvement and future opportunities in early detection, aiming to bridge the gap between innovative AI technologies and practical clinical utility.",
      "authors": "Babu Britty; Parvathy Gauri; Mohideen Bawa Fathima S; Gill Gurnoor S; Patel Jeeya; Sibia Dataar S; Sureddi Jayadev; Patel Vidhi",
      "year": "2024",
      "month": "Dec",
      "journal": "Cureus",
      "source": "pubmed"
    },
    {
      "pmid": "39775454",
      "doi": "10.1093/bioinformatics/btaf009",
      "title": "BetaAlign: a deep learning approach for multiple sequence alignment.",
      "abstract": "Multiple sequence alignments (MSAs) are extensively used in biology, from phylogenetic reconstruction to structure and function prediction. Here, we suggest an out-of-the-box approach for the inference of MSAs, which relies on algorithms developed for processing natural languages. We show that our artificial intelligence (AI)-based methodology can be trained to align sequences by processing alignments that are generated via simulations, and thus different aligners can be easily generated for datasets with specific evolutionary dynamics attributes. We expect that natural language processing (NLP) solutions will replace or augment classic solutions for computing alignments, and more generally, challenging inference tasks in phylogenomics. The MSA problem is a fundamental pillar in bioinformatics, comparative genomics, and phylogenetics. Here, we characterize and improve BetaAlign, the first deep learning aligner, which substantially deviates from conventional algorithms of alignment computation. BetaAlign draws on NLP techniques and trains transformers to map a set of unaligned biological sequences to an MSA. We show that our approach is highly accurate, comparable and sometimes better than state-of-the-art alignment tools. We characterize the performance of BetaAlign and the effect of various aspects on accuracy; for example, the size of the training data, the effect of different transformer architectures, and the effect of learning on a subspace of indel-model parameters (subspace learning). We also introduce a new technique that leads to improved performance compared to our previous approach. Our findings further uncover the potential of NLP-based methods for sequence alignment, highlighting that AI-based algorithms can substantially challenge classic approaches in phylogenomics and bioinformatics. Datasets used in this work are available on HuggingFace (Wolf et al. Transformers: state-of-the-art natural language processing. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. p.38-45. 2020) at: https://huggingface.co/dotan1111. Source code is available at: https://github.com/idotan286/SimulateAlignments.",
      "authors": "Dotan Edo; Wygoda Elya; Ecker Noa; Alburquerque Michael; Avram Oren; Belinkov Yonatan; Pupko Tal",
      "year": "2024",
      "month": "Dec",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "39747934",
      "doi": "10.1038/s41598-024-84105-9",
      "title": "DNA promoter task-oriented dictionary mining and prediction model based on natural language technology.",
      "abstract": "Promoters are essential DNA sequences that initiate transcription and regulate gene expression. Precisely identifying promoter sites is crucial for deciphering gene expression patterns and the roles of gene regulatory networks. Recent advancements in bioinformatics have leveraged deep learning and natural language processing (NLP) to enhance promoter prediction accuracy. Techniques such as convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and BERT models have been particularly impactful. However, current approaches often rely on arbitrary DNA sequence segmentation during BERT pre-training, which may not yield optimal results. To overcome this limitation, this article introduces a novel DNA sequence segmentation method. This approach develops a more refined dictionary for DNA sequences, utilizes it for BERT pre-training, and employs an Inception neural network as the foundational model. This BERT-Inception architecture captures information across multiple granularities. Experimental results show that the model improves the performance of several downstream tasks and introduces deep learning interpretability, providing new perspectives for interpreting and understanding DNA sequence information. The detailed source code is available at https://github.com/katouMegumiH/Promoter_BERT .",
      "authors": "Zeng Ruolei; Li Zihan; Li Jialu; Zhang Qingchuan",
      "year": "2025",
      "month": "Jan",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "39737571",
      "doi": "10.1093/bib/bbae678",
      "title": "microT-CNN: an avant-garde deep convolutional neural network unravels functional miRNA targets beyond canonical sites.",
      "abstract": "microRNAs (miRNAs) are central post-transcriptional gene expression regulators in healthy and diseased states. Despite decades of effort, deciphering miRNA targets remains challenging, leading to an incomplete miRNA interactome and partially elucidated miRNA functions. Here, we introduce microT-CNN, an avant-garde deep convolutional neural network model that moves the needle by integrating hundreds of tissue-matched (in-)direct experiments from 26 distinct cell types, corresponding to a unique training and evaluation set of >60 000 miRNA binding events and ~30 000 unique miRNA-gene target pairs. The multilayer sequence-based design enables the prediction of both host and virus-encoded miRNA interactions, providing for the first time up to 67% of direct genuine Epstein-Barr virus- and Kaposi's sarcoma-associated herpesvirus-derived miRNA-target pairs corresponding to one out of four binding events of virus-encoded miRNAs. microT-CNN fills the existing gap of the miRNA-target prediction by providing functional targets beyond the canonical sites, including 3' compensatory miRNA pairings, prompting 1.4-fold more validated miRNA binding events compared to other implementations and shedding light on previously unexplored facets of the miRNA interactome.",
      "authors": "Zacharopoulou Elissavet; Paraskevopoulou Maria D; Tastsoglou Spyros; Alexiou Athanasios; Karavangeli Anna; Pierros Vasilis; Digenis Stefanos; Mavromati Galatea; Hatzigeorgiou Artemis G; Karagkouni Dimitra",
      "year": "2024",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39713797",
      "doi": "",
      "title": "A multimodal ensemble approach for clear cell renal cell carcinoma treatment outcome prediction.",
      "abstract": "A reliable and comprehensive cancer prognosis model for clear cell renal cell carcinoma (ccRCC) could better assist in personalizing treatment. In this work, we developed a multi-modal ensemble model (MMEM) which integrates pretreatment clinical information, multi-omics data, and histopathology whole slide image (WSI) data to learn complementary information to predict overall survival (OS) and disease-free survival (DFS) for patients with ccRCC. We collected 226 patients from The Cancer Genome Atlas Kidney Renal Clear Cell Carcinoma dataset (TCGA-KIRC). These patients have OS and DFS follow up data available and five different data modalities provided, including clinical information, pathology data in the form of WSI, and three multi-omics data, which comprise mRNA expression, miRNA expression (miRSeq), and DNA methylation data. Five sets of separate survival prediction models were constructed separately for OS and DFS. We used a traditional Cox-proportional hazards (CPH) model with iterative forward feature selection for clinical and multi-omics data. Four different types of pre-trained encoder models, comprising ResNet and three recently developed general purpose foundation models for computational pathology, were utilized to extract features from processed WSI patches. A deep learning-based CPH model was constructed to predict survival outcomes using these encoded WSI features. For each of the survival outcomes of interest, we weigh and combine the predicted risk scores from all the five models to generate the final prediction. Model weighting was based on the training performance. Five-fold cross validation was performed to train and test the proposed workflow. We employed the concordance index (C-index) and area under the receiver operating characteristic curve (AUROC) metrics to assess the performance of our models for time-to-event prediction and time-specific binary prediction, respectively. Among the sub-models, the clinical feature based CPH model has the highest weight for both prediction tasks. For WSI-based prediction, the encoded feature using an image-based general purpose foundation model (UNI) showed the best prediction performance over other pretrained feature encoders. Our final model outperformed corresponding single-modality models on all prediction labels, achieving C-indices of 0.820 and 0.833 for OS and DFS, respectively. The AUROC values for binary prediction at follow-up of 3 year were 0.831 and 0.862 for patient death and cancer recurrence, respectively. Using the medians of predicted risks as thresholds to identify high-risk and low-risk patient groups, we performed log-rank tests, which revealed improved performance in both OS and DFS compared to single-modality models. We developed the first multi-modal prediction model MMEM for ccRCC patients that integrates features across five different data modalities. Our model demonstrated better prognostic ability compared with corresponding single-modality models for both prediction targets. If findings are independently reproduced, it has the potential to assist in management of ccRCC patients.",
      "authors": "Chen Meixu; Wang Kai; Kapur Payal; Brugarolas James; Hannan Raquibul; Wang Jing",
      "year": "2024",
      "month": "Dec",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "39713364",
      "doi": "10.1101/2024.12.09.627422",
      "title": "L2G: Repurposing Language Models for Genomics Tasks.",
      "abstract": "Pre-trained language models have transformed the field of natural language processing (NLP), and their success has inspired efforts in genomics to develop domain-specific foundation models (FMs). However, creating high-quality genomic FMs from scratch is resource-intensive, requiring significant computational power and high-quality pre-training data. The success of large language models (LLMs) in NLP has largely been driven by industrial-scale efforts leveraging vast, diverse corpora and massive computing infrastructure. In this work, we aim to bypass the data and computational bottlenecks of creating genomic FMs from scratch and instead propose repurposing existing LLMs for genomics tasks. Inspired by the recently observed 'cross-modal transfer' phenomenon - where transformers pre-trained on natural language can generalize to other modalities - we introduce L2G, which adapts a pre-trained LLM architecture for genomics using neural architecture search (NAS) and a novel three-stage training procedure. Remarkably, without requiring extensive pre-training on DNA sequence data, L2G achieves superior performance to fine-tuned genomic FMs and task-specific models on more than half of tasks across multiple genomics benchmarks. In an enhancer activity prediction task, L2G further demonstrates its capacity to identify significant transcription factor motifs. Our work not only highlights the generalizability and efficacy of language models in out-of-domain tasks such as genomics, but also opens new avenues for more efficient and less resource-intensive methodologies in genomic research.",
      "authors": "Cheng Wenduo; Shen Junhong; Khodak Mikhail; Ma Jian; Talwalkar Ameet",
      "year": "2024",
      "month": "Dec",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "39696471",
      "doi": "10.1186/s13059-024-03449-7",
      "title": "EpiGePT: a pretrained transformer-based language model for context-specific human epigenomics.",
      "abstract": "The inherent similarities between natural language and biological sequences have inspired the use of large language models in genomics, but current models struggle to incorporate chromatin interactions or predict in unseen cellular contexts. To address this, we propose EpiGePT, a transformer-based model designed for predicting context-specific human epigenomic signals. By incorporating transcription factor activities and 3D genome interactions, EpiGePT outperforms existing methods in epigenomic signal prediction tasks, especially in cell-type-specific long-range interaction predictions and genetic variant impacts, advancing our understanding of gene regulation. A free online prediction service is available at http://health.tsinghua.edu.cn/epigept .",
      "authors": "Gao Zijing; Liu Qiao; Zeng Wanwen; Jiang Rui; Wong Wing Hung",
      "year": "2024",
      "month": "Dec",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "39677442",
      "doi": "10.1101/2024.12.01.24318253",
      "title": "Improving Automated Deep Phenotyping Through Large Language Models Using Retrieval Augmented Generation.",
      "abstract": "Diagnosing rare genetic disorders relies on precise phenotypic and genotypic analysis, with the Human Phenotype Ontology (HPO) providing a standardized language for capturing clinical phenotypes. Traditional HPO tools, such as Doc2HPO and ClinPhen, employ concept recognition to automate phenotype extraction but struggle with incomplete phenotype assignment, often requiring intensive manual review. While large language models (LLMs) hold promise for more context-driven phenotype extraction, they are prone to errors and \"hallucinations,\" making them less reliable without further refinement. We present RAG-HPO, a Python-based tool that leverages Retrieval-Augmented Generation (RAG) to elevate LLM accuracy in HPO term assignment, bypassing the limitations of baseline models while avoiding the time and resource intensive process of fine-tuning. RAG-HPO integrates a dynamic vector database, allowing real-time retrieval and contextual matching. The high-dimensional vector database utilized by RAG-HPO includes >54,000 phenotypic phrases mapped to HPO IDs, derived from the HPO database and supplemented with additional validated phrases. The RAG-HPO workflow uses an LLM to first extract phenotypic phrases that are then matched via semantic similarity to entries within a vector database before providing best term matches back to the LLM as context for final HPO term assignment. A benchmarking dataset of 120 published case reports with 1,792 manually-assigned HPO terms was developed, and the performance of RAG-HPO measured against existing published tools Doc2HPO, ClinPhen, and FastHPOCR. In evaluations, RAG-HPO, powered by Llama-3 70B and applied to a set of 120 case reports, achieved a mean precision of 0.84, recall of 0.78, and an F1 score of 0.80-significantly surpassing conventional tools (p<0.00001). False positive HPO term identification occurred for 15.8% (256/1,624) of terms, of which only 2.7% (7/256) represented hallucinations, and 33.6% (86/256) unrelated terms; the remainder of false positives (63.7%, 163/256) were relative terms of the target term. RAG-HPO is a user-friendly, adaptable tool designed for secure evaluation of clinical text and outperforms standard HPO-matching tools in precision, recall, and F1. Its enhanced precision and recall represent a substantial advancement in phenotypic analysis, accelerating the identification of genetic mechanisms underlying rare diseases and driving progress in genetic research and clinical genomics.",
      "authors": "Garcia Brandon T; Westerfield Lauren; Yelemali Priya; Gogate Nikhita; Andres Rivera-Munoz E; Du Haowei; Dawood Moez; Jolly Angad; Lupski James R; Posey Jennifer E",
      "year": "2024",
      "month": "Dec",
      "journal": "medRxiv : the preprint server for health sciences",
      "source": "pubmed"
    },
    {
      "pmid": "39656774",
      "doi": "10.1093/bib/bbae630",
      "title": "Inferring single-cell resolution spatial gene expression via fusing spot-based spatial transcriptomics, location, and histology using GCN.",
      "abstract": "Spatial transcriptomics (ST technology allows for the detection of cellular transcriptome information while preserving the spatial location of cells. This capability enables researchers to better understand the cellular heterogeneity, spatial organization, and functional interactions in complex biological systems. However, current technological methods are limited by low resolution, which reduces the accuracy of gene expression levels. Here, we propose scstGCN, a multimodal information fusion method based on Vision Transformer and Graph Convolutional Network that integrates histological images, spot-based ST data and spatial location information to infer super-resolution gene expression profiles at single-cell level. We evaluated the accuracy of the super-resolution gene expression profiles generated on diverse tissue ST datasets with disease and healthy by scstGCN along with their performance in identifying spatial patterns, conducting functional enrichment analysis, and tissue annotation. The results show that scstGCN can predict super-resolution gene expression accurately and aid researchers in discovering biologically meaningful differentially expressed genes and pathways. Additionally, scstGCN can segment and annotate tissues at a finer granularity, with results demonstrating strong consistency with coarse manual annotations. Our source code and all used datasets are available at https://github.com/wenwenmin/scstGCN and https://zenodo.org/records/12800375.",
      "authors": "Xue Shuailin; Zhu Fangfang; Chen Jinyu; Min Wenwen",
      "year": "2024",
      "month": "Nov",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39654982",
      "doi": "10.3389/fdgth.2024.1471200",
      "title": "Opportunities, challenges and future perspectives of using bioinformatics and artificial intelligence techniques on tropical disease identification using omics data.",
      "abstract": "Tropical diseases can often be caused by viruses, bacteria, parasites, and fungi. They can be spread over vectors. Analysis of multiple omics data types can be utilized in providing comprehensive insights into biological system functions and disease progression. To this end, bioinformatics tools and diverse AI techniques are pivotal in identifying and understanding tropical diseases through the analysis of omics data. In this article, we provide a thorough review of opportunities, challenges, and future directions of utilizing Bioinformatics tools and AI-assisted models on tropical disease identification using various omics data types. We conducted the review from 2015 to 2024 considering reliable databases of peer-reviewed journals and conference articles. Several keywords were taken for the article searching and around 40 articles were reviewed. According to the review, we observed that utilization of omics data with Bioinformatics tools like BLAST, and Clustal Omega can make significant outcomes in tropical disease identification. Further, the integration of multiple omics data improves biomarker identification, and disease predictions including disease outbreak predictions. Moreover, AI-assisted models can improve the precision, cost-effectiveness, and efficiency of CRISPR-based gene editing, optimizing gRNA design, and supporting advanced genetic correction. Several AI-assisted models including XAI can be used to identify diseases and repurpose therapeutic targets and biomarkers efficiently. Furthermore, recent advancements including Transformer-based models such as BERT and GPT-4, have been mainly applied for sequence analysis and functional genomics. Finally, the most recent GeneViT model, utilizing Vision Transformers, and other AI techniques like Generative Adversarial Networks, Federated Learning, Transfer Learning, Reinforcement Learning, Automated ML and Attention Mechanism have shown significant performance in disease classification using omics data.",
      "authors": "Vidanagamachchi S M; Waidyarathna K M G T R",
      "year": "2024",
      "month": "",
      "journal": "Frontiers in digital health",
      "source": "pubmed"
    },
    {
      "pmid": "39650606",
      "doi": "",
      "title": "Deciphering genomic codes using advanced NLP techniques: a scoping review.",
      "abstract": "The vast and complex nature of human genomic sequencing data presents challenges for effective analysis. This review aims to investigate the application of Natural Language Processing (NLP) techniques, particularly Large Language Models (LLMs) and transformer architectures, in deciphering genomic codes, focusing on tokenization, transformer models, and regulatory annotation prediction. This review aims to assess data and model accessibility in the most recent literature, gaining a better understanding of the existing capabilities and constraints of these tools in processing genomic sequencing data. Following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, our scoping review was conducted across PubMed, Medline, Scopus, Web of Science, Embase, and ACM Digital Library. Studies were included if they focused on NLP methodologies applied to genomic sequencing data analysis, without restrictions on publication date or article type. A total of 26 studies published between 2021 and April 2024 were selected for review. The review highlights that tokenization and transformer models enhance the processing and understanding of genomic data, with applications in predicting regulatory annotations like transcription-factor binding sites and chromatin accessibility. The application of NLP and LLMs to genomic sequencing data interpretation is a promising field that can help streamline the processing of large-scale genomic data while providing a better understanding of its complex structures. It can potentially drive advancements in personalized medicine by offering more efficient and scalable solutions for genomic analysis. Further research is needed to discuss and overcome limitations, enhancing model transparency and applicability.",
      "authors": "Cheng Shuyan; Wei Yishu; Zhou Yiliang; Xu Zihan; Wright Drew N; Liu Jinze; Peng Yifan",
      "year": "2024",
      "month": "Nov",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "39638800",
      "doi": "10.1038/s41467-024-54812-y",
      "title": "RNA language models predict mutations that improve RNA function.",
      "abstract": "Structured RNA lies at the heart of many central biological processes, from gene expression to catalysis. RNA structure prediction is not yet possible due to a lack of high-quality reference data associated with organismal phenotypes that could inform RNA function. We present GARNET (Gtdb Acquired RNa with Environmental Temperatures), a new database for RNA structural and functional analysis anchored to the Genome Taxonomy Database (GTDB). GARNET links RNA sequences to experimental and predicted optimal growth temperatures of GTDB reference organisms. Using GARNET, we develop sequence- and structure-aware RNA generative models, with overlapping triplet tokenization providing optimal encoding for a GPT-like model. Leveraging hyperthermophilic RNAs in GARNET and these RNA generative models, we identify mutations in ribosomal RNA that confer increased thermostability to the Escherichia coli ribosome. The GTDB-derived data and deep learning models presented here provide a foundation for understanding the connections between RNA sequence, structure, and function.",
      "authors": "Shulgina Yekaterina; Trinidad Marena I; Langeberg Conner J; Nisonoff Hunter; Chithrananda Seyone; Skopintsev Petr; Nissley Amos J; Patel Jaymin; Boger Ron S; Shi Honglue; Yoon Peter H; Doherty Erin E; Pande Tara; Iyer Aditya M; Doudna Jennifer A; Cate Jamie H D",
      "year": "2024",
      "month": "Dec",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "39628660",
      "doi": "10.1145/3627673.3679576",
      "title": "scACT: Accurate Cross-modality Translation via Cycle-consistent Training from Unpaired Single-cell Data.",
      "abstract": "Single-cell sequencing technologies have revolutionized genomics by enabling the simultaneous profiling of various molecular modalities within individual cells. Their integration, especially cross-modality translation, offers deep insights into cellular regulatory mechanisms. Many methods have been developed for cross-modality translation, but their reliance on scarce high-quality co-assay data limits their applicability. Addressing this, we introduce scACT, a deep generative model designed to extract cross-modality biological insights from unpaired single-cell data. scACT tackles three major challenges: aligning unpaired multi-modal data via adversarial training, facilitating cross-modality translation without prior knowledge via cycle-consistent training, and enabling interpretable regulatory interconnections explorations via in-silico perturbations. To test its performance, we applied scACT on diverse single-cell datasets and found it outperformed existing methods in all three tasks. Finally, we have developed scACT as an individual open-source software package to advance single-cell omics data processing and analysis within the research community.",
      "authors": "Xu Siwei; Liu Junhao; Zhang Jing",
      "year": "2024",
      "month": "Oct",
      "journal": "Proceedings of the ... ACM International Conference on Information & Knowledge Management. ACM International Conference on Information and Knowledge Management",
      "source": "pubmed"
    },
    {
      "pmid": "39607984",
      "doi": "10.1093/gigascience/giae089",
      "title": "stMMR: accurate and robust spatial domain identification from spatially resolved transcriptomics with multimodal feature representation.",
      "abstract": "Deciphering spatial domains using spatially resolved transcriptomics (SRT) is of great value for characterizing and understanding tissue architecture. However, the inherent heterogeneity and varying spatial resolutions present challenges in the joint analysis of multimodal SRT data. We introduce a multimodal geometric deep learning method, named stMMR, to effectively integrate gene expression, spatial location, and histological information for accurate identifying spatial domains from SRT data. stMMR uses graph convolutional networks and a self-attention module for deep embedding of features within unimodality and incorporates similarity contrastive learning for integrating features across modalities. Comprehensive benchmark analysis on various types of spatial data shows superior performance of stMMR in multiple analyses, including spatial domain identification, pseudo-spatiotemporal analysis, and domain-specific gene discovery. In chicken heart development, stMMR reconstructed the spatiotemporal lineage structures, indicating an accurate developmental sequence. In breast cancer and lung cancer, stMMR clearly delineated the tumor microenvironment and identified marker genes associated with diagnosis and prognosis. Overall, stMMR is capable of effectively utilizing the multimodal information of various SRT data to explore and characterize tissue architectures of homeostasis, development, and tumor.",
      "authors": "Zhang Daoliang; Yu Na; Yuan Zhiyuan; Li Wenrui; Sun Xue; Zou Qi; Li Xiangyu; Liu Zhiping; Zhang Wei; Gao Rui",
      "year": "2024",
      "month": "Jan",
      "journal": "GigaScience",
      "source": "pubmed"
    },
    {
      "pmid": "39605181",
      "doi": "10.1002/advs.202409990",
      "title": "Integrating Prior Knowledge Using Transformer for Gene Regulatory Network Inference.",
      "abstract": "Gene regulatory network (GRN) inference, a process of reconstructing gene regulatory rules from experimental data, has the potential to discover new regulatory rules. However, existing methods often struggle to generalize across diverse cell types and account for unseen regulators. Here, this work presents GRNPT, a novel Transformer-based framework that integrates large language model (LLM) embeddings from publicly accessible biological data and a temporal convolutional network (TCN) autoencoder to capture regulatory patterns from single-cell RNA sequencing (scRNA-seq) trajectories. GRNPT significantly outperforms both supervised and unsupervised methods in inferring GRNs, particularly when training data is limited. Notably, GRNPT exhibits exceptional generalizability, accurately predicting regulatory relationships in previously unseen cell types and even regulators. By combining LLMs ability to distillate biological knowledge from text and deep learning methodologies capturing complex patterns in gene expression data, GRNPT overcomes the limitations of traditional GRN inference methods and enables more accurate and comprehensive understanding of gene regulatory dynamics.",
      "authors": "Weng Guangzheng; Martin Patrick; Kim Hyobin; Won Kyoung Jae",
      "year": "2025",
      "month": "Jan",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "39578697",
      "doi": "10.1093/nar/gkae1086",
      "title": "miRStart 2.0: enhancing miRNA regulatory insights through deep learning-based TSS identification.",
      "abstract": "MicroRNAs (miRNAs) are small non-coding RNAs that regulate gene expression by binding to the 3'-untranslated regions of target mRNAs, influencing various biological processes at the post-transcriptional level. Identifying miRNA transcription start sites (TSSs) and transcription factors' (TFs) regulatory roles is crucial for elucidating miRNA function and transcriptional regulation. miRStart 2.0 integrates over 4500 high-throughput datasets across five data types, utilizing a multi-modal approach to annotate 28 828 putative TSSs for 1745 human and 1181 mouse miRNAs, supported by sequencing-based signals. Over 6 million tissue-specific TF-miRNA interactions, integrated from ChIP-seq data, are supplemented by DNase hypersensitivity and UCSC conservation data, with network visualizations. Our deep learning-based model outperforms existing tools in miRNA TSS prediction, achieving the most overlaps with both cell-specific and non-cell-specific validated TSSs. The user-friendly web interface and visualization tools make miRStart 2.0 easily accessible to researchers, enabling efficient identification of miRNA upstream regulatory elements in relation to their TSSs. This updated database provides systems-level insights into gene regulation and disease mechanisms, offering a valuable resource for translational research, facilitating the discovery of novel therapeutic targets and precision medicine strategies. miRStart 2.0 is now accessible at https://awi.cuhk.edu.cn/∼miRStart2.",
      "authors": "Xu Jiatong; Wan Jingting; Huang Hsi-Yuan; Chen Yigang; Huang Yixian; Huang Junyang; Zhang Ziyue; Su Chang; Zhou Yuming; Lin Xingqiao; Lin Yang-Chi-Dung; Huang Hsien-Da",
      "year": "2025",
      "month": "Jan",
      "journal": "Nucleic acids research",
      "source": "pubmed"
    },
    {
      "pmid": "39567490",
      "doi": "10.1038/s41467-024-53340-z",
      "title": "multiDGD: A versatile deep generative model for multi-omics data.",
      "abstract": "Recent technological advancements in single-cell genomics have enabled joint profiling of gene expression and alternative modalities at unprecedented scale. Consequently, the complexity of multi-omics data sets is increasing massively. Existing models for multi-modal data are typically limited in functionality or scalability, making data integration and downstream analysis cumbersome. We present multiDGD, a scalable deep generative model providing a probabilistic framework to learn shared representations of transcriptome and chromatin accessibility. It shows outstanding performance on data reconstruction without feature selection. We demonstrate on several data sets from human and mouse that multiDGD learns well-clustered joint representations. We further find that probabilistic modeling of sample covariates enables post-hoc data integration without the need for fine-tuning. Additionally, we show that multiDGD can detect statistical associations between genes and regulatory regions conditioned on the learned representations. multiDGD is available as an scverse-compatible package on GitHub.",
      "authors": "Schuster Viktoria; Dann Emma; Krogh Anders; Teichmann Sarah A",
      "year": "2024",
      "month": "Nov",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "39554073",
      "doi": "10.1101/2024.10.28.620662",
      "title": "NeuroTD: A Time-Frequency Based Multimodal Learning Approach to Analyze Time Delays in Neural Activities.",
      "abstract": "Studying temporal features of neural activities is crucial for understanding the functions of neurons as well as underlying neural circuits. To this end, recent researches employ emerging techniques including calcium imaging, Neuropixels, depth electrodes, and Patch-seq to generate multimodal time-series data that depict the activities of single neurons, groups of neurons, and behaviors. However, challenges persist, including the analysis of noisy, high-sampling-rate neuronal data, and the modeling of temporal dynamics across various modalities. To address these challenges, we developed NeuroTD, a novel deep learning approach to align multimodal time-series datasets and infer cross-modality temporal relationships such as time delays or shifts. Particularly, NeuroTD integrates Siamese neural networks with frequency domain transformations and complex value optimization for inference. We applied NeuroTD to three multimodal datasets to (1) analyze electrophysiological (ephys) time series measured by depth electrodes, identifying time delays among neurons across various positions, (2) investigate neural activity and behavioral time series data derived from Neuropixels and 3D motion captures, establishing causal relationships between neural activities and corresponding behavioral activities, and (3) explore gene expression and ephys data of single neurons from Patch-seq, identifying gene expression signatures highly correlated with time shifts in ephys responses. Finally, NeuroTD is open-source at https://github.com/daifengwanglab/NeuroTD for general use.",
      "authors": "Huang Xiang; Kalafut Noah Cohen; Alatkar Sayali; Li Athan Z; Dong Qiping; Chang Qiang; Wang Daifeng",
      "year": "2024",
      "month": "Oct",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "39548084",
      "doi": "10.1038/s41467-024-53971-2",
      "title": "scPair: Boosting single cell multimodal analysis by leveraging implicit feature selection and single cell atlases.",
      "abstract": "Multimodal single-cell assays profile multiple sets of features in the same cells and are widely used for identifying and mapping cell states between chromatin and mRNA and linking regulatory elements to target genes. However, the high dimensionality of input features and shallow sequencing depth compared to unimodal assays pose challenges in data analysis. Here we present scPair, a multimodal single-cell data framework that overcomes these challenges by employing an implicit feature selection approach. scPair uses dual encoder-decoder structures trained on paired data to align cell states across modalities and predict features from one modality to another. We demonstrate that scPair outperforms existing methods in accuracy and execution time, and facilitates downstream tasks such as trajectory inference. We further show scPair can augment smaller multimodal datasets with larger unimodal atlases to increase statistical power to identify groups of transcription factors active during different stages of neural differentiation.",
      "authors": "Hu Hongru; Quon Gerald",
      "year": "2024",
      "month": "Nov",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "39489607",
      "doi": "10.1093/bib/bbae560",
      "title": "Semi-supervised learning with pseudo-labeling compares favorably with large language models for regulatory sequence prediction.",
      "abstract": "Predicting molecular processes using deep learning is a promising approach to provide biological insights for non-coding single nucleotide polymorphisms identified in genome-wide association studies. However, most deep learning methods rely on supervised learning, which requires DNA sequences associated with functional data, and whose amount is severely limited by the finite size of the human genome. Conversely, the amount of mammalian DNA sequences is growing exponentially due to ongoing large-scale sequencing projects, but in most cases without functional data. To alleviate the limitations of supervised learning, we propose a novel semi-supervised learning (SSL) based on pseudo-labeling, which allows to exploit unlabeled DNA sequences from numerous genomes during model pre-training. We further improved it incorporating principles from the Noisy Student algorithm to predict the confidence in pseudo-labeled data used for pre-training, which showed improvements for transcription factor with very few binding (very small training data). The approach is very flexible and can be used to train any neural architecture including state-of-the-art models, and shows in most cases strong predictive performance improvements compared to standard supervised learning. Moreover, small models trained by SSL showed similar or better performance than large language model DNABERT2.",
      "authors": "Phan Han; Brouard Céline; Mourad Raphaël",
      "year": "2024",
      "month": "Sep",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39484450",
      "doi": "10.1101/2024.10.20.619308",
      "title": "Toden-E: Topology-Based and Density-Based Ensembled Clustering for the Development of Super-PAG in Functional Genomics using PAG Network and LLM.",
      "abstract": "The integrative analysis of gene sets, networks, and pathways is pivotal for deciphering omics data in translational biomedical research. To significantly increase gene coverage and enhance the utility of pathways, annotated gene lists, and gene signatures from diverse sources, we introduced pathways, annotated gene lists, and gene signatures (PAGs) enriched with metadata to represent biological functions. Furthermore, we established PAG-PAG networks by leveraging gene member similarity and gene regulations. However, in practice, high similarity in functional descriptions or gene membership often leads to redundant PAGs, hindering the interpretation from a fuzzy enriched PAG list. In this study, we developed todenE (topology-based and density-based ensemble) clustering, pioneering in integrating topology-based and density-based clustering methods to detect PAG communities leveraging the PAG network and Large Language Models (LLM). In computational genomics annotation, the genes can be grouped/clustered through the gene relationships and gene functions via guilt by association. Similarly, PAGs can be grouped into higher-level clusters, forming concise functional representations called Super-PAGs. TodenE captures PAG-PAG similarity and encapsulates functional information through LLM, in characterizing network-based functional Super-PAGs. In synthetic data, we introduced a metric called the Disparity Index (DI), measuring the connectivity of gene neighbors to gauge clusterability. We compared multiple clustering algorithms to identify the best method for generating performance-driven clusters. In non-simulated data (Gene Ontology), by leveraging transfer learning and LLM, we formed a language-based similarity embedding. TodenE utilizes this embedding together with the topology-based embedding to generate putative Super-PAGs with superior performance in semantic and gene member inclusiveness.",
      "authors": "Li Qi; Nichols Cody; Welner Robert S; Chen Jake Y; Ku Wei-Shinn; Yue Zongliang",
      "year": "2024",
      "month": "Oct",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "39476415",
      "doi": "10.1146/annurev-pathmechdis-111523-023417",
      "title": "Challenges and Opportunities in the Clinical Translation of High-Resolution Spatial Transcriptomics.",
      "abstract": "Pathology has always been fueled by technological advances. Histology powered the study of tissue architecture at single-cell resolution and remains a cornerstone of clinical pathology today. In the last decade, next-generation sequencing has become informative for the targeted treatment of many diseases, demonstrating the importance of genome-scale molecular information for personalized medicine. Today, revolutionary developments in spatial transcriptomics technologies digitalize gene expression at subcellular resolution in intact tissue sections, enabling the computational analysis of cell types, cellular phenotypes, and cell-cell communication in routinely collected and archival clinical samples. Here we review how such molecular microscopes work, highlight their potential to identify disease mechanisms and guide personalized therapies, and provide guidance for clinical study design. Finally, we discuss remaining challenges to the swift translation of high-resolution spatial transcriptomics technologies and how integration of multimodal readouts and deep learning approaches is bringing us closer to a holistic understanding of tissue biology and pathology.",
      "authors": "Pentimalli Tancredi Massimo; Karaiskos Nikos; Rajewsky Nikolaus",
      "year": "2025",
      "month": "Jan",
      "journal": "Annual review of pathology",
      "source": "pubmed"
    },
    {
      "pmid": "39471412",
      "doi": "10.1093/bib/bbae551",
      "title": "Multimodal contrastive learning for spatial gene expression prediction using histology images.",
      "abstract": "In recent years, the advent of spatial transcriptomics (ST) technology has unlocked unprecedented opportunities for delving into the complexities of gene expression patterns within intricate biological systems. Despite its transformative potential, the prohibitive cost of ST technology remains a significant barrier to its widespread adoption in large-scale studies. An alternative, more cost-effective strategy involves employing artificial intelligence to predict gene expression levels using readily accessible whole-slide images stained with Hematoxylin and Eosin (H&E). However, existing methods have yet to fully capitalize on multimodal information provided by H&E images and ST data with spatial location. In this paper, we propose mclSTExp, a multimodal contrastive learning with Transformer and Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We conceptualize each spot as a \"word\", integrating its intrinsic features with spatial context through the self-attention mechanism of a Transformer encoder. This integration is further enriched by incorporating image features via contrastive learning, thereby enhancing the predictive capability of our model. We conducted an extensive evaluation of highly variable genes in two breast cancer datasets and a skin squamous cell carcinoma dataset, and the results demonstrate that mclSTExp exhibits superior performance in predicting spatial gene expression. Moreover, mclSTExp has shown promise in interpreting cancer-specific overexpressed genes, elucidating immune-related genes, and identifying specialized spatial domains annotated by pathologists. Our source code is available at https://github.com/shizhiceng/mclSTExp.",
      "authors": "Min Wenwen; Shi Zhiceng; Zhang Jun; Wan Jun; Wang Changmiao",
      "year": "2024",
      "month": "Sep",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39452530",
      "doi": "10.3390/jpm14101022",
      "title": "Evaluating Generative AI's Ability to Identify Cancer Subtypes in Publicly Available Structured Genetic Datasets.",
      "abstract": "Genetic data play a crucial role in diagnosing and treating various diseases, reflecting a growing imperative to integrate these data into clinical care. However, significant barriers such as the structure of electronic health records (EHRs), insurance costs for genetic testing, and the interpretability of genetic results impede this integration. This paper explores solutions to these challenges by combining recent technological advances with informatics and data science, focusing on the diagnostic potential of artificial intelligence (AI) in cancer research. AI has historically been applied in medical research with limited success, but recent developments have led to the emergence of large language models (LLMs). These transformer-based generative AI models, trained on vast datasets, offer significant potential for genetic and genomic analyses. However, their effectiveness is constrained by their training on predominantly human-written text rather than comprehensive, structured genetic datasets. This study reevaluates the capabilities of LLMs, specifically GPT models, in performing supervised prediction tasks using structured gene expression data. By comparing GPT models with traditional machine learning approaches, we assess their effectiveness in predicting cancer subtypes, demonstrating the potential of AI models to analyze real-world genetic data for generating real-world evidence.",
      "authors": "Hillis Ethan; Bhattarai Kriti; Abrams Zachary",
      "year": "2024",
      "month": "Sep",
      "journal": "Journal of personalized medicine",
      "source": "pubmed"
    },
    {
      "pmid": "39447059",
      "doi": "10.1093/bioinformatics/btae643",
      "title": "Prediction of human O-linked glycosylation sites using stacked generalization and embeddings from pre-trained protein language model.",
      "abstract": "O-linked glycosylation, an essential post-translational modification process in Homo sapiens, involves attaching sugar moieties to the oxygen atoms of serine and/or threonine residues. It influences various biological and cellular functions. While threonine or serine residues within protein sequences are potential sites for O-linked glycosylation, not all serine and/or threonine residues undergo this modification, underscoring the importance of characterizing its occurrence. This study presents a novel approach for predicting intracellular and extracellular O-linked glycosylation events on proteins, which are crucial for comprehending cellular processes. Two base multi-layer perceptron models were trained by leveraging a stacked generalization framework. These base models respectively use ProtT5 and Ankh O-linked glycosylation site-specific embeddings whose combined predictions are used to train the meta-multi-layer perceptron model. Trained on extensive O-linked glycosylation datasets, the stacked-generalization model demonstrated high predictive performance on independent test datasets. Furthermore, the study emphasizes the distinction between nucleocytoplasmic and extracellular O-linked glycosylation, offering insights into their functional implications that were overlooked in previous studies. By integrating the protein language model's embedding with stacked generalization techniques, this approach enhances predictive accuracy of O-linked glycosylation events and illuminates the intricate roles of O-linked glycosylation in proteomics, potentially accelerating the discovery of novel glycosylation sites. Stack-OglyPred-PLM produces Sensitivity, Specificity, Matthews Correlation Coefficient, and Accuracy of 90.50%, 89.60%, 0.464, and 89.70%, respectively on a benchmark NetOGlyc-4.0 independent test dataset. These results demonstrate that Stack-OglyPred-PLM is a robust computational tool to predict O-linked glycosylation sites in proteins. The developed tool, programs, training, and test dataset are available at https://github.com/PakhrinLab/Stack-OglyPred-PLM.",
      "authors": "Pakhrin Subash Chandra; Chauhan Neha; Khan Salman; Upadhyaya Jamie; Beck Moriah Rene; Blanco Eduardo",
      "year": "2024",
      "month": "Nov",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "39439006",
      "doi": "10.1186/s13059-024-03421-5",
      "title": "STASCAN deciphers fine-resolution cell distribution maps in spatial transcriptomics by deep learning.",
      "abstract": "Spatial transcriptomics technologies have been widely applied to decode cellular distribution by resolving gene expression profiles in tissue. However, sequencing techniques still limit the ability to create a fine-resolved spatial cell-type map. To this end, we develop a novel deep-learning-based approach, STASCAN, to predict the spatial cellular distribution of captured or uncharted areas where only histology images are available by cell feature learning integrating gene expression profiles and histology images. STASCAN is successfully applied across diverse datasets from different spatial transcriptomics technologies and displays significant advantages in deciphering higher-resolution cellular distribution and resolving enhanced organizational structures.",
      "authors": "Wu Ying; Zhou Jia-Yi; Yao Bofei; Cui Guanshen; Zhao Yong-Liang; Gao Chun-Chun; Yang Ying; Zhang Shihua; Yang Yun-Gui",
      "year": "2024",
      "month": "Oct",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "39435343",
      "doi": "10.1016/j.csbj.2024.09.031",
      "title": "Large language models and their applications in bioinformatics.",
      "abstract": "Recent advancements in Natural Language Processing (NLP) have been significantly driven by the development of Large Language Models (LLMs), representing a substantial leap in language-based technology capabilities. These models, built on sophisticated deep learning architectures, typically transformers, are characterized by billions of parameters and extensive training data, enabling them to achieve high accuracy across various tasks. The transformer architecture of LLMs allows them to effectively handle context and sequential information, which is crucial for understanding and generating human language. Beyond traditional NLP applications, LLMs have shown significant promise in bioinformatics, transforming the field by addressing challenges associated with large and complex biological datasets. In genomics, proteomics, and personalized medicine, LLMs facilitate identifying patterns, predicting protein structures, or understanding genetic variations. This capability is crucial, e.g., for advancing drug discovery, where accurate prediction of molecular interactions is essential. This review discusses the current trends in LLMs research and their potential to revolutionize the field of bioinformatics and accelerate novel discoveries in the life sciences.",
      "authors": "Sarumi Oluwafemi A; Heider Dominik",
      "year": "2024",
      "month": "Dec",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "39424861",
      "doi": "10.1038/s41467-024-53355-6",
      "title": "Modal-nexus auto-encoder for multi-modality cellular data integration and imputation.",
      "abstract": "Heterogeneous feature spaces and technical noise hinder the cellular data integration and imputation. The high cost of obtaining matched data across modalities further restricts analysis. Thus, there's a critical need for deep learning approaches to effectively integrate and impute unpaired multi-modality single-cell data, enabling deeper insights into cellular behaviors. To address these issues, we introduce the Modal-Nexus Auto-Encoder (Monae). Leveraging regulatory relationships between modalities and employing contrastive learning within modality-specific auto-encoders, Monae enhances cell representations in the unified space. The integration capability of Monae furnishes it with modality-complementary cellular representations, enabling the generation of precise intra-modal and cross-modal imputation counts for extensive and complex downstream tasks. In addition, we develop Monae-E (Monae-Extension), a variant of Monae that can converge rapidly and support biological discoveries. Evaluations on various datasets have validated Monae and Monae-E's accuracy and robustness in multi-modality cellular data integration and imputation.",
      "authors": "Tang Zhenchao; Chen Guanxing; Chen Shouzhi; Yao Jianhua; You Linlin; Chen Calvin Yu-Chian",
      "year": "2024",
      "month": "Oct",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "39415960",
      "doi": "10.1016/j.csbj.2024.09.010",
      "title": "Confronting the data deluge: How artificial intelligence can be used in the study of plant stress.",
      "abstract": "The advent of the genomics era enabled the generation of high-throughput data and computational methods that serve as powerful hypothesis-generating tools to understand the genomic and gene functional basis of plant stress resilience. The proliferation of experimental and analytical methods used in biology has resulted in a situation where plentiful data exists, but the volume and heterogeneity of this data has made analysis a significant challenge. Current advanced deep-learning models have displayed an unprecedented level of comprehension and problem-solving ability, and have been used to predict gene structure, function and expression based on DNA or protein sequence, and prominently also their use in high-throughput phenomics in agriculture. However, the application of deep-learning models to understand gene regulatory and signalling behaviour is still in its infancy. We discuss in this review the availability of data resources and bioinformatic tools, and several applications of these advanced ML/AI models in the context of plant stress response, and demonstrate the use of a publicly available LLM (ChatGPT) to derive a knowledge graph of various experimental and computational methods used in the study of plant stress. We hope this will stimulate further interest in collaboration between computer scientists, computational biologists and plant scientists to distil the deluge of genomic, transcriptomic, proteomic, metabolomic and phenomic data into meaningful knowledge that can be used for the benefit of humanity.",
      "authors": "Koh Eugene; Sunil Rohan Shawn; Lam Hilbert Yuen In; Mutwil Marek",
      "year": "2024",
      "month": "Dec",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "39399683",
      "doi": "10.21203/rs.3.rs-4844047/v1",
      "title": "Protein Set Transformer: A protein-based genome language model to power high diversity viromics.",
      "abstract": "Exponential increases in microbial and viral genomic data demand transformational advances in scalable, generalizable frameworks for their interpretation. Standard homology-based functional analyses are hindered by the rapid divergence of microbial and especially viral genomes and proteins that significantly decreases the volume of usable data. Here, we present Protein Set Transformer (PST), a protein-based genome language model that models genomes as sets of proteins without considering sparsely available functional labels. Trained on >100k viruses, PST outperformed other homology- and language model-based approaches for relating viral genomes based on shared protein content. Further, PST demonstrated protein structural and functional awareness by clustering capsid-fold-containing proteins with known capsid proteins and uniquely clustering late gene proteins within related viruses. Our data establish PST as a valuable method for diverse viral genomics, ecology, and evolutionary applications. We posit that the PST framework can be a foundation model for microbial genomics when trained on suitable data.",
      "authors": "Martin Cody; Gitter Anthony; Anantharaman Karthik",
      "year": "2024",
      "month": "Sep",
      "journal": "Research square",
      "source": "pubmed"
    },
    {
      "pmid": "39376034",
      "doi": "10.1093/bib/bbae492",
      "title": "MultiSC: a deep learning pipeline for analyzing multiomics single-cell data.",
      "abstract": "Single-cell technologies enable researchers to investigate cell functions at an individual cell level and study cellular processes with higher resolution. Several multi-omics single-cell sequencing techniques have been developed to explore various aspects of cellular behavior. Using NEAT-seq as an example, this method simultaneously obtains three kinds of omics data for each cell: gene expression, chromatin accessibility, and protein expression of transcription factors (TFs). Consequently, NEAT-seq offers a more comprehensive understanding of cellular activities in multiple modalities. However, there is a lack of tools available for effectively integrating the three types of omics data. To address this gap, we propose a novel pipeline called MultiSC for the analysis of MULTIomic Single-Cell data. Our pipeline leverages a multimodal constraint autoencoder (single-cell hierarchical constraint autoencoder) to integrate the multi-omics data during the clustering process and a matrix factorization-based model (scMF) to predict target genes regulated by a TF. Moreover, we utilize multivariate linear regression models to predict gene regulatory networks from the multi-omics data. Additional functionalities, including differential expression, mediation analysis, and causal inference, are also incorporated into the MultiSC pipeline. Extensive experiments were conducted to evaluate the performance of MultiSC. The results demonstrate that our pipeline enables researchers to gain a comprehensive view of cell activities and gene regulatory networks by fully leveraging the potential of multiomics single-cell data. By employing MultiSC, researchers can effectively integrate and analyze diverse omics data types, enhancing their understanding of cellular processes.",
      "authors": "Lin Xiang; Jiang Siqi; Gao Le; Wei Zhi; Wang Junwen",
      "year": "2024",
      "month": "Sep",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39369090",
      "doi": "10.1038/s41598-024-73916-5",
      "title": "Human-augmented large language model-driven selection of glutathione peroxidase 4 as a candidate blood transcriptional biomarker for circulating erythroid cells.",
      "abstract": "The identification of optimal candidate genes from large-scale blood transcriptomic data is crucial for developing targeted assays to monitor immune responses. Here, we introduce a novel, optimized large language model (LLM)-based approach for prioritizing candidate biomarkers from blood transcriptional modules. Focusing on module M14.51 from the BloodGen3 repertoire, we implemented a multi-step LLM-driven workflow. Initial high-throughput screening used GPT-4, Claude 3, and Claude 3.5 Sonnet to score and rank the module's constituent genes across six criteria. Top candidates then underwent high-resolution scoring using Consensus GPT, with concurrent manual fact-checking and, when needed, iterative refinement of the scores based on user feedback. Qualitative assessment of literature-based narratives and analysis of reference transcriptome data further refined the selection process. This novel multi-tiered approach consistently identified Glutathione Peroxidase 4 (GPX4) as the top candidate gene for module M14.51. GPX4's role in oxidative stress regulation, its potential as a future drug target, and its expression pattern across diverse cell types supported its selection. The incorporation of reference transcriptome data further validated GPX4 as the most suitable candidate for this module. This study presents an advanced LLM-driven workflow with a novel optimized scoring strategy for candidate gene prioritization, incorporating human-in-the-loop augmentation. The approach identified GPX4 as a key gene in the erythroid cell-associated module M14.51, suggesting its potential utility for biomarker discovery and targeted assay development. By combining AI-driven literature analysis with iterative human expert validation, this method leverages the strengths of both artificial and human intelligence, potentially contributing to the development of biologically relevant and clinically informative targeted assays. Further validation studies are needed to confirm the broader applicability of this human-augmented AI approach.",
      "authors": "Subba Bishesh; Toufiq Mohammed; Omi Fuadur; Yurieva Marina; Khan Taushif; Rinchai Darawan; Palucka Karolina; Chaussabel Damien",
      "year": "2024",
      "month": "Oct",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "39369061",
      "doi": "10.1038/s42003-024-06964-2",
      "title": "Imputing spatial transcriptomics through gene network constructed from protein language model.",
      "abstract": "Image-based spatial transcriptomic sequencing technologies have enabled the measurement of gene expression at single-cell resolution, but with a limited number of genes. Current computational approaches attempt to overcome these limitations by imputing missing genes, but face challenges regarding prediction accuracy and identification of cell populations due to the neglect of gene-gene relationships. In this context, we present stImpute, a method to impute spatial transcriptomics according to reference scRNA-seq data based on the gene network constructed from the protein language model ESM-2. Specifically, stImpute employs an autoencoder to create gene expression embeddings for both spatial transcriptomics and scRNA-seq data, which are used to identify the nearest neighboring cells between scRNA-seq and spatial transcriptomics datasets. According to the neighbored cells, the gene expressions of spatial transcriptomics cells are imputed through a graph neural network, where nodes are genes, and edges are based on cosine similarity between the ESM-2 embeddings of the gene-encoding proteins. The gene prediction uncertainty is further measured through a deep learning model. stImpute was shown to consistently outperform state-of-the-art methods across multiple datasets concerning imputation and clustering. stImpute also demonstrates robustness in producing consistent results that are insensitive to model parameters.",
      "authors": "Zeng Yuansong; Song Yujie; Zhang Chengyang; Li Haoxuan; Zhao Yongkang; Yu Weijiang; Zhang Shiqi; Zhang Hongyu; Dai Zhiming; Yang Yuedong",
      "year": "2024",
      "month": "Oct",
      "journal": "Communications biology",
      "source": "pubmed"
    },
    {
      "pmid": "39345504",
      "doi": "10.1101/2024.09.19.613754",
      "title": "scooby: Modeling multi-modal genomic profiles from DNA sequence at single-cell resolution.",
      "abstract": "Understanding how regulatory DNA elements shape gene expression across individual cells is a fundamental challenge in genomics. Joint RNA-seq and epigenomic profiling provides opportunities to build unifying models of gene regulation capturing sequence determinants across steps of gene expression. However, current models, developed primarily for bulk omics data, fail to capture the cellular heterogeneity and dynamic processes revealed by single-cell multi-modal technologies. Here, we introduce scooby, the first framework to model scRNA-seq coverage and scATAC-seq insertion profiles along the genome from sequence at single-cell resolution. For this, we leverage the pre-trained multi-omics profile predictor Borzoi as a foundation model, equip it with a cell-specific decoder, and fine-tune its sequence embeddings. Specifically, we condition the decoder on the cell position in a precomputed single-cell embedding resulting in strong generalization capability. Applied to a hematopoiesis dataset, scooby recapitulates cell-specific expression levels of held-out genes, and identifies regulators and their putative target genes through in silico motif deletion. Moreover, accurate variant effect prediction with scooby allows for breaking down bulk eQTL effects into single-cell effects and delineating their impact on chromatin accessibility and gene expression. We anticipate scooby to aid unraveling the complexities of gene regulation at the resolution of individual cells.",
      "authors": "Hingerl Johannes C; Martens Laura D; Karollus Alexander; Manz Trevor; Buenrostro Jason D; Theis Fabian J; Gagneur Julien",
      "year": "2025",
      "month": "Jul",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "39344205",
      "doi": "10.1111/jcmm.70101",
      "title": "Cross-modal integration of bulk RNA-seq and single-cell RNA sequencing data to reveal T-cell exhaustion in colorectal cancer.",
      "abstract": "Colorectal cancer (CRC) is a relatively common malignancy clinically and the second leading cause of cancer-related deaths. Recent studies have identified T-cell exhaustion as playing a crucial role in the pathogenesis of CRC. A long-standing challenge in the clinical management of CRC is to understand how T cells function during its progression and metastasis, and whether potential therapeutic targets for CRC treatment can be predicted through T cells. Here, we propose DeepTEX, a multi-omics deep learning approach that integrates cross-model data to investigate the heterogeneity of T-cell exhaustion in CRC. DeepTEX uses a domain adaptation model to align the data distributions from two different modalities and applies a cross-modal knowledge distillation model to predict the heterogeneity of T-cell exhaustion across diverse patients, identifying key functional pathways and genes. DeepTEX offers valuable insights into the application of deep learning in multi-omics, providing crucial data for exploring the stages of T-cell exhaustion associated with CRC and relevant therapeutic targets.",
      "authors": "Xu Mingcong; Zhang Guorui; Cui Ting; Liu Jiaqi; Wang Qiuyu; Shang Desi; Yu Tingting; Guo Bingzhou; Huang Jinjie; Li Chunquan",
      "year": "2024",
      "month": "Sep",
      "journal": "Journal of cellular and molecular medicine",
      "source": "pubmed"
    },
    {
      "pmid": "39330017",
      "doi": "10.3390/curroncol31090389",
      "title": "Artificial Intelligence in Head and Neck Cancer: Innovations, Applications, and Future Directions.",
      "abstract": "Artificial intelligence (AI) is revolutionizing head and neck cancer (HNC) care by providing innovative tools that enhance diagnostic accuracy and personalize treatment strategies. This review highlights the advancements in AI technologies, including deep learning and natural language processing, and their applications in HNC. The integration of AI with imaging techniques, genomics, and electronic health records is explored, emphasizing its role in early detection, biomarker discovery, and treatment planning. Despite noticeable progress, challenges such as data quality, algorithmic bias, and the need for interdisciplinary collaboration remain. Emerging innovations like explainable AI, AI-powered robotics, and real-time monitoring systems are poised to further advance the field. Addressing these challenges and fostering collaboration among AI experts, clinicians, and researchers is crucial for developing equitable and effective AI applications. The future of AI in HNC holds significant promise, offering potential breakthroughs in diagnostics, personalized therapies, and improved patient outcomes.",
      "authors": "Pham Tuan D; Teh Muy-Teck; Chatzopoulou Domniki; Holmes Simon; Coulthard Paul",
      "year": "2024",
      "month": "Sep",
      "journal": "Current oncology (Toronto, Ont.)",
      "source": "pubmed"
    },
    {
      "pmid": "39321458",
      "doi": "10.2196/59505",
      "title": "Multimodal Large Language Models in Health Care: Applications, Challenges, and Future Outlook.",
      "abstract": "In the complex and multidimensional field of medicine, multimodal data are prevalent and crucial for informed clinical decisions. Multimodal data span a broad spectrum of data types, including medical images (eg, MRI and CT scans), time-series data (eg, sensor data from wearable devices and electronic health records), audio recordings (eg, heart and respiratory sounds and patient interviews), text (eg, clinical notes and research articles), videos (eg, surgical procedures), and omics data (eg, genomics and proteomics). While advancements in large language models (LLMs) have enabled new applications for knowledge retrieval and processing in the medical field, most LLMs remain limited to processing unimodal data, typically text-based content, and often overlook the importance of integrating the diverse data modalities encountered in clinical practice. This paper aims to present a detailed, practical, and solution-oriented perspective on the use of multimodal LLMs (M-LLMs) in the medical field. Our investigation spanned M-LLM foundational principles, current and potential applications, technical and ethical challenges, and future research directions. By connecting these elements, we aimed to provide a comprehensive framework that links diverse aspects of M-LLMs, offering a unified vision for their future in health care. This approach aims to guide both future research and practical implementations of M-LLMs in health care, positioning them as a paradigm shift toward integrated, multimodal data-driven medical practice. We anticipate that this work will spark further discussion and inspire the development of innovative approaches in the next generation of medical M-LLM systems.",
      "authors": "AlSaad Rawan; Abd-Alrazaq Alaa; Boughorbel Sabri; Ahmed Arfan; Renault Max-Antoine; Damseh Rafat; Sheikh Javaid",
      "year": "2024",
      "month": "Sep",
      "journal": "Journal of medical Internet research",
      "source": "pubmed"
    },
    {
      "pmid": "39316944",
      "doi": "10.1093/bib/bbae469",
      "title": "Current computational tools for protein lysine acylation site prediction.",
      "abstract": "As a main subtype of post-translational modification (PTM), protein lysine acylations (PLAs) play crucial roles in regulating diverse functions of proteins. With recent advancements in proteomics technology, the identification of PTM is becoming a data-rich field. A large amount of experimentally verified data is urgently required to be translated into valuable biological insights. With computational approaches, PLA can be accurately detected across the whole proteome, even for organisms with small-scale datasets. Herein, a comprehensive summary of 166 in silico PLA prediction methods is presented, including a single type of PLA site and multiple types of PLA sites. This recapitulation covers important aspects that are critical for the development of a robust predictor, including data collection and preparation, sample selection, feature representation, classification algorithm design, model evaluation, and method availability. Notably, we discuss the application of protein language models and transfer learning to solve the small-sample learning issue. We also highlight the prediction methods developed for functionally relevant PLA sites and species/substrate/cell-type-specific PLA sites. In conclusion, this systematic review could potentially facilitate the development of novel PLA predictors and offer useful insights to researchers from various disciplines.",
      "authors": "Qin Zhaohui; Ren Haoran; Zhao Pei; Wang Kaiyuan; Liu Huixia; Miao Chunbo; Du Yanxiu; Li Junzhou; Wu Liuji; Chen Zhen",
      "year": "2024",
      "month": "Sep",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39303095",
      "doi": "10.1093/jbmr/zjae151",
      "title": "Linking transcriptome and morphology in bone cells at cellular resolution with generative AI.",
      "abstract": "Recent advancements in deep learning (DL) have revolutionized the capability of artificial intelligence (AI) by enabling the analysis of large-scale, complex datasets that are difficult for humans to interpret. However, large amounts of high-quality data are required to train such generative AI models successfully. With the rapid commercialization of single-cell sequencing and spatial transcriptomics platforms, the field is increasingly producing large-scale datasets such as histological images, single-cell molecular data, and spatial transcriptomic data. These molecular and morphological datasets parallel the multimodal text and image data used to train highly successful generative AI models for natural language processing and computer vision. Thus, these emerging data types offer great potential to train generative AI models that uncover intricate biological processes of bone cells at a cellular level. In this Perspective, we summarize the progress and prospects of generative AI applied to these datasets and their potential applications to bone research. In particular, we highlight three AI applications: predicting cell differentiation dynamics, linking molecular and morphological features, and predicting cellular responses to perturbations. To make generative AI models beneficial for bone research, important issues, such as technical biases in bone single-cell datasets, lack of profiling of important bone cell types, and lack of spatial information, needs to be addressed. Realizing the potential of generative AI for bone biology will also likely require generating large-scale, high-quality cellular-resolution spatial transcriptomics datasets, improving the sensitivity of current spatial transcriptomics datasets, and thorough experimental validation of model predictions.",
      "authors": "Lu Lu; Ono Noriaki; Welch Joshua D",
      "year": "2024",
      "month": "Dec",
      "journal": "Journal of bone and mineral research : the official journal of the American Society for Bone and Mineral Research",
      "source": "pubmed"
    },
    {
      "pmid": "39300113",
      "doi": "10.1038/s41467-024-52445-9",
      "title": "Detecting anomalous anatomic regions in spatial transcriptomics with STANDS.",
      "abstract": "Detection and Dissection of Anomalous Tissue Domains (DDATD) from multi-sample spatial transcriptomics (ST) data provides unprecedented opportunities to characterize anomalous tissue domains (ATDs), revealing both population-level and individual-specific pathogenic factors for understanding pathogenic heterogeneities behind diseases. However, no current methods can perform de novo DDATD from ST data, especially in the multi-sample context. Here, we introduce STANDS, an innovative framework based on Generative Adversarial Networks which integrates three core tasks in multi-sample DDATD: detecting, aligning, and subtyping ATDs. STANDS incorporates multimodal-learning, transfer-learning, and style-transfer techniques to effectively address major challenges in multi-sample DDATD, including complications caused by unalignable ATDs, under-utilization of multimodal information, and scarcity of normal ST datasets necessary for comparative analysis. Extensive benchmarks from diverse datasets demonstrate STAND's superiority in identifying both common and individual-specific ATDs and further dissecting them into biologically distinct subdomains. STANDS also provides clues to developing ATDs visually indistinguishable from surrounding normal tissues.",
      "authors": "Xu Kaichen; Lu Yan; Hou Suyang; Liu Kainan; Du Yihang; Huang Mengqian; Feng Hao; Wu Hao; Sun Xiaobo",
      "year": "2024",
      "month": "Sep",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "39294165",
      "doi": "10.1038/s41467-024-52533-w",
      "title": "Accurately predicting enzyme functions through geometric graph learning on ESMFold-predicted structures.",
      "abstract": "Enzymes are crucial in numerous biological processes, with the Enzyme Commission (EC) number being a commonly used method for defining enzyme function. However, current EC number prediction technologies have not fully recognized the importance of enzyme active sites and structural characteristics. Here, we propose GraphEC, a geometric graph learning-based EC number predictor using the ESMFold-predicted structures and a pre-trained protein language model. Specifically, we first construct a model to predict the enzyme active sites, which is utilized to predict the EC number. The prediction is further improved through a label diffusion algorithm by incorporating homology information. In parallel, the optimum pH of enzymes is predicted to reflect the enzyme-catalyzed reactions. Experiments demonstrate the superior performance of our model in predicting active sites, EC numbers, and optimum pH compared to other state-of-the-art methods. Additional analysis reveals that GraphEC is capable of extracting functional information from protein structures, emphasizing the effectiveness of geometric graph learning. This technology can be used to identify unannotated enzyme functions, as well as to predict their active sites and optimum pH, with the potential to advance research in synthetic biology, genomics, and other fields.",
      "authors": "Song Yidong; Yuan Qianmu; Chen Sheng; Zeng Yuansong; Zhao Huiying; Yang Yuedong",
      "year": "2024",
      "month": "Sep",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "39285512",
      "doi": "10.1093/bib/bbae448",
      "title": "Multimodal functional deep learning for multiomics data.",
      "abstract": "With rapidly evolving high-throughput technologies and consistently decreasing costs, collecting multimodal omics data in large-scale studies has become feasible. Although studying multiomics provides a new comprehensive approach in understanding the complex biological mechanisms of human diseases, the high dimensionality of omics data and the complexity of the interactions among various omics levels in contributing to disease phenotypes present tremendous analytical challenges. There is a great need of novel analytical methods to address these challenges and to facilitate multiomics analyses. In this paper, we propose a multimodal functional deep learning (MFDL) method for the analysis of high-dimensional multiomics data. The MFDL method models the complex relationships between multiomics variants and disease phenotypes through the hierarchical structure of deep neural networks and handles high-dimensional omics data using the functional data analysis technique. Furthermore, MFDL leverages the structure of the multimodal model to capture interactions between different types of omics data. Through simulation studies and real-data applications, we demonstrate the advantages of MFDL in terms of prediction accuracy and its robustness to the high dimensionality and noise within the data.",
      "authors": "Zhou Yuan; Geng Pei; Zhang Shan; Xiao Feifei; Cai Guoshuai; Chen Li; Lu Qing",
      "year": "2024",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39267420",
      "doi": "10.1177/15330338241277389",
      "title": "A 3 M Evaluation Protocol for Examining Lymph Nodes in Cancer Patients: Multi-Modal, Multi-Omics, Multi-Stage Approach.",
      "abstract": "Through meticulous examination of lymph nodes, the stage and severity of cancer can be determined. This information is invaluable for doctors to select the most appropriate treatment plan and predict patient prognosis; however, any oversight in the examination of lymph nodes may lead to cancer metastasis and poor prognosis. In this review, we summarize a significant number of articles supported by statistical data and clinical experience, proposing a standardized evaluation protocol for lymph nodes. This protocol begins with preoperative imaging to assess the presence of lymph node metastasis. Radiomics has replaced the single-modality approach, and deep learning models have been constructed to assist in image analysis with superior performance to that of the human eye. The focus of this review lies in intraoperative lymphadenectomy. Multiple international authorities have recommended specific numbers for lymphadenectomy in various cancers, providing surgeons with clear guidelines. These numbers are calculated by applying various statistical methods and real-world data. In the third chapter, we mention the growing concern about immune impairment caused by lymph node dissection, as the lack of CD8 memory T cells may have a negative impact on postoperative immunotherapy. Both excessive and less lymph node dissection have led to conflicting findings on postoperative immunotherapy. In conclusion, we propose a protocol that can be referenced by surgeons. With the systematic management of lymph nodes, we can control tumor progression with the greatest possible likelihood, optimize the preoperative examination process, reduce intraoperative risks, and improve postoperative quality of life.",
      "authors": "Wang Ruochong; Zhang Zhiyan; Zhao Mengyun; Zhu Guiquan",
      "year": "2024",
      "month": "",
      "journal": "Technology in cancer research & treatment",
      "source": "pubmed"
    },
    {
      "pmid": "39272021",
      "doi": "10.1186/s12859-024-05869-5",
      "title": "Distinguishing word identity and sequence context in DNA language models.",
      "abstract": "Transformer-based large language models (LLMs) are very suited for biological sequence data, because of analogies to natural language. Complex relationships can be learned, because a concept of \"words\" can be generated through tokenization. Training the models with masked token prediction, they learn both token sequence identity and larger sequence context. We developed methodology to interrogate model learning, which is both relevant for the interpretability of the model and to evaluate its potential for specific tasks. We used DNABERT, a DNA language model trained on the human genome with overlapping k-mers as tokens. To gain insight into the model's learning, we interrogated how the model performs predictions, extracted token embeddings, and defined a fine-tuning benchmarking task to predict the next tokens of different sizes without overlaps. This task evaluates foundation models without interrogating specific genome biology, it does not depend on tokenization strategies, vocabulary size, the dictionary, or the number of training parameters. Lastly, there is no leakage of information from token identity into the prediction task, which makes it particularly useful to evaluate the learning of sequence context. We discovered that the model with overlapping k-mers struggles to learn larger sequence context. Instead, the learned embeddings largely represent token sequence. Still, good performance is achieved for genome-biology-inspired fine-tuning tasks. Models with overlapping tokens may be used for tasks where a larger sequence context is of less relevance, but the token sequence directly represents the desired learning features. This emphasizes the need to interrogate knowledge representation in biological LLMs.",
      "authors": "Sanabria Melissa; Hirsch Jonas; Poetsch Anna R",
      "year": "2024",
      "month": "Sep",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39271260",
      "doi": "10.1016/bs.acr.2024.08.001",
      "title": "Deep learning-based multimodal spatial transcriptomics analysis for cancer.",
      "abstract": "The advent of deep learning (DL) and multimodal spatial transcriptomics (ST) has revolutionized cancer research, offering unprecedented insights into tumor biology. This book chapter explores the integration of DL with ST to advance cancer diagnostics, treatment planning, and precision medicine. DL, a subset of artificial intelligence, employs neural networks to model complex patterns in vast datasets, significantly enhancing diagnostic and treatment applications. In oncology, convolutional neural networks excel in image classification, segmentation, and tumor volume analysis, essential for identifying tumors and optimizing radiotherapy. The chapter also delves into multimodal data analysis, which integrates genomic, proteomic, imaging, and clinical data to offer a holistic understanding of cancer biology. Leveraging diverse data sources, researchers can uncover intricate details of tumor heterogeneity, microenvironment interactions, and treatment responses. Examples include integrating MRI data with genomic profiles for accurate glioma grading and combining proteomic and clinical data to uncover drug resistance mechanisms. DL's integration with multimodal data enables comprehensive and actionable insights for cancer diagnosis and treatment. The synergy between DL models and multimodal data analysis enhances diagnostic accuracy, personalized treatment planning, and prognostic modeling. Notable applications include ST, which maps gene expression patterns within tissue contexts, providing critical insights into tumor heterogeneity and potential therapeutic targets. In summary, the integration of DL and multimodal ST represents a paradigm shift towards more precise and personalized oncology. This chapter elucidates the methodologies and applications of these advanced technologies, highlighting their transformative potential in cancer research and clinical practice.",
      "authors": "Rajdeo Pankaj; Aronow Bruce; Surya Prasath V B",
      "year": "2024",
      "month": "",
      "journal": "Advances in cancer research",
      "source": "pubmed"
    },
    {
      "pmid": "39255657",
      "doi": "10.1016/j.compbiomed.2024.109082",
      "title": "Proximogram-A multi-omics network-based framework to capture tissue heterogeneity integrating single-cell omics and spatial profiling.",
      "abstract": "The increasing availability of patient-derived multimodal biological data for various diseases has opened up avenues for finding the optimal methods for jointly leveraging the information extracted in a customizable and scalable manner. Here, we propose the Proximogram, a graph-based representation that provides a joint construct for embedding independently obtained omics and spatial data. To evaluate the representation, we generated proximograms from 2 distinct biological sources, namely, multiplexed immunofluorescence images and single-cell RNA-seq data obtained from patients across two pancreatic diseases that include normal and chronic Pancreatitis (CP) and pancreatic ductal adenocarcinoma (PDAC). The generated proximograms were used as inputs to 2 distinct graph deep-learning models. The improved classification results over simpler spatial-data-based input graphs point to the increased discriminatory power obtained by integrating structural information from single-cell ligand-receptor signaling data and the spatial architecture of cells in each disease class, which can help point to markers of high diagnostic significance.",
      "authors": "Krishnan Santhoshi N; Ji Sunjong; Elhossiny Ahmed M; Rao Achyutha; Frankel Timothy L; Rao Arvind",
      "year": "2024",
      "month": "Nov",
      "journal": "Computers in biology and medicine",
      "source": "pubmed"
    },
    {
      "pmid": "39232270",
      "doi": "10.1016/j.artmed.2024.102972",
      "title": "SG-Fusion: A swin-transformer and graph convolution-based multi-modal deep neural network for glioma prognosis.",
      "abstract": "The integration of morphological attributes extracted from histopathological images and genomic data holds significant importance in advancing tumor diagnosis, prognosis, and grading. Histopathological images are acquired through microscopic examination of tissue slices, providing valuable insights into cellular structures and pathological features. On the other hand, genomic data provides information about tumor gene expression and functionality. The fusion of these two distinct data types is crucial for gaining a more comprehensive understanding of tumor characteristics and progression. In the past, many studies relied on single-modal approaches for tumor diagnosis. However, these approaches had limitations as they were unable to fully harness the information from multiple data sources. To address these limitations, researchers have turned to multi-modal methods that concurrently leverage both histopathological images and genomic data. These methods better capture the multifaceted nature of tumors and enhance diagnostic accuracy. Nonetheless, existing multi-modal methods have, to some extent, oversimplified the extraction processes for both modalities and the fusion process. In this study, we presented a dual-branch neural network, namely SG-Fusion. Specifically, for the histopathological modality, we utilize the Swin-Transformer structure to capture both local and global features and incorporate contrastive learning to encourage the model to discern commonalities and differences in the representation space. For the genomic modality, we developed a graph convolutional network based on gene functional and expression level similarities. Additionally, our model integrates a cross-attention module to enhance information interaction and employs divergence-based regularization to enhance the model's generalization performance. Validation conducted on glioma datasets from the Cancer Genome Atlas unequivocally demonstrates that our SG-Fusion model outperforms both single-modal methods and existing multi-modal approaches in both survival analysis and tumor grading.",
      "authors": "Fu Minghan; Fang Ming; Khan Rayyan Azam; Liao Bo; Hu Zhanli; Wu Fang-Xiang",
      "year": "2024",
      "month": "Nov",
      "journal": "Artificial intelligence in medicine",
      "source": "pubmed"
    },
    {
      "pmid": "39214760",
      "doi": "10.1016/S2589-7500(24)00151-1",
      "title": "The potential for large language models to transform cardiovascular medicine.",
      "abstract": "Cardiovascular diseases persist as the leading cause of death globally and their early detection and prediction remain a major challenge. Artificial intelligence (AI) tools can help meet this challenge as they have considerable potential for early diagnosis and prediction of occurrence of these diseases. Deep neural networks can improve the accuracy of medical image interpretation and their outputs can provide rich information that otherwise would not be detected by cardiologists. With recent advances in transformer models, multimodal AI, and large language models, the ability to integrate electronic health record data with images, genomics, biosensors, and other data has the potential to improve diagnosis and partition patients who are at high risk for primary preventive strategies. Although much emphasis has been placed on AI supporting clinicians, AI can also serve patients and provide immediate help with diagnosis, such as that of arrhythmia, and is being studied for automated self-imaging. Potential risks, such as loss of data privacy or potential diagnostic errors, should be addressed before use in clinical practice. This Series paper explores opportunities and limitations of AI models for cardiovascular medicine, and aims to identify specific barriers to and solutions in the application of AI models, facilitating their integration into health-care systems.",
      "authors": "Quer Giorgio; Topol Eric J",
      "year": "2024",
      "month": "Oct",
      "journal": "The Lancet. Digital health",
      "source": "pubmed"
    },
    {
      "pmid": "39212609",
      "doi": "10.1093/bioinformatics/btae529",
      "title": "Are genomic language models all you need? Exploring genomic language models on protein downstream tasks.",
      "abstract": "Large language models, trained on enormous corpora of biological sequences, are state-of-the-art for downstream genomic and proteomic tasks. Since the genome contains the information to encode all proteins, genomic language models (gLMs) hold the potential to make downstream predictions not only about DNA sequences, but also about proteins. However, the performance of gLMs on protein tasks remains unknown, due to few tasks pairing proteins with the coding DNA sequences (CDS) that can be processed by gLMs. In this work, we curated five such datasets and used them to evaluate the performance of gLMs and proteomic language models (pLMs). We show that gLMs are competitive and even outperform their pLMs counterparts on some tasks. The best performance was achieved using the retrieved CDS compared to sampling strategies. We found that training a joint genomic-proteomic model outperforms each individual approach, showing that they capture different but complementary sequence representations, as we demonstrate through model interpretation of their embeddings. Lastly, we explored different genomic tokenization schemes to improve downstream protein performance. We trained a new Nucleotide Transformer (50M) foundation model with 3mer tokenization that outperforms its 6mer counterpart on protein tasks while maintaining performance on genomics tasks. The application of gLMs to proteomics offers the potential to leverage rich CDS data, and in the spirit of the central dogma, the possibility of a unified and synergistic approach to genomics and proteomics. We make our inference code, 3mer pre-trained model weights and datasets available.",
      "authors": "Boshar Sam; Trop Evan; de Almeida Bernardo P; Copoiu Liviu; Pierrot Thomas",
      "year": "2024",
      "month": "Sep",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "39211867",
      "doi": "10.1101/2024.07.31.24311182",
      "title": "Achieving Inclusive Healthcare through Integrating Education and Research with AI and Personalized Curricula.",
      "abstract": "Precision medicine promises significant health benefits but faces challenges such as complex data management and analytics, interdisciplinary collaboration, and education of researchers, healthcare professionals, and participants. Addressing these needs requires the integration of computational experts, engineers, designers, and healthcare professionals to develop user-friendly systems and shared terminologies. The widespread adoption of large language models (LLMs) such as Generative Pretrained Transformer (GPT) and Claude highlights the importance of making complex data accessible to non-specialists. We evaluated the Stanford Data Ocean (SDO) precision medicine training program's learning outcomes, AI Tutor performance, and learner satisfaction by assessing self-rated competency on key learning objectives through pre- and post-learning surveys, along with formative and summative assessment completion rates. We also analyzed AI Tutor accuracy and learners' self-reported satisfaction, and post-program academic and career impacts. Additionally, we demonstrated the capabilities of the AI Data Visualization tool. SDO demonstrates the ability to improve learning outcomes for learners from broad educational and socioeconomic backgrounds with the support of the AI Tutor. The AI Data Visualization tool enables learners to interpret multi-omics and wearable data and replicate research findings. SDO strives to mitigate challenges in precision medicine through a scalable, cloud-based platform that supports data management for various data types, advanced research, and personalized learning. SDO provides AI tutors and AI-powered data visualization tools to enhance educational and research outcomes and make data analysis accessible to users from broad educational backgrounds. By extending engagement and cutting-edge research capabilities globally, SDO particularly benefits economically disadvantaged and historically marginalized communities, fostering interdisciplinary biomedical research and bridging the gap between education and practical application in the biomedical field. Precision medicine is the use of various types of health data specific to an individual to improve disease prevention, diagnosis, or treatment. We used artificial intelligence to build a precision medicine learning platform for clinicians and researchers in training. Students in 95 countries accessed the platform and found it helpful. It could be particularly helpful for training students in low- and middle-income countries.",
      "authors": "Bahmani Amir; Cha Kexin; Alavi Arash; Dixit Amit; Ross Antony; Park Ryan; Goncalves Francesca; Ma Shirley; Saxman Paul; Nair Ramesh; Akhavan-Sarraf Ramin; Zhou Xin; Wang Meng; Contrepois Kévin; Li-Pook-Than Jennifer; Monte Emma; Florez Rodriguez David Jose; Lai Jaslene; Babu Mohan; Tondar Abtin; Schüssler-Fiorenza Rose Sophia Miryam; Akbari Ilya; Zhang Xinyue; Yegnashankaran Kritika; Yracheta Joseph; Dale Kali; Miller Alison Derbenwick; Edmiston Scott; McGhee Eva M; Nebeker Camille; Wu Joseph C; Kundaje Anshul; Snyder Michael",
      "year": "2025",
      "month": "Aug",
      "journal": "medRxiv : the preprint server for health sciences",
      "source": "pubmed"
    },
    {
      "pmid": "39199425",
      "doi": "10.3390/biom14081039",
      "title": "MMFSyn: A Multimodal Deep Learning Model for Predicting Anticancer Synergistic Drug Combination Effect.",
      "abstract": "Combination therapy aims to synergistically enhance efficacy or reduce toxic side effects and has widely been used in clinical practice. However, with the rapid increase in the types of drug combinations, identifying the synergistic relationships between drugs remains a highly challenging task. This paper proposes a novel deep learning model MMFSyn based on multimodal drug data combined with cell line features. Firstly, to ensure the full expression of drug molecular features, multiple modalities of drugs, including Morgan fingerprints, atom sequences, molecular diagrams, and atomic point cloud data, are extracted using SMILES. Secondly, for different modal data, a Bi-LSTM, gMLP, multi-head attention mechanism, and multi-scale GCNs are comprehensively applied to extract the drug feature. Then, it selects appropriate omics features from gene expression and mutation omics data of cancer cell lines to construct cancer cell line features. Finally, these features are combined to predict the synergistic anti-cancer drug combination effect. The experimental results verify that MMFSyn has significant advantages in performance compared to other popular methods, with a root mean square error of 13.33 and a Pearson correlation coefficient of 0.81, which indicates that MMFSyn can better capture the complex relationship between multimodal drug combinations and omics data, thereby improving the synergistic drug combination prediction.",
      "authors": "Yang Tao; Li Haohao; Kang Yanlei; Li Zhong",
      "year": "2024",
      "month": "Aug",
      "journal": "Biomolecules",
      "source": "pubmed"
    },
    {
      "pmid": "39196755",
      "doi": "10.1093/bioinformatics/btae528",
      "title": "Deep5hmC: predicting genome-wide 5-hydroxymethylcytosine landscape via a multimodal deep learning model.",
      "abstract": "5-Hydroxymethylcytosine (5hmC), a crucial epigenetic mark with a significant role in regulating tissue-specific gene expression, is essential for understanding the dynamic functions of the human genome. Despite its importance, predicting 5hmC modification across the genome remains a challenging task, especially when considering the complex interplay between DNA sequences and various epigenetic factors such as histone modifications and chromatin accessibility. Using tissue-specific 5hmC sequencing data, we introduce Deep5hmC, a multimodal deep learning framework that integrates both the DNA sequence and epigenetic features such as histone modification and chromatin accessibility to predict genome-wide 5hmC modification. The multimodal design of Deep5hmC demonstrates remarkable improvement in predicting both qualitative and quantitative 5hmC modification compared to unimodal versions of Deep5hmC and state-of-the-art machine learning methods. This improvement is demonstrated through benchmarking on a comprehensive set of 5hmC sequencing data collected at four developmental stages during forebrain organoid development and across 17 human tissues. Compared to DeepSEA and random forest, Deep5hmC achieves close to 4% and 17% improvement of Area Under the Receiver Operating Characteristic (AUROC) across four forebrain developmental stages, and 6% and 27% across 17 human tissues for predicting binary 5hmC modification sites; and 8% and 22% improvement of Spearman correlation coefficient across four forebrain developmental stages, and 17% and 30% across 17 human tissues for predicting continuous 5hmC modification. Notably, Deep5hmC showcases its practical utility by accurately predicting gene expression and identifying differentially hydroxymethylated regions (DhMRs) in a case-control study of Alzheimer's disease (AD). Deep5hmC significantly improves our understanding of tissue-specific gene regulation and facilitates the development of new biomarkers for complex diseases. Deep5hmC is available via https://github.com/lichen-lab/Deep5hmC.",
      "authors": "Ma Xin; Thela Sai Ritesh; Zhao Fengdi; Yao Bing; Wen Zhexing; Jin Peng; Zhao Jinying; Chen Li",
      "year": "2024",
      "month": "Sep",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "39180095",
      "doi": "10.1186/s13321-024-00897-y",
      "title": "Deep learning of multimodal networks with topological regularization for drug repositioning.",
      "abstract": "Computational techniques for drug-disease prediction are essential in enhancing drug discovery and repositioning. While many methods utilize multimodal networks from various biological databases, few integrate comprehensive multi-omics data, including transcriptomes, proteomes, and metabolomes. We introduce STRGNN, a novel graph deep learning approach that predicts drug-disease relationships using extensive multimodal networks comprising proteins, RNAs, metabolites, and compounds. We have constructed a detailed dataset incorporating multi-omics data and developed a learning algorithm with topological regularization. This algorithm selectively leverages informative modalities while filtering out redundancies. STRGNN demonstrates superior accuracy compared to existing methods and has identified several novel drug effects, corroborating existing literature. STRGNN emerges as a powerful tool for drug prediction and discovery. The source code for STRGNN, along with the dataset for performance evaluation, is available at https://github.com/yuto-ohnuki/STRGNN.git .",
      "authors": "Ohnuki Yuto; Akiyama Manato; Sakakibara Yasubumi",
      "year": "2024",
      "month": "Aug",
      "journal": "Journal of cheminformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39146935",
      "doi": "10.1016/j.ajhg.2024.07.011",
      "title": "Evaluating large language models on medical, lay-language, and self-reported descriptions of genetic conditions.",
      "abstract": "Large language models (LLMs) are generating interest in medical settings. For example, LLMs can respond coherently to medical queries by providing plausible differential diagnoses based on clinical notes. However, there are many questions to explore, such as evaluating differences between open- and closed-source LLMs as well as LLM performance on queries from both medical and non-medical users. In this study, we assessed multiple LLMs, including Llama-2-chat, Vicuna, Medllama2, Bard/Gemini, Claude, ChatGPT3.5, and ChatGPT-4, as well as non-LLM approaches (Google search and Phenomizer) regarding their ability to identify genetic conditions from textbook-like clinician questions and their corresponding layperson translations related to 63 genetic conditions. For open-source LLMs, larger models were more accurate than smaller LLMs: 7b, 13b, and larger than 33b parameter models obtained accuracy ranges from 21%-49%, 41%-51%, and 54%-68%, respectively. Closed-source LLMs outperformed open-source LLMs, with ChatGPT-4 performing best (89%-90%). Three of 11 LLMs and Google search had significant performance gaps between clinician and layperson prompts. We also evaluated how in-context prompting and keyword removal affected open-source LLM performance. Models were provided with 2 types of in-context prompts: list-type prompts, which improved LLM performance, and definition-type prompts, which did not. We further analyzed removal of rare terms from descriptions, which decreased accuracy for 5 of 7 evaluated LLMs. Finally, we observed much lower performance with real individuals' descriptions; LLMs answered these questions with a maximum 21% accuracy.",
      "authors": "Flaharty Kendall A; Hu Ping; Hanchard Suzanna Ledgister; Ripper Molly E; Duong Dat; Waikel Rebekah L; Solomon Benjamin D",
      "year": "2024",
      "month": "Sep",
      "journal": "American journal of human genetics",
      "source": "pubmed"
    },
    {
      "pmid": "39131363",
      "doi": "10.1101/2024.07.26.605391",
      "title": "Protein Set Transformer: A protein-based genome language model to power high diversity viromics.",
      "abstract": "Exponential increases in microbial and viral genomic data demand transformational advances in scalable, generalizable frameworks for their interpretation. Standard homology-based functional analyses are hindered by the rapid divergence of microbial and especially viral genomes and proteins that significantly decreases the volume of usable data. Here, we present Protein Set Transformer (PST), a protein-based genome language model that models genomes as sets of proteins without considering sparsely available functional labels. Trained on >100k viruses, PST outperformed other homology- and language model-based approaches for relating viral genomes based on shared protein content. Further, PST demonstrated protein structural and functional awareness by clustering capsid-fold-containing proteins with known capsid proteins and uniquely clustering late gene proteins within related viruses. Our data establish PST as a valuable method for diverse viral genomics, ecology, and evolutionary applications. We posit that the PST framework can be a foundation model for microbial genomics when trained on suitable data.",
      "authors": "Martin Cody; Gitter Anthony; Anantharaman Karthik",
      "year": "2025",
      "month": "Jun",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "39131290",
      "doi": "10.1101/2024.07.31.605432",
      "title": "Imputing abundance of over 2500 surface proteins from single-cell transcriptomes with context-agnostic zero-shot deep ensembles.",
      "abstract": "Cell surface proteins serve as primary drug targets and cell identity markers. The emergence of techniques like CITE-seq has enabled simultaneous quantification of surface protein abundance and transcript expression for multimodal data analysis within individual cells. The published data have been utilized to train machine learning models for predicting surface protein abundance based solely from transcript expression. However, the small scale of proteins predicted and the poor generalization ability for these computational approaches across diverse contexts, such as different tissues or disease states, impede their widespread adoption. Here we propose SPIDER (surface protein prediction using deep ensembles from single-cell RNA-seq), a context-agnostic zero-shot deep ensemble model, which enables the large-scale prediction of cell surface protein abundance and generalizes better to various contexts. Comprehensive benchmarking shows that SPIDER outperforms other state-of-the-art methods. Using the predicted surface abundance of >2500 proteins from single-cell transcriptomes, we demonstrate the broad applications of SPIDER including cell type annotation, biomarker/target identification, and cell-cell interaction analysis in hepatocellular carcinoma and colorectal cancer.",
      "authors": "Chen Ruoqiao; Zhou Jiayu; Chen Bin",
      "year": "2024",
      "month": "Jul",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "39131276",
      "doi": "10.1101/2024.08.01.606099",
      "title": "EPInformer: a scalable deep learning framework for gene expression prediction by integrating promoter-enhancer sequences with multimodal epigenomic data.",
      "abstract": "Transcriptional regulation, critical for cellular differentiation and adaptation to environmental changes, involves coordinated interactions among DNA sequences, regulatory proteins, and chromatin architecture. Despite extensive data from consortia like ENCODE, understanding the dynamics of cis-regulatory elements (CREs) in gene expression remains challenging. Deep learning is a powerful tool for learning gene expression and epigenomic signals from DNA sequences, exhibiting superior performance compared to conventional machine learning approaches. However, even the most advanced deep learning-based methods may fall short in capturing the regulatory effects of distal elements such as enhancers, limiting their predictive accuracy. In addition, these methods may require significant resources to train or to adapt to newly generated data. To address these challenges, we present EPInformer, a scalable deep-learning framework for predicting gene expression by integrating promoter-enhancer interactions with their sequences, epigenomic signals, and chromatin contacts. Our model outperforms existing gene expression prediction models in rigorous cross-chromosome validation, accurately recapitulates enhancer-gene interactions validated by CRISPR perturbation experiments, and identifies crucial transcription factor motifs within regulatory sequences. EPInformer is available as open-source software at https://github.com/pinellolab/EPInformer.",
      "authors": "Lin Jiecong; Luo Ruibang; Pinello Luca",
      "year": "2024",
      "month": "Aug",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "39120644",
      "doi": "10.1093/bib/bbae388",
      "title": "xSiGra: explainable model for single-cell spatial data elucidation.",
      "abstract": "Recent advancements in spatial imaging technologies have revolutionized the acquisition of high-resolution multichannel images, gene expressions, and spatial locations at the single-cell level. Our study introduces xSiGra, an interpretable graph-based AI model, designed to elucidate interpretable features of identified spatial cell types, by harnessing multimodal features from spatial imaging technologies. By constructing a spatial cellular graph with immunohistology images and gene expression as node attributes, xSiGra employs hybrid graph transformer models to delineate spatial cell types. Additionally, xSiGra integrates a novel variant of gradient-weighted class activation mapping component to uncover interpretable features, including pivotal genes and cells for various cell types, thereby facilitating deeper biological insights from spatial data. Through rigorous benchmarking against existing methods, xSiGra demonstrates superior performance across diverse spatial imaging datasets. Application of xSiGra on a lung tumor slice unveils the importance score of cells, illustrating that cellular activity is not solely determined by itself but also impacted by neighboring cells. Moreover, leveraging the identified interpretable genes, xSiGra reveals endothelial cell subset interacting with tumor cells, indicating its heterogeneous underlying mechanisms within complex cellular interactions.",
      "authors": "Budhkar Aishwarya; Tang Ziyang; Liu Xiang; Zhang Xuhong; Su Jing; Song Qianqian",
      "year": "2024",
      "month": "Jul",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "39118787",
      "doi": "10.3389/frai.2024.1408843",
      "title": "Multimodal data integration for oncology in the era of deep neural networks: a review.",
      "abstract": "Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.",
      "authors": "Waqas Asim; Tripathi Aakash; Ramachandran Ravi P; Stewart Paul A; Rasool Ghulam",
      "year": "2024",
      "month": "",
      "journal": "Frontiers in artificial intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "39117678",
      "doi": "10.1038/s41514-024-00163-3",
      "title": "Precious2GPT: the combination of multiomics pretrained transformer and conditional diffusion for artificial multi-omics multi-species multi-tissue sample generation.",
      "abstract": "Synthetic data generation in omics mimics real-world biological data, providing alternatives for training and evaluation of genomic analysis tools, controlling differential expression, and exploring data architecture. We previously developed Precious1GPT, a multimodal transformer trained on transcriptomic and methylation data, along with metadata, for predicting biological age and identifying dual-purpose therapeutic targets potentially implicated in aging and age-associated diseases. In this study, we introduce Precious2GPT, a multimodal architecture that integrates Conditional Diffusion (CDiffusion) and decoder-only Multi-omics Pretrained Transformer (MoPT) models trained on gene expression and DNA methylation data. Precious2GPT excels in synthetic data generation, outperforming Conditional Generative Adversarial Networks (CGANs), CDiffusion, and MoPT. We demonstrate that Precious2GPT is capable of generating representative synthetic data that captures tissue- and age-specific information from real transcriptomics and methylomics data. Notably, Precious2GPT surpasses other models in age prediction accuracy using the generated data, and it can generate data beyond 120 years of age. Furthermore, we showcase the potential of using this model in identifying gene signatures and potential therapeutic targets in a colorectal cancer case study.",
      "authors": "Sidorenko Denis; Pushkov Stefan; Sakip Akhmed; Leung Geoffrey Ho Duen; Lok Sarah Wing Yan; Urban Anatoly; Zagirova Diana; Veviorskiy Alexander; Tihonova Nina; Kalashnikov Aleksandr; Kozlova Ekaterina; Naumov Vladimir; Pun Frank W; Aliper Alex; Ren Feng; Zhavoronkov Alex",
      "year": "2024",
      "month": "Aug",
      "journal": "npj aging",
      "source": "pubmed"
    },
    {
      "pmid": "39107889",
      "doi": "10.1093/bioinformatics/btae461",
      "title": "BertSNR: an interpretable deep learning framework for single-nucleotide resolution identification of transcription factor binding sites based on DNA language model.",
      "abstract": "Transcription factors are pivotal in the regulation of gene expression, and accurate identification of transcription factor binding sites (TFBSs) at high resolution is crucial for understanding the mechanisms underlying gene regulation. The task of identifying TFBSs from DNA sequences is a significant challenge in the field of computational biology today. To address this challenge, a variety of computational approaches have been developed. However, these methods face limitations in their ability to achieve high-resolution identification and often lack interpretability. We propose BertSNR, an interpretable deep learning framework for identifying TFBSs at single-nucleotide resolution. BertSNR integrates sequence-level and token-level information by multi-task learning based on pre-trained DNA language models. Benchmarking comparisons show that our BertSNR outperforms the existing state-of-the-art methods in TFBS predictions. Importantly, we enhanced the interpretability of the model through attentional weight visualization and motif analysis, and discovered the subtle relationship between attention weight and motif. Moreover, BertSNR effectively identifies TFBSs in promoter regions, facilitating the study of intricate gene regulation. The BertSNR source code can be found at https://github.com/lhy0322/BertSNR.",
      "authors": "Luo Hanyu; Tang Li; Zeng Min; Yin Rui; Ding Pingjian; Luo Lingyun; Li Min",
      "year": "2024",
      "month": "Aug",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "39107505",
      "doi": "10.1038/s41598-024-69198-6",
      "title": "MOSBY enables multi-omic inference and spatial biomarker discovery from whole slide images.",
      "abstract": "The utility of deep neural nets has been demonstrated for mapping hematoxylin-and-eosin (H&E) stained image features to expression of individual genes. However, these models have not been employed to discover clinically relevant spatial biomarkers. Here we develop MOSBY (Multi-Omic translation of whole slide images for Spatial Biomarker discoverY) that leverages contrastive self-supervised pretraining to extract improved H&E whole slide images features, learns a mapping between image and bulk omic profiles (RNA, DNA, and protein), and utilizes tile-level information to discover spatial biomarkers. We validate MOSBY gene and gene set predictions with spatial transcriptomic and serially-sectioned CD8 IHC image data. We demonstrate that MOSBY-inferred colocalization features have survival-predictive power orthogonal to gene expression, and enable concordance indices highly competitive with survival-trained multimodal networks. We identify and validate (1) an ER stress-associated colocalization feature as a chemotherapy-specific risk factor in lung adenocarcinoma, and (2) the colocalization of T effector cell vs cysteine signatures as a negative prognostic factor in multiple cancer indications. The discovery of clinically relevant biologically interpretable spatial biomarkers showcases the utility of the model in unraveling novel insights in cancer biology as well as informing clinical decision-making.",
      "authors": "Şenbabaoğlu Yasin; Prabhakar Vignesh; Khormali Aminollah; Eastham Jeff; Liu Evan; Warner Elisa; Nabet Barzin; Srivastava Minu; Ballinger Marcus; Liu Kai",
      "year": "2024",
      "month": "Aug",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "39095360",
      "doi": "10.1038/s41467-024-50837-5",
      "title": "Tissue characterization at an enhanced resolution across spatial omics platforms with deep generative model.",
      "abstract": "Recent advances in spatial omics have expanded the spectrum of profiled molecular categories beyond transcriptomics. However, many of these technologies are constrained by limited spatial resolution, hindering our ability to deeply characterize intricate tissue architectures. Existing computational methods primarily focus on the resolution enhancement of transcriptomics data, lacking the adaptability to address the emerging spatial omics technologies that profile various omics types. Here, we introduce soScope, a unified generative framework designed to enhance data quality and spatial resolution for molecular profiles obtained from diverse spatial technologies. soScope aggregates multimodal tissue information from omics, spatial relations and images, and jointly infers omics profiles at enhanced resolutions with omics-specific modeling through distribution priors. With comprehensive evaluations on diverse spatial omics platforms, including Visium, Xenium, spatial-CUT&Tag, and slide-DNA/RNA-seq, soScope improves performances in identifying biologically meaningful intestine and kidney architectures, revealing embryonic heart structure that cannot be resolved at the original resolution and correcting sample and technical biases arising from sequencing and sample processing. Furthermore, soScope extends to spatial multiomics technology spatial-CITE-seq and spatial ATAC-RNA-seq, leveraging cross-omics reference for simultaneous multiomics enhancement. soScope provides a versatile tool to improve the utilization of continually expanding spatial omics technologies and resources.",
      "authors": "Li Bohan; Bao Feng; Hou Yimin; Li Fengji; Li Hongjue; Deng Yue; Dai Qionghai",
      "year": "2024",
      "month": "Aug",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "39075536",
      "doi": "10.1186/s13059-024-03338-z",
      "title": "scCross: a deep generative model for unifying single-cell multi-omics with seamless integration, cross-modal generation, and in silico exploration.",
      "abstract": "Single-cell multi-omics data reveal complex cellular states, providing significant insights into cellular dynamics and disease. Yet, integration of multi-omics data presents challenges. Some modalities have not reached the robustness or clarity of established transcriptomics. Coupled with data scarcity for less established modalities and integration intricacies, these challenges limit our ability to maximize single-cell omics benefits. We introduce scCross, a tool leveraging variational autoencoders, generative adversarial networks, and the mutual nearest neighbors (MNN) technique for modality alignment. By enabling single-cell cross-modal data generation, multi-omics data simulation, and in silico cellular perturbations, scCross enhances the utility of single-cell multi-omics studies.",
      "authors": "Yang Xiuhui; Mann Koren K; Wu Hao; Ding Jun",
      "year": "2024",
      "month": "Jul",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "39062661",
      "doi": "10.3390/genes15070882",
      "title": "CrossMP: Enabling Cross-Modality Translation between Single-Cell RNA-Seq and Single-Cell ATAC-Seq through Web-Based Portal.",
      "abstract": "In recent years, there has been a growing interest in profiling multiomic modalities within individual cells simultaneously. One such example is integrating combined single-cell RNA sequencing (scRNA-seq) data and single-cell transposase-accessible chromatin sequencing (scATAC-seq) data. Integrated analysis of diverse modalities has helped researchers make more accurate predictions and gain a more comprehensive understanding than with single-modality analysis. However, generating such multimodal data is technically challenging and expensive, leading to limited availability of single-cell co-assay data. Here, we propose a model for cross-modal prediction between the transcriptome and chromatin profiles in single cells. Our model is based on a deep neural network architecture that learns the latent representations from the source modality and then predicts the target modality. It demonstrates reliable performance in accurately translating between these modalities across multiple paired human scATAC-seq and scRNA-seq datasets. Additionally, we developed CrossMP, a web-based portal allowing researchers to upload their single-cell modality data through an interactive web interface and predict the other type of modality data, using high-performance computing resources plugged at the backend.",
      "authors": "Lyu Zhen; Dahal Sabin; Zeng Shuai; Wang Juexin; Xu Dong; Joshi Trupti",
      "year": "2024",
      "month": "Jul",
      "journal": "Genes",
      "source": "pubmed"
    },
    {
      "pmid": "39062108",
      "doi": "10.3390/biomedicines12071535",
      "title": "Large Language Models and Genomics for Summarizing the Role of microRNA in Regulating mRNA Expression.",
      "abstract": "microRNA (miRNA)-messenger RNA (mRNA or gene) interactions are pivotal in various biological processes, including the regulation of gene expression, cellular differentiation, proliferation, apoptosis, and development, as well as the maintenance of cellular homeostasis and pathogenesis of numerous diseases, such as cancer, cardiovascular diseases, neurological disorders, and metabolic conditions. Understanding the mechanisms of miRNA-mRNA interactions can provide insights into disease mechanisms and potential therapeutic targets. However, extracting these interactions efficiently from a huge collection of published articles in PubMed is challenging. In the current study, we annotated a miRNA-mRNA Interaction Corpus (MMIC) and used it for evaluating the performance of a variety of machine learning (ML) models, deep learning-based transformer (DLT) models, and large language models (LLMs) in extracting the miRNA-mRNA interactions mentioned in PubMed. We used the genomics approaches for validating the extracted miRNA-mRNA interactions. Among the ML, DLT, and LLM models, PubMedBERT showed the highest precision, recall, and F-score, with all equal to 0.783. Among the LLM models, the performance of Llama-2 is better when compared to others. Llama 2 achieved 0.56 precision, 0.86 recall, and 0.68 F-score in a zero-shot experiment and 0.56 precision, 0.87 recall, and 0.68 F-score in a three-shot experiment. Our study shows that Llama 2 achieves better recall than ML and DLT models and leaves space for further improvement in terms of precision and F-score.",
      "authors": "Bhasuran Balu; Manoharan Sharanya; Iyyappan Oviya Ramalakshmi; Murugesan Gurusamy; Prabahar Archana; Raja Kalpana",
      "year": "2024",
      "month": "Jul",
      "journal": "Biomedicines",
      "source": "pubmed"
    },
    {
      "pmid": "39040448",
      "doi": "10.3389/fonc.2024.1432212",
      "title": "Unveiling the landscape of pathomics in personalized immunotherapy for lung cancer: a bibliometric analysis.",
      "abstract": "Pathomics has emerged as a promising biomarker that could facilitate personalized immunotherapy in lung cancer. It is essential to elucidate the global research trends and emerging prospects in this domain. The annual distribution, journals, authors, countries, institutions, and keywords of articles published between 2018 and 2023 were visualized and analyzed using CiteSpace and other bibliometric tools. A total of 109 relevant articles or reviews were included, demonstrating an overall upward trend; The terms \"deep learning\", \"tumor microenvironment\", \"biomarkers\", \"image analysis\", \"immunotherapy\", and \"survival prediction\", etc. are hot keywords in this field. In future research endeavors, advanced methodologies involving artificial intelligence and pathomics will be deployed for the digital analysis of tumor tissues and the tumor microenvironment in lung cancer patients, leveraging histopathological tissue sections. Through the integration of comprehensive multi-omics data, this strategy aims to enhance the depth of assessment, characterization, and understanding of the tumor microenvironment, thereby elucidating a broader spectrum of tumor features. Consequently, the development of a multimodal fusion model will ensue, enabling precise evaluation of personalized immunotherapy efficacy and prognosis for lung cancer patients, potentially establishing a pivotal frontier in this domain of investigation.",
      "authors": "Yuan Lei; Shen Zhiming; Shan Yibo; Zhu Jianwei; Wang Qi; Lu Yi; Shi Hongcan",
      "year": "2024",
      "month": "",
      "journal": "Frontiers in oncology",
      "source": "pubmed"
    },
    {
      "pmid": "39035833",
      "doi": "10.1016/j.csbj.2024.06.019",
      "title": "Deep Learning of radiology-genomics integration for computational oncology: A mini review.",
      "abstract": "In the field of computational oncology, patient status is often assessed using radiology-genomics, which includes two key technologies and data, such as radiology and genomics. Recent advances in deep learning have facilitated the integration of radiology-genomics data, and even new omics data, significantly improving the robustness and accuracy of clinical predictions. These factors are driving artificial intelligence (AI) closer to practical clinical applications. In particular, deep learning models are crucial in identifying new radiology-genomics biomarkers and therapeutic targets, supported by explainable AI (xAI) methods. This review focuses on recent developments in deep learning for radiology-genomics integration, highlights current challenges, and outlines some research directions for multimodal integration and biomarker discovery of radiology-genomics or radiology-omics that are urgently needed in computational oncology.",
      "authors": "Wang Feng-Ao; Li Yixue; Zeng Tao",
      "year": "2024",
      "month": "Dec",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "39006822",
      "doi": "10.3389/fpsyt.2024.1384842",
      "title": "Multi-modal deep learning from imaging genomic data for schizophrenia classification.",
      "abstract": "Schizophrenia (SZ) is a psychiatric condition that adversely affects an individual's cognitive, emotional, and behavioral aspects. The etiology of SZ, although extensively studied, remains unclear, as multiple factors come together to contribute toward its development. There is a consistent body of evidence documenting the presence of structural and functional deviations in the brains of individuals with SZ. Moreover, the hereditary aspect of SZ is supported by the significant involvement of genomics markers. Therefore, the need to investigate SZ from a multi-modal perspective and develop approaches for improved detection arises. Our proposed method employed a deep learning framework combining features from structural magnetic resonance imaging (sMRI), functional magnetic resonance imaging (fMRI), and genetic markers such as single nucleotide polymorphism (SNP). For sMRI, we used a pre-trained DenseNet to extract the morphological features. To identify the most relevant functional connections in fMRI and SNPs linked to SZ, we applied a 1-dimensional convolutional neural network (CNN) followed by layerwise relevance propagation (LRP). Finally, we concatenated these obtained features across modalities and fed them to the extreme gradient boosting (XGBoost) tree-based classifier to classify SZ from healthy control (HC). Experimental evaluation on clinical dataset demonstrated that, compared to the outcomes obtained from each modality individually, our proposed multi-modal approach performed classification of SZ individuals from HC with an improved accuracy of 79.01%. We proposed a deep learning based framework that selects multi-modal (sMRI, fMRI and genetic) features efficiently and fuse them to obtain improved classification scores. Additionally, by using Explainable AI (XAI), we were able to pinpoint and validate significant functional network connections and SNPs that contributed the most toward SZ classification, providing necessary interpretation behind our findings.",
      "authors": "Kanyal Ayush; Mazumder Badhan; Calhoun Vince D; Preda Adrian; Turner Jessica; Ford Judith; Ye Dong Hye",
      "year": "2024",
      "month": "",
      "journal": "Frontiers in psychiatry",
      "source": "pubmed"
    },
    {
      "pmid": "39001231",
      "doi": "10.3390/diagnostics14131339",
      "title": "Gene-Based Predictive Modelling for Enhanced Detection of Systemic Lupus Erythematosus Using CNN-Based DL Algorithm.",
      "abstract": "Systemic Lupus Erythematosus (SLE) is a multifaceted autoimmune disease that presents with a diverse array of clinical signs and unpredictable disease progression. Conventional diagnostic methods frequently fall short in terms of sensitivity and specificity, which can result in delayed diagnosis and less-than-optimal management. In this study, we introduce a novel approach for improving the identification of SLE through the use of gene-based predictive modelling and Stacked deep learning classifiers. The study proposes a new method for diagnosing SLE using Stacked Deep Learning Classifiers (SDLC) trained on Gene Expression Omnibus (GEO) database data. By combining transcriptomic data from GEO with clinical features and laboratory results, the SDLC model achieves a remarkable accuracy value of 0.996, outperforming traditional methods. Individual models within the SDLC, such as SBi-LSTM and ACNN, achieved accuracies of 92% and 95%, respectively. The SDLC's ensemble learning approach allows for identifying complex patterns in multi-modal data, enhancing accuracy in diagnosing SLE. This study emphasises the potential of deep learning methods, in conjunction with open repositories like GEO, to advance the diagnosis and management of SLE. Overall, this research shows strong performance and potential for improving precision medicine in managing SLE.",
      "authors": "Subramani Jothimani; Kumar G Sathish; Gadekallu Thippa Reddy",
      "year": "2024",
      "month": "Jun",
      "journal": "Diagnostics (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "38990290",
      "doi": "10.1097/JS9.0000000000001875",
      "title": "Artificial intelligence-based multi-modal multi-tasks analysis reveals tumor molecular heterogeneity, predicts preoperative lymph node metastasis and prognosis in papillary thyroid carcinoma: a retrospective study.",
      "abstract": "Papillary thyroid carcinoma (PTC) is the predominant form of thyroid cancer globally, especially when lymph node metastasis (LNM) occurs. Molecular heterogeneity, driven by genetic alterations and tumor microenvironment components, contributes to the complexity of PTC. Understanding these complexities is essential for precise risk stratification and therapeutic decisions. This study involved a comprehensive analysis of 521 patients with PTC from our hospital and 499 patients from The Cancer Genome Atlas (TCGA). The real-world cohort 1 comprised 256 patients with stage I-III PTC. Tissues from 252 patients were analyzed by DNA-based next-generation sequencing, and tissues from four patients were analyzed by single-cell RNA sequencing (scRNA-seq). Additionally, 586 PTC pathological sections were collected from TCGA, and 275 PTC pathological sections were collected from the real-world cohort 2. A deep-learning multi-modal model was developed using matched histopathology images, genomic, transcriptomic, and immune cell data to predict LNM and disease-free survival (DFS). This study included a total of 1011 PTC patients, comprising 256 patients from cohort 1, 275 patients from cohort 2, and 499 patients from TCGA. In cohort 1, the authors categorized PTC into four molecular subtypes based on BRAF, RAS, RET, and other mutations. BRAF mutations were significantly associated with LNM and impacted DFS. ScRNA-seq identified distinct T-cell subtypes and reduced B-cell diversity in BRAF-mutated PTC with LNM. The study also explored cancer-associated fibroblasts and macrophages, highlighting their associations with LNM. The deep-learning model was trained using 405 pathology slides and RNA sequences from 328 PTC patients and validated with 181 slides and RNA sequences from 140 PTC patients in the TCGA cohort. It achieved high accuracy, with an area under the curve (AUC) of 0.86 in the training cohort, 0.84 in the validation cohort, and 0.83 in the real-world cohort 2. High-risk patients in the training cohort had significantly lower DFS rates ( P <0.001). Model AUCs were 0.91 at 1 year, 0.93 at 3 years, and 0.87 at 5 years. In the validation cohort, high-risk patients also had lower DFS ( P <0.001); the AUCs were 0.89, 0.87, and 0.80 at 1, 3, and 5 years. The authors utilized the GradCAM algorithm to generate heatmaps from pathology-based deep-learning models, which visually highlighted high-risk tumor areas in PTC patients. This enhanced clinicians' understanding of the model's predictions and improved diagnostic accuracy, especially in cases with lymph node metastasis. The artificial intelligence (AI)-based analysis uncovered vital insights into PTC molecular heterogeneity, emphasizing BRAF mutations' impact. The integrated deep-learning model shows promise in predicting metastasis, offering valuable contributions to improved diagnostic and therapeutic strategies.",
      "authors": "Yu Yunfang; Ouyang Wenhao; Huang Yunxi; Huang Hong; Wang Zehua; Jia Xueyuan; Huang Zhenjun; Lin Ruichong; Zhu Yue; Yalikun Yisitandaer; Tan Langping; Li Xi; Zhao Fei; Chen Zhange; Li Wenting; Liao Jianwei; Yao Herui; Long Miaoyun",
      "year": "2025",
      "month": "Jan",
      "journal": "International journal of surgery (London, England)",
      "source": "pubmed"
    },
    {
      "pmid": "38982288",
      "doi": "10.1038/s42003-024-06465-2",
      "title": "A foundational large language model for edible plant genomes.",
      "abstract": "Significant progress has been made in the field of plant genomics, as demonstrated by the increased use of high-throughput methodologies that enable the characterization of multiple genome-wide molecular phenotypes. These findings have provided valuable insights into plant traits and their underlying genetic mechanisms, particularly in model plant species. Nonetheless, effectively leveraging them to make accurate predictions represents a critical step in crop genomic improvement. We present AgroNT, a foundational large language model trained on genomes from 48 plant species with a predominant focus on crop species. We show that AgroNT can obtain state-of-the-art predictions for regulatory annotations, promoter/terminator strength, tissue-specific gene expression, and prioritize functional variants. We conduct a large-scale in silico saturation mutagenesis analysis on cassava to evaluate the regulatory impact of over 10 million mutations and provide their predicted effects as a resource for variant characterization. Finally, we propose the use of the diverse datasets compiled here as the Plants Genomic Benchmark (PGB), providing a comprehensive benchmark for deep learning-based methods in plant genomic research. The pre-trained AgroNT model is publicly available on HuggingFace at https://huggingface.co/InstaDeepAI/agro-nucleotide-transformer-1b  for future research purposes.",
      "authors": "Mendoza-Revilla Javier; Trop Evan; Gonzalez Liam; Roller Maša; Dalla-Torre Hugo; de Almeida Bernardo P; Richard Guillaume; Caton Jonathan; Lopez Carranza Nicolas; Skwark Marcin; Laterre Alex; Beguir Karim; Pierrot Thomas; Lopez Marie",
      "year": "2024",
      "month": "Jul",
      "journal": "Communications biology",
      "source": "pubmed"
    },
    {
      "pmid": "38981473",
      "doi": "10.1016/j.crmeth.2024.100817",
      "title": "Cross-attention enables deep learning on limited omics-imaging-clinical data of 130 lung cancer patients.",
      "abstract": "Deep-learning tools that extract prognostic factors derived from multi-omics data have recently contributed to individualized predictions of survival outcomes. However, the limited size of integrated omics-imaging-clinical datasets poses challenges. Here, we propose two biologically interpretable and robust deep-learning architectures for survival prediction of non-small cell lung cancer (NSCLC) patients, learning simultaneously from computed tomography (CT) scan images, gene expression data, and clinical information. The proposed models integrate patient-specific clinical, transcriptomic, and imaging data and incorporate Kyoto Encyclopedia of Genes and Genomes (KEGG) and Reactome pathway information, adding biological knowledge within the learning process to extract prognostic gene biomarkers and molecular pathways. While both models accurately stratify patients in high- and low-risk groups when trained on a dataset of only 130 patients, introducing a cross-attention mechanism in a sparse autoencoder significantly improves the performance, highlighting tumor regions and NSCLC-related genes as potential biomarkers and thus offering a significant methodological advancement when learning from small imaging-omics-clinical samples.",
      "authors": "Verma Suraj; Magazzù Giuseppe; Eftekhari Noushin; Lou Thai; Gilhespy Alex; Occhipinti Annalisa; Angione Claudio",
      "year": "2024",
      "month": "Jul",
      "journal": "Cell reports methods",
      "source": "pubmed"
    },
    {
      "pmid": "38978567",
      "doi": "10.21203/rs.3.rs-4536158/v1",
      "title": "Spatial Deconvolution of Cell Types and Cell States at Scale Utilizing TACIT.",
      "abstract": "Identifying cell types and states remains a time-consuming, error-prone challenge for spatial biology. While deep learning is increasingly used, it is difficult to generalize due to variability at the level of cells, neighborhoods, and niches in health and disease. To address this, we developed TACIT, an unsupervised algorithm for cell annotation using predefined signatures that operates without training data. TACIT uses unbiased thresholding to distinguish positive cells from background, focusing on relevant markers to identify ambiguous cells in multiomic assays. Using five datasets (5,000,000-cells; 51-cell types) from three niches (brain, intestine, gland), TACIT outperformed existing unsupervised methods in accuracy and scalability. Integrating TACIT-identified cell types with a novel Shiny app revealed new phenotypes in two inflammatory gland diseases. Finally, using combined spatial transcriptomics and proteomics, we discovered under- and overrepresented immune cell types and states in regions of interest, suggesting multimodality is essential for translating spatial biology to clinical applications.",
      "authors": "Huynh Khoa L A; Tyc Katarzyna M; Matuck Bruno F; Easter Quinn T; Pratapa Aditya; Kumar Nikhil V; Pérez Paola; Kulchar Rachel J; Pranzatelli Thomas J F; de Souza Deiziane; Weaver Theresa M; Qu Xufeng; Soares Junior Luiz Alberto Valente; Dolhnokoff Marisa; Kleiner David E; Hewitt Stephen M; Ferraz da Silva Luiz Fernando; Rocha Vanderson Geraldo; Warner Blake M; Byrd Kevin M; Liu Jinze",
      "year": "2024",
      "month": "Jun",
      "journal": "Research square",
      "source": "pubmed"
    },
    {
      "pmid": "38972973",
      "doi": "10.1186/s12916-024-03482-0",
      "title": "Mining the interpretable prognostic features from pathological image of intrahepatic cholangiocarcinoma using multi-modal deep learning.",
      "abstract": "The advances in deep learning-based pathological image analysis have invoked tremendous insights into cancer prognostication. Still, lack of interpretability remains a significant barrier to clinical application. We established an integrative prognostic neural network for intrahepatic cholangiocarcinoma (iCCA), towards a comprehensive evaluation of both architectural and fine-grained information from whole-slide images. Then, leveraging on multi-modal data, we conducted extensive interrogative approaches to the models, to extract and visualize the morphological features that most correlated with clinical outcome and underlying molecular alterations. The models were developed and optimized on 373 iCCA patients from our center and demonstrated consistent accuracy and robustness on both internal (n = 213) and external (n = 168) cohorts. The occlusion sensitivity map revealed that the distribution of tertiary lymphoid structures, the geometric traits of the invasive margin, the relative composition of tumor parenchyma and stroma, the extent of necrosis, the presence of the disseminated foci, and the tumor-adjacent micro-vessels were the determining architectural features that impacted on prognosis. Quantifiable morphological vector extracted by CellProfiler demonstrated that tumor nuclei from high-risk patients exhibited significant larger size, more distorted shape, with less prominent nuclear envelope and textural contrast. The multi-omics data (n = 187) further revealed key molecular alterations left morphological imprints that could be attended by the network, including glycolysis, hypoxia, apical junction, mTORC1 signaling, and immune infiltration. We proposed an interpretable deep-learning framework to gain insights into the biological behavior of iCCA. Most of the significant morphological prognosticators perceived by the network are comprehensible to human minds.",
      "authors": "Ding Guang-Yu; Tan Wei-Min; Lin You-Pei; Ling Yu; Huang Wen; Zhang Shu; Shi Jie-Yi; Luo Rong-Kui; Ji Yuan; Wang Xiao-Ying; Zhou Jian; Fan Jia; Cai Mu-Yan; Yan Bo; Gao Qiang",
      "year": "2024",
      "month": "Jul",
      "journal": "BMC medicine",
      "source": "pubmed"
    },
    {
      "pmid": "38960869",
      "doi": "10.1515/jib-2023-0043",
      "title": "Transformers meets neoantigen detection: a systematic literature review.",
      "abstract": "Cancer immunology offers a new alternative to traditional cancer treatments, such as radiotherapy and chemotherapy. One notable alternative is the development of personalized vaccines based on cancer neoantigens. Moreover, Transformers are considered a revolutionary development in artificial intelligence with a significant impact on natural language processing (NLP) tasks and have been utilized in proteomics studies in recent years. In this context, we conducted a systematic literature review to investigate how Transformers are applied in each stage of the neoantigen detection process. Additionally, we mapped current pipelines and examined the results of clinical trials involving cancer vaccines.",
      "authors": "Machaca Vicente; Goyzueta Valeria; Cruz María Graciel; Sejje Erika; Pilco Luz Marina; López Julio; Túpac Yván",
      "year": "2024",
      "month": "Jun",
      "journal": "Journal of integrative bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "38956082",
      "doi": "10.1038/s41467-024-49806-9",
      "title": "Multi-modal generative modeling for joint analysis of single-cell T cell receptor and gene expression data.",
      "abstract": "Recent advances in single-cell immune profiling have enabled the simultaneous measurement of transcriptome and T cell receptor (TCR) sequences, offering great potential for studying immune responses at the cellular level. However, integrating these diverse modalities across datasets is challenging due to their unique data characteristics and technical variations. Here, to address this, we develop the multimodal generative model mvTCR to fuse modality-specific information across transcriptome and TCR into a shared representation. Our analysis demonstrates the added value of multimodal over unimodal approaches to capture antigen specificity. Notably, we use mvTCR to distinguish T cell subpopulations binding to SARS-CoV-2 antigens from bystander cells. Furthermore, when combined with reference mapping approaches, mvTCR can map newly generated datasets to extensive T cell references, facilitating knowledge transfer. In summary, we envision mvTCR to enable a scalable analysis of multimodal immune profiling data and advance our understanding of immune responses.",
      "authors": "Drost Felix; An Yang; Bonafonte-Pardàs Irene; Dratva Lisa M; Lindeboom Rik G H; Haniffa Muzlifah; Teichmann Sarah A; Theis Fabian; Lotfollahi Mohammad; Schubert Benjamin",
      "year": "2024",
      "month": "Jul",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "38955188",
      "doi": "10.1016/j.xgen.2024.100603",
      "title": "Mudskipper detects combinatorial RNA binding protein interactions in multiplexed CLIP data.",
      "abstract": "The uncovering of protein-RNA interactions enables a deeper understanding of RNA processing. Recent multiplexed crosslinking and immunoprecipitation (CLIP) technologies such as antibody-barcoded eCLIP (ABC) dramatically increase the throughput of mapping RNA binding protein (RBP) binding sites. However, multiplex CLIP datasets are multivariate, and each RBP suffers non-uniform signal-to-noise ratio. To address this, we developed Mudskipper, a versatile computational suite comprising two components: a Dirichlet multinomial mixture model to account for the multivariate nature of ABC datasets and a softmasking approach that identifies and removes non-specific protein-RNA interactions in RBPs with low signal-to-noise ratio. Mudskipper demonstrates superior precision and recall over existing tools on multiplex datasets and supports analysis of repetitive elements and small non-coding RNAs. Our findings unravel splicing outcomes and variant-associated disruptions, enabling higher-throughput investigations into diseases and regulation mediated by RBPs.",
      "authors": "Her Hsuanlin; Rothamel Katherine L; Nguyen Grady G; Boyle Evan A; Yeo Gene W",
      "year": "2024",
      "month": "Jul",
      "journal": "Cell genomics",
      "source": "pubmed"
    },
    {
      "pmid": "38948789",
      "doi": "10.1101/2024.06.12.598655",
      "title": "Signals in the Cells: Multimodal and Contextualized Machine Learning Foundations for Therapeutics.",
      "abstract": "Drug discovery AI datasets and benchmarks have not traditionally included single-cell analysis biomarkers. While benchmarking efforts in single-cell analysis have recently released collections of single-cell tasks, they have yet to comprehensively release datasets, models, and benchmarks that integrate a broad range of therapeutic discovery tasks with cell-type-specific biomarkers. Therapeutics Commons (TDC-2) presents datasets, tools, models, and benchmarks integrating cell-type-specific contextual features with ML tasks across therapeutics. We present four tasks for contextual learning at single-cell resolution: drug-target nomination, genetic perturbation response prediction, chemical perturbation response prediction, and protein-peptide interaction prediction. We introduce datasets, models, and benchmarks for these four tasks. Finally, we detail the advancements and challenges in machine learning and biology that drove the implementation of TDC-2 and how they are reflected in its architecture, datasets and benchmarks, and foundation model tooling.",
      "authors": "Velez-Arce Alejandro; Li Michelle M; Gao Wenhao; Lin Xiang; Huang Kexin; Fu Tianfan; Pentelute Bradley L; Kellis Manolis; Zitnik Marinka",
      "year": "2024",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38947922",
      "doi": "",
      "title": "AN INTERPRETABLE GENERATIVE MULTIMODAL NEUROIMAGING-GENOMICS FRAMEWORK FOR DECODING ALZHEIMER'S DISEASE.",
      "abstract": "Alzheimer's disease (AD) is the most prevalent form of dementia worldwide, encompassing a prodromal stage known as Mild Cognitive Impairment (MCI), where patients may either progress to AD or remain stable. The objective of the work was to capture structural and functional modulations of brain structure and function relying on multimodal MRI data and Single Nucleotide Polymorphisms, also in case of missing views, with the twofold goal of classifying AD patients versus healthy controls and detecting MCI converters. We propose a multimodal DL-based classification framework where a generative module employing Cycle Generative Adversarial Networks was introduced in the latent space for imputing missing data (a common issue of multimodal approaches). Explainable AI method was then used to extract input features' relevance allowing for post-hoc validation and enhancing the interpretability of the learned representations. Experimental results on two tasks, AD detection and MCI conversion, showed that our framework reached competitive performance in the state-of-the-art with an accuracy of 0.926 ± 0.02 and 0.711 ± 0.01 in the two tasks, respectively. The interpretability analysis revealed gray matter modulations in cortical and subcortical brain areas typically associated with AD. Moreover, impairments in sensory-motor and visual resting state networks along the disease continuum, as well as genetic mutations defining biological processes linked to endocytosis, amyloid-beta, and cholesterol, were identified. Our integrative and interpretable DL approach shows promising performance for AD detection and MCI prediction while shedding light on important biological insights.",
      "authors": "Dolci Giorgio; Cruciani Federica; Rahaman Md Abdur; Abrol Anees; Chen Jiayu; Fu Zening; Galazzo Ilaria Boscolo; Menegaz Gloria; Calhoun Vince D",
      "year": "2025",
      "month": "Feb",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "38935938",
      "doi": "10.2196/52700",
      "title": "ChatGPT and Medicine: Together We Embrace the AI Renaissance.",
      "abstract": "The generative artificial intelligence (AI) model ChatGPT holds transformative prospects in medicine. The development of such models has signaled the beginning of a new era where complex biological data can be made more accessible and interpretable. ChatGPT is a natural language processing tool that can process, interpret, and summarize vast data sets. It can serve as a digital assistant for physicians and researchers, aiding in integrating medical imaging data with other multiomics data and facilitating the understanding of complex biological systems. The physician's and AI's viewpoints emphasize the value of such AI models in medicine, providing tangible examples of how this could enhance patient care. The editorial also discusses the rise of generative AI, highlighting its substantial impact in democratizing AI applications for modern medicine. While AI may not supersede health care professionals, practitioners incorporating AI into their practices could potentially have a competitive edge.",
      "authors": "Hacking Sean",
      "year": "2024",
      "month": "May",
      "journal": "JMIR bioinformatics and biotechnology",
      "source": "pubmed"
    },
    {
      "pmid": "38935882",
      "doi": "10.1200/EDBK_438516",
      "title": "Applications of Artificial Intelligence in Prostate Cancer Care: A Path to Enhanced Efficiency and Outcomes.",
      "abstract": "The landscape of prostate cancer care has rapidly evolved. We have transitioned from the use of conventional imaging, radical surgeries, and single-agent androgen deprivation therapy to an era of advanced imaging, precision diagnostics, genomics, and targeted treatment options. Concurrently, the emergence of large language models (LLMs) has dramatically transformed the paradigm for artificial intelligence (AI). This convergence of advancements in prostate cancer management and AI provides a compelling rationale to comprehensively review the current state of AI applications in prostate cancer care. Here, we review the advancements in AI-driven applications across the continuum of the journey of a patient with prostate cancer from early interception to survivorship care. We subsequently discuss the role of AI in prostate cancer drug discovery, clinical trials, and clinical practice guidelines. In the localized disease setting, deep learning models demonstrated impressive performance in detecting and grading prostate cancer using imaging and pathology data. For biochemically recurrent diseases, machine learning approaches are being tested for improved risk stratification and treatment decisions. In advanced prostate cancer, deep learning can potentially improve prognostication and assist in clinical decision making. Furthermore, LLMs are poised to revolutionize information summarization and extraction, clinical trial design and operations, drug development, evidence synthesis, and clinical practice guidelines. Synergistic integration of multimodal data integration and human-AI integration are emerging as a key strategy to unlock the full potential of AI in prostate cancer care.",
      "authors": "Riaz Irbaz Bin; Harmon Stephanie; Chen Zhijun; Naqvi Syed Arsalan Ahmed; Cheng Liang",
      "year": "2024",
      "month": "Jun",
      "journal": "American Society of Clinical Oncology educational book. American Society of Clinical Oncology. Annual Meeting",
      "source": "pubmed"
    },
    {
      "pmid": "38928078",
      "doi": "10.3390/ijms25126371",
      "title": "ESMSec: Prediction of Secreted Proteins in Human Body Fluids Using Protein Language Models and Attention.",
      "abstract": "The secreted proteins of human body fluid have the potential to be used as biomarkers for diseases. These biomarkers can be used for early diagnosis and risk prediction of diseases, so the study of secreted proteins of human body fluid has great application value. In recent years, the deep-learning-based transformer language model has transferred from the field of natural language processing (NLP) to the field of proteomics, leading to the development of protein language models (PLMs) for protein sequence representation. Here, we propose a deep learning framework called ESM Predict Secreted Proteins (ESMSec) to predict three types of proteins secreted in human body fluid. The ESMSec is based on the ESM2 model and attention architecture. Specifically, the protein sequence data are firstly put into the ESM2 model to extract the feature information from the last hidden layer, and all the input proteins are encoded into a fixed 1000 × 480 matrix. Secondly, multi-head attention with a fully connected neural network is employed as the classifier to perform binary classification according to whether they are secreted into each body fluid. Our experiment utilized three human body fluids that are important and ubiquitous markers. Experimental results show that ESMSec achieved average accuracy of 0.8486, 0.8358, and 0.8325 on the testing datasets for plasma, cerebrospinal fluid (CSF), and seminal fluid, which on average outperform the state-of-the-art (SOTA) methods. The outstanding performance results of ESMSec demonstrate that the ESM can improve the prediction performance of the model and has great potential to screen the secretion information of human body fluid proteins.",
      "authors": "Wang Yan; Sun Huiting; Sheng Nan; He Kai; Hou Wenjv; Zhao Ziqi; Yang Qixing; Huang Lan",
      "year": "2024",
      "month": "Jun",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "38915408",
      "doi": "10.3389/fimmu.2024.1409555",
      "title": "Advancing precision rheumatology: applications of machine learning for rheumatoid arthritis management.",
      "abstract": "Rheumatoid arthritis (RA) is an autoimmune disease causing progressive joint damage. Early diagnosis and treatment is critical, but remains challenging due to RA complexity and heterogeneity. Machine learning (ML) techniques may enhance RA management by identifying patterns within multidimensional biomedical data to improve classification, diagnosis, and treatment predictions. In this review, we summarize the applications of ML for RA management. Emerging studies or applications have developed diagnostic and predictive models for RA that utilize a variety of data modalities, including electronic health records, imaging, and multi-omics data. High-performance supervised learning models have demonstrated an Area Under the Curve (AUC) exceeding 0.85, which is used for identifying RA patients and predicting treatment responses. Unsupervised learning has revealed potential RA subtypes. Ongoing research is integrating multimodal data with deep learning to further improve performance. However, key challenges remain regarding model overfitting, generalizability, validation in clinical settings, and interpretability. Small sample sizes and lack of diverse population testing risks overestimating model performance. Prospective studies evaluating real-world clinical utility are lacking. Enhancing model interpretability is critical for clinician acceptance. In summary, while ML shows promise for transforming RA management through earlier diagnosis and optimized treatment, larger scale multisite data, prospective clinical validation of interpretable models, and testing across diverse populations is still needed. As these gaps are addressed, ML may pave the way towards precision medicine in RA.",
      "authors": "Shi Yiming; Zhou Mi; Chang Cen; Jiang Ping; Wei Kai; Zhao Jianan; Shan Yu; Zheng Yixin; Zhao Fuyu; Lv Xinliang; Guo Shicheng; Wang Fubo; He Dongyi",
      "year": "2024",
      "month": "",
      "journal": "Frontiers in immunology",
      "source": "pubmed"
    },
    {
      "pmid": "38895432",
      "doi": "10.1101/2024.06.04.596709",
      "title": "Cross-species modeling of plant genomes at single nucleotide resolution using a pre-trained DNA language model.",
      "abstract": "Interpreting function and fitness effects in diverse plant genomes requires transferable models. Language models (LMs) pre-trained on large-scale biological sequences can learn evolutionary conservation and offer cross-species prediction better than supervised models through fine-tuning limited labeled data. We introduce PlantCaduceus, a plant DNA LM based on the Caduceus and Mamba architectures, pre-trained on a curated dataset of 16 Angiosperm genomes. Fine-tuning PlantCaduceus on limited labeled Arabidopsis data for four tasks, including predicting translation initiation/termination sites and splice donor and acceptor sites, demonstrated high transferability to 160 million year diverged maize, outperforming the best existing DNA LM by 1.45 to 7.23-fold. PlantCaduceus is competitive to state-of-the-art protein LMs in terms of deleterious mutation identification, and is threefold better than PhyloP. Additionally, PlantCaduceus successfully identifies well-known causal variants in both Arabidopsis and maize. Overall, PlantCaduceus is a versatile DNA LM that can accelerate plant genomics and crop breeding applications.",
      "authors": "Zhai Jingjing; Gokaslan Aaron; Schiff Yair; Berthel Ana; Liu Zong-Yan; Lai Wei-Yun; Miller Zachary R; Scheben Armin; Stitzer Michelle C; Romay M Cinta; Buckler Edward S; Kuleshov Volodymyr",
      "year": "2024",
      "month": "Aug",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38895230",
      "doi": "10.1101/2024.05.31.596861",
      "title": "Spatial Deconvolution of Cell Types and Cell States at Scale Utilizing TACIT.",
      "abstract": "Identifying cell types and states remains a time-consuming and error-prone challenge for spatial biology. While deep learning is increasingly used, it is difficult to generalize due to variability at the level of cells, neighborhoods, and niches in health and disease. To address this, we developed TACIT, an unsupervised algorithm for cell annotation using predefined signatures that operates without training data, using unbiased thresholding to distinguish positive cells from background, focusing on relevant markers to identify ambiguous cells in multiomic assays. Using five datasets (5,000,000-cells; 51-cell types) from three niches (brain, intestine, gland), TACIT outperformed existing unsupervised methods in accuracy and scalability. Integration of TACIT-identified cell with a novel Shiny app revealed new phenotypes in two inflammatory gland diseases. Finally, using combined spatial transcriptomics and proteomics, we discover under- and overrepresented immune cell types and states in regions of interest, suggesting multimodality is essential for translating spatial biology to clinical applications.",
      "authors": "Huynh Khoa L A; Tyc Katarzyna M; Matuck Bruno F; Easter Quinn T; Pratapa Aditya; Kumar Nikhil V; Pérez Paola; Kulchar Rachel; Pranzatelli Thomas; de Souza Deiziane; Weaver Theresa M; Qu Xufeng; Valente Soares Luiz Alberto; Dolhnokoff Marisa; Kleiner David E; Hewitt Stephen M; da Silva Luiz Fernando Ferraz; Rocha Vanderson Geraldo; Warner Blake M; Byrd Kevin M; Liu Jinze",
      "year": "2024",
      "month": "Jun",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38886164",
      "doi": "10.1093/bib/bbae284",
      "title": "Morphological profiling for drug discovery in the era of deep learning.",
      "abstract": "Morphological profiling is a valuable tool in phenotypic drug discovery. The advent of high-throughput automated imaging has enabled the capturing of a wide range of morphological features of cells or organisms in response to perturbations at the single-cell resolution. Concurrently, significant advances in machine learning and deep learning, especially in computer vision, have led to substantial improvements in analyzing large-scale high-content images at high throughput. These efforts have facilitated understanding of compound mechanism of action, drug repurposing, characterization of cell morphodynamics under perturbation, and ultimately contributing to the development of novel therapeutics. In this review, we provide a comprehensive overview of the recent advances in the field of morphological profiling. We summarize the image profiling analysis workflow, survey a broad spectrum of analysis strategies encompassing feature engineering- and deep learning-based approaches, and introduce publicly available benchmark datasets. We place a particular emphasis on the application of deep learning in this pipeline, covering cell segmentation, image representation learning, and multimodal learning. Additionally, we illuminate the application of morphological profiling in phenotypic drug discovery and highlight potential challenges and opportunities in this field.",
      "authors": "Tang Qiaosi; Ratnayake Ranjala; Seabra Gustavo; Jiang Zhe; Fang Ruogu; Cui Lina; Ding Yousong; Kahveci Tamer; Bian Jiang; Li Chenglong; Luesch Hendrik; Li Yanjun",
      "year": "2024",
      "month": "May",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "38883738",
      "doi": "10.1101/2024.06.01.24308293",
      "title": "Histopathology and proteomics are synergistic for High-Grade Serous Ovarian Cancer platinum response prediction.",
      "abstract": "Patients with High-Grade Serous Ovarian Cancer (HGSOC) exhibit varied responses to treatment, with 20-30% showing ",
      "authors": "Kilim Oz; Olar Alex; Biricz András; Madaras Lilla; Pollner Péter; Szállási Zoltán; Sztupinszki Zsofia; Csabai István",
      "year": "2024",
      "month": "Jun",
      "journal": "medRxiv : the preprint server for health sciences",
      "source": "pubmed"
    },
    {
      "pmid": "38872306",
      "doi": "10.1016/j.xplc.2024.101002",
      "title": "Dual-extraction modeling: A multi-modal deep-learning architecture for phenotypic prediction and functional gene mining of complex traits.",
      "abstract": "Despite considerable advances in extracting crucial insights from bio-omics data to unravel the intricate mechanisms underlying complex traits, the absence of a universal multi-modal computational tool with robust interpretability for accurate phenotype prediction and identification of trait-associated genes remains a challenge. This study introduces the dual-extraction modeling (DEM) approach, a multi-modal deep-learning architecture designed to extract representative features from heterogeneous omics datasets, enabling the prediction of complex trait phenotypes. Through comprehensive benchmarking experiments, we demonstrate the efficacy of DEM in classification and regression prediction of complex traits. DEM consistently exhibits superior accuracy, robustness, generalizability, and flexibility. Notably, we establish its effectiveness in predicting pleiotropic genes that influence both flowering time and rosette leaf number, underscoring its commendable interpretability. In addition, we have developed user-friendly software to facilitate seamless utilization of DEM's functions. In summary, this study presents a state-of-the-art approach with the ability to effectively predict qualitative and quantitative traits and identify functional genes, confirming its potential as a valuable tool for exploring the genetic basis of complex traits.",
      "authors": "Ren Yanlin; Wu Chenhua; Zhou He; Hu Xiaona; Miao Zhenyan",
      "year": "2024",
      "month": "Sep",
      "journal": "Plant communications",
      "source": "pubmed"
    },
    {
      "pmid": "38855263",
      "doi": "10.1038/s42256-024-00823-9",
      "title": "A 5' UTR Language Model for Decoding Untranslated Regions of mRNA and Function Predictions.",
      "abstract": "The 5' UTR, a regulatory region at the beginning of an mRNA molecule, plays a crucial role in regulating the translation process and impacts the protein expression level. Language models have showcased their effectiveness in decoding the functions of protein and genome sequences. Here, we introduced a language model for 5' UTR, which we refer to as the UTR-LM. The UTR-LM is pre-trained on endogenous 5' UTRs from multiple species and is further augmented with supervised information including secondary structure and minimum free energy. We fine-tuned the UTR-LM in a variety of downstream tasks. The model outperformed the best known benchmark by up to 5% for predicting the Mean Ribosome Loading, and by up to 8% for predicting the Translation Efficiency and the mRNA Expression Level. The model also applies to identifying unannotated Internal Ribosome Entry Sites within the untranslated region and improves the AUPR from 0.37 to 0.52 compared to the best baseline. Further, we designed a library of 211 novel 5' UTRs with high predicted values of translation efficiency and evaluated them via a wet-lab assay. Experiment results confirmed that our top designs achieved a 32.5% increase in protein production level relative to well-established 5' UTR optimized for therapeutics.",
      "authors": "Chu Yanyi; Yu Dan; Li Yupeng; Huang Kaixuan; Shen Yue; Cong Le; Zhang Jason; Wang Mengdi",
      "year": "2024",
      "month": "Apr",
      "journal": "Nature machine intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "38845006",
      "doi": "10.1186/s13059-024-03293-9",
      "title": "TMO-Net: an explainable pretrained multi-omics model for multi-task learning in oncology.",
      "abstract": "Cancer is a complex disease composing systemic alterations in multiple scales. In this study, we develop the Tumor Multi-Omics pre-trained Network (TMO-Net) that integrates multi-omics pan-cancer datasets for model pre-training, facilitating cross-omics interactions and enabling joint representation learning and incomplete omics inference. This model enhances multi-omics sample representation and empowers various downstream oncology tasks with incomplete multi-omics datasets. By employing interpretable learning, we characterize the contributions of distinct omics features to clinical outcomes. The TMO-Net model serves as a versatile framework for cross-modal multi-omics learning in oncology, paving the way for tumor omics-specific foundation models.",
      "authors": "Wang Feng-Ao; Zhuang Zhenfeng; Gao Feng; He Ruikun; Zhang Shaoting; Wang Liansheng; Liu Junwei; Li Yixue",
      "year": "2024",
      "month": "Jun",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "38826977",
      "doi": "10.7759/cureus.59507",
      "title": "Deep Learning Approaches for Medical Image Analysis and Diagnosis.",
      "abstract": "In addition to enhancing diagnostic accuracy, deep learning techniques offer the potential to streamline workflows, reduce interpretation time, and ultimately improve patient outcomes. The scalability and adaptability of deep learning algorithms enable their deployment across diverse clinical settings, ranging from radiology departments to point-of-care facilities. Furthermore, ongoing research efforts focus on addressing the challenges of data heterogeneity, model interpretability, and regulatory compliance, paving the way for seamless integration of deep learning solutions into routine clinical practice. As the field continues to evolve, collaborations between clinicians, data scientists, and industry stakeholders will be paramount in harnessing the full potential of deep learning for advancing medical image analysis and diagnosis. Furthermore, the integration of deep learning algorithms with other technologies, including natural language processing and computer vision, may foster multimodal medical data analysis and clinical decision support systems to improve patient care. The future of deep learning in medical image analysis and diagnosis is promising. With each success and advancement, this technology is getting closer to being leveraged for medical purposes. Beyond medical image analysis, patient care pathways like multimodal imaging, imaging genomics, and intelligent operating rooms or intensive care units can benefit from deep learning models.",
      "authors": "Thakur Gopal Kumar; Thakur Abhishek; Kulkarni Shridhar; Khan Naseebia; Khan Shahnawaz",
      "year": "2024",
      "month": "May",
      "journal": "Cureus",
      "source": "pubmed"
    },
    {
      "pmid": "38816885",
      "doi": "10.1186/s12915-024-01923-z",
      "title": "msBERT-Promoter: a multi-scale ensemble predictor based on BERT pre-trained model for the two-stage prediction of DNA promoters and their strengths.",
      "abstract": "A promoter is a specific sequence in DNA that has transcriptional regulatory functions, playing a role in initiating gene expression. Identifying promoters and their strengths can provide valuable information related to human diseases. In recent years, computational methods have gained prominence as an effective means for identifying promoter, offering a more efficient alternative to labor-intensive biological approaches. In this study, a two-stage integrated predictor called \"msBERT-Promoter\" is proposed for identifying promoters and predicting their strengths. The model incorporates multi-scale sequence information through a tokenization strategy and fine-tunes the DNABERT model. Soft voting is then used to fuse the multi-scale information, effectively addressing the issue of insufficient DNA sequence information extraction in traditional models. To the best of our knowledge, this is the first time an integrated approach has been used in the DNABERT model for promoter identification and strength prediction. Our model achieves accuracy rates of 96.2% for promoter identification and 79.8% for promoter strength prediction, significantly outperforming existing methods. Furthermore, through attention mechanism analysis, we demonstrate that our model can effectively combine local and global sequence information, enhancing its interpretability. msBERT-Promoter provides an effective tool that successfully captures sequence-related attributes of DNA promoters and can accurately identify promoters and predict their strengths. This work paves a new path for the application of artificial intelligence in traditional biology.",
      "authors": "Li Yazi; Wei Xiaoman; Yang Qinglin; Xiong An; Li Xingfeng; Zou Quan; Cui Feifei; Zhang Zilong",
      "year": "2024",
      "month": "May",
      "journal": "BMC biology",
      "source": "pubmed"
    },
    {
      "pmid": "38798675",
      "doi": "10.21203/rs.3.rs-4355413/v1",
      "title": "Multimodal Learning for Mapping the Genotype-Phenotype Dynamics.",
      "abstract": "How complex phenotypes emerge from intricate gene expression patterns is a fundamental question in biology. Quantitative characterization of this relationship, however, is challenging due to the vast combinatorial possibilities and dynamic interplay between genotype and phenotype landscapes. Integrating high-content genotyping approaches such as single-cell RNA sequencing and advanced learning methods such as language models offers an opportunity for dissecting this complex relationship. Here, we present a computational integrated genetics framework designed to analyze and interpret the high-dimensional landscape of genotypes and their associated phenotypes simultaneously. We applied this approach to develop a multimodal foundation model to explore the genotype-phenotype relationship manifold for human transcriptomics at the cellular level. Analyzing this joint manifold showed a refined resolution of cellular heterogeneity, enhanced precision in phenotype annotating, and uncovered potential cross-tissue biomarkers that are undetectable through conventional gene expression analysis alone. Moreover, our results revealed that the gene networks are characterized by scale-free patterns and show context-dependent gene-gene interactions, both of which result in significant variations in the topology of the gene network, particularly evident during aging. Finally, utilizing contextualized embeddings, we investigated gene polyfunctionality which illustrates the multifaceted roles that genes play in different biological processes, and demonstrated that for VWF gene in endothelial cells. Overall, this study advances our understanding of the dynamic interplay between gene expression and phenotypic manifestation and demonstrates the potential of integrated genetics in uncovering new dimensions of cellular function and complexity.",
      "authors": "Khodaee Farhan; Zandie Rohola; Edelman Elazer R",
      "year": "2024",
      "month": "May",
      "journal": "Research square",
      "source": "pubmed"
    },
    {
      "pmid": "38754993",
      "doi": "10.1093/schbul/sbae069",
      "title": "Exploring Schizophrenia Classification Through Multimodal MRI and Deep Graph Neural Networks: Unveiling Brain Region-Specific Weight Discrepancies and Their Association With Cell-Type Specific Transcriptomic Features.",
      "abstract": "Schizophrenia (SZ) is a prevalent mental disorder that imposes significant health burdens. Diagnostic accuracy remains challenging due to clinical subjectivity. To address this issue, we explore magnetic resonance imaging (MRI) as a tool to enhance SZ diagnosis and provide objective references and biomarkers. Using deep learning with graph convolution, we represent MRI data as graphs, aligning with brain structure, and improving feature extraction, and classification. Integration of multiple modalities is expected to enhance classification. Our study enrolled 683 SZ patients and 606 healthy controls from 7 hospitals, collecting structural MRI and functional MRI data. Both data types were represented as graphs, processed by 2 graph attention networks, and fused for classification. Grad-CAM with graph convolution ensured interpretability, and partial least squares analyzed gene expression in brain regions. Our method excelled in the classification task, achieving 83.32% accuracy, 83.41% sensitivity, and 83.20% specificity in 10-fold cross-validation, surpassing traditional methods. And our multimodal approach outperformed unimodal methods. Grad-CAM identified potential brain biomarkers consistent with gene analysis and prior research. Our study demonstrates the effectiveness of deep learning with graph attention networks, surpassing previous SZ diagnostic methods. Multimodal MRI's superiority over unimodal MRI confirms our initial hypothesis. Identifying potential brain biomarkers alongside gene biomarkers holds promise for advancing objective SZ diagnosis and research in SZ.",
      "authors": "Gao Jingjing; Qian Maomin; Wang Zhengning; Li Yanling; Luo Na; Xie Sangma; Shi Weiyang; Li Peng; Chen Jun; Chen Yunchun; Wang Huaning; Liu Wenming; Li Zhigang; Yang Yongfeng; Guo Hua; Wan Ping; Lv Luxian; Lu Lin; Yan Jun; Song Yuqing; Wang Huiling; Zhang Hongxing; Wu Huawang; Ning Yuping; Du Yuhui; Cheng Yuqi; Xu Jian; Xu Xiufeng; Zhang Dai; Jiang Tianzai",
      "year": "2024",
      "month": "Dec",
      "journal": "Schizophrenia bulletin",
      "source": "pubmed"
    },
    {
      "pmid": "38748882",
      "doi": "10.1016/j.xpro.2024.103066",
      "title": "Protocol to perform integrative analysis of high-dimensional single-cell multimodal data using an interpretable deep learning technique.",
      "abstract": "The advent of single-cell multi-omics sequencing technology makes it possible for researchers to leverage multiple modalities for individual cells. Here, we present a protocol to perform integrative analysis of high-dimensional single-cell multimodal data using an interpretable deep learning technique called moETM. We describe steps for data preprocessing, multi-omics integration, inclusion of prior pathway knowledge, and cross-omics imputation. As a demonstration, we used the single-cell multi-omics data collected from bone marrow mononuclear cells (GSE194122) as in our original study. For complete details on the use and execution of this protocol, please refer to Zhou et al.",
      "authors": "Zhou Manqi; Zhang Hao; Bai Zilong; Mann-Krzisnik Dylan; Wang Fei; Li Yue",
      "year": "2024",
      "month": "Jun",
      "journal": "STAR protocols",
      "source": "pubmed"
    },
    {
      "pmid": "38746321",
      "doi": "10.1101/2024.04.27.591458",
      "title": "xSiGra: Explainable model for single-cell spatial data elucidation.",
      "abstract": "Recent advancements in spatial imaging technologies have revolutionized the acquisition of high-resolution multi-channel images, gene expressions, and spatial locations at the single-cell level. Our study introduces xSiGra, an interpretable graph-based AI model, designed to elucidate interpretable features of identified spatial cell types, by harnessing multi-modal features from spatial imaging technologies. By constructing a spatial cellular graph with immunohistology images and gene expression as node attributes, xSiGra employs hybrid graph transformer models to delineate spatial cell types. Additionally, xSiGra integrates a novel variant of Grad-CAM component to uncover interpretable features, including pivotal genes and cells for various cell types, thereby facilitating deeper biological insights from spatial data. Through rigorous benchmarking against existing methods, xSiGra demonstrates superior performance across diverse spatial imaging datasets. Application of xSiGra on a lung tumor slice unveils the importance score of cells, illustrating that cellular activity is not solely determined by itself but also impacted by neighboring cells. Moreover, leveraging the identified interpretable genes, xSiGra reveals endothelial cell subset interacting with tumor cells, indicating its heterogeneous underlying mechanisms within the complex cellular communications.",
      "authors": "Budhkar Aishwarya; Tang Ziyang; Liu Xiang; Zhang Xuhong; Su Jing; Song Qianqian",
      "year": "2024",
      "month": "Apr",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38746190",
      "doi": "10.1101/2024.04.30.591806",
      "title": "ntEmbd: Deep learning embedding for nucleotide sequences.",
      "abstract": "Enabled by the explosion of data and substantial increase in computational power, deep learning has transformed fields such as computer vision and natural language processing (NLP) and it has become a successful method to be applied to many transcriptomic analysis tasks. A core advantage of deep learning is its inherent capability to incorporate feature computation within the machine learning models. This results in a comprehensive and machine-readable representation of sequences, facilitating the downstream classification and clustering tasks. Compared to machine translation problems in NLP, feature embedding is particularly challenging for transcriptomic studies as the sequences are string of thousands of nucleotides in length, which make the long-term dependencies between features from different parts of the sequence even more difficult to capture. This highlights the need for nucleotide sequence embedding methods that are capable of learning input sequence features implicitly. Here we introduce ntEmbd, a deep learning embedding tool that captures dependencies between different features of the sequences and learns a latent representation for given nucleotide sequences. We further provide two sample use cases, describing how learned RNA features can be used in downstream analysis. The first use case demonstrates ntEmbd's utility in classifying coding and noncoding RNA benchmarked against existing tools, and the second one explores the utility of learned representations in identifying adapter sequences in nanopore RNA-seq reads. The tool as well as the trained models are freely available on GitHub at https://github.com/bcgsc/ntEmbd.",
      "authors": "Hafezqorani Saber; Nip Ka Ming; Birol Inanc",
      "year": "2024",
      "month": "May",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38741230",
      "doi": "10.1093/bioinformatics/btae316",
      "title": "Pathformer: a biological pathway informed transformer for disease diagnosis and prognosis using multi-omics data.",
      "abstract": "Multi-omics data provide a comprehensive view of gene regulation at multiple levels, which is helpful in achieving accurate diagnosis of complex diseases like cancer. However, conventional integration methods rarely utilize prior biological knowledge and lack interpretability. To integrate various multi-omics data of tissue and liquid biopsies for disease diagnosis and prognosis, we developed a biological pathway informed Transformer, Pathformer. It embeds multi-omics input with a compacted multi-modal vector and a pathway-based sparse neural network. Pathformer also leverages criss-cross attention mechanism to capture the crosstalk between different pathways and modalities. We first benchmarked Pathformer with 18 comparable methods on multiple cancer datasets, where Pathformer outperformed all the other methods, with an average improvement of 6.3%-14.7% in F1 score for cancer survival prediction, 5.1%-12% for cancer stage prediction, and 8.1%-13.6% for cancer drug response prediction. Subsequently, for cancer prognosis prediction based on tissue multi-omics data, we used a case study to demonstrate the biological interpretability of Pathformer by identifying key pathways and their biological crosstalk. Then, for cancer early diagnosis based on liquid biopsy data, we used plasma and platelet datasets to demonstrate Pathformer's potential of clinical applications in cancer screening. Moreover, we revealed deregulation of interesting pathways (e.g. scavenger receptor pathway) and their crosstalk in cancer patients' blood, providing potential candidate targets for cancer microenvironment study. Pathformer is implemented and freely available at https://github.com/lulab/Pathformer.",
      "authors": "Liu Xiaofan; Tao Yuhuan; Cai Zilin; Bao Pengfei; Ma Hongli; Li Kexing; Li Mengtao; Zhu Yunping; Lu Zhi John",
      "year": "2024",
      "month": "May",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "38707535",
      "doi": "10.1016/j.csbj.2024.04.039",
      "title": "A contrastive learning approach to integrate spatial transcriptomics and histological images.",
      "abstract": "The rapid growth of spatially resolved transcriptomics technology provides new perspectives on spatial tissue architecture. Deep learning has been widely applied to derive useful representations for spatial transcriptome analysis. However, effectively integrating spatial multi-modal data remains challenging. Here, we present ConGcR, a contrastive learning-based model for integrating gene expression, spatial location, and tissue morphology for data representation and spatial tissue architecture identification. Graph convolution and ResNet were used as encoders for gene expression with spatial location and histological image inputs, respectively. We further enhanced ConGcR with a graph auto-encoder as ConGaR to better model spatially embedded representations. We validated our models using 16 human brains, four chicken hearts, eight breast tumors, and 30 human lung spatial transcriptomics samples. The results showed that our models generated more effective embeddings for obtaining tissue architectures closer to the ground truth than other methods. Overall, our models not only can improve tissue architecture identification's accuracy but also may provide valuable insights and effective data representation for other tasks in spatial transcriptome analyses.",
      "authors": "Lin Yu; Liang Yanchun; Wang Duolin; Chang Yuzhou; Ma Qin; Wang Yan; He Fei; Xu Dong",
      "year": "2024",
      "month": "Dec",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "38689652",
      "doi": "10.3389/fgene.2024.1377285",
      "title": "iDNA-OpenPrompt: OpenPrompt learning model for identifying DNA methylation.",
      "abstract": "",
      "authors": "Yu Xia; Ren Jia; Long Haixia; Zeng Rao; Zhang Guoqiang; Bilal Anas; Cui Yani",
      "year": "2024",
      "month": "",
      "journal": "Frontiers in genetics",
      "source": "pubmed"
    },
    {
      "pmid": "38665395",
      "doi": "10.3390/info15010007",
      "title": "Data Augmentation with Cross-Modal Variational Autoencoders (DACMVA) for Cancer Survival Prediction.",
      "abstract": "The ability to translate Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) into different modalities and data types is essential to improve Deep Learning (DL) for predictive medicine. This work presents DACMVA, a novel framework to conduct data augmentation in a cross-modal dataset by translating between modalities and oversampling imputations of missing data. DACMVA was inspired by previous work on the alignment of latent spaces in Autoencoders. DACMVA is a DL data augmentation pipeline that improves the performance in a downstream prediction task. The unique DACMVA framework leverages a cross-modal loss to improve the imputation quality and employs training strategies to enable regularized latent spaces. Oversampling of augmented data is integrated into the prediction training. It is empirically demonstrated that the new DACMVA framework is effective in the often-neglected scenario of DL training on tabular data with continuous labels. Specifically, DACMVA is applied towards cancer survival prediction on tabular gene expression data where there is a portion of missing data in a given modality. DACMVA significantly (",
      "authors": "Rajaram Sara; Mitchell Cassie S",
      "year": "2024",
      "month": "Jan",
      "journal": "Information (Basel)",
      "source": "pubmed"
    },
    {
      "pmid": "38649301",
      "doi": "10.1093/gigascience/giae017",
      "title": "Large-scale genomic survey with deep learning-based method reveals strain-level phage specificity determinants.",
      "abstract": "Phage therapy, reemerging as a promising approach to counter antimicrobial-resistant infections, relies on a comprehensive understanding of the specificity of individual phages. Yet the significant diversity within phage populations presents a considerable challenge. Currently, there is a notable lack of tools designed for large-scale characterization of phage receptor-binding proteins, which are crucial in determining the phage host range. In this study, we present SpikeHunter, a deep learning method based on the ESM-2 protein language model. With SpikeHunter, we identified 231,965 diverse phage-encoded tailspike proteins, a crucial determinant of phage specificity that targets bacterial polysaccharide receptors, across 787,566 bacterial genomes from 5 virulent, antibiotic-resistant pathogens. Notably, 86.60% (143,200) of these proteins exhibited strong associations with specific bacterial polysaccharides. We discovered that phages with identical tailspike proteins can infect different bacterial species with similar polysaccharide receptors, underscoring the pivotal role of tailspike proteins in determining host range. The specificity is mainly attributed to the protein's C-terminal domain, which strictly correlates with host specificity during domain swapping in tailspike proteins. Importantly, our dataset-driven predictions of phage-host specificity closely match the phage-host pairs observed in real-world phage therapy cases we studied. Our research provides a rich resource, including both the method and a database derived from a large-scale genomics survey. This substantially enhances understanding of phage specificity determinants at the strain level and offers a valuable framework for guiding phage selection in therapeutic applications.",
      "authors": "Yang Yiyan; Dufault-Thompson Keith; Yan Wei; Cai Tian; Xie Lei; Jiang Xiaofang",
      "year": "2024",
      "month": "Jan",
      "journal": "GigaScience",
      "source": "pubmed"
    },
    {
      "pmid": "38643080",
      "doi": "10.1186/s12859-024-05780-z",
      "title": "TEC-miTarget: enhancing microRNA target prediction based on deep learning of ribonucleic acid sequences.",
      "abstract": "MicroRNAs play a critical role in regulating gene expression by binding to specific target sites within gene transcripts, making the identification of microRNA targets a prominent focus of research. Conventional experimental methods for identifying microRNA targets are both time-consuming and expensive, prompting the development of computational tools for target prediction. However, the existing computational tools exhibit limited performance in meeting the demands of practical applications, highlighting the need to improve the performance of microRNA target prediction models. In this paper, we utilize the most popular natural language processing and computer vision technologies to propose a novel approach, called TEC-miTarget, for microRNA target prediction based on transformer encoder and convolutional neural networks. TEC-miTarget treats RNA sequences as a natural language and encodes them using a transformer encoder, a widely used encoder in natural language processing. It then combines the representations of a pair of microRNA and its candidate target site sequences into a contact map, which is a three-dimensional array similar to a multi-channel image. Therefore, the contact map's features are extracted using a four-layer convolutional neural network, enabling the prediction of interactions between microRNA and its candidate target sites. We applied a series of comparative experiments to demonstrate that TEC-miTarget significantly improves microRNA target prediction, compared with existing state-of-the-art models. Our approach is the first approach to perform comparisons with other approaches at both sequence and transcript levels. Furthermore, it is the first approach compared with both deep learning-based and seed-match-based methods. We first compared TEC-miTarget's performance with approaches at the sequence level, and our approach delivers substantial improvements in performance using the same datasets and evaluation metrics. Moreover, we utilized TEC-miTarget to predict microRNA targets in long mRNA sequences, which involves two steps: selecting candidate target site sequences and applying sequence-level predictions. We finally showed that TEC-miTarget outperforms other approaches at the transcript level, including the popular seed match methods widely used in previous years. We propose a novel approach for predicting microRNA targets at both sequence and transcript levels, and demonstrate that our approach outperforms other methods based on deep learning or seed match. We also provide our approach as an easy-to-use software, TEC-miTarget, at https://github.com/tingpeng17/TEC-miTarget . Our results provide new perspectives for microRNA target prediction.",
      "authors": "Yang Tingpeng; Wang Yu; He Yonghong",
      "year": "2024",
      "month": "Apr",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "38617247",
      "doi": "10.1101/2024.04.05.588317",
      "title": "RNA language models predict mutations that improve RNA function.",
      "abstract": "Structured RNA lies at the heart of many central biological processes, from gene expression to catalysis. While advances in deep learning enable the prediction of accurate protein structural models, RNA structure prediction is not possible at present due to a lack of abundant high-quality reference data",
      "authors": "Shulgina Yekaterina; Trinidad Marena I; Langeberg Conner J; Nisonoff Hunter; Chithrananda Seyone; Skopintsev Petr; Nissley Amos J; Patel Jaymin; Boger Ron S; Shi Honglue; Yoon Peter H; Doherty Erin E; Pande Tara; Iyer Aditya M; Doudna Jennifer A; Cate Jamie H D",
      "year": "2024",
      "month": "Sep",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38608194",
      "doi": "10.1093/bioinformatics/btae185",
      "title": "Literature mining discerns latent disease-gene relationships.",
      "abstract": "Dysregulation of a gene's function, either due to mutations or impairments in regulatory networks, often triggers pathological states in the affected tissue. Comprehensive mapping of these apparent gene-pathology relationships is an ever-daunting task, primarily due to genetic pleiotropy and lack of suitable computational approaches. With the advent of high throughput genomics platforms and community scale initiatives such as the Human Cell Landscape project, researchers have been able to create gene expression portraits of healthy tissues resolved at the level of single cells. However, a similar wealth of knowledge is currently not at our finger-tip when it comes to diseases. This is because the genetic manifestation of a disease is often quite diverse and is confounded by several clinical and demographic covariates. To circumvent this, we mined ∼18 million PubMed abstracts published till May 2019 and automatically selected ∼4.5 million of them that describe roles of particular genes in disease pathogenesis. Further, we fine-tuned the pretrained bidirectional encoder representations from transformers (BERT) for language modeling from the domain of natural language processing to learn vector representation of entities such as genes, diseases, tissues, cell-types, etc., in a way such that their relationship is preserved in a vector space. The repurposed BERT predicted disease-gene associations that are not cited in the training data, thereby highlighting the feasibility of in silico synthesis of hypotheses linking different biological entities such as genes and conditions. PathoBERT pretrained model: https://github.com/Priyadarshini-Rai/Pathomap-Model. BioSentVec-based abstract classification model: https://github.com/Priyadarshini-Rai/Pathomap-Model. Pathomap R package: https://github.com/Priyadarshini-Rai/Pathomap.",
      "authors": "Rai Priyadarshini; Jain Atishay; Kumar Shivani; Sharma Divya; Jha Neha; Chawla Smriti; Raj Abhijit; Gupta Apoorva; Poonia Sarita; Majumdar Angshul; Chakraborty Tanmoy; Ahuja Gaurav; Sengupta Debarka",
      "year": "2024",
      "month": "Mar",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "38608190",
      "doi": "10.1093/bioinformatics/btae196",
      "title": "Effect of tokenization on transformers for biological sequences.",
      "abstract": "Deep-learning models are transforming biological research, including many bioinformatics and comparative genomics algorithms, such as sequence alignments, phylogenetic tree inference, and automatic classification of protein functions. Among these deep-learning algorithms, models for processing natural languages, developed in the natural language processing (NLP) community, were recently applied to biological sequences. However, biological sequences are different from natural languages, such as English, and French, in which segmentation of the text to separate words is relatively straightforward. Moreover, biological sequences are characterized by extremely long sentences, which hamper their processing by current machine-learning models, notably the transformer architecture. In NLP, one of the first processing steps is to transform the raw text to a list of tokens. Deep-learning applications to biological sequence data mostly segment proteins and DNA to single characters. In this work, we study the effect of alternative tokenization algorithms on eight different tasks in biology, from predicting the function of proteins and their stability, through nucleotide sequence alignment, to classifying proteins to specific families. We demonstrate that applying alternative tokenization algorithms can increase accuracy and at the same time, substantially reduce the input length compared to the trivial tokenizer in which each character is a token. Furthermore, applying these tokenization algorithms allows interpreting trained models, taking into account dependencies among positions. Finally, we trained these tokenizers on a large dataset of protein sequences containing more than 400 billion amino acids, which resulted in over a 3-fold decrease in the number of tokens. We then tested these tokenizers trained on large-scale data on the above specific tasks and showed that for some tasks it is highly beneficial to train database-specific tokenizers. Our study suggests that tokenizers are likely to be a critical component in future deep-network analysis of biological sequence data. Code, data, and trained tokenizers are available on https://github.com/technion-cs-nlp/BiologicalTokenizers.",
      "authors": "Dotan Edo; Jaschek Gal; Pupko Tal; Belinkov Yonatan",
      "year": "2024",
      "month": "Mar",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "38587959",
      "doi": "10.1109/TMI.2024.3386108",
      "title": "Graph Attention-Based Fusion of Pathology Images and Gene Expression for Prediction of Cancer Survival.",
      "abstract": "Multimodal machine learning models are being developed to analyze pathology images and other modalities, such as gene expression, to gain clinical and biological insights. However, most frameworks for multimodal data fusion do not fully account for the interactions between different modalities. Here, we present an attention-based fusion architecture that integrates a graph representation of pathology images with gene expression data and concomitantly learns from the fused information to predict patient-specific survival. In our approach, pathology images are represented as undirected graphs, and their embeddings are combined with embeddings of gene expression signatures using an attention mechanism to stratify tumors by patient survival. We show that our framework improves the survival prediction of human non-small cell lung cancers, outperforming existing state-of-the-art approaches that leverage multimodal data. Our framework can facilitate spatial molecular profiling to identify tumor heterogeneity using pathology images and gene expression data, complementing results obtained from more expensive spatial transcriptomic and proteomic technologies.",
      "authors": "Zheng Yi; Conrad Regan D; Green Emily J; Burks Eric J; Betke Margrit; Beane Jennifer E; Kolachalama Vijaya B",
      "year": "2024",
      "month": "Sep",
      "journal": "IEEE transactions on medical imaging",
      "source": "pubmed"
    },
    {
      "pmid": "38576453",
      "doi": "10.1038/s44222-023-00114-9",
      "title": "Diffusion models in bioinformatics and computational biology.",
      "abstract": "Denoising diffusion models embody a type of generative artificial intelligence that can be applied in computer vision, natural language processing and bioinformatics. In this Review, we introduce the key concepts and theoretical foundations of three diffusion modelling frameworks (denoising diffusion probabilistic models, noise-conditioned scoring networks and score stochastic differential equations). We then explore their applications in bioinformatics and computational biology, including protein design and generation, drug and small-molecule design, protein-ligand interaction modelling, cryo-electron microscopy image data analysis and single-cell data analysis. Finally, we highlight open-source diffusion model tools and consider the future applications of diffusion models in bioinformatics.",
      "authors": "Guo Zhiye; Liu Jian; Wang Yanli; Chen Mengrui; Wang Duolin; Xu Dong; Cheng Jianlin",
      "year": "2024",
      "month": "Feb",
      "journal": "Nature reviews bioengineering",
      "source": "pubmed"
    },
    {
      "pmid": "38571784",
      "doi": "10.1093/bioadv/vbae046",
      "title": "BioNexusSentinel: a visual tool for bioregulatory network and cytohistological RNA-seq genetic expression profiling within the context of multicellular simulation research using ChatGPT-augmented software engineering.",
      "abstract": "Motivated by the need to parameterize ongoing multicellular simulation research, this paper documents the culmination of a ChatGPT augmented software engineering cycle resulting in an integrated visual platform for efficient cytohistological RNA-seq and bioregulatory network exploration. As contrasted to other systems and synthetic biology tools, BioNexusSentinel was developed  BioNexusSentinel project releases, with corresponding data and installation instructions, are available at https://github.com/RichardMatzko/BioNexusSentinel.",
      "authors": "Matzko Richard Oliver; Konur Savas",
      "year": "2024",
      "month": "",
      "journal": "Bioinformatics advances",
      "source": "pubmed"
    },
    {
      "pmid": "38571502",
      "doi": "10.3389/fonc.2024.1343627",
      "title": "Breast cancer risk prediction using machine learning: a systematic review.",
      "abstract": "Breast cancer is the leading cause of cancer-related fatalities among women worldwide. Conventional screening and risk prediction models primarily rely on demographic and patient clinical history to devise policies and estimate likelihood. However, recent advancements in artificial intelligence (AI) techniques, particularly deep learning (DL), have shown promise in the development of personalized risk models. These models leverage individual patient information obtained from medical imaging and associated reports. In this systematic review, we thoroughly investigated the existing literature on the application of DL to digital mammography, radiomics, genomics, and clinical information for breast cancer risk assessment. We critically analyzed these studies and discussed their findings, highlighting the promising prospects of DL techniques for breast cancer risk prediction. Additionally, we explored ongoing research initiatives and potential future applications of AI-driven approaches to further improve breast cancer risk prediction, thereby facilitating more effective screening and personalized risk management strategies. This study presents a comprehensive overview of imaging and non-imaging features used in breast cancer risk prediction using traditional and AI models. The features reviewed in this study included imaging, radiomics, genomics, and clinical features. Furthermore, this survey systematically presented DL methods developed for breast cancer risk prediction, aiming to be useful for both beginners and advanced-level researchers. A total of 600 articles were identified, 20 of which met the set criteria and were selected. Parallel benchmarking of DL models, along with natural language processing (NLP) applied to imaging and non-imaging features, could allow clinicians and researchers to gain greater awareness as they consider the clinical deployment or development of new models. This review provides a comprehensive guide for understanding the current status of breast cancer risk assessment using AI. This study offers investigators a different perspective on the use of AI for breast cancer risk prediction, incorporating numerous imaging and non-imaging features.",
      "authors": "Hussain Sadam; Ali Mansoor; Naseem Usman; Nezhadmoghadam Fahimeh; Jatoi Munsif Ali; Gulliver T Aaron; Tamez-Peña Jose Gerardo",
      "year": "2024",
      "month": "",
      "journal": "Frontiers in oncology",
      "source": "pubmed"
    },
    {
      "pmid": "38510148",
      "doi": "10.1016/j.isci.2024.109352",
      "title": "scGREAT: Transformer-based deep-language model for gene regulatory network inference from single-cell transcriptomics.",
      "abstract": "Gene regulatory networks (GRNs) involve complex and multi-layer regulatory interactions between regulators and their target genes. Precise knowledge of GRNs is important in understanding cellular processes and molecular functions. Recent breakthroughs in single-cell sequencing technology made it possible to infer GRNs at single-cell level. Existing methods, however, are limited by expensive computations, and sometimes simplistic assumptions. To overcome these obstacles, we propose scGREAT, a framework to infer GRN using gene embeddings and transformer from single-cell transcriptomics. scGREAT starts by constructing gene expression and gene biotext dictionaries from scRNA-seq data and gene text information. The representation of TF gene pairs is learned through optimizing embedding space by transformer-based engine. Results illustrated scGREAT outperformed other contemporary methods on benchmarks. Besides, gene representations from scGREAT provide valuable gene regulation insights, and external validation on spatial transcriptomics illuminated the mechanism behind scGREAT annotation. Moreover, scGREAT identified several TF target regulations corroborated in studies.",
      "authors": "Wang Yuchen; Chen Xingjian; Zheng Zetian; Huang Lei; Xie Weidun; Wang Fuzhou; Zhang Zhaolei; Wong Ka-Chun",
      "year": "2024",
      "month": "Apr",
      "journal": "iScience",
      "source": "pubmed"
    },
    {
      "pmid": "38504331",
      "doi": "10.1186/s13059-024-03211-z",
      "title": "DANCE: a deep learning library and benchmark platform for single-cell analysis.",
      "abstract": "DANCE is the first standard, generic, and extensible benchmark platform for accessing and evaluating computational methods across the spectrum of benchmark datasets for numerous single-cell analysis tasks. Currently, DANCE supports 3 modules and 8 popular tasks with 32 state-of-art methods on 21 benchmark datasets. People can easily reproduce the results of supported algorithms across major benchmark datasets via minimal efforts, such as using only one command line. In addition, DANCE provides an ecosystem of deep learning architectures and tools for researchers to facilitate their own model development. DANCE is an open-source Python package that welcomes all kinds of contributions.",
      "authors": "Ding Jiayuan; Liu Renming; Wen Hongzhi; Tang Wenzhuo; Li Zhaoheng; Venegas Julian; Su Runze; Molho Dylan; Jin Wei; Wang Yixin; Lu Qiaolin; Li Lingxiao; Zuo Wangyang; Chang Yi; Xie Yuying; Tang Jiliang",
      "year": "2024",
      "month": "Mar",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "38496575",
      "doi": "10.1101/2024.03.04.583444",
      "title": "Deep5hmC: Predicting genome-wide 5-Hydroxymethylcytosine landscape via a multimodal deep learning model.",
      "abstract": "5-hydroxymethylcytosine (5hmC), a critical epigenetic mark with a significant role in regulating tissue-specific gene expression, is essential for understanding the dynamic functions of the human genome. Using tissue-specific 5hmC sequencing data, we introduce Deep5hmC, a multimodal deep learning framework that integrates both the DNA sequence and the histone modification information to predict genome-wide 5hmC modification. The multimodal design of Deep5hmC demonstrates remarkable improvement in predicting both qualitative and quantitative 5hmC modification compared to unimodal versions of Deep5hmC and state-of-the-art machine learning methods. This improvement is demonstrated through benchmarking on a comprehensive set of 5hmC sequencing data collected at four time points during forebrain organoid development and across 17 human tissues. Notably, Deep5hmC showcases its practical utility by accurately predicting gene expression and identifying differentially hydroxymethylated regions in a case-control study of Alzheimer's disease.",
      "authors": "Ma Xin; Thela Sai Ritesh; Zhao Fengdi; Yao Bing; Wen Zhexing; Jin Peng; Zhao Jinying; Chen Li",
      "year": "2024",
      "month": "Mar",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38495441",
      "doi": "10.1007/s12551-023-01091-4",
      "title": "Representing and extracting knowledge from single-cell data.",
      "abstract": "Single-cell analysis is currently one of the most high-resolution techniques to study biology. The large complex datasets that have been generated have spurred numerous developments in computational biology, in particular the use of advanced statistics and machine learning. This review attempts to explain the deeper theoretical concepts that underpin current state-of-the-art analysis methods. Single-cell analysis is covered from cell, through instruments, to current and upcoming models. The aim of this review is to spread concepts which are not yet in common use, especially from topology and generative processes, and how new statistical models can be developed to capture more of biology. This opens epistemological questions regarding our ontology and models, and some pointers will be given to how natural language processing (NLP) may help overcome our cognitive limitations for understanding single-cell data.",
      "authors": "Mihai Ionut Sebastian; Chafle Sarang; Henriksson Johan",
      "year": "2024",
      "month": "Feb",
      "journal": "Biophysical reviews",
      "source": "pubmed"
    },
    {
      "pmid": "38493338",
      "doi": "10.1093/bib/bbae102",
      "title": "Effective multi-modal clustering method via skip aggregation network for parallel scRNA-seq and scATAC-seq data.",
      "abstract": "In recent years, there has been a growing trend in the realm of parallel clustering analysis for single-cell RNA-seq (scRNA) and single-cell Assay of Transposase Accessible Chromatin (scATAC) data. However, prevailing methods often treat these two data modalities as equals, neglecting the fact that the scRNA mode holds significantly richer information compared to the scATAC. This disregard hinders the model benefits from the insights derived from multiple modalities, compromising the overall clustering performance. To this end, we propose an effective multi-modal clustering model scEMC for parallel scRNA and Assay of Transposase Accessible Chromatin data. Concretely, we have devised a skip aggregation network to simultaneously learn global structural information among cells and integrate data from diverse modalities. To safeguard the quality of integrated cell representation against the influence stemming from sparse scATAC data, we connect the scRNA data with the aggregated representation via skip connection. Moreover, to effectively fit the real distribution of cells, we introduced a Zero Inflated Negative Binomial-based denoising autoencoder that accommodates corrupted data containing synthetic noise, concurrently integrating a joint optimization module that employs multiple losses. Extensive experiments serve to underscore the effectiveness of our model. This work contributes significantly to the ongoing exploration of cell subpopulations and tumor microenvironments, and the code of our work will be public at https://github.com/DayuHuu/scEMC.",
      "authors": "Hu Dayu; Liang Ke; Dong Zhibin; Wang Jun; Zhao Yawei; He Kunlun",
      "year": "2024",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "38483255",
      "doi": "10.1093/bib/bbae082",
      "title": "Deep learning in spatially resolved transcriptfomics: a comprehensive technical view.",
      "abstract": "Spatially resolved transcriptomics (SRT) is a pioneering method for simultaneously studying morphological contexts and gene expression at single-cell precision. Data emerging from SRT are multifaceted, presenting researchers with intricate gene expression matrices, precise spatial details and comprehensive histology visuals. Such rich and intricate datasets, unfortunately, render many conventional methods like traditional machine learning and statistical models ineffective. The unique challenges posed by the specialized nature of SRT data have led the scientific community to explore more sophisticated analytical avenues. Recent trends indicate an increasing reliance on deep learning algorithms, especially in areas such as spatial clustering, identification of spatially variable genes and data alignment tasks. In this manuscript, we provide a rigorous critique of these advanced deep learning methodologies, probing into their merits, limitations and avenues for further refinement. Our in-depth analysis underscores that while the recent innovations in deep learning tailored for SRT have been promising, there remains a substantial potential for enhancement. A crucial area that demands attention is the development of models that can incorporate intricate biological nuances, such as phylogeny-aware processing or in-depth analysis of minuscule histology image segments. Furthermore, addressing challenges like the elimination of batch effects, perfecting data normalization techniques and countering the overdispersion and zero inflation patterns seen in gene expression is pivotal. To support the broader scientific community in their SRT endeavors, we have meticulously assembled a comprehensive directory of readily accessible SRT databases, hoping to serve as a foundation for future research initiatives.",
      "authors": "Zahedi Roxana; Ghamsari Reza; Argha Ahmadreza; Macphillamy Callum; Beheshti Amin; Alizadehsani Roohallah; Lovell Nigel H; Lotfollahi Mohammad; Alinejad-Rokny Hamid",
      "year": "2024",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "38483032",
      "doi": "10.1002/advs.202307835",
      "title": "scmFormer Integrates Large-Scale Single-Cell Proteomics and Transcriptomics Data by Multi-Task Transformer.",
      "abstract": "Transformer-based models have revolutionized single cell RNA-seq (scRNA-seq) data analysis. However, their applicability is challenged by the complexity and scale of single-cell multi-omics data. Here a novel single-cell multi-modal/multi-task transformer (scmFormer) is proposed to fill up the existing blank of integrating single-cell proteomics with other omics data. Through systematic benchmarking, it is demonstrated that scmFormer excels in integrating large-scale single-cell multimodal data and heterogeneous multi-batch paired multi-omics data, while preserving shared information across batchs and distinct biological information. scmFormer achieves 54.5% higher average F1 score compared to the second method in transferring cell-type labels from single-cell transcriptomics to proteomics data. Using COVID-19 datasets, it is presented that scmFormer successfully integrates over 1.48 million cells on a personal computer. Moreover, it is also proved that scmFormer performs better than existing methods on generating the unmeasured modality and is well-suited for spatial multi-omic data. Thus, scmFormer is a powerful and comprehensive tool for analyzing single-cell multi-omics data.",
      "authors": "Xu Jing; Huang De-Shuang; Zhang Xiujun",
      "year": "2024",
      "month": "May",
      "journal": "Advanced science (Weinheim, Baden-Wurttemberg, Germany)",
      "source": "pubmed"
    },
    {
      "pmid": "38454967",
      "doi": "10.1002/imt2.115",
      "title": "PyComplexHeatmap: a Python package to visualize multimodal genomics data.",
      "abstract": "Python has emerged as a robust programming language increasingly employed in genomics data analysis, largely due to its comprehensive deep learning libraries and proficiency in handling large-scale data, such as single-cell multi-omics datasets. Although Python has become a prominent data science ecosystem for bioinformatics, there remains a growing demand for advanced heatmap visualization and assembly tools, which are not sufficiently addressed by existing Python-based data visualization libraries. We present PyComplexHeatmap, an all-inclusive Python library for heatmap visualization, inspired by the ComplexHeatmap package currently available in R. PyComplexHeatmap is built upon the matplotlib library and features a versatile, modular interface that seamlessly integrates with other Python-based data science tools, such as Pandas, NumPy, and genomics tools, such as Scanpy, in a standard-compliant manner. This library caters to the requirements of exquisite rendering of multimodal matrix data, incorporating both textual and graphical annotations, thereby enabling efficient integrative analysis of multimodal data and associated metadata.",
      "authors": "Ding Wubin; Goldberg David; Zhou Wanding",
      "year": "2023",
      "month": "Aug",
      "journal": "iMeta",
      "source": "pubmed"
    },
    {
      "pmid": "38453964",
      "doi": "10.1038/s41598-024-56172-5",
      "title": "Multimodal artificial intelligence-based pathogenomics improves survival prediction in oral squamous cell carcinoma.",
      "abstract": "In this study, we aimed to develop a novel prognostic algorithm for oral squamous cell carcinoma (OSCC) using a combination of pathogenomics and AI-based techniques. We collected comprehensive clinical, genomic, and pathology data from a cohort of OSCC patients in the TCGA dataset and used machine learning and deep learning algorithms to identify relevant features that are predictive of survival outcomes. Our analyses included 406 OSCC patients. Initial analyses involved gene expression analyses, principal component analyses, gene enrichment analyses, and feature importance analyses. These insights were foundational for subsequent model development. Furthermore, we applied five machine learning/deep learning algorithms (Random Survival Forest, Gradient Boosting Survival Analysis, Cox PH, Fast Survival SVM, and DeepSurv) for survival prediction. Our initial analyses revealed relevant gene expression variations and biological pathways, laying the groundwork for robust feature selection in model building. The results showed that the multimodal model outperformed the unimodal models across all methods, with c-index values of 0.722 for RSF, 0.633 for GBSA, 0.625 for FastSVM, 0.633 for CoxPH, and 0.515 for DeepSurv. When considering only important features, the multimodal model continued to outperform the unimodal models, with c-index values of 0.834 for RSF, 0.747 for GBSA, 0.718 for FastSVM, 0.742 for CoxPH, and 0.635 for DeepSurv. Our results demonstrate the potential of pathogenomics and AI-based techniques in improving the accuracy of prognostic prediction in OSCC, which may ultimately aid in the development of personalized treatment strategies for patients with this devastating disease.",
      "authors": "Vollmer Andreas; Hartmann Stefan; Vollmer Michael; Shavlokhova Veronika; Brands Roman C; Kübler Alexander; Wollborn Jakob; Hassel Frank; Couillard-Despres Sebastien; Lang Gernot; Saravi Babak",
      "year": "2024",
      "month": "Mar",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "38438615",
      "doi": "10.1038/s41592-024-02199-5",
      "title": "Spatial landmark detection and tissue registration with deep learning.",
      "abstract": "Spatial landmarks are crucial in describing histological features between samples or sites, tracking regions of interest in microscopy, and registering tissue samples within a common coordinate framework. Although other studies have explored unsupervised landmark detection, existing methods are not well-suited for histological image data as they often require a large number of images to converge, are unable to handle nonlinear deformations between tissue sections and are ineffective for z-stack alignment, other modalities beyond image data or multimodal data. We address these challenges by introducing effortless landmark detection, a new unsupervised landmark detection and registration method using neural-network-guided thin-plate splines. Our proposed method is evaluated on a diverse range of datasets including histology and spatially resolved transcriptomics, demonstrating superior performance in both accuracy and stability compared to existing approaches.",
      "authors": "Ekvall Markus; Bergenstråhle Ludvig; Andersson Alma; Czarnewski Paulo; Olegård Johannes; Käll Lukas; Lundeberg Joakim",
      "year": "2024",
      "month": "Apr",
      "journal": "Nature methods",
      "source": "pubmed"
    },
    {
      "pmid": "38420834",
      "doi": "10.31083/j.fbl2902075",
      "title": "Deep-Learning Uncovers certain CCM Isoforms as Transcription Factors.",
      "abstract": "Cerebral Cavernous Malformations (CCMs) are brain vascular abnormalities associated with an increased risk of hemorrhagic strokes. Familial CCMs result from autosomal dominant inheritance involving three genes:  To investigate this potential, we employed our proprietary deep-learning (DL)-based algorithm, specifically utilizing a biased-Support Vector Machine (SVM) model, to explore the plausible cellular function of any of the CSC proteins, particularly focusing on  Through a comparative DL-based predictive analysis, we have effectively discerned a collective of 11 isoforms across all CCM proteins (CCM1-3). Additionally, we have substantiated the TF functionality of 8 isoforms derived from CCM1 and CCM2 proteins, marking the inaugural identification of CCM isoforms in the role of TFs. This groundbreaking discovery directly challenges the prevailing paradigm, which predominantly emphasizes the involvement of CSC solely in endothelial cellular functions amid various potential cellular signal cascades during angiogenesis.",
      "authors": "Croft Jacob; Gao Liyuan; Sheng Victor; Zhang Jun",
      "year": "2024",
      "month": "Feb",
      "journal": "Frontiers in bioscience (Landmark edition)",
      "source": "pubmed"
    },
    {
      "pmid": "38388681",
      "doi": "10.1093/bib/bbae047",
      "title": "Continually adapting pre-trained language model to universal annotation of single-cell RNA-seq data.",
      "abstract": "Cell-type annotation of single-cell RNA-sequencing (scRNA-seq) data is a hallmark of biomedical research and clinical application. Current annotation tools usually assume the simultaneous acquisition of well-annotated data, but without the ability to expand knowledge from new data. Yet, such tools are inconsistent with the continuous emergence of scRNA-seq data, calling for a continuous cell-type annotation model. In addition, by their powerful ability of information integration and model interpretability, transformer-based pre-trained language models have led to breakthroughs in single-cell biology research. Therefore, the systematic combining of continual learning and pre-trained language models for cell-type annotation tasks is inevitable. We herein propose a universal cell-type annotation tool, called CANAL, that continuously fine-tunes a pre-trained language model trained on a large amount of unlabeled scRNA-seq data, as new well-labeled data emerges. CANAL essentially alleviates the dilemma of catastrophic forgetting, both in terms of model inputs and outputs. For model inputs, we introduce an experience replay schema that repeatedly reviews previous vital examples in current training stages. This is achieved through a dynamic example bank with a fixed buffer size. The example bank is class-balanced and proficient in retaining cell-type-specific information, particularly facilitating the consolidation of patterns associated with rare cell types. For model outputs, we utilize representation knowledge distillation to regularize the divergence between previous and current models, resulting in the preservation of knowledge learned from past training stages. Moreover, our universal annotation framework considers the inclusion of new cell types throughout the fine-tuning and testing stages. We can continuously expand the cell-type annotation library by absorbing new cell types from newly arrived, well-annotated training datasets, as well as automatically identify novel cells in unlabeled datasets. Comprehensive experiments with data streams under various biological scenarios demonstrate the versatility and high model interpretability of CANAL. An implementation of CANAL is available from https://github.com/aster-ww/CANAL-torch. dengmh@pku.edu.cn. Supplementary data are available at Journal Name online.",
      "authors": "Wan Hui; Yuan Musu; Fu Yiwei; Deng Minghua",
      "year": "2024",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "38385876",
      "doi": "10.1093/bib/bbae030",
      "title": "ADH-Enhancer: an attention-based deep hybrid framework for enhancer identification and strength prediction.",
      "abstract": "Enhancers play an important role in the process of gene expression regulation. In DNA sequence abundance or absence of enhancers and irregularities in the strength of enhancers affects gene expression process that leads to the initiation and propagation of diverse types of genetic diseases such as hemophilia, bladder cancer, diabetes and congenital disorders. Enhancer identification and strength prediction through experimental approaches is expensive, time-consuming and error-prone. To accelerate and expedite the research related to enhancers identification and strength prediction, around 19 computational frameworks have been proposed. These frameworks used machine and deep learning methods that take raw DNA sequences and predict enhancer's presence and strength. However, these frameworks still lack in performance and are not useful in real time analysis. This paper presents a novel deep learning framework that uses language modeling strategies for transforming DNA sequences into statistical feature space. It applies transfer learning by training a language model in an unsupervised fashion by predicting a group of nucleotides also known as k-mers based on the context of existing k-mers in a sequence. At the classification stage, it presents a novel classifier that reaps the benefits of two different architectures: convolutional neural network and attention mechanism. The proposed framework is evaluated over the enhancer identification benchmark dataset where it outperforms the existing best-performing framework by 5%, and 9% in terms of accuracy and MCC. Similarly, when evaluated over the enhancer strength prediction benchmark dataset, it outperforms the existing best-performing framework by 4%, and 7% in terms of accuracy and MCC.",
      "authors": "Mehmood Faiza; Arshad Shazia; Shoaib Muhammad",
      "year": "2024",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "38371918",
      "doi": "10.1093/bioadv/vbae010",
      "title": "MMDRP: drug response prediction and biomarker discovery using multi-modal deep learning.",
      "abstract": "A major challenge in cancer care is that patients with similar demographics, tumor types, and medical histories can respond quite differently to the same drug regimens. This difference is largely explained by genetic and other molecular variabilities among the patients and their cancers. Efforts in the pharmacogenomics field are underway to understand better the relationship between the genome of the patient's healthy and tumor cells and their response to therapy. To advance this goal, research groups and consortia have undertaken large-scale systematic screening of panels of drugs across multiple cancer cell lines that have been molecularly profiled by genomics, proteomics, and similar techniques. These large data drug screening sets have been applied to the problem of drug response prediction (DRP), the challenge of predicting the response of a previously untested drug/cell-line combination. Although deep learning algorithms outperform traditional methods, there are still many challenges in DRP that ultimately result in these models' low generalizability and hampers their clinical application. In this article, we describe a novel algorithm that addresses the major shortcomings of current DRP methods by combining multiple cell line characterization data, addressing drug response data skewness, and improving chemical compound representation. MMDRP is implemented as an open-source, Python-based, command-line program and is available at https://github.com/LincolnSteinLab/MMDRP.",
      "authors": "Taj Farzan; Stein Lincoln D",
      "year": "2024",
      "month": "",
      "journal": "Bioinformatics advances",
      "source": "pubmed"
    },
    {
      "pmid": "38366241",
      "doi": "10.1038/s41592-024-02171-3",
      "title": "Multiscale biochemical mapping of the brain through deep-learning-enhanced high-throughput mass spectrometry.",
      "abstract": "Spatial omics technologies can reveal the molecular intricacy of the brain. While mass spectrometry imaging (MSI) provides spatial localization of compounds, comprehensive biochemical profiling at a brain-wide scale in three dimensions by MSI with single-cell resolution has not been achieved. We demonstrate complementary brain-wide and single-cell biochemical mapping using MEISTER, an integrative experimental and computational mass spectrometry (MS) framework. Our framework integrates a deep-learning-based reconstruction that accelerates high-mass-resolving MS by 15-fold, multimodal registration creating three-dimensional (3D) molecular distributions and a data integration method fitting cell-specific mass spectra to 3D datasets. We imaged detailed lipid profiles in tissues with millions of pixels and in large single-cell populations acquired from the rat brain. We identified region-specific lipid contents and cell-specific localizations of lipids depending on both cell subpopulations and anatomical origins of the cells. Our workflow establishes a blueprint for future development of multiscale technologies for biochemical characterization of the brain.",
      "authors": "Xie Yuxuan Richard; Castro Daniel C; Rubakhin Stanislav S; Trinklein Timothy J; Sweedler Jonathan V; Lam Fan",
      "year": "2024",
      "month": "Mar",
      "journal": "Nature methods",
      "source": "pubmed"
    },
    {
      "pmid": "38352937",
      "doi": "10.1016/j.csbj.2024.01.014",
      "title": "Large language models assisted multi-effect variants mining on cerebral cavernous malformation familial whole genome sequencing.",
      "abstract": "Cerebral cavernous malformation (CCM) is a polygenic disease with intricate genetic interactions contributing to quantitative pathogenesis across multiple factors. The principal pathogenic genes of CCM, specifically KRIT1, CCM2, and PDCD10, have been reported, accompanied by a growing wealth of genetic data related to mutations. Furthermore, numerous other molecules associated with CCM have been unearthed. However, tackling such massive volumes of unstructured data remains challenging until the advent of advanced large language models. In this study, we developed an automated analytical pipeline specialized in single nucleotide variants (SNVs) related biomedical text analysis called BRLM. To facilitate this, BioBERT was employed to vectorize the rich information of SNVs, while a deep residue network was used to discriminate the classes of the SNVs. BRLM was initially constructed on mutations from 12 different types of TCGA cancers, achieving an accuracy exceeding 99%. It was further examined for CCM mutations in familial sequencing data analysis, highlighting an upstream master regulator gene fibroblast growth factor 1 (FGF1). With multi-omics characterization and validation in biological function, FGF1 demonstrated to play a significant role in the development of CCMs, which proved the effectiveness of our model. The BRLM web server is available at http://1.117.230.196.",
      "authors": "Wang Yiqi; Zuo Jinmei; Duan Chao; Peng Hao; Huang Jia; Zhao Liang; Zhang Li; Dong Zhiqiang",
      "year": "2024",
      "month": "Dec",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "38352605",
      "doi": "10.1101/2024.01.27.577455",
      "title": "Parameter-Efficient Fine-Tuning Enhances Adaptation of Single Cell Large Language Model for Cell Type Identification.",
      "abstract": "Single-cell sequencing transformed biology and medicine, providing an unprecedented high-resolution view at the cellular level. However, the vast variability inherent in single-cell sequencing data impedes its utility for in-depth downstream analysis. Inspired by the foundation models in natural language processing, recent advancements have led to the development of single-cell Large Language Models (scLLMs). These models are designed to discern universal patterns across diverse single-cell datasets, thereby enhancing the signal-to-noise ratio. Despite their potential, multiple studies indicate existing scLLMs do not perform well in zero-short settings, highlighting a pressing need for more effective adaptation techniques. This research proposes several adaptation techniques for scLLMs by preserving the original model parameters while selectively updating newly introduced tensors. This approach aims to overcome the limitations associated with traditional fine-tuning practices, such as catastrophic forgetting and computational inefficiencies. We introduce two Parameter-Efficient Fine-Tuning (PEFT) strategies specifically tailored to refine scLLMs for cell type identification. Our investigations utilizing scGPT demonstrate that PEFT can enhance performance, with the added benefit of up to a 90% reduction in parameter training compared to conventional fine-tuning methodologies. This work paves the way for a new direction in leveraging single-cell models with greater efficiency and efficacy in single-cell biology.",
      "authors": "He Fei; Fei Ruixin; Gao Mingyue; Su Li; Zhang Xinyu; Xu Dong",
      "year": "2024",
      "month": "Jan",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38352580",
      "doi": "10.1101/2024.02.02.578662",
      "title": "Spatial domain detection using contrastive self-supervised learning for spatial multi-omics technologies.",
      "abstract": "Recent advances in spatially-resolved single-omics and multi-omics technologies have led to the emergence of computational tools to detect or predict spatial domains. Additionally, histological images and immunofluorescence (IF) staining of proteins and cell types provide multiple perspectives and a more complete understanding of tissue architecture. Here, we introduce Proust, a scalable tool to predict discrete domains using spatial multi-omics data by combining the low-dimensional representation of biological profiles based on graph-based contrastive self-supervised learning. Our scalable method integrates multiple data modalities, such as RNA, protein, and H&E images, and predicts spatial domains within tissue samples. Through the integration of multiple modalities, Proust consistently demonstrates enhanced accuracy in detecting spatial domains, as evidenced across various benchmark datasets and technological platforms.",
      "authors": "Yao Jianing; Yu Jinglun; Caffo Brian; Page Stephanie C; Martinowich Keri; Hicks Stephanie C",
      "year": "2024",
      "month": "Feb",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38340264",
      "doi": "10.1007/s12539-024-00605-2",
      "title": "A Combined Manual Annotation and Deep-Learning Natural Language Processing Study on Accurate Entity Extraction in Hereditary Disease Related Biomedical Literature.",
      "abstract": "We report a combined manual annotation and deep-learning natural language processing study to make accurate entity extraction in hereditary disease related biomedical literature. A total of 400 full articles were manually annotated based on published guidelines by experienced genetic interpreters at Beijing Genomics Institute (BGI). The performance of our manual annotations was assessed by comparing our re-annotated results with those publicly available. The overall Jaccard index was calculated to be 0.866 for the four entity types-gene, variant, disease and species. Both a BERT-based large name entity recognition (NER) model and a DistilBERT-based simplified NER model were trained, validated and tested, respectively. Due to the limited manually annotated corpus, Such NER models were fine-tuned with two phases. The F1-scores of BERT-based NER for gene, variant, disease and species are 97.28%, 93.52%, 92.54% and 95.76%, respectively, while those of DistilBERT-based NER are 95.14%, 86.26%, 91.37% and 89.92%, respectively. Most importantly, the entity type of variant has been extracted by a large language model for the first time and a comparable F1-score with the state-of-the-art variant extraction model tmVar has been achieved.",
      "authors": "Huang Dao-Ling; Zeng Quanlei; Xiong Yun; Liu Shuixia; Pang Chaoqun; Xia Menglei; Fang Ting; Ma Yanli; Qiang Cuicui; Zhang Yi; Zhang Yu; Li Hong; Yuan Yuying",
      "year": "2024",
      "month": "Jun",
      "journal": "Interdisciplinary sciences, computational life sciences",
      "source": "pubmed"
    },
    {
      "pmid": "38337352",
      "doi": "10.3390/jcm13030656",
      "title": "Evaluating Computer Vision, Large Language, and Genome-Wide Association Models in a Limited Sized Patient Cohort for Pre-Operative Risk Stratification in Adult Spinal Deformity Surgery.",
      "abstract": "",
      "authors": "Schonfeld Ethan; Pant Aaradhya; Shah Aaryan; Sadeghzadeh Sina; Pangal Dhiraj; Rodrigues Adrian; Yoo Kelly; Marianayagam Neelan; Haider Ghani; Veeravagu Anand",
      "year": "2024",
      "month": "Jan",
      "journal": "Journal of clinical medicine",
      "source": "pubmed"
    },
    {
      "pmid": "38325383",
      "doi": "10.1016/j.crmeth.2024.100707",
      "title": "PolyAMiner-Bulk is a deep learning-based algorithm that decodes alternative polyadenylation dynamics from bulk RNA-seq data.",
      "abstract": "Alternative polyadenylation (APA) is a key post-transcriptional regulatory mechanism; yet, its regulation and impact on human diseases remain understudied. Existing bulk RNA sequencing (RNA-seq)-based APA methods predominantly rely on predefined annotations, severely impacting their ability to decode novel tissue- and disease-specific APA changes. Furthermore, they only account for the most proximal and distal cleavage and polyadenylation sites (C/PASs). Deconvoluting overlapping C/PASs and the inherent noisy 3' UTR coverage in bulk RNA-seq data pose additional challenges. To overcome these limitations, we introduce PolyAMiner-Bulk, an attention-based deep learning algorithm that accurately recapitulates C/PAS sequence grammar, resolves overlapping C/PASs, captures non-proximal-to-distal APA changes, and generates visualizations to illustrate APA dynamics. Evaluation on multiple datasets strongly evinces the performance merit of PolyAMiner-Bulk, accurately identifying more APA changes compared with other methods. With the growing importance of APA and the abundance of bulk RNA-seq data, PolyAMiner-Bulk establishes a robust paradigm of APA analysis.",
      "authors": "Jonnakuti Venkata Soumith; Wagner Eric J; Maletić-Savatić Mirjana; Liu Zhandong; Yalamanchili Hari Krishna",
      "year": "2024",
      "month": "Feb",
      "journal": "Cell reports methods",
      "source": "pubmed"
    },
    {
      "pmid": "38321340",
      "doi": "10.1186/s41747-023-00413-1",
      "title": "Empowering PET: harnessing deep learning for improved clinical insight.",
      "abstract": "This review aims to take a journey into the transformative impact of artificial intelligence (AI) on positron emission tomography (PET) imaging. To this scope, a broad overview of AI applications in the field of nuclear medicine and a thorough exploration of deep learning (DL) implementations in cancer diagnosis and therapy through PET imaging will be presented. We firstly describe the behind-the-scenes use of AI for image generation, including acquisition (event positioning, noise reduction though time-of-flight estimation and scatter correction), reconstruction (data-driven and model-driven approaches), restoration (supervised and unsupervised methods), and motion correction. Thereafter, we outline the integration of AI into clinical practice through the applications to segmentation, detection and classification, quantification, treatment planning, dosimetry, and radiomics/radiogenomics combined to tumour biological characteristics. Thus, this review seeks to showcase the overarching transformation of the field, ultimately leading to tangible improvements in patient treatment and response assessment. Finally, limitations and ethical considerations of the AI application to PET imaging and future directions of multimodal data mining in this discipline will be briefly discussed, including pressing challenges to the adoption of AI in molecular imaging such as the access to and interoperability of huge amount of data as well as the \"black-box\" problem, contributing to the ongoing dialogue on the transformative potential of AI in nuclear medicine.Relevance statementAI is rapidly revolutionising the world of medicine, including the fields of radiology and nuclear medicine. In the near future, AI will be used to support healthcare professionals. These advances will lead to improvements in diagnosis, in the assessment of response to treatment, in clinical decision making and in patient management.Key points• Applying AI has the potential to enhance the entire PET imaging pipeline.• AI may support several clinical tasks in both PET diagnosis and prognosis.• Interpreting the relationships between imaging and multiomics data will heavily rely on AI.",
      "authors": "Artesani Alessia; Bruno Alessandro; Gelardi Fabrizia; Chiti Arturo",
      "year": "2024",
      "month": "Feb",
      "journal": "European radiology experimental",
      "source": "pubmed"
    },
    {
      "pmid": "38317154",
      "doi": "10.1186/s12920-024-01796-9",
      "title": "A systematic analysis of deep learning in genomics and histopathology for precision oncology.",
      "abstract": "Digitized histopathological tissue slides and genomics profiling data are available for many patients with solid tumors. In the last 5 years, Deep Learning (DL) has been broadly used to extract clinically actionable information and biological knowledge from pathology slides and genomic data in cancer. In addition, a number of recent studies have introduced multimodal DL models designed to simultaneously process both images from pathology slides and genomic data as inputs. By comparing patterns from one data modality with those in another, multimodal DL models are capable of achieving higher performance compared to their unimodal counterparts. However, the application of these methodologies across various tumor entities and clinical scenarios lacks consistency. Here, we present a systematic survey of the academic literature from 2010 to November 2023, aiming to quantify the application of DL for pathology, genomics, and the combined use of both data types. After filtering 3048 publications, our search identified 534 relevant articles which then were evaluated by basic (diagnosis, grading, subtyping) and advanced (mutation, drug response and survival prediction) application types, publication year and addressed cancer tissue. Our analysis reveals a predominant application of DL in pathology compared to genomics. However, there is a notable surge in DL incorporation within both domains. Furthermore, while DL applied to pathology primarily targets the identification of histology-specific patterns in individual tissues, DL in genomics is more commonly used in a pan-cancer context. Multimodal DL, on the contrary, remains a niche topic, evidenced by a limited number of publications, primarily focusing on prognosis predictions. In summary, our quantitative analysis indicates that DL not only has a well-established role in histopathology but is also being successfully integrated into both genomic and multimodal applications. In addition, there is considerable potential in multimodal DL for harnessing further advanced tasks, such as predicting drug response. Nevertheless, this review also underlines the need for further research to bridge the existing gaps in these fields.",
      "authors": "Unger Michaela; Kather Jakob Nikolas",
      "year": "2024",
      "month": "Feb",
      "journal": "BMC medical genomics",
      "source": "pubmed"
    },
    {
      "pmid": "38303441",
      "doi": "10.3934/mbe.2024031",
      "title": "A prognostic prediction model for ovarian cancer using a cross-modal view correlation discovery network.",
      "abstract": "Ovarian cancer is a tumor with different clinicopathological and molecular features, and the vast majority of patients have local or extensive spread at the time of diagnosis. Early diagnosis and prognostic prediction of patients can contribute to the understanding of the underlying pathogenesis of ovarian cancer and the improvement of therapeutic outcomes. The occurrence of ovarian cancer is influenced by multiple complex mechanisms, including the genome, transcriptome and proteome. Different types of omics analysis help predict the survival rate of ovarian cancer patients. Multi-omics data of ovarian cancer exhibit high-dimensional heterogeneity, and existing methods for integrating multi-omics data have not taken into account the variability and inter-correlation between different omics data. In this paper, we propose a deep learning model, MDCADON, which utilizes multi-omics data and cross-modal view correlation discovery network. We introduce random forest into LASSO regression for feature selection on mRNA expression, DNA methylation, miRNA expression and copy number variation (CNV), aiming to select important features highly correlated with ovarian cancer prognosis. A multi-modal deep neural network is used to comprehensively learn feature representations of each omics data and clinical data, and cross-modal view correlation discovery network is employed to construct the multi-omics discovery tensor, exploring the inter-relationships between different omics data. The experimental results demonstrate that MDCADON is superior to the existing methods in predicting ovarian cancer prognosis, which enables survival analysis for patients and facilitates the determination of follow-up treatment plans. Finally, we perform Gene Ontology (GO) term analysis and biological pathway analysis on the genes identified by MDCADON, revealing the underlying mechanisms of ovarian cancer and providing certain support for guiding ovarian cancer treatments.",
      "authors": "Wang Huiqing; Han Xiao; Ren Jianxue; Cheng Hao; Li Haolin; Li Ying; Li Xue",
      "year": "2024",
      "month": "Jan",
      "journal": "Mathematical biosciences and engineering : MBE",
      "source": "pubmed"
    },
    {
      "pmid": "38267858",
      "doi": "10.1186/s12859-024-05656-2",
      "title": "InClust+: the deep generative framework with mask modules for multimodal data integration, imputation, and cross-modal generation.",
      "abstract": "With the development of single-cell technology, many cell traits can be measured. Furthermore, the multi-omics profiling technology could jointly measure two or more traits in a single cell simultaneously. In order to process the various data accumulated rapidly, computational methods for multimodal data integration are needed. Here, we present inClust+, a deep generative framework for the multi-omics. It's built on previous inClust that is specific for transcriptome data, and augmented with two mask modules designed for multimodal data processing: an input-mask module in front of the encoder and an output-mask module behind the decoder. InClust+ was first used to integrate scRNA-seq and MERFISH data from similar cell populations, and to impute MERFISH data based on scRNA-seq data. Then, inClust+ was shown to have the capability to integrate the multimodal data (e.g. tri-modal data with gene expression, chromatin accessibility and protein abundance) with batch effect. Finally, inClust+ was used to integrate an unlabeled monomodal scRNA-seq dataset and two labeled multimodal CITE-seq datasets, transfer labels from CITE-seq datasets to scRNA-seq dataset, and generate the missing modality of protein abundance in monomodal scRNA-seq data. In the above examples, the performance of inClust+ is better than or comparable to the most recent tools in the corresponding task. The inClust+ is a suitable framework for handling multimodal data. Meanwhile, the successful implementation of mask in inClust+ means that it can be applied to other deep learning methods with similar encoder-decoder architecture to broaden the application scope of these models.",
      "authors": "Wang Lifei; Nie Rui; Miao Xuexia; Cai Yankai; Wang Anqi; Zhang Hanwen; Zhang Jiang; Cai Jun",
      "year": "2024",
      "month": "Jan",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "38263515",
      "doi": "10.1038/s41587-023-02040-y",
      "title": "Mosaic integration and knowledge transfer of single-cell multimodal data with MIDAS.",
      "abstract": "Integrating single-cell datasets produced by multiple omics technologies is essential for defining cellular heterogeneity. Mosaic integration, in which different datasets share only some of the measured modalities, poses major challenges, particularly regarding modality alignment and batch effect removal. Here, we present a deep probabilistic framework for the mosaic integration and knowledge transfer (MIDAS) of single-cell multimodal data. MIDAS simultaneously achieves dimensionality reduction, imputation and batch correction of mosaic data by using self-supervised modality alignment and information-theoretic latent disentanglement. We demonstrate its superiority to 19 other methods and reliability by evaluating its performance in trimodal and mosaic integration tasks. We also constructed a single-cell trimodal atlas of human peripheral blood mononuclear cells and tailored transfer learning and reciprocal reference mapping schemes to enable flexible and accurate knowledge transfer from the atlas to new data. Applications in mosaic integration, pseudotime analysis and cross-tissue knowledge transfer on bone marrow mosaic datasets demonstrate the versatility and superiority of MIDAS. MIDAS is available at https://github.com/labomics/midas .",
      "authors": "He Zhen; Hu Shuofeng; Chen Yaowen; An Sijing; Zhou Jiahao; Liu Runyan; Shi Junfeng; Wang Jing; Dong Guohua; Shi Jinhui; Zhao Jiaxin; Ou-Yang Le; Zhu Yuan; Bo Xiaochen; Ying Xiaomin",
      "year": "2024",
      "month": "Oct",
      "journal": "Nature biotechnology",
      "source": "pubmed"
    },
    {
      "pmid": "38259343",
      "doi": "",
      "title": "Advancing bioinformatics with large language models: components, applications and perspectives.",
      "abstract": "Large language models (LLMs) are a class of artificial intelligence models based on deep learning, which have great performance in various tasks, especially in natural language processing (NLP). Large language models typically consist of artificial neural networks with numerous parameters, trained on large amounts of unlabeled input using self-supervised or semi-supervised learning. However, their potential for solving bioinformatics problems may even exceed their proficiency in modeling human language. In this review, we will provide a comprehensive overview of the essential components of large language models (LLMs) in bioinformatics, spanning genomics, transcriptomics, proteomics, drug discovery, and single-cell analysis. Key aspects covered include tokenization methods for diverse data types, the architecture of transformer models, the core attention mechanism, and the pre-training processes underlying these models. Additionally, we will introduce currently available foundation models and highlight their downstream applications across various bioinformatics domains. Finally, drawing from our experience, we will offer practical guidance for both LLM users and developers, emphasizing strategies to optimize their use and foster further innovation in the field.",
      "authors": "Liu Jiajia; Yang Mengyuan; Yu Yankai; Xu Haixia; Wang Tiangang; Li Kang; Zhou Xiaobo",
      "year": "2025",
      "month": "Jan",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "38235187",
      "doi": "10.1016/j.xinn.2023.100541",
      "title": "Microsnoop: A generalist tool for microscopy image representation.",
      "abstract": "Accurate profiling of microscopy images from small scale to high throughput is an essential procedure in basic and applied biological research. Here, we present Microsnoop, a novel deep learning-based representation tool trained on large-scale microscopy images using masked self-supervised learning. Microsnoop can process various complex and heterogeneous images, and we classified images into three categories: single-cell, full-field, and batch-experiment images. Our benchmark study on 10 high-quality evaluation datasets, containing over 2,230,000 images, demonstrated Microsnoop's robust and state-of-the-art microscopy image representation ability, surpassing existing generalist and even several custom algorithms. Microsnoop can be integrated with other pipelines to perform tasks such as superresolution histopathology image and multimodal analysis. Furthermore, Microsnoop can be adapted to various hardware and can be easily deployed on local or cloud computing platforms. We will regularly retrain and reevaluate the model using community-contributed data to consistently improve Microsnoop.",
      "authors": "Xun Dejin; Wang Rui; Zhang Xingcai; Wang Yi",
      "year": "2024",
      "month": "Jan",
      "journal": "Innovation (Cambridge (Mass.))",
      "source": "pubmed"
    },
    {
      "pmid": "38216534",
      "doi": "10.1093/bioinformatics/btae013",
      "title": "Multiomics-integrated deep language model enables in silico genome-wide detection of transcription factor binding site in unexplored biosamples.",
      "abstract": "Transcription factor binding sites (TFBS) are regulatory elements that have significant impact on transcription regulation and cell fate determination. Canonical motifs, biological experiments, and computational methods have made it possible to discover TFBS. However, most existing in silico TFBS prediction models are solely DNA-based, and are trained and utilized within the same biosample, which fail to infer TFBS in experimentally unexplored biosamples. Here, we propose TFBS prediction by modified TransFormer (TFTF), a multimodal deep language architecture which integrates multiomics information in epigenetic studies. In comparison to existing computational techniques, TFTF has state-of-the-art accuracy, and is also the first approach to accurately perform genome-wide detection for cell-type and species-specific TFBS in experimentally unexplored biosamples. Compared to peak calling methods, TFTF consistently discovers true TFBS in threshold tuning-free way, with higher recalled rates. The underlying mechanism of TFTF reveals greater attention to the targeted TF's motif region in TFBS, and general attention to the entire peak region in non-TFBS. TFTF can benefit from the integration of broader and more diverse data for improvement and can be applied to multiple epigenetic scenarios. We provide a web server (https://tftf.ibreed.cn/) for users to utilize TFTF model. Users can train TFTF model and discover TFBS with their own data.",
      "authors": "Yang Zikun; Li Xin; Sheng Lele; Zhu Ming; Lan Xun; Gu Fei",
      "year": "2024",
      "month": "Jan",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "38182825",
      "doi": "10.1038/s41556-023-01316-4",
      "title": "Single-cell spatial multi-omics and deep learning dissect enhancer-driven gene regulatory networks in liver zonation.",
      "abstract": "In the mammalian liver, hepatocytes exhibit diverse metabolic and functional profiles based on their location within the liver lobule. However, it is unclear whether this spatial variation, called zonation, is governed by a well-defined gene regulatory code. Here, using a combination of single-cell multiomics, spatial omics, massively parallel reporter assays and deep learning, we mapped enhancer-gene regulatory networks across mouse liver cell types. We found that zonation affects gene expression and chromatin accessibility in hepatocytes, among other cell types. These states are driven by the repressors TCF7L1 and TBX3, alongside other core hepatocyte transcription factors, such as HNF4A, CEBPA, FOXA1 and ONECUT1. To examine the architecture of the enhancers driving these cell states, we trained a hierarchical deep learning model called DeepLiver. Our study provides a multimodal understanding of the regulatory code underlying hepatocyte identity and their zonation state that can be used to engineer enhancers with specific activity levels and zonation patterns.",
      "authors": "Bravo González-Blas Carmen; Matetovici Irina; Hillen Hanne; Taskiran Ibrahim Ihsan; Vandepoel Roel; Christiaens Valerie; Sansores-García Leticia; Verboven Elisabeth; Hulselmans Gert; Poovathingal Suresh; Demeulemeester Jonas; Psatha Nikoleta; Mauduit David; Halder Georg; Aerts Stein",
      "year": "2024",
      "month": "Jan",
      "journal": "Nature cell biology",
      "source": "pubmed"
    },
    {
      "pmid": "38168460",
      "doi": "",
      "title": "Morphological Profiling for Drug Discovery in the Era of Deep Learning.",
      "abstract": "Morphological profiling is a valuable tool in phenotypic drug discovery. The advent of high-throughput automated imaging has enabled the capturing of a wide range of morphological features of cells or organisms in response to perturbations at the single-cell resolution. Concurrently, significant advances in machine learning and deep learning, especially in computer vision, have led to substantial improvements in analyzing large-scale high-content images at high-throughput. These efforts have facilitated understanding of compound mechanism-of-action (MOA), drug repurposing, characterization of cell morphodynamics under perturbation, and ultimately contributing to the development of novel therapeutics. In this review, we provide a comprehensive overview of the recent advances in the field of morphological profiling. We summarize the image profiling analysis workflow, survey a broad spectrum of analysis strategies encompassing feature engineering- and deep learning-based approaches, and introduce publicly available benchmark datasets. We place a particular emphasis on the application of deep learning in this pipeline, covering cell segmentation, image representation learning, and multimodal learning. Additionally, we illuminate the application of morphological profiling in phenotypic drug discovery and highlight potential challenges and opportunities in this field.",
      "authors": "Tang Qiaosi; Ratnayake Ranjala; Seabra Gustavo; Jiang Zhe; Fang Ruogu; Cui Lina; Ding Yousong; Kahveci Tamer; Bian Jiang; Li Chenglong; Luesch Hendrik; Li Yanjun",
      "year": "2024",
      "month": "Jan",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "38105974",
      "doi": "10.1101/2023.12.05.570153",
      "title": "Inferring Metabolic States from Single Cell Transcriptomic Data via Geometric Deep Learning.",
      "abstract": "The ability to measure gene expression at single-cell resolution has elevated our understanding of how biological features emerge from complex and interdependent networks at molecular, cellular, and tissue scales. As technologies have evolved that complement scRNAseq measurements with things like single-cell proteomic, epigenomic, and genomic information, it becomes increasingly apparent how much biology exists as a product of multimodal regulation. Biological processes such as transcription, translation, and post-translational or epigenetic modification impose both energetic and specific molecular demands on a cell and are therefore implicitly constrained by the metabolic state of the cell. While metabolomics is crucial for defining a holistic model of any biological process, the chemical heterogeneity of the metabolome makes it particularly difficult to measure, and technologies capable of doing this at single-cell resolution are far behind other multiomics modalities. To address these challenges, we present GEFMAP (Gene Expression-based Flux Mapping and Metabolic Pathway Prediction), a method based on geometric deep learning for predicting flux through reactions in a global metabolic network using transcriptomics data, which we ultimately apply to scRNAseq. GEFMAP leverages the natural graph structure of metabolic networks to learn both a biological objective for each cell and estimate a mass-balanced relative flux rate for each reaction in each cell using novel deep learning models.",
      "authors": "Steach Holly; Viswanath Siddharth; He Yixuan; Zhang Xitong; Ivanova Natalia; Hirn Matthew; Perlmutter Michael; Krishnaswamy Smita",
      "year": "2023",
      "month": "Dec",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38065399",
      "doi": "10.1016/j.biosystems.2023.105095",
      "title": "SetQuence & SetOmic: Deep set transformers for whole genome and exome tumour analysis.",
      "abstract": "In oncology, Deep Learning has shown great potential to personalise tasks such as tumour type classification, based on per-patient omics data-sets. Being high dimensional, incorporation of such data in one model is a challenge, often leading to one-dimensional studies and, therefore, information loss. Instead, we first propose relying on non-fixed sets of whole genome or whole exome variant-associated sequences, which can be used for supervised learning of oncology-relevant tasks by our Set Transformer based Deep Neural Network, SetQuence. We optimise this architecture to improve its efficiency. This allows for exploration of not just coding but also non-coding variants, from large datasets. Second, we extend the model to incorporate these representations together with multiple other sources of omics data in a flexible way with SetOmic. Evaluation, using these representations, shows improved robustness and reduced information loss compared to previous approaches, while still being computationally tractable. By means of Explainable Artificial Intelligence methods, our models are able to recapitulate the biological contribution of highly attributed features in the tumours studied. This validation opens the door to novel directions in multi-faceted genome and exome wide biomarker discovery and personalised treatment among other presently clinically relevant tasks.",
      "authors": "Jurenaite Neringa; León-Periñán Daniel; Donath Veronika; Torge Sunna; Jäkel René",
      "year": "2024",
      "month": "Jan",
      "journal": "Bio Systems",
      "source": "pubmed"
    },
    {
      "pmid": "38046141",
      "doi": "10.1016/j.heliyon.2023.e22244",
      "title": "Multimodal and multi-omics-based deep learning model for screening of optic neuropathy.",
      "abstract": "To examine the use of multimodal data and multi-omics strategies for optic nerve disease screening. This was a single-center retrospective study. A deep learning model was created from fundus photography and infrared reflectance (IR) images of patients with diabetic optic neuropathy, glaucomatous optic neuropathy, and optic neuritis. Patients who were seen at the Ophthalmology Department of First Affiliated Hospital of Nanchang University in Jiangxi Province from November 2019 to April 2023 were included in this study. The data were analyzed in single and multimodal modes following the traditional omics, Resnet101, and fusion models. The accuracy and area-under-the-curve (AUC) of each model were compared. A total of 312 images fundus and infrared fundus photographs were collected from 156 patients. When multi-modal data was used, the accuracy of the traditional omics mode, Resnet101, and fusion models with the training set were 0.97, 0.98, and 0.99, respectively. The accuracy of the same models with the test sets were 0.72, 0.87, and 0.88, respectively. We compared single- and multi-mode states by applying the data to the different groups in the learning model. In the traditional omics model, the macro-average AUCs of the features extracted from fundus photography, IR images, and multimodal data were 0.94, 0.90, and 0.96, respectively. When the same data were processed in the Resnet101 model, the scores were 0.97 equally. However, when multimodal data was utilized, the macro-average AUCs in the traditional omics, Resnet101, and fusion modesl were 0.96, 0.97, and 0.99, respectively. The deep learning model based on multimodal data and multi-omics strategies can improve the accuracy of screening and diagnosing diabetic optic neuropathy, glaucomatous optic neuropathy, and optic neuritis.",
      "authors": "Lin Ye-Ting; Zhou Qiong; Tan Jian; Tao Yulin",
      "year": "2023",
      "month": "Dec",
      "journal": "Heliyon",
      "source": "pubmed"
    },
    {
      "pmid": "38016996",
      "doi": "10.1038/s41598-023-47624-5",
      "title": "PepCNN deep learning tool for predicting peptide binding residues in proteins using sequence, structural, and language model features.",
      "abstract": "Protein-peptide interactions play a crucial role in various cellular processes and are implicated in abnormal cellular behaviors leading to diseases such as cancer. Therefore, understanding these interactions is vital for both functional genomics and drug discovery efforts. Despite a significant increase in the availability of protein-peptide complexes, experimental methods for studying these interactions remain laborious, time-consuming, and expensive. Computational methods offer a complementary approach but often fall short in terms of prediction accuracy. To address these challenges, we introduce PepCNN, a deep learning-based prediction model that incorporates structural and sequence-based information from primary protein sequences. By utilizing a combination of half-sphere exposure, position specific scoring matrices from multiple-sequence alignment tool, and embedding from a pre-trained protein language model, PepCNN outperforms state-of-the-art methods in terms of specificity, precision, and AUC. The PepCNN software and datasets are publicly available at https://github.com/abelavit/PepCNN.git .",
      "authors": "Chandra Abel; Sharma Alok; Dehzangi Iman; Tsunoda Tatsuhiko; Sattar Abdul",
      "year": "2023",
      "month": "Nov",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "38007979",
      "doi": "10.1016/j.media.2023.103040",
      "title": "Transformer with convolution and graph-node co-embedding: An accurate and interpretable vision backbone for predicting gene expressions from local histopathological image.",
      "abstract": "Inferring gene expressions from histopathological images has long been a fascinating yet challenging task, primarily due to the substantial disparities between the two modality. Existing strategies using local or global features of histological images are suffering model complexity, GPU consumption, low interpretability, insufficient encoding of local features, and over-smooth prediction of gene expressions among neighboring sites. In this paper, we develop TCGN (Transformer with Convolution and Graph-Node co-embedding method) for gene expression estimation from H&E-stained pathological slide images. TCGN comprises a combination of convolutional layers, transformer encoders, and graph neural networks, and is the first to integrate these blocks in a general and interpretable computer vision backbone. Notably, TCGN uniquely operates with just a single spot image as input for histopathological image analysis, simplifying the process while maintaining interpretability. We validate TCGN on three publicly available spatial transcriptomic datasets. TCGN consistently exhibited the best performance (with median PCC 0.232). TCGN offers superior accuracy while keeping parameters to a minimum (just 86.241 million), and it consumes minimal memory, allowing it to run smoothly even on personal computers. Moreover, TCGN can be extended to handle bulk RNA-seq data while providing the interpretability. Enhancing the accuracy of omics information prediction from pathological images not only establishes a connection between genotype and phenotype, enabling the prediction of costly-to-measure biomarkers from affordable histopathological images, but also lays the groundwork for future multi-modal data modeling. Our results confirm that TCGN is a powerful tool for inferring gene expressions from histopathological images in precision health applications.",
      "authors": "Xiao Xiao; Kong Yan; Li Ronghan; Wang Zuoheng; Lu Hui",
      "year": "2024",
      "month": "Jan",
      "journal": "Medical image analysis",
      "source": "pubmed"
    },
    {
      "pmid": "38002245",
      "doi": "10.3390/biom13111563",
      "title": "A New Approach for Multimodal Usage of Gene Expression and Its Image Representation for the Detection of Alzheimer's Disease.",
      "abstract": "Alzheimer's disease (AD) is a complex neurodegenerative disorder and the multifaceted nature of it requires innovative approaches that integrate various data modalities to enhance its detection. However, due to the cost of collecting multimodal data, multimodal datasets suffer from an insufficient number of samples. To mitigate the impact of a limited sample size on classification, we introduce a novel deep learning method (",
      "authors": "Akkaya Umit Murat; Kalkan Habil",
      "year": "2023",
      "month": "Oct",
      "journal": "Biomolecules",
      "source": "pubmed"
    },
    {
      "pmid": "38001875",
      "doi": "10.3390/biomedicines11112875",
      "title": "Empowering Renal Cancer Management with AI and Digital Pathology: Pathology, Diagnostics and Prognosis.",
      "abstract": "Renal cell carcinoma is a significant health burden worldwide, necessitating accurate and efficient diagnostic methods to guide treatment decisions. Traditional pathology practices have limitations, including interobserver variability and time-consuming evaluations. In recent years, digital pathology tools emerged as a promising solution to enhance the diagnosis and management of renal cancer. This review aims to provide a comprehensive overview of the current state and potential of digital pathology in the context of renal cell carcinoma. Through advanced image analysis algorithms, artificial intelligence (AI) technologies facilitate quantification of cellular and molecular markers, leading to improved accuracy and reproducibility in renal cancer diagnosis. Digital pathology platforms empower remote collaboration between pathologists and help with the creation of comprehensive databases for further research and machine learning applications. The integration of digital pathology tools with other diagnostic modalities, such as radiology and genomics, enables a novel multimodal characterization of different types of renal cell carcinoma. With continuous advancements and refinement, AI technologies are expected to play an integral role in diagnostics and clinical decision-making, improving patient outcomes. In this article, we explored the digital pathology instruments available for clear cell, papillary and chromophobe renal cancers from pathologist and data analyst perspectives.",
      "authors": "Ivanova Elena; Fayzullin Alexey; Grinin Victor; Ermilov Dmitry; Arutyunyan Alexander; Timashev Peter; Shekhter Anatoly",
      "year": "2023",
      "month": "Oct",
      "journal": "Biomedicines",
      "source": "pubmed"
    },
    {
      "pmid": "38001023",
      "doi": "10.1093/bioinformatics/btad717",
      "title": "Multimodal learning in clinical proteomics: enhancing antimicrobial resistance prediction models with chemical information.",
      "abstract": "Large-scale clinical proteomics datasets of infectious pathogens, combined with antimicrobial resistance outcomes, have recently opened the door for machine learning models which aim to improve clinical treatment by predicting resistance early. However, existing prediction frameworks typically train a separate model for each antimicrobial and species in order to predict a pathogen's resistance outcome, resulting in missed opportunities for chemical knowledge transfer and generalizability. We demonstrate the effectiveness of multimodal learning over proteomic and chemical features by exploring two clinically relevant tasks for our proposed deep learning models: drug recommendation and generalized resistance prediction. By adopting this multi-view representation of the pathogenic samples and leveraging the scale of the available datasets, our models outperformed the previous single-drug and single-species predictive models by statistically significant margins. We extensively validated the multi-drug setting, highlighting the challenges in generalizing beyond the training data distribution, and quantitatively demonstrate how suitable representations of antimicrobial drugs constitute a crucial tool in the development of clinically relevant predictive models. The code used to produce the results presented in this article is available at https://github.com/BorgwardtLab/MultimodalAMR.",
      "authors": "Visonà Giovanni; Duroux Diane; Miranda Lucas; Sükei Emese; Li Yiran; Borgwardt Karsten; Oliver Carlos",
      "year": "2023",
      "month": "Dec",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "37998588",
      "doi": "10.3390/diagnostics13223452",
      "title": "Cancer Diagnosis through Contour Visualization of Gene Expression Leveraging Deep Learning Techniques.",
      "abstract": "Prompt diagnostics and appropriate cancer therapy necessitate the use of gene expression databases. The integration of analytical methods can enhance detection precision by capturing intricate patterns and subtle connections in the data. This study proposes a diagnostic-integrated approach combining Empirical Bayes Harmonization (EBS), Jensen-Shannon Divergence (JSD), deep learning, and contour mathematics for cancer detection using gene expression data. EBS preprocesses the gene expression data, while JSD measures the distributional differences between cancerous and non-cancerous samples, providing invaluable insights into gene expression patterns. Deep learning (DL) models are employed for automatic deep feature extraction and to discern complex patterns from the data. Contour mathematics is applied to visualize decision boundaries and regions in the high-dimensional feature space. JSD imparts significant information to the deep learning model, directing it to concentrate on pertinent features associated with cancerous samples. Contour visualization elucidates the model's decision-making process, bolstering interpretability. The amalgamation of JSD, deep learning, and contour mathematics in gene expression dataset analysis diagnostics presents a promising pathway for precise cancer detection. This method taps into the prowess of deep learning for feature extraction while employing JSD to pinpoint distributional differences and contour mathematics for visual elucidation. The outcomes underscore its potential as a formidable instrument for cancer detection, furnishing crucial insights for timely diagnostics and tailor-made treatment strategies.",
      "authors": "Venkatesan Vinoth Kumar; Kuppusamy Murugesan Karthick Raghunath; Chandrasekaran Kaladevi Amarakundhi; Thyluru Ramakrishna Mahesh; Khan Surbhi Bhatia; Almusharraf Ahlam; Albuali Abdullah",
      "year": "2023",
      "month": "Nov",
      "journal": "Diagnostics (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "37993103",
      "doi": "10.1016/j.mcpro.2023.100682",
      "title": "IDPpub: Illuminating the Dark Phosphoproteome Through PubMed Mining.",
      "abstract": "Global phosphoproteomics experiments quantify tens of thousands of phosphorylation sites. However, data interpretation is hampered by our limited knowledge on functions, biological contexts, or precipitating enzymes of the phosphosites. This study establishes a repository of phosphosites with associated evidence in biomedical abstracts, using deep learning-based natural language processing techniques. Our model for illuminating the dark phosphoproteome through PubMed mining (IDPpub) was generated by fine-tuning BioBERT, a deep learning tool for biomedical text mining. Trained using sentences containing protein substrates and phosphorylation site positions from 3000 abstracts, the IDPpub model was then used to extract phosphorylation sites from all MEDLINE abstracts. The extracted proteins were normalized to gene symbols using the National Center for Biotechnology Information gene query, and sites were mapped to human UniProt sequences using ProtMapper and mouse UniProt sequences by direct match. Precision and recall were calculated using 150 curated abstracts, and utility was assessed by analyzing the CPTAC (Clinical Proteomics Tumor Analysis Consortium) pan-cancer phosphoproteomics datasets and the PhosphoSitePlus database. Using 10-fold cross validation, pairs of correct substrates and phosphosite positions were extracted with an average precision of 0.93 and recall of 0.94. After entity normalization and site mapping to human reference sequences, an independent validation achieved a precision of 0.91 and recall of 0.77. The IDPpub repository contains 18,458 unique human phosphorylation sites with evidence sentences from 58,227 abstracts and 5918 mouse sites in 14,610 abstracts. This included evidence sentences for 1803 sites identified in CPTAC studies that are not covered by manually curated functional information in PhosphoSitePlus. Evaluation results demonstrate the potential of IDPpub as an effective biomedical text mining tool for collecting phosphosites. Moreover, the repository (http://idppub.ptmax.org), which can be automatically updated, can serve as a powerful complement to existing resources.",
      "authors": "Savage Sara R; Zhang Yaoyun; Jaehnig Eric J; Liao Yuxing; Shi Zhiao; Pham Huy Anh; Xu Hua; Zhang Bing",
      "year": "2024",
      "month": "Jan",
      "journal": "Molecular & cellular proteomics : MCP",
      "source": "pubmed"
    },
    {
      "pmid": "37986761",
      "doi": "10.1101/2023.11.09.566187",
      "title": "Democratizing Protein Language Models with Parameter-Efficient Fine-Tuning.",
      "abstract": "Proteomics has been revolutionized by large pre-trained protein language models, which learn unsupervised representations from large corpora of sequences. The parameters of these models are then fine-tuned in a supervised setting to tailor the model to a specific downstream task. However, as model size increases, the computational and memory footprint of fine-tuning becomes a barrier for many research groups. In the field of natural language processing, which has seen a similar explosion in the size of models, these challenges have been addressed by methods for parameter-efficient fine-tuning (PEFT). In this work, we newly bring parameter-efficient fine-tuning methods to proteomics. Using the parameter-efficient method LoRA, we train new models for two important proteomic tasks: predicting protein-protein interactions (PPI) and predicting the symmetry of homooligomers. We show that for homooligomer symmetry prediction, these approaches achieve performance competitive with traditional fine-tuning while requiring reduced memory and using three orders of magnitude fewer parameters. On the PPI prediction task, we surprisingly find that PEFT models actually outperform traditional fine-tuning while using two orders of magnitude fewer parameters. Here, we go even further to show that freezing the parameters of the language model and training only a classification head also outperforms fine-tuning, using five orders of magnitude fewer parameters, and that both of these models outperform state-of-the-art PPI prediction methods with substantially reduced compute. We also demonstrate that PEFT is robust to variations in training hyper-parameters, and elucidate where best practices for PEFT in proteomics differ from in natural language processing. Thus, we provide a blueprint to democratize the power of protein language model tuning to groups which have limited computational resources.",
      "authors": "Sledzieski Samuel; Kshirsagar Meghana; Baek Minkyung; Berger Bonnie; Dodhia Rahul; Ferres Juan Lavista",
      "year": "2023",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "37958843",
      "doi": "10.3390/ijms242115858",
      "title": "Deep Learning for Genomics: From Early Neural Nets to Modern Large Language Models.",
      "abstract": "The data explosion driven by advancements in genomic research, such as high-throughput sequencing techniques, is constantly challenging conventional methods used in genomics. In parallel with the urgent demand for robust algorithms, deep learning has succeeded in various fields such as vision, speech, and text processing. Yet genomics entails unique challenges to deep learning, since we expect a superhuman intelligence that explores beyond our knowledge to interpret the genome from deep learning. A powerful deep learning model should rely on the insightful utilization of task-specific knowledge. In this paper, we briefly discuss the strengths of different deep learning models from a genomic perspective so as to fit each particular task with proper deep learning-based architecture, and we remark on practical considerations of developing deep learning architectures for genomics. We also provide a concise review of deep learning applications in various aspects of genomic research and point out current challenges and potential research directions for future genomics applications. We believe the collaborative use of ever-growing diverse data and the fast iteration of deep learning models will continue to contribute to the future of genomics.",
      "authors": "Yue Tianwei; Wang Yuanxin; Zhang Longxiang; Gu Chunming; Xue Haoru; Wang Wenping; Lyu Qi; Dun Yujie",
      "year": "2023",
      "month": "Nov",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "37957311",
      "doi": "10.1038/s41598-023-47113-9",
      "title": "A novel method for identifying key genes in macroevolution based on deep learning with attention mechanism.",
      "abstract": "Macroevolution can be regarded as the result of evolutionary changes of synergistically acting genes. Unfortunately, the importance of these genes in macroevolution is difficult to assess and hence the identification of macroevolutionary key genes is a major challenge in evolutionary biology. In this study, we designed various word embedding libraries of natural language processing (NLP) considering the multiple mechanisms of evolutionary genomics. A novel method (IKGM) based on three types of attention mechanisms (domain attention, kmer attention and fused attention) were proposed to calculate the weights of different genes in macroevolution. Taking 34 species of diurnal butterflies and nocturnal moths in Lepidoptera as an example, we identified a few of key genes with high weights, which annotated to the functions of circadian rhythms, sensory organs, as well as behavioral habits etc. This study not only provides a novel method to identify the key genes of macroevolution at the genomic level, but also helps us to understand the microevolution mechanisms of diurnal butterflies and nocturnal moths in Lepidoptera.",
      "authors": "Mao Jiawei; Cao Yong; Zhang Yan; Huang Biaosheng; Zhao Youjie",
      "year": "2023",
      "month": "Nov",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "37916871",
      "doi": "10.1021/acssynbio.3c00154",
      "title": "Nucleic Transformer: Classifying DNA Sequences with Self-Attention and Convolutions.",
      "abstract": "Much work has been done to apply machine learning and deep learning to genomics tasks, but these applications usually require extensive domain knowledge, and the resulting models provide very limited interpretability. Here, we present the Nucleic Transformer, a conceptually simple but effective and interpretable model architecture that excels in the classification of DNA sequences. The Nucleic Transformer employs self-attention and convolutions on nucleic acid sequences, leveraging two prominent deep learning strategies commonly used in computer vision and natural language analysis. We demonstrate that the Nucleic Transformer can be trained without much domain knowledge to achieve high performance in ",
      "authors": "He Shujun; Gao Baizhen; Sabnis Rushant; Sun Qing",
      "year": "2023",
      "month": "Nov",
      "journal": "ACS synthetic biology",
      "source": "pubmed"
    },
    {
      "pmid": "37905130",
      "doi": "10.1101/2023.10.16.562533",
      "title": "GenePT: A Simple But Effective Foundation Model for Genes and Cells Built From ChatGPT.",
      "abstract": "There has been significant recent progress in leveraging large-scale gene expression data to develop foundation models for single-cell biology. Models such as Geneformer and scGPT implicitly learn gene and cellular functions from the gene expression profiles of millions of cells, which requires extensive data curation and resource-intensive training. Here we explore a much simpler alternative by leveraging ChatGPT embeddings of genes based on literature. Our proposal, GenePT, uses NCBI text descriptions of individual genes with GPT-3.5 to generate gene embeddings. From there, GenePT generates single-cell embeddings in two ways: (i) by averaging the gene embeddings, weighted by each gene's expression level; or (ii) by creating a sentence embedding for each cell, using gene names ordered by the expression level. Without the need for dataset curation and additional pretraining, GenePT is efficient and easy to use. On many downstream tasks used to evaluate recent single-cell foundation models - e.g., classifying gene properties and cell types - GenePT achieves comparable, and often better, performance than Geneformer and other models. GenePT demonstrates that large language model embedding of literature is a simple and effective path for biological foundation models.",
      "authors": "Chen Yiqun; Zou James",
      "year": "2024",
      "month": "Mar",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "37904945",
      "doi": "10.1101/2023.10.12.562113",
      "title": "GUANinE v1.0: Benchmark Datasets for Genomic AI Sequence-to-Function Models.",
      "abstract": "Computational genomics increasingly relies on machine learning methods for genome interpretation, and the recent adoption of neural sequence-to-function models highlights the need for rigorous model specification and controlled evaluation, problems familiar to other fields of AI. Research strategies that have greatly benefited other fields - including benchmarking, auditing, and algorithmic fairness - are also needed to advance the field of genomic AI and to facilitate model development. Here we propose a genomic AI benchmark, GUANinE, for evaluating model generalization across a number of distinct genomic tasks. Compared to existing task formulations in computational genomics, GUANinE is large-scale, de-noised, and suitable for evaluating pretrained models. GUANinE v1.0 primarily focuses on functional genomics tasks such as functional element annotation and gene expression prediction, and it also draws upon connections to evolutionary biology through sequence conservation tasks. The current GUANinE tasks provide insight into the performance of existing genomic AI models and non-neural baselines, with opportunities to be refined, revisited, and broadened as the field matures. Finally, the GUANinE benchmark allows us to evaluate new self-supervised T5 models and explore the tradeoffs between tokenization and model performance, while showcasing the potential for self-supervision to complement existing pretraining procedures.",
      "authors": "Robson Eyes S; Ioannidis Nilah M",
      "year": "2024",
      "month": "Mar",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "37904203",
      "doi": "10.1186/s13073-023-01248-6",
      "title": "DeepGAMI: deep biologically guided auxiliary learning for multimodal integration and imputation to improve genotype-phenotype prediction.",
      "abstract": "Genotypes are strongly associated with disease phenotypes, particularly in brain disorders. However, the molecular and cellular mechanisms behind this association remain elusive. With emerging multimodal data for these mechanisms, machine learning methods can be applied for phenotype prediction at different scales, but due to the black-box nature of machine learning, integrating these modalities and interpreting biological mechanisms can be challenging. Additionally, the partial availability of these multimodal data presents a challenge in developing these predictive models. To address these challenges, we developed DeepGAMI, an interpretable neural network model to improve genotype-phenotype prediction from multimodal data. DeepGAMI leverages functional genomic information, such as eQTLs and gene regulation, to guide neural network connections. Additionally, it includes an auxiliary learning layer for cross-modal imputation allowing the imputation of latent features of missing modalities and thus predicting phenotypes from a single modality. Finally, DeepGAMI uses integrated gradient to prioritize multimodal features for various phenotypes. We applied DeepGAMI to several multimodal datasets including genotype and bulk and cell-type gene expression data in brain diseases, and gene expression and electrophysiology data of mouse neuronal cells. Using cross-validation and independent validation, DeepGAMI outperformed existing methods for classifying disease types, and cellular and clinical phenotypes, even using single modalities (e.g., AUC score of 0.79 for Schizophrenia and 0.73 for cognitive impairment in Alzheimer's disease). We demonstrated that DeepGAMI improves phenotype prediction and prioritizes phenotypic features and networks in multiple multimodal datasets in complex brains and brain diseases. Also, it prioritized disease-associated variants, genes, and regulatory networks linked to different phenotypes, providing novel insights into the interpretation of gene regulatory mechanisms. DeepGAMI is open-source and available for general use.",
      "authors": "Chandrashekar Pramod Bharadwaj; Alatkar Sayali; Wang Jiebiao; Hoffman Gabriel E; He Chenfeng; Jin Ting; Khullar Saniya; Bendl Jaroslav; Fullard John F; Roussos Panos; Wang Daifeng",
      "year": "2023",
      "month": "Oct",
      "journal": "Genome medicine",
      "source": "pubmed"
    },
    {
      "pmid": "37884495",
      "doi": "10.1038/s41467-023-42547-1",
      "title": "Dynamic characterization and interpretation for protein-RNA interactions across diverse cellular conditions using HDRNet.",
      "abstract": "RNA-binding proteins play crucial roles in the regulation of gene expression, and understanding the interactions between RNAs and RBPs in distinct cellular conditions forms the basis for comprehending the underlying RNA function. However, current computational methods pose challenges to the cross-prediction of RNA-protein binding events across diverse cell lines and tissue contexts. Here, we develop HDRNet, an end-to-end deep learning-based framework to precisely predict dynamic RBP binding events under diverse cellular conditions. Our results demonstrate that HDRNet can accurately and efficiently identify binding sites, particularly for dynamic prediction, outperforming other state-of-the-art models on 261 linear RNA datasets from both eCLIP and CLIP-seq, supplemented with additional tissue data. Moreover, we conduct motif and interpretation analyses to provide fresh insights into the pathological mechanisms underlying RNA-RBP interactions from various perspectives. Our functional genomic analysis further explores the gene-human disease associations, uncovering previously uncharacterized observations for a broad range of genetic disorders.",
      "authors": "Zhu Haoran; Yang Yuning; Wang Yunhe; Wang Fuzhou; Huang Yujian; Chang Yi; Wong Ka-Chun; Li Xiangtao",
      "year": "2023",
      "month": "Oct",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "37879443",
      "doi": "10.1016/j.annonc.2023.10.125",
      "title": "Artificial intelligence for predictive biomarker discovery in immuno-oncology: a systematic review.",
      "abstract": "The widespread use of immune checkpoint inhibitors (ICIs) has revolutionised treatment of multiple cancer types. However, selecting patients who may benefit from ICI remains challenging. Artificial intelligence (AI) approaches allow exploitation of high-dimension oncological data in research and development of precision immuno-oncology. We conducted a systematic literature review of peer-reviewed original articles studying the ICI efficacy prediction in cancer patients across five data modalities: genomics (including genomics, transcriptomics, and epigenomics), radiomics, digital pathology (pathomics), and real-world and multimodality data. A total of 90 studies were included in this systematic review, with 80% published in 2021-2022. Among them, 37 studies included genomic, 20 radiomic, 8 pathomic, 20 real-world, and 5 multimodal data. Standard machine learning (ML) methods were used in 72% of studies, deep learning (DL) methods in 22%, and both in 6%. The most frequently studied cancer type was non-small-cell lung cancer (36%), followed by melanoma (16%), while 25% included pan-cancer studies. No prospective study design incorporated AI-based methodologies from the outset; rather, all implemented AI as a post hoc analysis. Novel biomarkers for ICI in radiomics and pathomics were identified using AI approaches, and molecular biomarkers have expanded past genomics into transcriptomics and epigenomics. Finally, complex algorithms and new types of AI-based markers, such as meta-biomarkers, are emerging by integrating multimodal/multi-omics data. AI-based methods have expanded the horizon for biomarker discovery, demonstrating the power of integrating multimodal data from existing datasets to discover new meta-biomarkers. While most of the included studies showed promise for AI-based prediction of benefit from immunotherapy, none provided high-level evidence for immediate practice change. A priori planned prospective trial designs are needed to cover all lifecycle steps of these software biomarkers, from development and validation to integration into clinical practice.",
      "authors": "Prelaj A; Miskovic V; Zanitti M; Trovo F; Genova C; Viscardi G; Rebuzzi S E; Mazzeo L; Provenzano L; Kosta S; Favali M; Spagnoletti A; Castelo-Branco L; Dolezal J; Pearson A T; Lo Russo G; Proto C; Ganzinelli M; Giani C; Ambrosini E; Turajlic S; Au L; Koopman M; Delaloge S; Kather J N; de Braud F; Garassino M C; Pentheroudakis G; Spencer C; Pedrocchi A L G",
      "year": "2024",
      "month": "Jan",
      "journal": "Annals of oncology : official journal of the European Society for Medical Oncology",
      "source": "pubmed"
    },
    {
      "pmid": "41675241",
      "doi": "10.15302/J-QB-022-0323",
      "title": "Transformer-based DNA methylation detection on ionic signals from Oxford Nanopore sequencing data.",
      "abstract": "Transformer is an algorithm that adopts self-attention architecture in the neural networks and has been widely used in natural language processing. In the current study, we apply Transformer architecture to detect DNA methylation on ionic signals from Oxford Nanopore sequencing data. We evaluated this idea using real data sets ( Oxford Nanopore long-read sequencing technology addresses current limitations for DNA methylation detection that are inherent in short-read bisulfite sequencing or methylation microarrays. A number of analytical tools, such as Nanopolish, Guppy/Tombo and DeepMod, have been developed to detect DNA methylation on Nanopore data. However, additional improvements can be made in computational efficiency, prediction accuracy, and contextual interpretation on complex genomics regions (such as repetitive regions, low GC density regions). In the current study, we apply Transformer architecture to detect DNA methylation on ionic signals from Oxford Nanopore sequencing data. Transformer is an algorithm that adopts self-attention architecture in the neural networks and has been widely used in natural language processing. Compared to traditional deep-learning method such as convolutional neural network (CNN) and recurrent neural network (RNN), Transformer may have specific advantages in DNA methylation detection, because the self-attention mechanism can assist the relationship detection between bases that are far from each other and pay more attention to important bases that carry characteristic methylation-specific signals within a specific sequence context. We demonstrated the ability of Transformers to detect methylation on ionic signal data.",
      "authors": "Wang Xiuquan; Ahsan Mian Umair; Zhou Yunyun; Wang Kai",
      "year": "2023",
      "month": "Sep",
      "journal": "Quantitative biology (Beijing, China)",
      "source": "pubmed"
    },
    {
      "pmid": "37845713",
      "doi": "10.1186/s12967-023-04576-8",
      "title": "Harnessing large language models (LLMs) for candidate gene prioritization and selection.",
      "abstract": "Feature selection is a critical step for translating advances afforded by systems-scale molecular profiling into actionable clinical insights. While data-driven methods are commonly utilized for selecting candidate genes, knowledge-driven methods must contend with the challenge of efficiently sifting through extensive volumes of biomedical information. This work aimed to assess the utility of large language models (LLMs) for knowledge-driven gene prioritization and selection. In this proof of concept, we focused on 11 blood transcriptional modules associated with an Erythroid cells signature. We evaluated four leading LLMs across multiple tasks. Next, we established a workflow leveraging LLMs. The steps consisted of: (1) Selecting one of the 11 modules; (2) Identifying functional convergences among constituent genes using the LLMs; (3) Scoring candidate genes across six criteria capturing the gene's biological and clinical relevance; (4) Prioritizing candidate genes and summarizing justifications; (5) Fact-checking justifications and identifying supporting references; (6) Selecting a top candidate gene based on validated scoring justifications; and (7) Factoring in transcriptome profiling data to finalize the selection of the top candidate gene. Of the four LLMs evaluated, OpenAI's GPT-4 and Anthropic's Claude demonstrated the best performance and were chosen for the implementation of the candidate gene prioritization and selection workflow. This workflow was run in parallel for each of the 11 erythroid cell modules by participants in a data mining workshop. Module M9.2 served as an illustrative use case. The 30 candidate genes forming this module were assessed, and the top five scoring genes were identified as BCL2L1, ALAS2, SLC4A1, CA1, and FECH. Researchers carefully fact-checked the summarized scoring justifications, after which the LLMs were prompted to select a top candidate based on this information. GPT-4 initially chose BCL2L1, while Claude selected ALAS2. When transcriptional profiling data from three reference datasets were provided for additional context, GPT-4 revised its initial choice to ALAS2, whereas Claude reaffirmed its original selection for this module. Taken together, our findings highlight the ability of LLMs to prioritize candidate genes with minimal human intervention. This suggests the potential of this technology to boost productivity, especially for tasks that require leveraging extensive biomedical knowledge.",
      "authors": "Toufiq Mohammed; Rinchai Darawan; Bettacchioli Eleonore; Kabeer Basirudeen Syed Ahamed; Khan Taushif; Subba Bishesh; White Olivia; Yurieva Marina; George Joshy; Jourde-Chiche Noemie; Chiche Laurent; Palucka Karolina; Chaussabel Damien",
      "year": "2023",
      "month": "Oct",
      "journal": "Journal of translational medicine",
      "source": "pubmed"
    },
    {
      "pmid": "37835770",
      "doi": "10.3390/diagnostics13193027",
      "title": "Application of Multimodal MRI in the Early Diagnosis of Autism Spectrum Disorders: A Review.",
      "abstract": "Autism spectrum disorder (ASD) is a neurodevelopmental disorder in children. Early diagnosis and intervention can remodel the neural structure of the brain and improve quality of life but may be inaccurate if based solely on clinical symptoms and assessment scales. Therefore, we aimed to analyze multimodal magnetic resonance imaging (MRI) data from the existing literature and review the abnormal changes in brain structural-functional networks, perfusion, neuronal metabolism, and the glymphatic system in children with ASD, which could help in early diagnosis and precise intervention. Structural MRI revealed morphological differences, abnormal developmental trajectories, and network connectivity changes in the brain at different ages. Functional MRI revealed disruption of functional networks, abnormal perfusion, and neurovascular decoupling associated with core ASD symptoms. Proton magnetic resonance spectroscopy revealed abnormal changes in the neuronal metabolites during different periods. Decreased diffusion tensor imaging signals along the perivascular space index reflected impaired glymphatic system function in children with ASD. Differences in age, subtype, degree of brain damage, and remodeling in children with ASD led to heterogeneity in research results. Multimodal MRI is expected to further assist in early and accurate clinical diagnosis of ASD through deep learning combined with genomics and artificial intelligence.",
      "authors": "Wang Miaoyan; Xu Dandan; Zhang Lili; Jiang Haoxiang",
      "year": "2023",
      "month": "Sep",
      "journal": "Diagnostics (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "37833700",
      "doi": "10.1186/s12920-023-01675-9",
      "title": "c-Diadem: a constrained dual-input deep learning model to identify novel biomarkers in Alzheimer's disease.",
      "abstract": "Alzheimer's disease (AD) is an incurable, debilitating neurodegenerative disorder. Current biomarkers for AD diagnosis require expensive neuroimaging or invasive cerebrospinal fluid sampling, thus precluding early detection. Blood-based biomarker discovery in Alzheimer's can facilitate less-invasive, routine diagnostic tests to aid early intervention. Therefore, we propose \"c-Diadem\" (constrained dual-input Alzheimer's disease model), a novel deep learning classifier which incorporates KEGG (Kyoto Encyclopedia of Genes and Genomes) pathway constraints on the input genotyping data to predict disease, i.e., mild cognitive impairment (MCI)/AD or cognitively normal (CN). SHAP (SHapley Additive exPlanations) was used to explain the model and identify novel, potential blood-based genetic markers of MCI/AD. We developed a novel constrained deep learning neural network which utilizes SNPs (single nucleotide polymorphisms) and microarray data from ADNI (Alzheimer's Disease Neuroimaging Initiative) to predict the disease status of participants, i.e., CN or with disease (MCI/AD), and identify potential blood-based biomarkers for diagnosis and intervention. The dataset contains samples from 626 participants, of which 212 are CN (average age 74.6 ± 5.4 years) and 414 patients have MCI/AD (average age 72.7 ± 7.6 years). KEGG pathway information was used to generate constraints applied to the input tensors, thus enhancing the interpretability of the model. SHAP scores were used to identify genes which could potentially serve as biomarkers for diagnosis and targets for drug development. Our model's performance, with accuracy of 69% and AUC of 70% in the test dataset, is superior to previous models. The SHAP scores show that SNPs in PRKCZ, PLCB1 and ITPR2 as well as expression of HLA-DQB1, EIF1AY, HLA-DQA1, and ZFP57 have more impact on model predictions. In addition to predicting MCI/AD, our model has been interrogated for potential genetic biomarkers using SHAP. From our analysis, we have identified blood-based genetic markers related to Ca",
      "authors": "Jemimah Sherlyn; AlShehhi Aamna",
      "year": "2023",
      "month": "Oct",
      "journal": "BMC medical genomics",
      "source": "pubmed"
    },
    {
      "pmid": "37786667",
      "doi": "10.1101/2023.09.19.558548",
      "title": "",
      "abstract": "Single-cell spatial transcriptomics such as ",
      "authors": "Jin Kang; Zhang Zuobai; Zhang Ke; Viggiani Francesca; Callahan Claire; Tang Jian; Aronow Bruce J; Shu Jian",
      "year": "2023",
      "month": "Sep",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "37779744",
      "doi": "10.7759/cureus.44359",
      "title": "Artificial Intelligence and Machine Learning in Pharmacological Research: Bridging the Gap Between Data and Drug Discovery.",
      "abstract": "Artificial intelligence (AI) has transformed pharmacological research through machine learning, deep learning, and natural language processing. These advancements have greatly influenced drug discovery, development, and precision medicine. AI algorithms analyze vast biomedical data identifying potential drug targets, predicting efficacy, and optimizing lead compounds. AI has diverse applications in pharmacological research, including target identification, drug repurposing, virtual screening, de novo drug design, toxicity prediction, and personalized medicine. AI improves patient selection, trial design, and real-time data analysis in clinical trials, leading to enhanced safety and efficacy outcomes. Post-marketing surveillance utilizes AI-based systems to monitor adverse events, detect drug interactions, and support pharmacovigilance efforts. Machine learning models extract patterns from complex datasets, enabling accurate predictions and informed decision-making, thus accelerating drug discovery. Deep learning, specifically convolutional neural networks (CNN), excels in image analysis, aiding biomarker identification and optimizing drug formulation. Natural language processing facilitates the mining and analysis of scientific literature, unlocking valuable insights and information. However, the adoption of AI in pharmacological research raises ethical considerations. Ensuring data privacy and security, addressing algorithm bias and transparency, obtaining informed consent, and maintaining human oversight in decision-making are crucial ethical concerns. The responsible deployment of AI necessitates robust frameworks and regulations. The future of AI in pharmacological research is promising, with integration with emerging technologies like genomics, proteomics, and metabolomics offering the potential for personalized medicine and targeted therapies. Collaboration among academia, industry, and regulatory bodies is essential for the ethical implementation of AI in drug discovery and development. Continuous research and development in AI techniques and comprehensive training programs will empower scientists and healthcare professionals to fully exploit AI's potential, leading to improved patient outcomes and innovative pharmacological interventions.",
      "authors": "Singh Shruti; Kumar Rajesh; Payra Shuvasree; Singh Sunil K",
      "year": "2023",
      "month": "Aug",
      "journal": "Cureus",
      "source": "pubmed"
    },
    {
      "pmid": "37671028",
      "doi": "10.1016/j.crmeth.2023.100563",
      "title": "Single-cell multi-omics topic embedding reveals cell-type-specific and COVID-19 severity-related immune signatures.",
      "abstract": "The advent of single-cell multi-omics sequencing technology makes it possible for researchers to leverage multiple modalities for individual cells and explore cell heterogeneity. However, the high-dimensional, discrete, and sparse nature of the data make the downstream analysis particularly challenging. Here, we propose an interpretable deep learning method called moETM to perform integrative analysis of high-dimensional single-cell multimodal data. moETM integrates multiple omics data via a product-of-experts in the encoder and employs multiple linear decoders to learn the multi-omics signatures. moETM demonstrates superior performance compared with six state-of-the-art methods on seven publicly available datasets. By applying moETM to the scRNA + scATAC data, we identified sequence motifs corresponding to the transcription factors regulating immune gene signatures. Applying moETM to CITE-seq data from the COVID-19 patients revealed not only known immune cell-type-specific signatures but also composite multi-omics biomarkers of critical conditions due to COVID-19, thus providing insights from both biological and clinical perspectives.",
      "authors": "Zhou Manqi; Zhang Hao; Bai Zilong; Mann-Krzisnik Dylan; Wang Fei; Li Yue",
      "year": "2023",
      "month": "Aug",
      "journal": "Cell reports methods",
      "source": "pubmed"
    },
    {
      "pmid": "37669132",
      "doi": "10.1093/bioinformatics/btad541",
      "title": "Multimodal learning of noncoding variant effects using genome sequence and chromatin structure.",
      "abstract": "A growing amount of noncoding genetic variants, including single-nucleotide polymorphisms, are found to be associated with complex human traits and diseases. Their mechanistic interpretation is relatively limited and can use the help from computational prediction of their effects on epigenetic profiles. However, current models often focus on local, 1D genome sequence determinants and disregard global, 3D chromatin structure that critically affects epigenetic events. We find that noncoding variants of unexpected high similarity in epigenetic profiles, with regards to their relatively low similarity in local sequences, can be largely attributed to their proximity in chromatin structure. Accordingly, we have developed a multimodal deep learning scheme that incorporates both data of 1D genome sequence and 3D chromatin structure for predicting noncoding variant effects. Specifically, we have integrated convolutional and recurrent neural networks for sequence embedding and graph neural networks for structure embedding despite the resolution gap between the two types of data, while utilizing recent DNA language models. Numerical results show that our models outperform competing sequence-only models in predicting epigenetic profiles and their use of long-range interactions complement sequence-only models in extracting regulatory motifs. They prove to be excellent predictors for noncoding variant effects in gene expression and pathogenicity, whether in unsupervised \"zero-shot\" learning or supervised \"few-shot\" learning. Codes and data can be accessed at https://github.com/Shen-Lab/ncVarPred-1D3D and https://zenodo.org/record/7975777.",
      "authors": "Tan Wuwei; Shen Yang",
      "year": "2023",
      "month": "Sep",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "37651607",
      "doi": "10.1093/bib/bbad313",
      "title": "Multimodal deep learning approaches for single-cell multi-omics data integration.",
      "abstract": "Integrating single-cell multi-omics data is a challenging task that has led to new insights into complex cellular systems. Various computational methods have been proposed to effectively integrate these rapidly accumulating datasets, including deep learning. However, despite the proven success of deep learning in integrating multi-omics data and its better performance over classical computational methods, there has been no systematic study of its application to single-cell multi-omics data integration. To fill this gap, we conducted a literature review to explore the use of multimodal deep learning techniques in single-cell multi-omics data integration, taking into account recent studies from multiple perspectives. Specifically, we first summarized different modalities found in single-cell multi-omics data. We then reviewed current deep learning techniques for processing multimodal data and categorized deep learning-based integration methods for single-cell multi-omics data according to data modality, deep learning architecture, fusion strategy, key tasks and downstream analysis. Finally, we provided insights into using these deep learning models to integrate multi-omics data and better understand single-cell biological mechanisms.",
      "authors": "Athaya Tasbiraha; Ripan Rony Chowdhury; Li Xiaoman; Hu Haiyan",
      "year": "2023",
      "month": "Sep",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "37645040",
      "doi": "",
      "title": "Single-Cell Multimodal Prediction via Transformers.",
      "abstract": "The recent development of multimodal single-cell technology has made the possibility of acquiring multiple omics data from individual cells, thereby enabling a deeper understanding of cellular states and dynamics. Nevertheless, the proliferation of multimodal single-cell data also introduces tremendous challenges in modeling the complex interactions among different modalities. The recently advanced methods focus on constructing static interaction graphs and applying graph neural networks (GNNs) to learn from multimodal data. However, such static graphs can be suboptimal as they do not take advantage of the downstream task information; meanwhile GNNs also have some inherent limitations when deeply stacking GNN layers. To tackle these issues, in this work, we investigate how to leverage transformers for multimodal single-cell data in an end-to-end manner while exploiting downstream task information. In particular, we propose a ",
      "authors": "Tang Wenzhuo; Wen Hongzhi; Liu Renming; Ding Jiayuan; Jin Wei; Xie Yuying; Liu Hui; Tang Jiliang",
      "year": "2023",
      "month": "Oct",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "37635383",
      "doi": "10.1093/bib/bbad307",
      "title": "A systematic benchmark of machine learning methods for protein-RNA interaction prediction.",
      "abstract": "RNA-binding proteins (RBPs) are central actors of RNA post-transcriptional regulation. Experiments to profile-binding sites of RBPs in vivo are limited to transcripts expressed in the experimental cell type, creating the need for computational methods to infer missing binding information. While numerous machine-learning based methods have been developed for this task, their use of heterogeneous training and evaluation datasets across different sets of RBPs and CLIP-seq protocols makes a direct comparison of their performance difficult. Here, we compile a set of 37 machine learning (primarily deep learning) methods for in vivo RBP-RNA interaction prediction and systematically benchmark a subset of 11 representative methods across hundreds of CLIP-seq datasets and RBPs. Using homogenized sample pre-processing and two negative-class sample generation strategies, we evaluate methods in terms of predictive performance and assess the impact of neural network architectures and input modalities on model performance. We believe that this study will not only enable researchers to choose the optimal prediction method for their tasks at hand, but also aid method developers in developing novel, high-performing methods by introducing a standardized framework for their evaluation.",
      "authors": "Horlacher Marc; Cantini Giulia; Hesse Julian; Schinke Patrick; Goedert Nicolas; Londhe Shubhankar; Moyon Lambert; Marsico Annalisa",
      "year": "2023",
      "month": "Sep",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "37547471",
      "doi": "10.3389/fgene.2023.1199087",
      "title": "A review of multi-omics data integration through deep learning approaches for disease diagnosis, prognosis, and treatment.",
      "abstract": "Accurate diagnosis is the key to providing prompt and explicit treatment and disease management. The recognized biological method for the molecular diagnosis of infectious pathogens is polymerase chain reaction (PCR). Recently, deep learning approaches are playing a vital role in accurately identifying disease-related genes for diagnosis, prognosis, and treatment. The models reduce the time and cost used by wet-lab experimental procedures. Consequently, sophisticated computational approaches have been developed to facilitate the detection of cancer, a leading cause of death globally, and other complex diseases. In this review, we systematically evaluate the recent trends in multi-omics data analysis based on deep learning techniques and their application in disease prediction. We highlight the current challenges in the field and discuss how advances in deep learning methods and their optimization for application is vital in overcoming them. Ultimately, this review promotes the development of novel deep-learning methodologies for data integration, which is essential for disease detection and treatment.",
      "authors": "Wekesa Jael Sanyanda; Kimwele Michael",
      "year": "2023",
      "month": "",
      "journal": "Frontiers in genetics",
      "source": "pubmed"
    },
    {
      "pmid": "37546876",
      "doi": "10.1101/2023.07.27.550727",
      "title": "Nextflow Pipeline for Visium and H&E Data from Patient-Derived Xenograft Samples.",
      "abstract": "We have developed an automated data processing pipeline to quantify mouse and human data from patient-derived xenograft samples assayed by Visium spatial transcriptomics with matched hematoxylin and eosin (H&E) stained image. We enable deconvolution of reads with Xenome, quantification of spatial gene expression from host and graft species with Space Ranger, extraction of B-allele frequencies, and splicing quantification with Velocyto. In the H&E image processing sub-workflow, we generate morphometric and deep learning-derived feature quantifications complementary to the Visium spots, enabling multi-modal H&E/expression comparisons. We have wrapped the pipeline into Nextflow DSL2 in a scalable, portable, and easy-to-use framework. We designed a Nextflow DSL2-based pipeline, Spatial Transcriptomics Quantification (STQ), for simultaneous processing of 10x Genomics Visium spatial transcriptomics data and a matched hematoxylin and eosin (H&E)-stained whole slide image (WSI), optimized for Patient-Derived Xenograft (PDX) cancer specimens. Our pipeline enables the classification of sequenced transcripts for deconvolving the mouse and human species and mapping the transcripts to reference transcriptomes. We align the H&E WSI with the spatial layout of the Visium slide and generate imaging and quantitative morphology features for each Visium spot. The pipeline design enables multiple analysis workflows, including single or dual reference genomes input and stand-alone image analysis. We showed the utility of our pipeline on a dataset from Visium profiling of four melanoma PDX samples. The clustering of Visium spots and clustering of imaging features of H&E data reveal similar patterns arising from the two data modalities.",
      "authors": "Domanskyi Sergii; Srivastava Anuj; Kaster Jessica; Li Haiyin; Herlyn Meenhard; Rubinstein Jill C; Chuang Jeffrey H",
      "year": "2023",
      "month": "Jul",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "37508462",
      "doi": "10.3390/biology12071033",
      "title": "Transformer Architecture and Attention Mechanisms in Genome Data Analysis: A Comprehensive Review.",
      "abstract": "The emergence and rapid development of deep learning, specifically transformer-based architectures and attention mechanisms, have had transformative implications across several domains, including bioinformatics and genome data analysis. The analogous nature of genome sequences to language texts has enabled the application of techniques that have exhibited success in fields ranging from natural language processing to genomic data. This review provides a comprehensive analysis of the most recent advancements in the application of transformer architectures and attention mechanisms to genome and transcriptome data. The focus of this review is on the critical evaluation of these techniques, discussing their advantages and limitations in the context of genome data analysis. With the swift pace of development in deep learning methodologies, it becomes vital to continually assess and reflect on the current standing and future direction of the research. Therefore, this review aims to serve as a timely resource for both seasoned researchers and newcomers, offering a panoramic view of the recent advancements and elucidating the state-of-the-art applications in the field. Furthermore, this review paper serves to highlight potential areas of future investigation by critically evaluating studies from 2019 to 2023, thereby acting as a stepping-stone for further research endeavors.",
      "authors": "Choi Sanghyuk Roy; Lee Minhyeok",
      "year": "2023",
      "month": "Jul",
      "journal": "Biology",
      "source": "pubmed"
    },
    {
      "pmid": "37502861",
      "doi": "10.1101/2023.07.15.549134",
      "title": "EpiGePT: a Pretrained Transformer model for epigenomics.",
      "abstract": "The inherent similarities between natural language and biological sequences have given rise to great interest in adapting the transformer-based large language models (LLMs) underlying recent breakthroughs in natural language processing (references), for applications in genomics. However, current LLMs for genomics suffer from several limitations such as the inability to include chromatin interactions in the training data, and the inability to make prediction in new cellular contexts not represented in the training data. To mitigate these problems, we propose EpiGePT, a transformer-based pretrained language model for predicting context-specific epigenomic signals and chromatin contacts. By taking the context-specific activities of transcription factors (TFs) and 3D genome interactions into consideration, EpiGePT offers wider applicability and deeper biological insights than models trained on DNA sequence only. In a series of experiments, EpiGePT demonstrates superior performance in a diverse set of epigenomic signals prediction tasks when compared to existing methods. In particular, our model enables cross-cell-type prediction of long-range interactions and offers insight on the functional impact of genetic variants under different cellular contexts. These new capabilities will enhance the usefulness of LLM in the study of gene regulatory mechanisms. We provide free online prediction service of EpiGePT through http://health.tsinghua.edu.cn/epigept/.",
      "authors": "Gao Zijing; Liu Qiao; Zeng Wanwen; Jiang Rui; Wong Wing Hung",
      "year": "2024",
      "month": "Feb",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "37481666",
      "doi": "10.1186/s13040-023-00338-w",
      "title": "Assessment of emerging pretraining strategies in interpretable multimodal deep learning for cancer prognostication.",
      "abstract": "Deep learning models can infer cancer patient prognosis from molecular and anatomic pathology information. Recent studies that leveraged information from complementary multimodal data improved prognostication, further illustrating the potential utility of such methods. However, current approaches: 1) do not comprehensively leverage biological and histomorphological relationships and 2) make use of emerging strategies to \"pretrain\" models (i.e., train models on a slightly orthogonal dataset/modeling objective) which may aid prognostication by reducing the amount of information required for achieving optimal performance. In addition, model interpretation is crucial for facilitating the clinical adoption of deep learning methods by fostering practitioner understanding and trust in the technology. Here, we develop an interpretable multimodal modeling framework that combines DNA methylation, gene expression, and histopathology (i.e., tissue slides) data, and we compare performance of crossmodal pretraining, contrastive learning, and transfer learning versus the standard procedure. Our models outperform the existing state-of-the-art method (average 11.54% C-index increase), and baseline clinically driven models (average 11.7% C-index increase). Model interpretations elucidate consideration of biologically meaningful factors in making prognosis predictions. Our results demonstrate that the selection of pretraining strategies is crucial for obtaining highly accurate prognostication models, even more so than devising an innovative model architecture, and further emphasize the all-important role of the tumor microenvironment on disease progression.",
      "authors": "Azher Zarif L; Suvarna Anish; Chen Ji-Qing; Zhang Ze; Christensen Brock C; Salas Lucas A; Vaickus Louis J; Levy Joshua J",
      "year": "2023",
      "month": "Jul",
      "journal": "BioData mining",
      "source": "pubmed"
    },
    {
      "pmid": "37467372",
      "doi": "10.1021/acssynbio.3c00203",
      "title": "Deep Neural Networks for Predicting Single-Cell Responses and Probability Landscapes.",
      "abstract": "Engineering biology relies on the accurate prediction of cell responses. However, making these predictions is challenging for a variety of reasons, including the stochasticity of biochemical reactions, variability between cells, and incomplete information about underlying biological processes. Machine learning methods, which can model diverse input-output relationships without requiring ",
      "authors": "Klumpe Heidi E; Lugagne Jean-Baptiste; Khalil Ahmad S; Dunlop Mary J",
      "year": "2023",
      "month": "Aug",
      "journal": "ACS synthetic biology",
      "source": "pubmed"
    },
    {
      "pmid": "37426456",
      "doi": "",
      "title": "HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.",
      "abstract": "Genomic (DNA) sequences encode an enormous amount of information for gene regulation and protein synthesis. Similar to natural language models, researchers have proposed foundation models in genomics to learn generalizable features from unlabeled genome data that can then be fine-tuned for downstream tasks such as identifying regulatory elements. Due to the quadratic scaling of attention, previous Transformer-based genomic models have used 512 to 4k tokens as context (<0.001% of the human genome), significantly limiting the modeling of long-range interactions in DNA. In addition, these methods rely on tokenizers or fixed k-mers to aggregate meaningful DNA units, losing single nucleotide resolution where subtle genetic variations can completely alter protein function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a large language model based on implicit convolutions was shown to match attention in quality while allowing longer context lengths and lower time complexity. Leveraging Hyena's new long-range capabilities, we present HyenaDNA, a genomic foundation model pretrained on the human reference genome with context lengths of up to 1 million tokens at the single nucleotide-level - an up to 500x increase over previous dense attention-based models. HyenaDNA scales sub-quadratically in sequence length (training up to 160x faster than Transformer), uses single nucleotide tokens, and has full global context at each layer. We explore what longer context enables - including the first use of in-context learning in genomics. On fine-tuned benchmarks from the Nucleotide Transformer, HyenaDNA reaches state-of-the-art (SotA) on 12 of 18 datasets using a model with orders of magnitude less parameters and pretraining data. On the GenomicBenchmarks, HyenaDNA surpasses SotA on 7 of 8 datasets on average by +10 accuracy points. Code at https://github.com/HazyResearch/hyena-dna.",
      "authors": "Nguyen Eric; Poli Michael; Faizi Marjan; Thomas Armin; Birch-Sykes Callum; Wornow Michael; Patel Aman; Rabideau Clayton; Massaroli Stefano; Bengio Yoshua; Ermon Stefano; Baccus Stephen A; Ré Chris",
      "year": "2023",
      "month": "Nov",
      "journal": "ArXiv",
      "source": "pubmed"
    },
    {
      "pmid": "37421941",
      "doi": "10.1016/j.molcel.2023.06.019",
      "title": "HydRA: Deep-learning models for predicting RNA-binding capacity from protein interaction association context and protein sequence.",
      "abstract": "RNA-binding proteins (RBPs) control RNA metabolism to orchestrate gene expression and, when dysfunctional, underlie human diseases. Proteome-wide discovery efforts predict thousands of RBP candidates, many of which lack canonical RNA-binding domains (RBDs). Here, we present a hybrid ensemble RBP classifier (HydRA), which leverages information from both intermolecular protein interactions and internal protein sequence patterns to predict RNA-binding capacity with unparalleled specificity and sensitivity using support vector machines (SVMs), convolutional neural networks (CNNs), and Transformer-based protein language models. Occlusion mapping by HydRA robustly detects known RBDs and predicts hundreds of uncharacterized RNA-binding associated domains. Enhanced CLIP (eCLIP) for HydRA-predicted RBP candidates reveals transcriptome-wide RNA targets and confirms RNA-binding activity for HydRA-predicted RNA-binding associated domains. HydRA accelerates construction of a comprehensive RBP catalog and expands the diversity of RNA-binding associated domains.",
      "authors": "Jin Wenhao; Brannan Kristopher W; Kapeli Katannya; Park Samuel S; Tan Hui Qing; Gosztyla Maya L; Mujumdar Mayuresh; Ahdout Joshua; Henroid Bryce; Rothamel Katherine; Xiang Joy S; Wong Limsoon; Yeo Gene W",
      "year": "2023",
      "month": "Jul",
      "journal": "Molecular cell",
      "source": "pubmed"
    },
    {
      "pmid": "37398021",
      "doi": "10.1101/2023.05.31.543144",
      "title": "Integrative Multiscale Biochemical Mapping of the Brain via Deep-Learning-Enhanced High-Throughput Mass Spectrometry.",
      "abstract": "Elucidating the spatial-biochemical organization of the brain across different scales produces invaluable insight into the molecular intricacy of the brain. While mass spectrometry imaging (MSI) provides spatial localization of compounds, comprehensive chemical profiling at a brain-wide scale in three dimensions by MSI with single-cell resolution has not been achieved. We demonstrate complementary brain-wide and single-cell biochemical mapping via MEISTER, an integrative experimental and computational mass spectrometry framework. MEISTER integrates a deep-learning-based reconstruction that accelerates high-mass-resolving MS by 15-fold, multimodal registration creating 3D molecular distributions, and a data integration method fitting cell-specific mass spectra to 3D data sets. We imaged detailed lipid profiles in tissues with data sets containing millions of pixels, and in large single-cell populations acquired from the rat brain. We identified region-specific lipid contents, and cell-specific localizations of lipids depending on both cell subpopulations and anatomical origins of the cells. Our workflow establishes a blueprint for future developments of multiscale technologies for biochemical characterization of the brain.",
      "authors": "Xie Yuxuan Richard; Castro Daniel C; Rubakhin Stanislav S; Trinklein Timothy J; Sweedler Jonathan V; Lam Fan",
      "year": "2023",
      "month": "Nov",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "37387141",
      "doi": "10.1093/bioinformatics/btad248",
      "title": "Cell type matching across species using protein embeddings and transfer learning.",
      "abstract": "Knowing the relation between cell types is crucial for translating experimental results from mice to humans. Establishing cell type matches, however, is hindered by the biological differences between the species. A substantial amount of evolutionary information between genes that could be used to align the species is discarded by most of the current methods since they only use one-to-one orthologous genes. Some methods try to retain the information by explicitly including the relation between genes, however, not without caveats. In this work, we present a model to transfer and align cell types in cross-species analysis (TACTiCS). First, TACTiCS uses a natural language processing model to match genes using their protein sequences. Next, TACTiCS employs a neural network to classify cell types within a species. Afterward, TACTiCS uses transfer learning to propagate cell type labels between species. We applied TACTiCS on scRNA-seq data of the primary motor cortex of human, mouse, and marmoset. Our model can accurately match and align cell types on these datasets. Moreover, our model outperforms Seurat and the state-of-the-art method SAMap. Finally, we show that our gene matching method results in better cell type matches than BLAST in our model. The implementation is available on GitHub (https://github.com/kbiharie/TACTiCS). The preprocessed datasets and trained models can be downloaded from Zenodo (https://doi.org/10.5281/zenodo.7582460).",
      "authors": "Biharie Kirti; Michielsen Lieke; Reinders Marcel J T; Mahfouz Ahmed",
      "year": "2023",
      "month": "Jun",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "37386189",
      "doi": "10.1038/s41592-023-01909-9",
      "title": "MultiVI: deep generative model for the integration of multimodal data.",
      "abstract": "Jointly profiling the transcriptome, chromatin accessibility and other molecular properties of single cells offers a powerful way to study cellular diversity. Here we present MultiVI, a probabilistic model to analyze such multiomic data and leverage it to enhance single-modality datasets. MultiVI creates a joint representation that allows an analysis of all modalities included in the multiomic input data, even for cells for which one or more modalities are missing. It is available at scvi-tools.org .",
      "authors": "Ashuach Tal; Gabitto Mariano I; Koodli Rohan V; Saldi Giuseppe-Antonio; Jordan Michael I; Yosef Nir",
      "year": "2023",
      "month": "Aug",
      "journal": "Nature methods",
      "source": "pubmed"
    },
    {
      "pmid": "37379157",
      "doi": "10.1093/bioinformatics/btad411",
      "title": "MDTips: a multimodal-data-based drug-target interaction prediction system fusing knowledge, gene expression profile, and structural data.",
      "abstract": "Screening new drug-target interactions (DTIs) by traditional experimental methods is costly and time-consuming. Recent advances in knowledge graphs, chemical linear notations, and genomic data enable researchers to develop computational-based-DTI models, which play a pivotal role in drug repurposing and discovery. However, there still needs to develop a multimodal fusion DTI model that integrates available heterogeneous data into a unified framework. We developed MDTips, a multimodal-data-based DTI prediction system, by fusing the knowledge graphs, gene expression profiles, and structural information of drugs/targets. MDTips yielded accurate and robust performance on DTI predictions. We found that multimodal fusion learning can fully consider the importance of each modality and incorporate information from multiple aspects, thus improving model performance. Extensive experimental results demonstrate that deep learning-based encoders (i.e. Attentive FP and Transformer) outperform traditional chemical descriptors/fingerprints, and MDTips outperforms other state-of-the-art prediction models. MDTips is designed to predict the input drugs' candidate targets, side effects, and indications with all available modalities. Via MDTips, we reverse-screened candidate targets of 6766 drugs, which can be used for drug repurposing and discovery. https://github.com/XiaoqiongXia/MDTips and https://doi.org/10.5281/zenodo.7560544.",
      "authors": "Xia Xiaoqiong; Zhu Chaoyu; Zhong Fan; Liu Lei",
      "year": "2023",
      "month": "Jul",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "37314966",
      "doi": "10.1093/bioinformatics/btad382",
      "title": "Ensemble deep learning of embeddings for clustering multimodal single-cell omics data.",
      "abstract": "Recent advances in multimodal single-cell omics technologies enable multiple modalities of molecular attributes, such as gene expression, chromatin accessibility, and protein abundance, to be profiled simultaneously at a global level in individual cells. While the increasing availability of multiple data modalities is expected to provide a more accurate clustering and characterization of cells, the development of computational methods that are capable of extracting information embedded across data modalities is still in its infancy. We propose SnapCCESS for clustering cells by integrating data modalities in multimodal single-cell omics data using an unsupervised ensemble deep learning framework. By creating snapshots of embeddings of multimodality using variational autoencoders, SnapCCESS can be coupled with various clustering algorithms for generating consensus clustering of cells. We applied SnapCCESS with several clustering algorithms to various datasets generated from popular multimodal single-cell omics technologies. Our results demonstrate that SnapCCESS is effective and more efficient than conventional ensemble deep learning-based clustering methods and outperforms other state-of-the-art multimodal embedding generation methods in integrating data modalities for clustering cells. The improved clustering of cells from SnapCCESS will pave the way for more accurate characterization of cell identity and types, an essential step for various downstream analyses of multimodal single-cell omics data. SnapCCESS is implemented as a Python package and is freely available from https://github.com/PYangLab/SnapCCESS under the open-source license of GPL-3. The data used in this study are publicly available (see section 'Data availability').",
      "authors": "Yu Lijia; Liu Chunlei; Yang Jean Yee Hwa; Yang Pengyi",
      "year": "2023",
      "month": "Jun",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "41675657",
      "doi": "10.15302/J-QB-022-0315",
      "title": "Prediction of chromatin looping using deep hybrid learning (DHL).",
      "abstract": "With the development of rapid and cheap sequencing techniques, the cost of whole-genome sequencing (WGS) has dropped significantly. However, the complexity of the human genome is not limited to the pure sequence-and additional experiments are required to learn the human genome's influence on complex traits. One of the most exciting aspects for scientists nowadays is the spatial organisation of the genome, which can be discovered using spatial experiments (  We have used an ensemble of deep learning with classical machine learning algorithms. The deep learning network we used was DNABERT, which utilises the BERT language model (based on transformers) for the genomic function. The classical machine learning models included support vector machines (SVMs), random forests (RFs), and K-nearest neighbor (KNN). The whole approach was wrapped together as deep hybrid learning (DHL). We found that the DNABERT can be used to predict the ChIA-PET experiments with high precision. Additionally, the DHL approach has increased the metrics on CTCF and RNAPII sets. DHL approach should be taken into consideration for the models utilising the power of deep learning. While straightforward in the concept, it can improve the results significantly.",
      "authors": "Chiliński Mateusz; Halder Anup Kumar; Plewczynski Dariusz",
      "year": "2023",
      "month": "Jun",
      "journal": "Quantitative biology (Beijing, China)",
      "source": "pubmed"
    },
    {
      "pmid": "39175596",
      "doi": "10.1038/s42256-023-00663-z",
      "title": "Joint variational autoencoders for multimodal imputation and embedding.",
      "abstract": "Single-cell multimodal datasets have measured various characteristics of individual cells, enabling a deep understanding of cellular and molecular mechanisms. However, multimodal data generation remains costly and challenging, and missing modalities happen frequently. Recently, machine learning approaches have been developed for data imputation but typically require fully matched multimodalities to learn common latent embeddings that potentially lack modality specificity. To address these issues, we developed an open-source machine learning model, Joint Variational Autoencoders for multimodal Imputation and Embedding (JAMIE). JAMIE takes single-cell multimodal data that can have partially matched samples across modalities. Variational autoencoders learn the latent embeddings of each modality. Then, embeddings from matched samples across modalities are aggregated to identify joint cross-modal latent embeddings before reconstruction. To perform cross-modal imputation, the latent embeddings of one modality can be used with the decoder of the other modality. For interpretability, Shapley values are used to prioritize input features for cross-modal imputation and known sample labels. We applied JAMIE to both simulation data and emerging single-cell multimodal data including gene expression, chromatin accessibility, and electrophysiology in human and mouse brains. JAMIE significantly outperforms existing state-of-the-art methods in general and prioritized multimodal features for imputation, providing potentially novel mechanistic insights at cellular resolution.",
      "authors": "Kalafut Noah Cohen; Huang Xiang; Wang Daifeng",
      "year": "2023",
      "month": "Jun",
      "journal": "Nature machine intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "37258680",
      "doi": "10.1038/s41586-023-06139-9",
      "title": "Transfer learning enables predictions in network biology.",
      "abstract": "Mapping gene networks requires large amounts of transcriptomic data to learn the connections between genes, which impedes discoveries in settings with limited data, including rare diseases and diseases affecting clinically inaccessible tissues. Recently, transfer learning has revolutionized fields such as natural language understanding",
      "authors": "Theodoris Christina V; Xiao Ling; Chopra Anant; Chaffin Mark D; Al Sayed Zeina R; Hill Matthew C; Mantineo Helene; Brydon Elizabeth M; Zeng Zexian; Liu X Shirley; Ellinor Patrick T",
      "year": "2023",
      "month": "Jun",
      "journal": "Nature",
      "source": "pubmed"
    },
    {
      "pmid": "37238173",
      "doi": "10.3390/diagnostics13101688",
      "title": "An Ensembled Framework for Human Breast Cancer Survivability Prediction Using Deep Learning.",
      "abstract": "Breast cancer is categorized as an aggressive disease, and it is one of the leading causes of death. Accurate survival predictions for both long-term and short-term survivors, when delivered on time, can help physicians make effective treatment decisions for their patients. Therefore, there is a dire need to design an efficient and rapid computational model for breast cancer prognosis. In this study, we propose an ensemble model for breast cancer survivability prediction (EBCSP) that utilizes multi-modal data and stacks the output of multiple neural networks. Specifically, we design a convolutional neural network (CNN) for clinical modalities, a deep neural network (DNN) for copy number variations (CNV), and a long short-term memory (LSTM) architecture for gene expression modalities to effectively handle multi-dimensional data. The independent models' results are then used for binary classification (long term > 5 years and short term < 5 years) based on survivability using the random forest method. The EBCSP model's successful application outperforms models that utilize a single data modality for prediction and existing benchmarks.",
      "authors": "Mustafa Ehzaz; Jadoon Ehtisham Khan; Khaliq-Uz-Zaman Sardar; Humayun Mohammad Ali; Maray Mohammed",
      "year": "2023",
      "month": "May",
      "journal": "Diagnostics (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "37228671",
      "doi": "10.3389/fbinf.2023.1131021",
      "title": "Multimodal AI for prediction of distant metastasis in carcinoma patients.",
      "abstract": "Metastasis of cancer is directly related to death in almost all cases, however a lot is yet to be understood about this process. Despite advancements in the available radiological investigation techniques, not all cases of Distant Metastasis (DM) are diagnosed at initial clinical presentation. Also, there are currently no standard biomarkers of metastasis. Early, accurate diagnosis of DM is however crucial for clinical decision making, and planning of appropriate management strategies. Previous works have achieved little success in attempts to predict DM from either clinical, genomic, radiology, or histopathology data. In this work we attempt a multimodal approach to predict the presence of DM in cancer patients by combining gene expression data, clinical data and histopathology images. We tested a novel combination of Random Forest (RF) algorithm with an optimization technique for gene selection, and investigated if gene expression pattern in the primary tissues of three cancer types (Bladder Carcinoma, Pancreatic Adenocarcinoma, and Head and Neck Squamous Carcinoma) with DM are similar or different. Gene expression biomarkers of DM identified by our proposed method outperformed Differentially Expressed Genes (DEGs) identified by the DESeq2 software package in the task of predicting presence or absence of DM. Genes involved in DM tend to be more cancer type specific rather than general across all cancers. Our results also indicate that multimodal data is more predictive of metastasis than either of the three unimodal data tested, and genomic data provides the highest contribution by a wide margin. The results re-emphasize the importance for availability of sufficient image data when a weakly supervised training technique is used. Code is made available at: https://github.com/rit-cui-lab/Multimodal-AI-for-Prediction-of-Distant-Metastasis-in-Carcinoma-Patients.",
      "authors": "Olatunji Isaac; Cui Feng",
      "year": "2023",
      "month": "",
      "journal": "Frontiers in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "37220903",
      "doi": "10.1093/bioinformatics/btad336",
      "title": "Multi-modal deep learning improves grain yield prediction in wheat breeding by fusing genomics and phenomics.",
      "abstract": "Developing new crop varieties with superior performance is highly important to ensure robust and sustainable global food security. The speed of variety development is limited by long field cycles and advanced generation selections in plant breeding programs. While methods to predict yield from genotype or phenotype data have been proposed, improved performance and integrated models are needed. We propose a machine learning model that leverages both genotype and phenotype measurements by fusing genetic variants with multiple data sources collected by unmanned aerial systems. We use a deep multiple instance learning framework with an attention mechanism that sheds light on the importance given to each input during prediction, enhancing interpretability. Our model reaches 0.754 ± 0.024 Pearson correlation coefficient when predicting yield in similar environmental conditions; a 34.8% improvement over the genotype-only linear baseline (0.559 ± 0.050). We further predict yield on new lines in an unseen environment using only genotypes, obtaining a prediction accuracy of 0.386 ± 0.010, a 13.5% improvement over the linear baseline. Our multi-modal deep learning architecture efficiently accounts for plant health and environment, distilling the genetic contribution and providing excellent predictions. Yield prediction algorithms leveraging phenotypic observations during training therefore promise to improve breeding programs, ultimately speeding up delivery of improved varieties. Available at https://github.com/BorgwardtLab/PheGeMIL (code) and https://doi.org/doi:10.5061/dryad.kprr4xh5p (data).",
      "authors": "Togninalli Matteo; Wang Xu; Kucera Tim; Shrestha Sandesh; Juliana Philomin; Mondal Suchismita; Pinto Francisco; Govindan Velu; Crespo-Herrera Leonardo; Huerta-Espino Julio; Singh Ravi P; Borgwardt Karsten; Poland Jesse",
      "year": "2023",
      "month": "Jun",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "37159669",
      "doi": "10.1016/j.crmeth.2023.100461",
      "title": "Systematic comparison of multi-omics survival models reveals a widespread lack of noise resistance.",
      "abstract": "As observed in several previous studies, integrating more molecular modalities in multi-omics cancer survival models may not always improve model accuracy. In this study, we compared eight deep learning and four statistical integration techniques for survival prediction on 17 multi-omics datasets, examining model performance in terms of overall accuracy and noise resistance. We found that one deep learning method, mean late fusion, and two statistical methods, ",
      "authors": "Wissel David; Rowson Daniel; Boeva Valentina",
      "year": "2023",
      "month": "Apr",
      "journal": "Cell reports methods",
      "source": "pubmed"
    },
    {
      "pmid": "37079731",
      "doi": "10.1093/bioinformatics/btad258",
      "title": "Molecular property prediction by contrastive learning with attention-guided positive sample selection.",
      "abstract": "Predicting molecular properties is one of the fundamental problems in drug design and discovery. In recent years, self-supervised learning (SSL) has shown its promising performance in image recognition, natural language processing, and single-cell data analysis. Contrastive learning (CL) is a typical SSL method used to learn the features of data so that the trained model can more effectively distinguish the data. One important issue of CL is how to select positive samples for each training example, which will significantly impact the performance of CL. In this article, we propose a new method for molecular property prediction (MPP) by Contrastive Learning with Attention-guided Positive-sample Selection (CLAPS). First, we generate positive samples for each training example based on an attention-guided selection scheme. Second, we employ a Transformer encoder to extract latent feature vectors and compute the contrastive loss aiming to distinguish positive and negative sample pairs. Finally, we use the trained encoder for predicting molecular properties. Experiments on various benchmark datasets show that our approach outperforms the state-of-the-art (SOTA) methods in most cases. The code is publicly available at https://github.com/wangjx22/CLAPS.",
      "authors": "Wang Jinxian; Guan Jihong; Zhou Shuigeng",
      "year": "2023",
      "month": "May",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "37039115",
      "doi": "10.1093/gigascience/giad021",
      "title": "Delineating regions of interest for mass spectrometry imaging by multimodally corroborated spatial segmentation.",
      "abstract": "Mass spectrometry imaging (MSI), which localizes molecules in a tag-free, spatially resolved manner, is a powerful tool for the understanding of underlying biochemical mechanisms of biological phenomena. When analyzing MSI data, it is essential to delineate regions of interest (ROIs) that correspond to tissue areas of different anatomical or pathological labels. Spatial segmentation, obtained by clustering MSI pixels according to their mass spectral similarities, is a popular approach to automate ROI definition. However, how to select the number of clusters (#Clusters), which determines the granularity of segmentation, remains to be resolved, and an inappropriate #Clusters may lead to ROIs not biologically real. Here we report a multimodal fusion strategy to enable an objective and trustworthy selection of #Clusters by utilizing additional information from corresponding histology images. A deep learning-based algorithm is proposed to extract \"histomorphological feature spectra\" across an entire hematoxylin and eosin image. Clustering is then similarly performed to produce histology segmentation. Since ROIs originating from instrumental noise or artifacts would not be reproduced cross-modally, the consistency between histology and MSI segmentation becomes an effective measure of the biological validity of the results. So, #Clusters that maximize the consistency is deemed as most probable. We validated our strategy on mouse kidney and renal tumor specimens by producing multimodally corroborated ROIs that agreed excellently with ground truths. Downstream analysis based on the said ROIs revealed lipid molecules highly specific to tissue anatomy or pathology. Our work will greatly facilitate MSI-mediated spatial lipidomics, metabolomics, and proteomics research by providing intelligent software to automatically and reliably generate ROIs.",
      "authors": "Guo Ang; Chen Zhiyu; Li Fang; Luo Qian",
      "year": "2022",
      "month": "Dec",
      "journal": "GigaScience",
      "source": "pubmed"
    },
    {
      "pmid": "36991216",
      "doi": "10.1038/s43856-023-00276-y",
      "title": "Multimodal deep learning to predict prognosis in adult and pediatric brain tumors.",
      "abstract": "The introduction of deep learning in both imaging and genomics has significantly advanced the analysis of biomedical data. For complex diseases such as cancer, different data modalities may reveal different disease characteristics, and the integration of imaging with genomic data has the potential to unravel additional information than when using these data sources in isolation. Here, we propose a DL framework that combines these two modalities with the aim to predict brain tumor prognosis. Using two separate glioma cohorts of 783 adults and 305 pediatric patients we developed a DL framework that can fuse histopathology images with gene expression profiles. Three strategies for data fusion were implemented and compared: early, late, and joint fusion. Additional validation of the adult glioma models was done on an independent cohort of 97 adult patients. Here we show that the developed multimodal data models achieve better prediction results compared to the single data models, but also lead to the identification of more relevant biological pathways. When testing our adult models on a third brain tumor dataset, we show our multimodal framework is able to generalize and performs better on new data from different cohorts. Leveraging the concept of transfer learning, we demonstrate how our pediatric multimodal models can be used to predict prognosis for two more rare (less available samples) pediatric brain tumors. Our study illustrates that a multimodal data fusion approach can be successfully implemented and customized to model clinical outcome of adult and pediatric brain tumors.",
      "authors": "Steyaert Sandra; Qiu Yeping Lina; Zheng Yuanning; Mukherjee Pritam; Vogel Hannes; Gevaert Olivier",
      "year": "2023",
      "month": "Mar",
      "journal": "Communications medicine",
      "source": "pubmed"
    },
    {
      "pmid": "36985684",
      "doi": "10.3390/molecules28062712",
      "title": "Mass Spectrometry Imaging for Single-Cell or Subcellular Lipidomics: A Review of Recent Advancements and Future Development.",
      "abstract": "Mass Spectrometry Imaging (MSI) has emerged as a powerful imaging technique for the analysis of biological samples, providing valuable insights into the spatial distribution and structural characterization of lipids. The advancements in high-resolution MSI have made it an indispensable tool for single-cell or subcellular lipidomics. By preserving both intracellular and intercellular information, MSI enables a comprehensive analysis of lipidomics in individual cells and organelles. This enables researchers to delve deeper into the diversity of lipids within cells and to understand the role of lipids in shaping cell behavior. In this review, we aim to provide a comprehensive overview of recent advancements and future prospects of MSI for cellular/subcellular lipidomics. By keeping abreast of the cutting-edge studies in this field, we will continue to push the boundaries of the understanding of lipid metabolism and the impact of lipids on cellular behavior.",
      "authors": "Li Dan; Ouyang Zheng; Ma Xiaoxiao",
      "year": "2023",
      "month": "Mar",
      "journal": "Molecules (Basel, Switzerland)",
      "source": "pubmed"
    },
    {
      "pmid": "36980853",
      "doi": "10.3390/genes14030582",
      "title": "A Grid Search-Based Multilayer Dynamic Ensemble System to Identify DNA N4-Methylcytosine Using Deep Learning Approach.",
      "abstract": "DNA (Deoxyribonucleic Acid) N4-methylcytosine (4mC), a kind of epigenetic modification of DNA, is important for modifying gene functions, such as protein interactions, conformation, and stability in DNA, as well as for the control of gene expression throughout cell development and genomic imprinting. This simply plays a crucial role in the restriction-modification system. To further understand the function and regulation mechanism of 4mC, it is essential to precisely locate the 4mC site and detect its chromosomal distribution. This research aims to design an efficient and high-throughput discriminative intelligent computational system using the natural language processing method \"word2vec\" and a multi-configured 1D convolution neural network (1D CNN) to predict 4mC sites. In this article, we propose a grid search-based multi-layer dynamic ensemble system (GS-MLDS) that can enhance existing knowledge of each level. Each layer uses a grid search-based weight searching approach to find the optimal accuracy while minimizing computation time and additional layers. We have used eight publicly available benchmark datasets collected from different sources to test the proposed model's efficiency. Accuracy results in test operations were obtained as follows: 0.978, 0.954, 0.944, 0.961, 0.950, 0.973, 0.948, 0.952, 0.961, and 0.980. The proposed model has also been compared to 16 distinct models, indicating that it can accurately predict 4mC.",
      "authors": "Halder Rajib Kumar; Uddin Mohammed Nasir; Uddin Md Ashraf; Aryal Sunil; Islam Md Aminul; Hossain Fahima; Jahan Nusrat; Khraisat Ansam; Alazab Ammar",
      "year": "2023",
      "month": "Feb",
      "journal": "Genes",
      "source": "pubmed"
    },
    {
      "pmid": "36960342",
      "doi": "10.3389/fmed.2023.1058919",
      "title": "Data augmentation and multimodal learning for predicting drug response in patient-derived xenografts from gene expressions and histology images.",
      "abstract": "Patient-derived xenografts (PDXs) are an appealing platform for preclinical drug studies. A primary challenge in modeling drug response prediction (DRP) with PDXs and neural networks (NNs) is the limited number of drug response samples. We investigate multimodal neural network (MM-Net) and data augmentation for DRP in PDXs. The MM-Net learns to predict response using drug descriptors, gene expressions (GE), and histology whole-slide images (WSIs). We explore whether combining WSIs with GE improves predictions as compared with models that use GE alone. We propose two data augmentation methods which allow us training multimodal and unimodal NNs without changing architectures with a single larger dataset: 1) combine single-drug and drug-pair treatments by homogenizing drug representations, and 2) augment drug-pairs which doubles the sample size of all drug-pair samples. Unimodal NNs which use GE are compared to assess the contribution of data augmentation. The NN that uses the original and the augmented drug-pair treatments as well as single-drug treatments outperforms NNs that ignore either the augmented drug-pairs or the single-drug treatments. In assessing the multimodal learning based on the MCC metric, MM-Net outperforms all the baselines. Our results show that data augmentation and integration of histology images with GE can improve prediction performance of drug response in PDXs.",
      "authors": "Partin Alexander; Brettin Thomas; Zhu Yitan; Dolezal James M; Kochanny Sara; Pearson Alexander T; Shukla Maulik; Evrard Yvonne A; Doroshow James H; Stevens Rick L",
      "year": "2023",
      "month": "",
      "journal": "Frontiers in medicine",
      "source": "pubmed"
    },
    {
      "pmid": "36952569",
      "doi": "10.1371/journal.pcbi.1010200",
      "title": "A systematic evaluation of deep learning methods for the prediction of drug synergy in cancer.",
      "abstract": "One of the main obstacles to the successful treatment of cancer is the phenomenon of drug resistance. A common strategy to overcome resistance is the use of combination therapies. However, the space of possibilities is huge and efficient search strategies are required. Machine Learning (ML) can be a useful tool for the discovery of novel, clinically relevant anti-cancer drug combinations. In particular, deep learning (DL) has become a popular choice for modeling drug combination effects. Here, we set out to examine the impact of different methodological choices on the performance of multimodal DL-based drug synergy prediction methods, including the use of different input data types, preprocessing steps and model architectures. Focusing on the NCI ALMANAC dataset, we found that feature selection based on prior biological knowledge has a positive impact-limiting gene expression data to cancer or drug response-specific genes improved performance. Drug features appeared to be more predictive of drug response, with a 41% increase in coefficient of determination (R2) and 26% increase in Spearman correlation relative to a baseline model that used only cell line and drug identifiers. Molecular fingerprint-based drug representations performed slightly better than learned representations-ECFP4 fingerprints increased R2 by 5.3% and Spearman correlation by 2.8% w.r.t the best learned representations. In general, fully connected feature-encoding subnetworks outperformed other architectures. DL outperformed other ML methods by more than 35% (R2) and 14% (Spearman). Additionally, an ensemble combining the top DL and ML models improved performance by about 6.5% (R2) and 4% (Spearman). Using a state-of-the-art interpretability method, we showed that DL models can learn to associate drug and cell line features with drug response in a biologically meaningful way. The strategies explored in this study will help to improve the development of computational methods for the rational design of effective drug combinations for cancer therapy.",
      "authors": "Baptista Delora; Ferreira Pedro G; Rocha Miguel",
      "year": "2023",
      "month": "Mar",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    },
    {
      "pmid": "36923821",
      "doi": "10.3389/fdata.2023.1156811",
      "title": "Editorial: AI and data science in drug development and public health: Highlights from the MCBIOS 2022 conference.",
      "abstract": "",
      "authors": "Homayouni Ramin; Manda Prashanti; Tan Aik Choon; Qin Zhaohui S",
      "year": "2023",
      "month": "",
      "journal": "Frontiers in big data",
      "source": "pubmed"
    },
    {
      "pmid": "36902216",
      "doi": "10.3390/ijms24054784",
      "title": "A Unified Deep Learning Framework for Single-Cell ATAC-Seq Analysis Based on ProdDep Transformer Encoder.",
      "abstract": "Recent advances in single-cell sequencing assays for the transposase-accessibility chromatin (scATAC-seq) technique have provided cell-specific chromatin accessibility landscapes of cis-regulatory elements, providing deeper insights into cellular states and dynamics. However, few research efforts have been dedicated to modeling the relationship between regulatory grammars and single-cell chromatin accessibility and incorporating different analysis scenarios of scATAC-seq data into the general framework. To this end, we propose a unified deep learning framework based on the ProdDep Transformer Encoder, dubbed PROTRAIT, for scATAC-seq data analysis. Specifically motivated by the deep language model, PROTRAIT leverages the ProdDep Transformer Encoder to capture the syntax of transcription factor (TF)-DNA binding motifs from scATAC-seq peaks for predicting single-cell chromatin accessibility and learning single-cell embedding. Based on cell embedding, PROTRAIT annotates cell types using the Louvain algorithm. Furthermore, according to the identified likely noises of raw scATAC-seq data, PROTRAIT denoises these values based on predated chromatin accessibility. In addition, PROTRAIT employs differential accessibility analysis to infer TF activity at single-cell and single-nucleotide resolution. Extensive experiments based on the Buenrostro2018 dataset validate the effeteness of PROTRAIT for chromatin accessibility prediction, cell type annotation, and scATAC-seq data denoising, therein outperforming current approaches in terms of different evaluation metrics. Besides, we confirm the consistency between the inferred TF activity and the literature review. We also demonstrate the scalability of PROTRAIT to analyze datasets containing over one million cells.",
      "authors": "Wang Zixuan; Zhang Yongqing; Yu Yun; Zhang Junming; Liu Yuhang; Zou Quan",
      "year": "2023",
      "month": "Mar",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "36875765",
      "doi": "10.3389/fcell.2023.1091047",
      "title": "resVAE ensemble: Unsupervised identification of gene sets in multi-modal single-cell sequencing data using deep ensembles.",
      "abstract": "Feature identification and manual inspection is currently still an integral part of biological data analysis in single-cell sequencing. Features such as expressed genes and open chromatin status are selectively studied in specific contexts, cell states or experimental conditions. While conventional analysis methods construct a relatively static view on gene candidates, artificial neural networks have been used to model their interactions after hierarchical gene regulatory networks. However, it is challenging to identify consistent features in this modeling process due to the inherently stochastic nature of these methods. Therefore, we propose using ensembles of autoencoders and subsequent rank aggregation to extract consensus features in a less biased manner. Here, we performed sequencing data analyses of different modalities either independently or simultaneously as well as with other analysis tools. Our resVAE ensemble method can successfully complement and find additional unbiased biological insights with minimal data processing or feature selection steps while giving a measurement of confidence, especially for models using stochastic or approximation algorithms. In addition, our method can also work with overlapping clustering identity assignment suitable for transitionary cell types or cell fates in comparison to most conventional tools.",
      "authors": "Ten Foo Wei; Yuan Dongsheng; Jabareen Nabil; Phua Yin Jun; Eils Roland; Lukassen Sören; Conrad Christian",
      "year": "2023",
      "month": "",
      "journal": "Frontiers in cell and developmental biology",
      "source": "pubmed"
    },
    {
      "pmid": "36869747",
      "doi": "10.1093/g3journal/jkad045",
      "title": "Multimodal deep learning methods enhance genomic prediction of wheat breeding.",
      "abstract": "While several statistical machine learning methods have been developed and studied for assessing the genomic prediction (GP) accuracy of unobserved phenotypes in plant breeding research, few methods have linked genomics and phenomics (imaging). Deep learning (DL) neural networks have been developed to increase the GP accuracy of unobserved phenotypes while simultaneously accounting for the complexity of genotype-environment interaction (GE); however, unlike conventional GP models, DL has not been investigated for when genomics is linked with phenomics. In this study we used 2 wheat data sets (DS1 and DS2) to compare a novel DL method with conventional GP models. Models fitted for DS1 were GBLUP, gradient boosting machine (GBM), support vector regression (SVR) and the DL method. Results indicated that for 1 year, DL provided better GP accuracy than results obtained by the other models. However, GP accuracy obtained for other years indicated that the GBLUP model was slightly superior to the DL. DS2 is comprised only of genomic data from wheat lines tested for 3 years, 2 environments (drought and irrigated) and 2-4 traits. DS2 results showed that when predicting the irrigated environment with the drought environment, DL had higher accuracy than the GBLUP model in all analyzed traits and years. When predicting drought environment with information on the irrigated environment, the DL model and GBLUP model had similar accuracy. The DL method used in this study is novel and presents a strong degree of generalization as several modules can potentially be incorporated and concatenated to produce an output for a multi-input data structure.",
      "authors": "Montesinos-López Abelardo; Rivera Carolina; Pinto Francisco; Piñera Francisco; Gonzalez David; Reynolds Mathew; Pérez-Rodríguez Paulino; Li Huihui; Montesinos-López Osval A; Crossa Jose",
      "year": "2023",
      "month": "May",
      "journal": "G3 (Bethesda, Md.)",
      "source": "pubmed"
    },
    {
      "pmid": "36845202",
      "doi": "10.1093/bioadv/vbad006",
      "title": "Pancancer survival prediction using a deep learning architecture with multimodal representation and integration.",
      "abstract": "Use of multi-omics data carrying comprehensive signals about the disease is strongly desirable for understanding and predicting disease progression, cancer particularly as a serious disease with a high mortality rate. However, recent methods currently fail to effectively utilize the multi-omics data for cancer survival prediction and thus significantly limiting the accuracy of survival prediction using omics data. In this work, we constructed a deep learning model with multimodal representation and integration to predict the survival of patients using multi-omics data. We first developed an unsupervised learning part to extract high-level feature representations from omics data of different modalities. Then, we used an attention-based method to integrate feature representations, produced by the unsupervised learning part, into a single compact vector and finally we fed the vector into fully connected layers for survival prediction. We used multimodal data to train the model and predict pancancer survival, and the results show that using multimodal data can lead to higher prediction accuracy compared to using single modal data. Furthermore, we used the concordance index and the 5-fold cross-validation method for comparing our proposed method with current state-of-the-art methods and our results show that our model achieves better performance on the majority of cancer types in our testing datasets. https://github.com/ZhangqiJiang07/MultimodalSurvivalPrediction. Supplementary data are available at ",
      "authors": "Fan Ziling; Jiang Zhangqi; Liang Hengyu; Han Chao",
      "year": "2023",
      "month": "",
      "journal": "Bioinformatics advances",
      "source": "pubmed"
    },
    {
      "pmid": "36788477",
      "doi": "10.1186/s12859-023-05146-x",
      "title": "A multimodal deep learning model to infer cell-type-specific functional gene networks.",
      "abstract": "Functional gene networks (FGNs) capture functional relationships among genes that vary across tissues and cell types. Construction of cell-type-specific FGNs enables the understanding of cell-type-specific functional gene relationships and insights into genetic mechanisms of human diseases in disease-relevant cell types. However, most existing FGNs were developed without consideration of specific cell types within tissues. In this study, we created a multimodal deep learning model (MDLCN) to predict cell-type-specific FGNs in the human brain by integrating single-nuclei gene expression data with global protein interaction networks. We systematically evaluated the prediction performance of the MDLCN and showed its superior performance compared to two baseline models (boosting tree and convolutional neural network). Based on the predicted cell-type-specific FGNs, we observed that cell-type marker genes had a higher level of hubness than non-marker genes in their corresponding cell type. Furthermore, we showed that risk genes underlying autism and Alzheimer's disease were more strongly connected in disease-relevant cell types, supporting the cellular context of predicted cell-type-specific FGNs. Our study proposes a powerful deep learning approach (MDLCN) to predict FGNs underlying a diverse set of cell types in human brain. The MDLCN model enhances prediction accuracy of cell-type-specific FGNs compared to single modality convolutional neural network (CNN) and boosting tree models, as shown by higher areas under both receiver operating characteristic (ROC) and precision-recall curves for different levels of independent test datasets. The predicted FGNs also show evidence for the cellular context and distinct topological features (i.e. higher hubness and topological score) of cell-type marker genes. Moreover, we observed stronger modularity among disease-associated risk genes in FGNs of disease-relevant cell types. For example, the strength of connectivity among autism risk genes was stronger in neurons, but risk genes underlying Alzheimer's disease were more connected in microglia.",
      "authors": "Afshar Shiva; Braun Patricia R; Han Shizhong; Lin Ying",
      "year": "2023",
      "month": "Feb",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "36778483",
      "doi": "10.1101/2023.01.31.526312",
      "title": "Single-cell multi-omic topic embedding reveals cell-type-specific and COVID-19 severity-related immune signatures.",
      "abstract": "The advent of single-cell multi-omics sequencing technology makes it possible for re-searchers to leverage multiple modalities for individual cells and explore cell heterogeneity. However, the high dimensional, discrete, and sparse nature of the data make the downstream analysis particularly challenging. Most of the existing computational methods for single-cell data analysis are either limited to single modality or lack flexibility and interpretability. In this study, we propose an interpretable deep learning method called multi-omic embedded topic model (moETM) to effectively perform integrative analysis of high-dimensional single-cell multimodal data. moETM integrates multiple omics data via a product-of-experts in the encoder for efficient variational inference and then employs multiple linear decoders to learn the multi-omic signatures of the gene regulatory programs. Through comprehensive experiments on public single-cell transcriptome and chromatin accessibility data (i.e., scRNA+scATAC), as well as scRNA and proteomic data (i.e., CITE-seq), moETM demonstrates superior performance compared with six state-of-the-art single-cell data analysis methods on seven publicly available datasets. By applying moETM to the scRNA+scATAC data in human bone marrow mononuclear cells (BMMCs), we identified sequence motifs corresponding to the transcription factors that regulate immune gene signatures. Applying moETM analysis to CITE-seq data from the COVID-19 patients revealed not only known immune cell-type-specific signatures but also composite multi-omic biomarkers of critical conditions due to COVID-19, thus providing insights from both biological and clinical perspectives.",
      "authors": "Zhou Manqi; Zhang Hao; Baii Zilong; Mann-Krzisnik Dylan; Wang Fei; Li Yue",
      "year": "2023",
      "month": "Jun",
      "journal": "bioRxiv : the preprint server for biology",
      "source": "pubmed"
    },
    {
      "pmid": "38505815",
      "doi": "10.1063/5.0091135",
      "title": "Deep learning in spatial transcriptomics: Learning from the next next-generation sequencing.",
      "abstract": "Spatial transcriptomics (ST) technologies are rapidly becoming the extension of single-cell RNA sequencing (scRNAseq), holding the potential of profiling gene expression at a single-cell resolution while maintaining cellular compositions within a tissue. Having both expression profiles and tissue organization enables researchers to better understand cellular interactions and heterogeneity, providing insight into complex biological processes that would not be possible with traditional sequencing technologies. Data generated by ST technologies are inherently noisy, high-dimensional, sparse, and multi-modal (including histological images, count matrices, etc.), thus requiring specialized computational tools for accurate and robust analysis. However, many ST studies currently utilize traditional scRNAseq tools, which are inadequate for analyzing complex ST datasets. On the other hand, many of the existing ST-specific methods are built upon traditional statistical or machine learning frameworks, which have shown to be sub-optimal in many applications due to the scale, multi-modality, and limitations of spatially resolved data (such as spatial resolution, sensitivity, and gene coverage). Given these intricacies, researchers have developed deep learning (DL)-based models to alleviate ST-specific challenges. These methods include new state-of-the-art models in alignment, spatial reconstruction, and spatial clustering, among others. However, DL models for ST analysis are nascent and remain largely underexplored. In this review, we provide an overview of existing state-of-the-art tools for analyzing spatially resolved transcriptomics while delving deeper into the DL-based approaches. We discuss the new frontiers and the open questions in this field and highlight domains in which we anticipate transformational DL applications.",
      "authors": "Heydari A Ali; Sindi Suzanne S",
      "year": "2023",
      "month": "Mar",
      "journal": "Biophysics reviews",
      "source": "pubmed"
    },
    {
      "pmid": "36736097",
      "doi": "10.1016/j.compbiomed.2023.106576",
      "title": "Deep multimodal graph-based network for survival prediction from highly multiplexed images and patient variables.",
      "abstract": "The spatial architecture of the tumour microenvironment and phenotypic heterogeneity of tumour cells have been shown to be associated with cancer prognosis and clinical outcomes, including survival. Recent advances in highly multiplexed imaging, including imaging mass cytometry (IMC), capture spatially resolved, high-dimensional maps that quantify dozens of disease-relevant biomarkers at single-cell resolution, that contain potential to inform patient-specific prognosis. Existing automated methods for predicting survival, on the other hand, typically do not leverage spatial phenotype information captured at the single-cell level. Furthermore, there is no end-to-end method designed to leverage the rich information in whole IMC images and all marker channels, and aggregate this information with clinical data in a complementary manner to predict survival with enhanced accuracy. To that end, we present a deep multimodal graph-based network (DMGN) with two modules: (1) a multimodal graph-based module that considers relationships between spatial phenotype information in all image regions and all clinical variables adaptively, and (2) a clinical embedding module that automatically generates embeddings specialised for each clinical variable to enhance multimodal aggregation. We demonstrate that our modules are consistently effective at improving survival prediction performance using two public breast cancer datasets, and that our new approach can outperform state-of-the-art methods in survival prediction.",
      "authors": "Fu Xiaohang; Patrick Ellis; Yang Jean Y H; Feng David Dagan; Kim Jinman",
      "year": "2023",
      "month": "Mar",
      "journal": "Computers in biology and medicine",
      "source": "pubmed"
    },
    {
      "pmid": "36678141",
      "doi": "10.3390/nu15020270",
      "title": "Identifying and Analyzing Topic Clusters in a Nutri-, Food-, and Diet-Proteomic Corpus Using Machine Reading.",
      "abstract": "Nutrition affects the early stages of disease development, but the mechanisms remain poorly understood. High-throughput proteomic methods are being used to generate data and information on the effects of nutrients, foods, and diets on health and disease processes. In this report, a novel machine reading pipeline was used to identify all articles and abstracts on proteomics, diet, food, and nutrition in humans. The resulting proteomic corpus was further analyzed to produce seven clusters of \"thematic\" content defined as documents that have similar word content. Examples of publications from several of these clusters were then described in a similar way to a typical descriptive review.",
      "authors": "Monteiro Jacqueline Pontes; Morine Melissa J; Ued Fabio V; Kaput Jim",
      "year": "2023",
      "month": "Jan",
      "journal": "Nutrients",
      "source": "pubmed"
    },
    {
      "pmid": "36672494",
      "doi": "10.3390/cancers15020545",
      "title": "Multimodal Deep Learning-Based Prognostication in Glioma Patients: A Systematic Review.",
      "abstract": "Malignant brain tumors pose a substantial burden on morbidity and mortality. As clinical data collection improves, along with the capacity to analyze it, novel predictive clinical tools may improve prognosis prediction. Deep learning (DL) holds promise for integrating clinical data of various modalities. A systematic review of the DL-based prognostication of gliomas was performed using the Embase (Elsevier), PubMed MEDLINE (National library of Medicine), and Scopus (Elsevier) databases, in accordance with PRISMA guidelines. All included studies focused on the prognostication of gliomas, and predicted overall survival (13 studies, 81%), overall survival as well as genotype (2 studies, 12.5%), and response to immunotherapy (1 study, 6.2%). Multimodal analyses were varied, with 6 studies (37.5%) combining MRI with clinical data; 6 studies (37.5%) integrating MRI with histologic, clinical, and biomarker data; 3 studies (18.8%) combining MRI with genomic data; and 1 study (6.2%) combining histologic imaging with clinical data. Studies that compared multimodal models to unimodal-only models demonstrated improved predictive performance. The risk of bias was mixed, most commonly due to inconsistent methodological reporting. Overall, the use of multimodal data in DL assessments of gliomas leads to a more accurate overall survival prediction. However, due to data limitations and a lack of transparency in model and code reporting, the full extent of multimodal DL as a resource for brain tumor patients has not yet been realized.",
      "authors": "Alleman Kaitlyn; Knecht Erik; Huang Jonathan; Zhang Lu; Lam Sandi; DeCuypere Michael",
      "year": "2023",
      "month": "Jan",
      "journal": "Cancers",
      "source": "pubmed"
    },
    {
      "pmid": "36622018",
      "doi": "10.1093/bioinformatics/btad005",
      "title": "A multi-view latent variable model reveals cellular heterogeneity in complex tissues for paired multimodal single-cell data.",
      "abstract": "Single-cell multimodal assays allow us to simultaneously measure two different molecular features of the same cell, enabling new insights into cellular heterogeneity, cell development and diseases. However, most existing methods suffer from inaccurate dimensionality reduction for the joint-modality data, hindering their discovery of novel or rare cell subpopulations. Here, we present VIMCCA, a computational framework based on variational-assisted multi-view canonical correlation analysis to integrate paired multimodal single-cell data. Our statistical model uses a common latent variable to interpret the common source of variances in two different data modalities. Our approach jointly learns an inference model and two modality-specific non-linear models by leveraging variational inference and deep learning. We perform VIMCCA and compare it with 10 existing state-of-the-art algorithms on four paired multi-modal datasets sequenced by different protocols. Results demonstrate that VIMCCA facilitates integrating various types of joint-modality data, thus leading to more reliable and accurate downstream analysis. VIMCCA improves our ability to identify novel or rare cell subtypes compared to existing widely used methods. Besides, it can also facilitate inferring cell lineage based on joint-modality profiles. The VIMCCA algorithm has been implemented in our toolkit package scbean (≥0.5.0), and its code has been archived at https://github.com/jhu99/scbean under MIT license. Supplementary data are available at Bioinformatics online.",
      "authors": "Wang Yuwei; Lian Bin; Zhang Haohui; Zhong Yuanke; He Jie; Wu Fashuai; Reinert Knut; Shang Xuequn; Yang Hui; Hu Jialu",
      "year": "2023",
      "month": "Jan",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "36593394",
      "doi": "10.1038/s41587-022-01520-x",
      "title": "Discovery of drug-omics associations in type 2 diabetes with generative deep-learning models.",
      "abstract": "The application of multiple omics technologies in biomedical cohorts has the potential to reveal patient-level disease characteristics and individualized response to treatment. However, the scale and heterogeneous nature of multi-modal data makes integration and inference a non-trivial task. We developed a deep-learning-based framework, multi-omics variational autoencoders (MOVE), to integrate such data and applied it to a cohort of 789 people with newly diagnosed type 2 diabetes with deep multi-omics phenotyping from the DIRECT consortium. Using in silico perturbations, we identified drug-omics associations across the multi-modal datasets for the 20 most prevalent drugs given to people with type 2 diabetes with substantially higher sensitivity than univariate statistical tests. From these, we among others, identified novel associations between metformin and the gut microbiota as well as opposite molecular responses for the two statins, simvastatin and atorvastatin. We used the associations to quantify drug-drug similarities, assess the degree of polypharmacy and conclude that drug effects are distributed across the multi-omics modalities.",
      "authors": "Allesøe Rosa Lundbye; Lundgaard Agnete Troen; Hernández Medina Ricardo; Aguayo-Orozco Alejandro; Johansen Joachim; Nissen Jakob Nybo; Brorsson Caroline; Mazzoni Gianluca; Niu Lili; Biel Jorge Hernansanz; Leal Rodríguez Cristina; Brasas Valentas; Webel Henry; Benros Michael Eriksen; Pedersen Anders Gorm; Chmura Piotr Jaroslaw; Jacobsen Ulrik Plesner; Mari Andrea; Koivula Robert; Mahajan Anubha; Vinuela Ana; Tajes Juan Fernandez; Sharma Sapna; Haid Mark; Hong Mun-Gwan; Musholt Petra B; De Masi Federico; Vogt Josef; Pedersen Helle Krogh; Gudmundsdottir Valborg; Jones Angus; Kennedy Gwen; Bell Jimmy; Thomas E Louise; Frost Gary; Thomsen Henrik; Hansen Elizaveta; Hansen Tue Haldor; Vestergaard Henrik; Muilwijk Mirthe; Blom Marieke T; 't Hart Leen M; Pattou Francois; Raverdy Violeta; Brage Soren; Kokkola Tarja; Heggie Alison; McEvoy Donna; Mourby Miranda; Kaye Jane; Hattersley Andrew; McDonald Timothy; Ridderstråle Martin; Walker Mark; Forgie Ian; Giordano Giuseppe N; Pavo Imre; Ruetten Hartmut; Pedersen Oluf; Hansen Torben; Dermitzakis Emmanouil; Franks Paul W; Schwenk Jochen M; Adamski Jerzy; McCarthy Mark I; Pearson Ewan; Banasik Karina; Rasmussen Simon; Brunak Søren",
      "year": "2023",
      "month": "Mar",
      "journal": "Nature biotechnology",
      "source": "pubmed"
    },
    {
      "pmid": "36574598",
      "doi": "10.1002/hbm.26077",
      "title": "Deep multimodal predictome for studying mental disorders.",
      "abstract": "Characterizing neuropsychiatric disorders is challenging due to heterogeneity in the population. We propose combining structural and functional neuroimaging and genomic data in a multimodal classification framework to leverage their complementary information. Our objectives are two-fold (i) to improve the classification of disorders and (ii) to introspect the concepts learned to explore underlying neural and biological mechanisms linked to mental disorders. Previous multimodal studies have focused on naïve neural networks, mostly perceptron, to learn modality-wise features and often assume equal contribution from each modality. Our focus is on the development of neural networks for feature learning and implementing an adaptive control unit for the fusion phase. Our mid fusion with attention model includes a multilayer feed-forward network, an autoencoder, a bi-directional long short-term memory unit with attention as the features extractor, and a linear attention module for controlling modality-specific influence. The proposed model acquired 92% (p < .0001) accuracy in schizophrenia prediction, outperforming several other state-of-the-art models applied to unimodal or multimodal data. Post hoc feature analyses uncovered critical neural features and genes/biological pathways associated with schizophrenia. The proposed model effectively combines multimodal neuroimaging and genomics data for predicting mental disorders. Interpreting salient features identified by the model may advance our understanding of their underlying etiological mechanisms.",
      "authors": "Rahaman Md Abdur; Chen Jiayu; Fu Zening; Lewis Noah; Iraji Armin; van Erp Theo G M; Calhoun Vince D",
      "year": "2023",
      "month": "Feb",
      "journal": "Human brain mapping",
      "source": "pubmed"
    },
    {
      "pmid": "36568390",
      "doi": "10.3389/fgene.2022.1003711",
      "title": "Single-cell RNA-seq data analysis using graph autoencoders and graph attention networks.",
      "abstract": "With the development of high-throughput sequencing technology, the scale of single-cell RNA sequencing (scRNA-seq) data has surged. Its data are typically high-dimensional, with high dropout noise and high sparsity. Therefore, gene imputation and cell clustering analysis of scRNA-seq data is increasingly important. Statistical or traditional machine learning methods are inefficient, and improved accuracy is needed. The methods based on deep learning cannot directly process non-Euclidean spatial data, such as cell diagrams. In this study, we developed scGAEGAT, a multi-modal model with graph autoencoders and graph attention networks for scRNA-seq analysis based on graph neural networks. Cosine similarity, median L1 distance, and root-mean-squared error were used to measure the gene imputation performance of different methods for comparison with scGAEGAT. Furthermore, adjusted mutual information, normalized mutual information, completeness score, and Silhouette coefficient score were used to measure the cell clustering performance of different methods for comparison with scGAEGAT. Experimental results demonstrated promising performance of the scGAEGAT model in gene imputation and cell clustering prediction on four scRNA-seq data sets with gold-standard cell labels.",
      "authors": "Feng Xiang; Fang Fang; Long Haixia; Zeng Rao; Yao Yuhua",
      "year": "2022",
      "month": "",
      "journal": "Frontiers in genetics",
      "source": "pubmed"
    },
    {
      "pmid": "36523958",
      "doi": "10.3389/fnagi.2022.1040001",
      "title": "Predicting AT(N) pathologies in Alzheimer's disease from blood-based proteomic data using neural networks.",
      "abstract": "Blood-based biomarkers represent a promising approach to help identify early Alzheimer's disease (AD). Previous research has applied traditional machine learning (ML) to analyze plasma omics data and search for potential biomarkers, but the most modern ML methods based on deep learning has however been scarcely explored. In the current study, we aim to harness the power of state-of-the-art deep learning neural networks (NNs) to identify plasma proteins that predict amyloid, tau, and neurodegeneration (AT[N]) pathologies in AD. We measured 3,635 proteins using SOMAscan in 881 participants from the European Medical Information Framework for AD Multimodal Biomarker Discovery study (EMIF-AD MBD). Participants underwent measurements of brain amyloid β (Aβ) burden, phosphorylated tau (p-tau) burden, and total tau (t-tau) burden to determine their AT(N) statuses. We ranked proteins by their association with Aβ, p-tau, t-tau, and AT(N), and fed the top 100 proteins along with age and apolipoprotein E ( Age and  Combined with age and ",
      "authors": "Zhang Yuting; Ghose Upamanyu; Buckley Noel J; Engelborghs Sebastiaan; Sleegers Kristel; Frisoni Giovanni B; Wallin Anders; Lleó Alberto; Popp Julius; Martinez-Lage Pablo; Legido-Quigley Cristina; Barkhof Frederik; Zetterberg Henrik; Visser Pieter Jelle; Bertram Lars; Lovestone Simon; Nevado-Holgado Alejo J; Shi Liu",
      "year": "2022",
      "month": "",
      "journal": "Frontiers in aging neuroscience",
      "source": "pubmed"
    },
    {
      "pmid": "36513636",
      "doi": "10.1038/s41467-022-35031-9",
      "title": "Clustering of single-cell multi-omics data with a multimodal deep learning method.",
      "abstract": "Single-cell multimodal sequencing technologies are developed to simultaneously profile different modalities of data in the same cell. It provides a unique opportunity to jointly analyze multimodal data at the single-cell level for the identification of distinct cell types. A correct clustering result is essential for the downstream complex biological functional studies. However, combining different data sources for clustering analysis of single-cell multimodal data remains a statistical and computational challenge. Here, we develop a novel multimodal deep learning method, scMDC, for single-cell multi-omics data clustering analysis. scMDC is an end-to-end deep model that explicitly characterizes different data sources and jointly learns latent features of deep embedding for clustering analysis. Extensive simulation and real-data experiments reveal that scMDC outperforms existing single-cell single-modal and multimodal clustering methods on different single-cell multimodal datasets. The linear scalability of running time makes scMDC a promising method for analyzing large multimodal datasets.",
      "authors": "Lin Xiang; Tian Tian; Wei Zhi; Hakonarson Hakon",
      "year": "2022",
      "month": "Dec",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "36495179",
      "doi": "10.1093/bioinformatics/btac801",
      "title": "DeepPHiC: predicting promoter-centered chromatin interactions using a novel deep learning approach.",
      "abstract": "Promoter-centered chromatin interactions, which include promoter-enhancer (PE) and promoter-promoter (PP) interactions, are important to decipher gene regulation and disease mechanisms. The development of next-generation sequencing technologies such as promoter capture Hi-C (pcHi-C) leads to the discovery of promoter-centered chromatin interactions. However, pcHi-C experiments are expensive and thus may be unavailable for tissues/cell types of interest. In addition, these experiments may be underpowered due to insufficient sequencing depth or various artifacts, which results in a limited finding of interactions. Most existing computational methods for predicting chromatin interactions are based on in situ Hi-C and can detect chromatin interactions across the entire genome. However, they may not be optimal for predicting promoter-centered chromatin interactions. We develop a supervised multi-modal deep learning model, which utilizes a comprehensive set of features such as genomic sequence, epigenetic signal, anchor distance, evolutionary features and DNA structural features to predict tissue/cell type-specific PE and PP interactions. We further extend the deep learning model in a multi-task learning and a transfer learning framework and demonstrate that the proposed approach outperforms state-of-the-art deep learning methods. Moreover, the proposed approach can achieve comparable prediction performance using predefined biologically relevant tissues/cell types compared to using all tissues/cell types in the pretraining especially for predicting PE interactions. The prediction performance can be further improved by using computationally inferred biologically relevant tissues/cell types in the pretraining, which are defined based on the common genes in the proximity of two anchors in the chromatin interactions. https://github.com/lichen-lab/DeepPHiC. Supplementary data are available at Bioinformatics online.",
      "authors": "Agarwal Aman; Chen Li",
      "year": "2023",
      "month": "Jan",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "39036310",
      "doi": "10.1016/j.jncc.2022.11.004",
      "title": "Intelligent oncology: The convergence of artificial intelligence and oncology.",
      "abstract": "With increasingly explored ideologies and technologies for potential applications of artificial intelligence (AI) in oncology, we here describe a holistic and structured concept termed intelligent oncology. Intelligent oncology is defined as a cross-disciplinary specialty which integrates oncology, radiology, pathology, molecular biology, multi-omics and computer sciences, aiming to promote cancer prevention, screening, early diagnosis and precision treatment. The development of intelligent oncology has been facilitated by fast AI technology development such as natural language processing, machine/deep learning, computer vision, and robotic process automation. While the concept and applications of intelligent oncology is still in its infancy, and there are still many hurdles and challenges, we are optimistic that it will play a pivotal role for the future of basic, translational and clinical oncology.",
      "authors": "Lin Bo; Tan Zhibo; Mo Yaqi; Yang Xue; Liu Yajie; Xu Bo",
      "year": "2023",
      "month": "Mar",
      "journal": "Journal of the National Cancer Center",
      "source": "pubmed"
    },
    {
      "pmid": "36459654",
      "doi": "10.1073/pnas.2214414119",
      "title": "Robust probabilistic modeling for single-cell multimodal mosaic integration and imputation via scVAEIT.",
      "abstract": "Recent advances in single-cell technologies enable joint profiling of multiple omics. These profiles can reveal the complex interplay of different regulatory layers in single cells; still, new challenges arise when integrating datasets with some features shared across experiments and others exclusive to a single source; combining information across these sources is called mosaic integration. The difficulties lie in imputing missing molecular layers to build a self-consistent atlas, finding a common latent space, and transferring learning to new data sources robustly. Existing mosaic integration approaches based on matrix factorization cannot efficiently adapt to nonlinear embeddings for the latent cell space and are not designed for accurate imputation of missing molecular layers. By contrast, we propose a probabilistic variational autoencoder model, scVAEIT, to integrate and impute multimodal datasets with mosaic measurements. A key advance is the use of a missing mask for learning the conditional distribution of unobserved modalities and features, which makes scVAEIT flexible to combine different panels of measurements from multimodal datasets accurately and in an end-to-end manner. Imputing the masked features serves as a supervised learning procedure while preventing overfitting by regularization. Focusing on gene expression, protein abundance, and chromatin accessibility, we validate that scVAEIT robustly imputes the missing modalities and features of cells biologically different from the training data. scVAEIT also adjusts for batch effects while maintaining the biological variation, which provides better latent representations for the integrated datasets. We demonstrate that scVAEIT significantly improves integration and imputation across unseen cell types, different technologies, and different tissues.",
      "authors": "Du Jin-Hong; Cai Zhanrui; Roeder Kathryn",
      "year": "2022",
      "month": "Dec",
      "journal": "Proceedings of the National Academy of Sciences of the United States of America",
      "source": "pubmed"
    },
    {
      "pmid": "36442416",
      "doi": "10.1016/j.neurobiolaging.2022.10.005",
      "title": "Predicting time-to-conversion for dementia of Alzheimer's type using multi-modal deep survival analysis.",
      "abstract": "Dementia of Alzheimer's Type (DAT) is a complex disorder influenced by numerous factors, and it is difficult to predict individual progression trajectory from normal or mildly impaired cognition to DAT. An in-depth examination of multiple modalities of data may yield an accurate estimate of time-to-conversion to DAT for preclinical subjects at various stages of disease development. We used a deep-learning model designed for survival analyses to predict subjects' time-to-conversion to DAT using the baseline data of 401 subjects with 63 features from MRI, genetic, and CDC (Cognitive tests, Demographic, and CSF) data in the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Our study demonstrated that CDC data outperform genetic or MRI data in predicting DAT time-to-conversion for subjects with Mild Cognitive Impairment (MCI). On the other hand, genetic data provided the most predictive power for subjects with Normal Cognition (NC) at the time of the visit. Furthermore, combining MRI and genetic features improved the time-to-event prediction over using either modality alone. Finally, adding CDC to any combination of features only worked as well as using only the CDC features.",
      "authors": "Mirabnahrazam Ghazal; Ma Da; Beaulac Cédric; Lee Sieun; Popuri Karteek; Lee Hyunwoo; Cao Jiguo; Galvin James E; Wang Lei; Beg Mirza Faisal",
      "year": "2023",
      "month": "Jan",
      "journal": "Neurobiology of aging",
      "source": "pubmed"
    },
    {
      "pmid": "36304291",
      "doi": "10.3389/fbinf.2022.910531",
      "title": "Recent Advances in the Prediction of Subcellular Localization of Proteins and Related Topics.",
      "abstract": "Prediction of subcellular localization of proteins from their amino acid sequences has a long history in bioinformatics and is still actively developing, incorporating the latest advances in machine learning and proteomics. Notably, deep learning-based methods for natural language processing have made great contributions. Here, we review recent advances in the field as well as its related fields, such as subcellular proteomics and the prediction/recognition of subcellular localization from image data.",
      "authors": "Nakai Kenta; Wei Leyi",
      "year": "2022",
      "month": "",
      "journal": "Frontiers in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "36290366",
      "doi": "10.3390/biology11101462",
      "title": "Estimating the Prognosis of Low-Grade Glioma with Gene Attention Using Multi-Omics and Multi-Modal Schemes.",
      "abstract": "The prognosis estimation of low-grade glioma (LGG) patients with deep learning models using gene expression data has been extensively studied in recent years. However, the deep learning models used in these studies do not utilize the latest deep learning techniques, such as residual learning and ensemble learning. To address this limitation, in this study, a deep learning model using multi-omics and multi-modal schemes, namely the Multi-Prognosis Estimation Network (Multi-PEN), is proposed. When using Multi-PEN, gene attention layers are employed for each datatype, including mRNA and miRNA, thereby allowing us to identify prognostic genes. Additionally, recent developments in deep learning, such as residual learning and layer normalization, are utilized. As a result, Multi-PEN demonstrates competitive performance compared to conventional models for prognosis estimation. Furthermore, the most significant prognostic mRNA and miRNA were identified using the attention layers in Multi-PEN. For instance, MYBL1 was identified as the most significant prognostic mRNA. Such a result accords with the findings in existing studies that have demonstrated that MYBL1 regulates cell survival, proliferation, and differentiation. Additionally, hsa-mir-421 was identified as the most significant prognostic miRNA, and it has been extensively reported that hsa-mir-421 is highly associated with various cancers. These results indicate that the estimations of Multi-PEN are valid and reliable and showcase Multi-PEN's capacity to present hypotheses regarding prognostic mRNAs and miRNAs.",
      "authors": "Choi Sanghyuk Roy; Lee Minhyeok",
      "year": "2022",
      "month": "Oct",
      "journal": "Biology",
      "source": "pubmed"
    },
    {
      "pmid": "36289266",
      "doi": "10.1038/s41598-022-22514-4",
      "title": "Artificial intelligence-based methods for fusion of electronic health records and imaging data.",
      "abstract": "Healthcare data are inherently multimodal, including electronic health records (EHR), medical images, and multi-omics data. Combining these multimodal data sources contributes to a better understanding of human health and provides optimal personalized healthcare. The most important question when using multimodal data is how to fuse them-a field of growing interest among researchers. Advances in artificial intelligence (AI) technologies, particularly machine learning (ML), enable the fusion of these different data modalities to provide multimodal insights. To this end, in this scoping review, we focus on synthesizing and analyzing the literature that uses AI techniques to fuse multimodal medical data for different clinical applications. More specifically, we focus on studies that only fused EHR with medical imaging data to develop various AI methods for clinical applications. We present a comprehensive analysis of the various fusion strategies, the diseases and clinical outcomes for which multimodal fusion was used, the ML algorithms used to perform multimodal fusion for each clinical application, and the available multimodal medical datasets. We followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines. We searched Embase, PubMed, Scopus, and Google Scholar to retrieve relevant studies. After pre-processing and screening, we extracted data from 34 studies that fulfilled the inclusion criteria. We found that studies fusing imaging data with EHR are increasing and doubling from 2020 to 2021. In our analysis, a typical workflow was observed: feeding raw data, fusing different data modalities by applying conventional machine learning (ML) or deep learning (DL) algorithms, and finally, evaluating the multimodal fusion through clinical outcome predictions. Specifically, early fusion was the most used technique in most applications for multimodal learning (22 out of 34 studies). We found that multimodality fusion models outperformed traditional single-modality models for the same task. Disease diagnosis and prediction were the most common clinical outcomes (reported in 20 and 10 studies, respectively) from a clinical outcome perspective. Neurological disorders were the dominant category (16 studies). From an AI perspective, conventional ML models were the most used (19 studies), followed by DL models (16 studies). Multimodal data used in the included studies were mostly from private repositories (21 studies). Through this scoping review, we offer new insights for researchers interested in knowing the current state of knowledge within this research field.",
      "authors": "Mohsen Farida; Ali Hazrat; El Hajj Nady; Shah Zubair",
      "year": "2022",
      "month": "Oct",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "36271868",
      "doi": "10.1093/bioinformatics/btac696",
      "title": "DeepPerVar: a multi-modal deep learning framework for functional interpretation of genetic variants in personal genome.",
      "abstract": "Understanding the functional consequence of genetic variants, especially the non-coding ones, is important but particularly challenging. Genome-wide association studies (GWAS) or quantitative trait locus analyses may be subject to limited statistical power and linkage disequilibrium, and thus are less optimal to pinpoint the causal variants. Moreover, most existing machine-learning approaches, which exploit the functional annotations to interpret and prioritize putative causal variants, cannot accommodate the heterogeneity of personal genetic variations and traits in a population study, targeting a specific disease. By leveraging paired whole-genome sequencing data and epigenetic functional assays in a population study, we propose a multi-modal deep learning framework to predict genome-wide quantitative epigenetic signals by considering both personal genetic variations and traits. The proposed approach can further evaluate the functional consequence of non-coding variants on an individual level by quantifying the allelic difference of predicted epigenetic signals. By applying the approach to the ROSMAP cohort studying Alzheimer's disease (AD), we demonstrate that the proposed approach can accurately predict quantitative genome-wide epigenetic signals and in key genomic regions of AD causal genes, learn canonical motifs reported to regulate gene expression of AD causal genes, improve the partitioning heritability analysis and prioritize putative causal variants in a GWAS risk locus. Finally, we release the proposed deep learning model as a stand-alone Python toolkit and a web server. https://github.com/lichen-lab/DeepPerVar. Supplementary data are available at Bioinformatics online.",
      "authors": "Wang Ye; Chen Li",
      "year": "2022",
      "month": "Dec",
      "journal": "Bioinformatics (Oxford, England)",
      "source": "pubmed"
    },
    {
      "pmid": "36220072",
      "doi": "10.1016/j.ccell.2022.09.012",
      "title": "Artificial intelligence for multimodal data integration in oncology.",
      "abstract": "In oncology, the patient state is characterized by a whole spectrum of modalities, ranging from radiology, histology, and genomics to electronic health records. Current artificial intelligence (AI) models operate mainly in the realm of a single modality, neglecting the broader clinical context, which inevitably diminishes their potential. Integration of different data modalities provides opportunities to increase robustness and accuracy of diagnostic and prognostic models, bringing AI closer to clinical practice. AI models are also capable of discovering novel patterns within and across modalities suitable for explaining differences in patient outcomes or treatment resistance. The insights gleaned from such models can guide exploration studies and contribute to the discovery of novel biomarkers and therapeutic targets. To support these advances, here we present a synopsis of AI methods and strategies for multimodal data fusion and association discovery. We outline approaches for AI interpretability and directions for AI-driven exploration through multimodal data interconnections. We examine challenges in clinical adoption and discuss emerging solutions.",
      "authors": "Lipkova Jana; Chen Richard J; Chen Bowen; Lu Ming Y; Barbieri Matteo; Shao Daniel; Vaidya Anurag J; Chen Chengkuan; Zhuang Luoting; Williamson Drew F K; Shaban Muhammad; Chen Tiffany Y; Mahmood Faisal",
      "year": "2022",
      "month": "Oct",
      "journal": "Cancer cell",
      "source": "pubmed"
    },
    {
      "pmid": "36199680",
      "doi": "10.21037/aes-21-29",
      "title": "RegenX: an NLP recommendation engine for neuroregeneration topics over time.",
      "abstract": "In this investigation, we explore the literature regarding neuroregeneration from the 1700s to the present. The regeneration of central nervous system neurons or the regeneration of axons from cell bodies and their reconnection with other neurons remains a major hurdle. Injuries relating to war and accidents attracted medical professionals throughout early history to regenerate and reconnect nerves. Early literature till 1990 lacked specific molecular details and is likely provide some clues to conditions that promoted neuron and/or axon regeneration. This is an avenue for the application of natural language processing (NLP) to gain actionable intelligence. Post 1990 period saw an explosion of all molecular details. With the advent of genomic, transcriptomics, proteomics, and other omics-there is an emergence of big data sets and is another rich area for application of NLP. How the neuron and/or axon regeneration related keywords have changed over the years is a first step towards this endeavor. Specifically, this article curates over 600 published works in the field of neuroregeneration. We then apply a dynamic topic modeling algorithm based on the Latent Dirichlet allocation (LDA) algorithm to assess how topics cluster based on topics. Based on how documents are assigned to topics, we then build a recommendation engine to assist researchers to access domain-specific literature based on how their search text matches to recommended document topics. The interface further includes interactive topic visualizations for researchers to understand how topics grow closer and further apart, and how intra-topic composition changes over time. We present a recommendation engine and interactive interface that enables dynamic topic modeling for neuronal regeneration.",
      "authors": "Khosla Shaan; Abdelrahman Leila; Johnson Joseph; Samarah Mohammad; Bhattacharya Sanjoy K",
      "year": "2022",
      "month": "Mar",
      "journal": "Annals of eye science",
      "source": "pubmed"
    },
    {
      "pmid": "36175448",
      "doi": "10.1038/s41467-022-33397-4",
      "title": "Deciphering microbial gene function using natural language processing.",
      "abstract": "Revealing the function of uncharacterized genes is a fundamental challenge in an era of ever-increasing volumes of sequencing data. Here, we present a concept for tackling this challenge using deep learning methodologies adopted from natural language processing (NLP). We repurpose NLP algorithms to model \"gene semantics\" based on a biological corpus of more than 360 million microbial genes within their genomic context. We use the language models to predict functional categories for 56,617 genes and find that out of 1369 genes associated with recently discovered defense systems, 98% are inferred correctly. We then systematically evaluate the \"discovery potential\" of different functional categories, pinpointing those with the most genes yet to be characterized. Finally, we demonstrate our method's ability to discover systems associated with microbial interaction and defense. Our results highlight that combining microbial genomics and language models is a promising avenue for revealing gene functions in microbes.",
      "authors": "Miller Danielle; Stern Adi; Burstein David",
      "year": "2022",
      "month": "Sep",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "36130281",
      "doi": "10.1093/nar/gkac781",
      "title": "Integrated analysis of multimodal single-cell data with structural similarity.",
      "abstract": "Multimodal single-cell sequencing technologies provide unprecedented information on cellular heterogeneity from multiple layers of genomic readouts. However, joint analysis of two modalities without properly handling the noise often leads to overfitting of one modality by the other and worse clustering results than vanilla single-modality analysis. How to efficiently utilize the extra information from single cell multi-omics to delineate cell states and identify meaningful signal remains as a significant computational challenge. In this work, we propose a deep learning framework, named SAILERX, for efficient, robust, and flexible analysis of multi-modal single-cell data. SAILERX consists of a variational autoencoder with invariant representation learning to correct technical noises from sequencing process, and a multimodal data alignment mechanism to integrate information from different modalities. Instead of performing hard alignment by projecting both modalities to a shared latent space, SAILERX encourages the local structures of two modalities measured by pairwise similarities to be similar. This strategy is more robust against overfitting of noises, which facilitates various downstream analysis such as clustering, imputation, and marker gene detection. Furthermore, the invariant representation learning part enables SAILERX to perform integrative analysis on both multi- and single-modal datasets, making it an applicable and scalable tool for more general scenarios.",
      "authors": "Cao Yingxin; Fu Laiyi; Wu Jie; Peng Qinke; Nie Qing; Zhang Jing; Xie Xiaohui",
      "year": "2022",
      "month": "Nov",
      "journal": "Nucleic acids research",
      "source": "pubmed"
    },
    {
      "pmid": "36124302",
      "doi": "10.1016/j.patter.2022.100577",
      "title": "Single-cell multi-modal GAN reveals spatial patterns in single-cell data from triple-negative breast cancer.",
      "abstract": "Exciting advances in technologies to measure biological systems are currently at the forefront of research. The ability to gather data along an increasing number of omic dimensions has created a need for tools to analyze all of this information together, rather than siloing each technology into separate analysis pipelines. To advance this goal, we introduce a framework called the single-cell multi-modal generative adversarial network (scMMGAN) that integrates data from multiple modalities into a unified representation in the ambient data space for downstream analysis using a combination of adversarial learning and data geometry techniques. The framework's key improvement is an additional diffusion geometry loss with a new kernel that constrains the otherwise over-parameterized GAN. We demonstrate scMMGAN's ability to produce more meaningful alignments than alternative methods on a wide variety of data modalities and that its output can be used to draw conclusions from real-world biological experimental data.",
      "authors": "Amodio Matthew; Youlten Scott E; Venkat Aarthi; San Juan Beatriz P; Chaffer Christine L; Krishnaswamy Smita",
      "year": "2022",
      "month": "Sep",
      "journal": "Patterns (New York, N.Y.)",
      "source": "pubmed"
    },
    {
      "pmid": "36041084",
      "doi": "10.1158/2159-8290.CD-21-1443",
      "title": "Developmental Deconvolution for Classification of Cancer Origin.",
      "abstract": "Cancer is partly a developmental disease, with malignancies named based on cell or tissue of origin. However, a systematic atlas of tumor origins is lacking. Here we map the single-cell organogenesis of 56 developmental trajectories to the transcriptomes of over 10,000 tumors across 33 cancer types. We deconvolute tumor transcriptomes into signals for individual developmental trajectories. Using these signals as inputs, we construct a developmental multilayer perceptron (D-MLP) classifier that outputs cancer origin. D-MLP (ROC-AUC: 0.974 for top prediction) outperforms benchmark classifiers. We analyze tumors from patients with cancer of unknown primary (CUP), selecting the most difficult cases in which extensive multimodal workup yielded no definitive tumor type. Interestingly, CUPs form groups distinguished by developmental trajectories, and classification reveals diagnosis for patient tumors. Our results provide an atlas of tumor developmental origins, provide a tool for diagnostic pathology, and suggest developmental classification may be a useful approach for patient tumors. Here we map the developmental trajectories of tumors. We deconvolute tumor transcriptomes into signals for mammalian developmental programs and use this information to construct a deep learning classifier that outputs tumor type. We apply the classifier to CUP and reveal the developmental origins of patient tumors. See related commentary by Wang, p. 2498. This article is highlighted in the In This Issue feature, p. 2483.",
      "authors": "Moiso Enrico; Farahani Alexander; Marble Hetal D; Hendricks Austin; Mildrum Samuel; Levine Stuart; Lennerz Jochen K; Garg Salil",
      "year": "2022",
      "month": "Nov",
      "journal": "Cancer discovery",
      "source": "pubmed"
    },
    {
      "pmid": "36008134",
      "doi": "10.1261/rna.079365.122",
      "title": "De novo prediction of RNA-protein interactions with graph neural networks.",
      "abstract": "RNA-binding proteins (RBPs) are key co- and post-transcriptional regulators of gene expression, playing a crucial role in many biological processes. Experimental methods like CLIP-seq have enabled the identification of transcriptome-wide RNA-protein interactions for select proteins; however, the time- and resource-intensive nature of these technologies call for the development of computational methods to complement their predictions. Here, we leverage recent, large-scale CLIP-seq experiments to construct a de novo predictor of RNA-protein interactions based on graph neural networks (GNN). We show that the GNN method allows us not only to predict missing links in an RNA-protein network, but to predict the entire complement of targets of previously unassayed proteins, and even to reconstruct the entire network of RNA-protein interactions in different conditions based on minimal information. Our results demonstrate the potential of modern machine learning methods to extract useful information on post-transcriptional regulation from large data sets.",
      "authors": "Arora Viplove; Sanguinetti Guido",
      "year": "2022",
      "month": "Nov",
      "journal": "RNA (New York, N.Y.)",
      "source": "pubmed"
    },
    {
      "pmid": "35944502",
      "doi": "10.1016/j.ccell.2022.07.004",
      "title": "Pan-cancer integrative histology-genomic analysis via multimodal deep learning.",
      "abstract": "The rapidly emerging field of computational pathology has demonstrated promise in developing objective prognostic models from histology images. However, most prognostic models are either based on histology or genomics alone and do not address how these data sources can be integrated to develop joint image-omic prognostic models. Additionally, identifying explainable morphological and molecular descriptors from these models that govern such prognosis is of interest. We use multimodal deep learning to jointly examine pathology whole-slide images and molecular profile data from 14 cancer types. Our weakly supervised, multimodal deep-learning algorithm is able to fuse these heterogeneous modalities to predict outcomes and discover prognostic features that correlate with poor and favorable outcomes. We present all analyses for morphological and molecular correlates of patient prognosis across the 14 cancer types at both a disease and a patient level in an interactive open-access database to allow for further exploration, biomarker discovery, and feature assessment.",
      "authors": "Chen Richard J; Lu Ming Y; Williamson Drew F K; Chen Tiffany Y; Lipkova Jana; Noor Zahra; Shaban Muhammad; Shady Maha; Williams Mane; Joo Bumjin; Mahmood Faisal",
      "year": "2022",
      "month": "Aug",
      "journal": "Cancer cell",
      "source": "pubmed"
    },
    {
      "pmid": "35865460",
      "doi": "10.3389/fonc.2022.925079",
      "title": "Evaluating the Microsatellite Instability of Colorectal Cancer Based on Multimodal Deep Learning Integrating Histopathological and Molecular Data.",
      "abstract": "Microsatellite instability (MSI), an important biomarker for immunotherapy and the diagnosis of Lynch syndrome, refers to the change of microsatellite (MS) sequence length caused by insertion or deletion during DNA replication. However, traditional wet-lab experiment-based MSI detection is time-consuming and relies on experimental conditions. In addition, a comprehensive study on the associations between MSI status and various molecules like mRNA and miRNA has not been performed. In this study, we first studied the association between MSI status and several molecules including mRNA, miRNA, lncRNA, DNA methylation, and copy number variation (CNV) using colorectal cancer data from The Cancer Genome Atlas (TCGA). Then, we developed a novel deep learning framework to predict MSI status based solely on hematoxylin and eosin (H&E) staining images, and combined the H&E image with the above-mentioned molecules by multimodal compact bilinear pooling. Our results showed that there were significant differences in mRNA, miRNA, and lncRNA between the high microsatellite instability (MSI-H) patient group and the low microsatellite instability or microsatellite stability (MSI-L/MSS) patient group. By using the H&E image alone, one can predict MSI status with an acceptable prediction area under the curve (AUC) of 0.809 in 5-fold cross-validation. The fusion models integrating H&E image with a single type of molecule have higher prediction accuracies than that using H&E image alone, with the highest AUC of 0.952 achieved when combining H&E image with DNA methylation data. However, prediction accuracy will decrease when combining H&E image with all types of molecular data. In conclusion, combining H&E image with deep learning can predict the MSI status of colorectal cancer, the accuracy of which can further be improved by integrating appropriate molecular data. This study may have clinical significance in practice.",
      "authors": "Qiu Wenjing; Yang Jiasheng; Wang Bing; Yang Min; Tian Geng; Wang Peizhen; Yang Jialiang",
      "year": "2022",
      "month": "",
      "journal": "Frontiers in oncology",
      "source": "pubmed"
    },
    {
      "pmid": "35804988",
      "doi": "10.3390/cancers14133215",
      "title": "Combining Molecular, Imaging, and Clinical Data Analysis for Predicting Cancer Prognosis.",
      "abstract": "Cancer is one of the most detrimental diseases globally. Accordingly, the prognosis prediction of cancer patients has become a field of interest. In this review, we have gathered 43 state-of-the-art scientific papers published in the last 6 years that built cancer prognosis predictive models using multimodal data. We have defined the multimodality of data as four main types: clinical, anatomopathological, molecular, and medical imaging; and we have expanded on the information that each modality provides. The 43 studies were divided into three categories based on the modelling approach taken, and their characteristics were further discussed together with current issues and future trends. Research in this area has evolved from survival analysis through statistical modelling using mainly clinical and anatomopathological data to the prediction of cancer prognosis through a multi-faceted data-driven approach by the integration of complex, multimodal, and high-dimensional data containing multi-omics and medical imaging information and by applying Machine Learning and, more recently, Deep Learning techniques. This review concludes that cancer prognosis predictive multimodal models are capable of better stratifying patients, which can improve clinical management and contribute to the implementation of personalised medicine as well as provide new and valuable knowledge on cancer biology and its progression.",
      "authors": "Lobato-Delgado Barbara; Priego-Torres Blanca; Sanchez-Morillo Daniel",
      "year": "2022",
      "month": "Jun",
      "journal": "Cancers",
      "source": "pubmed"
    },
    {
      "pmid": "35801589",
      "doi": "10.1172/jci.insight.160267",
      "title": "HIV viral transcription and immune perturbations in the CNS of people with HIV despite ART.",
      "abstract": "People with HIV (PWH) on antiretroviral therapy (ART) experience elevated rates of neurological impairment, despite controlling for demographic factors and comorbidities, suggesting viral or neuroimmune etiologies for these deficits. Here, we apply multimodal and cross-compartmental single-cell analyses of paired cerebrospinal fluid (CSF) and peripheral blood in PWH and uninfected controls. We demonstrate that a subset of central memory CD4+ T cells in the CSF produced HIV-1 RNA, despite apparent systemic viral suppression, and that HIV-1-infected cells were more frequently found in the CSF than in the blood. Using cellular indexing of transcriptomes and epitopes by sequencing (CITE-seq), we show that the cell surface marker CD204 is a reliable marker for rare microglia-like cells in the CSF, which have been implicated in HIV neuropathogenesis, but which we did not find to contain HIV transcripts. Through a feature selection method for supervised deep learning of single-cell transcriptomes, we find that abnormal CD8+ T cell activation, rather than CD4+ T cell abnormalities, predominated in the CSF of PWH compared with controls. Overall, these findings suggest ongoing CNS viral persistence and compartmentalized CNS neuroimmune effects of HIV infection during ART and demonstrate the power of single-cell studies of CSF to better understand the CNS reservoir during HIV infection.",
      "authors": "Farhadian Shelli F; Lindenbaum Ofir; Zhao Jun; Corley Michael J; Im Yunju; Walsh Hannah; Vecchio Alyssa; Garcia-Milian Rolando; Chiarella Jennifer; Chintanaphol Michelle; Calvi Rachela; Wang Guilin; Ndhlovu Lishomwa C; Yoon Jennifer; Trotta Diane; Ma Shuangge; Kluger Yuval; Spudich Serena",
      "year": "2022",
      "month": "Jul",
      "journal": "JCI insight",
      "source": "pubmed"
    },
    {
      "pmid": "35782725",
      "doi": "10.1016/j.csbj.2022.06.031",
      "title": "DESSO-DB: A web database for sequence and shape motif analyses and identification.",
      "abstract": "",
      "authors": "Wang Xiaoying; Wang Cankun; Li Lang; Ma Qin; Ma Anjun; Liu Bingqiang",
      "year": "2022",
      "month": "",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "35769139",
      "doi": "10.7717/peerj.13613",
      "title": "Genomics enters the deep learning era.",
      "abstract": "The tremendous amount of biological sequence data available, combined with the recent methodological breakthrough in deep learning in domains such as computer vision or natural language processing, is leading today to the transformation of bioinformatics through the emergence of deep genomics, the application of deep learning to genomic sequences. We review here the new applications that the use of deep learning enables in the field, focusing on three aspects: the functional annotation of genomes, the sequence determinants of the genome functions and the possibility to write synthetic genomic sequences.",
      "authors": "Routhier Etienne; Mozziconacci Julien",
      "year": "2022",
      "month": "",
      "journal": "PeerJ",
      "source": "pubmed"
    },
    {
      "pmid": "35687826",
      "doi": "10.1200/EDBK_350652",
      "title": "Artificial Intelligence in Oncology: Current Capabilities, Future Opportunities, and Ethical Considerations.",
      "abstract": "The promise of highly personalized oncology care using artificial intelligence (AI) technologies has been forecasted since the emergence of the field. Cumulative advances across the science are bringing this promise to realization, including refinement of machine learning- and deep learning algorithms; expansion in the depth and variety of databases, including multiomics; and the decreased cost of massively parallelized computational power. Examples of successful clinical applications of AI can be found throughout the cancer continuum and in multidisciplinary practice, with computer vision-assisted image analysis in particular having several U.S. Food and Drug Administration-approved uses. Techniques with emerging clinical utility include whole blood multicancer detection from deep sequencing, virtual biopsies, natural language processing to infer health trajectories from medical notes, and advanced clinical decision support systems that combine genomics and clinomics. Substantial issues have delayed broad adoption, with data transparency and interpretability suffering from AI's \"black box\" mechanism, and intrinsic bias against underrepresented persons limiting the reproducibility of AI models and perpetuating health care disparities. Midfuture projections of AI maturation involve increasing a model's complexity by using multimodal data elements to better approximate an organic system. Far-future positing includes living databases that accumulate all aspects of a person's health into discrete data elements; this will fuel highly convoluted modeling that can tailor treatment selection, dose determination, surveillance modality and schedule, and more. The field of AI has had a historical dichotomy between its proponents and detractors. The successful development of recent applications, and continued investment in prospective validation that defines their impact on multilevel outcomes, has established a momentum of accelerated progress.",
      "authors": "Shreve Jacob T; Khanani Sadia A; Haddad Tufia C",
      "year": "2022",
      "month": "Apr",
      "journal": "American Society of Clinical Oncology educational book. American Society of Clinical Oncology. Annual Meeting",
      "source": "pubmed"
    },
    {
      "pmid": "35677355",
      "doi": "10.3389/fnins.2022.866666",
      "title": "Combining Neuroimaging and Omics Datasets for Disease Classification Using Graph Neural Networks.",
      "abstract": "Both neuroimaging and genomics datasets are often gathered for the detection of neurodegenerative diseases. Huge dimensionalities of neuroimaging data as well as omics data pose tremendous challenge for methods integrating multiple modalities. There are few existing solutions that can combine both multi-modal imaging and multi-omics datasets to derive neurological insights. We propose a deep neural network architecture that combines both structural and functional connectome data with multi-omics data for disease classification. A graph convolution layer is used to model functional magnetic resonance imaging (fMRI) and diffusion tensor imaging (DTI) data simultaneously to learn compact representations of the connectome. A separate set of graph convolution layers are then used to model multi-omics datasets, expressed in the form of population graphs, and combine them with latent representations of the connectome. An attention mechanism is used to fuse these outputs and provide insights on which omics data contributed most to the model's classification decision. We demonstrate our methods for Parkinson's disease (PD) classification by using datasets from the Parkinson's Progression Markers Initiative (PPMI). PD has been shown to be associated with changes in the human connectome and it is also known to be influenced by genetic factors. We combine DTI and fMRI data with multi-omics data from RNA Expression, Single Nucleotide Polymorphism (SNP), DNA Methylation and non-coding RNA experiments. A Matthew Correlation Coefficient of greater than 0.8 over many combinations of multi-modal imaging data and multi-omics data was achieved with our proposed architecture. To address the paucity of paired multi-modal imaging data and the problem of imbalanced data in the PPMI dataset, we compared the use of oversampling against using CycleGAN on structural and functional connectomes to generate missing imaging modalities. Furthermore, we performed ablation studies that offer insights into the importance of each imaging and omics modality for the prediction of PD. Analysis of the generated attention matrices revealed that DNA Methylation and SNP data were the most important omics modalities out of all the omics datasets considered. Our work motivates further research into imaging genetics and the creation of more multi-modal imaging and multi-omics datasets to study PD and other complex neurodegenerative diseases.",
      "authors": "Chan Yi Hao; Wang Conghao; Soh Wei Kwek; Rajapakse Jagath C",
      "year": "2022",
      "month": "",
      "journal": "Frontiers in neuroscience",
      "source": "pubmed"
    },
    {
      "pmid": "35657113",
      "doi": "10.1093/database/baac036",
      "title": "GeMI: interactive interface for transformer-based Genomic Metadata Integration.",
      "abstract": "The Gene Expression Omnibus (GEO) is a public archive containing >4 million digital samples from functional genomics experiments collected over almost two decades. The accompanying metadata describing the experiments suffer from redundancy, inconsistency and incompleteness due to the prevalence of free text and the lack of well-defined data formats and their validation. To remedy this situation, we created Genomic Metadata Integration (GeMI; http://gmql.eu/gemi/), a web application that learns to automatically extract structured metadata (in the form of key-value pairs) from the plain text descriptions of GEO experiments. The extracted information can then be indexed for structured search and used for various downstream data mining activities. GeMI works in continuous interaction with its users. The natural language processing transformer-based model at the core of our system is a fine-tuned version of the Generative Pre-trained Transformer 2 (GPT2) model that is able to learn continuously from the feedback of the users thanks to an active learning framework designed for the purpose. As a part of such a framework, a machine learning interpretation mechanism (that exploits saliency maps) allows the users to understand easily and quickly whether the predictions of the model are correct and improves the overall usability. GeMI's ability to extract attributes not explicitly mentioned (such as sex, tissue type, cell type, ethnicity and disease) allows researchers to perform specific queries and classification of experiments, which was previously possible only after spending time and resources with tedious manual annotation. The usefulness of GeMI is demonstrated on practical research use cases. Database URL http://gmql.eu/gemi/.",
      "authors": "Serna Garcia Giuseppe; Leone Michele; Bernasconi Anna; Carman Mark J",
      "year": "2022",
      "month": "Jun",
      "journal": "Database : the journal of biological databases and curation",
      "source": "pubmed"
    },
    {
      "pmid": "35489069",
      "doi": "10.1093/nar/gkac278",
      "title": "DeepLoc 2.0: multi-label subcellular localization prediction using protein language models.",
      "abstract": "The prediction of protein subcellular localization is of great relevance for proteomics research. Here, we propose an update to the popular tool DeepLoc with multi-localization prediction and improvements in both performance and interpretability. For training and validation, we curate eukaryotic and human multi-location protein datasets with stringent homology partitioning and enriched with sorting signal information compiled from the literature. We achieve state-of-the-art performance in DeepLoc 2.0 by using a pre-trained protein language model. It has the further advantage that it uses sequence input rather than relying on slower protein profiles. We provide two means of better interpretability: an attention output along the sequence and highly accurate prediction of nine different types of protein sorting signals. We find that the attention output correlates well with the position of sorting signals. The webserver is available at services.healthtech.dtu.dk/service.php?DeepLoc-2.0.",
      "authors": "Thumuluri Vineet; Almagro Armenteros José Juan; Johansen Alexander Rosenberg; Nielsen Henrik; Winther Ole",
      "year": "2022",
      "month": "Jul",
      "journal": "Nucleic acids research",
      "source": "pubmed"
    },
    {
      "pmid": "35474667",
      "doi": "10.1016/j.crmeth.2021.100071",
      "title": "A mixture-of-experts deep generative model for integrated analysis of single-cell multiomics data.",
      "abstract": "The recent development of single-cell multiomics analysis has enabled simultaneous detection of multiple traits at the single-cell level, providing deeper insights into cellular phenotypes and functions in diverse tissues. However, currently, it is challenging to infer the joint representations and learn relationships among multiple modalities from complex multimodal single-cell data. Here, we present scMM, a novel deep generative model-based framework for the extraction of interpretable joint representations and crossmodal generation. scMM addresses the complexity of data by leveraging a mixture-of-experts multimodal variational autoencoder. The pseudocell generation strategy of scMM compensates for the limited interpretability of deep learning models, and the proposed approach experimentally discovered multimodal regulatory programs associated with latent dimensions. Analysis of recently produced datasets validated that scMM facilitates high-resolution clustering with rich interpretability. Furthermore, we show that crossmodal generation by scMM leads to more precise prediction and data integration compared with the state-of-the-art and conventional approaches.",
      "authors": "Minoura Kodai; Abe Ko; Nam Hyunha; Nishikawa Hiroyoshi; Shimamura Teppei",
      "year": "2021",
      "month": "Sep",
      "journal": "Cell reports methods",
      "source": "pubmed"
    },
    {
      "pmid": "35456374",
      "doi": "10.3390/genes13040568",
      "title": "SemanticCAP: Chromatin Accessibility Prediction Enhanced by Features Learning from a Language Model.",
      "abstract": "A large number of inorganic and organic compounds are able to bind DNA and form complexes, among which drug-related molecules are important. Chromatin accessibility changes not only directly affect drug-DNA interactions, but they can promote or inhibit the expression of the critical genes associated with drug resistance by affecting the DNA binding capacity of TFs and transcriptional regulators. However, the biological experimental techniques for measuring it are expensive and time-consuming. In recent years, several kinds of computational methods have been proposed to identify accessible regions of the genome. Existing computational models mostly ignore the contextual information provided by the bases in gene sequences. To address these issues, we proposed a new solution called SemanticCAP. It introduces a gene language model that models the context of gene sequences and is thus able to provide an effective representation of a certain site in a gene sequence. Basically, we merged the features provided by the gene language model into our chromatin accessibility model. During the process, we designed methods called SFA and SFC to make feature fusion smoother. Compared to DeepSEA, gkm-SVM, and k-mer using public benchmarks, our model proved to have better performance, showing a 1.25% maximum improvement in auROC and a 2.41% maximum improvement in auPRC.",
      "authors": "Zhang Yikang; Chu Xiaomin; Jiang Yelu; Wu Hongjie; Quan Lijun",
      "year": "2022",
      "month": "Mar",
      "journal": "Genes",
      "source": "pubmed"
    },
    {
      "pmid": "35402436",
      "doi": "10.3389/fmed.2022.771982",
      "title": "Recent Technical Advances in Accelerating the Clinical Translation of Small Animal Brain Imaging: Hybrid Imaging, Deep Learning, and Transcriptomics.",
      "abstract": "Small animal models play a fundamental role in brain research by deepening the understanding of the physiological functions and mechanisms underlying brain disorders and are thus essential in the development of therapeutic and diagnostic imaging tracers targeting the central nervous system. Advances in structural, functional, and molecular imaging using MRI, PET, fluorescence imaging, and optoacoustic imaging have enabled the interrogation of the rodent brain across a large temporal and spatial resolution scale in a non-invasively manner. However, there are still several major gaps in translating from preclinical brain imaging to the clinical setting. The hindering factors include the following: (1) intrinsic differences between biological species regarding brain size, cell type, protein expression level, and metabolism level and (2) imaging technical barriers regarding the interpretation of image contrast and limited spatiotemporal resolution. To mitigate these factors, single-cell transcriptomics and measures to identify the cellular source of PET tracers have been developed. Meanwhile, hybrid imaging techniques that provide highly complementary anatomical and molecular information are emerging. Furthermore, deep learning-based image analysis has been developed to enhance the quantification and optimization of the imaging protocol. In this mini-review, we summarize the recent developments in small animal neuroimaging toward improved translational power, with a focus on technical improvement including hybrid imaging, data processing, transcriptomics, awake animal imaging, and on-chip pharmacokinetics. We also discuss outstanding challenges in standardization and considerations toward increasing translational power and propose future outlooks.",
      "authors": "Ren Wuwei; Ji Bin; Guan Yihui; Cao Lei; Ni Ruiqing",
      "year": "2022",
      "month": "",
      "journal": "Frontiers in medicine",
      "source": "pubmed"
    },
    {
      "pmid": "35368657",
      "doi": "10.3389/fgene.2022.800853",
      "title": "A Novel Deep Learning Method to Predict Lung Cancer Long-Term Survival With Biological Knowledge Incorporated Gene Expression Images and Clinical Data.",
      "abstract": "Lung cancer is the leading cause of the cancer deaths. Therefore, predicting the survival status of lung cancer patients is of great value. However, the existing methods mainly depend on statistical machine learning (ML) algorithms. Moreover, they are not appropriate for high-dimensionality genomics data, and deep learning (DL), with strong high-dimensional data learning capability, can be used to predict lung cancer survival using genomics data. The Cancer Genome Atlas (TCGA) is a great database that contains many kinds of genomics data for 33 cancer types. With this enormous amount of data, researchers can analyze key factors related to cancer therapy. This paper proposes a novel method to predict lung cancer long-term survival using gene expression data from TCGA. Firstly, we select the most relevant genes to the target problem by the supervised feature selection method called mutual information selector. Secondly, we propose a method to convert gene expression data into two kinds of images with KEGG BRITE and KEGG Pathway data incorporated, so that we could make good use of the convolutional neural network (CNN) model to learn high-level features. Afterwards, we design a CNN-based DL model and added two kinds of clinical data to improve the performance, so that we finally got a multimodal DL model. The generalized experiments results indicated that our method performed much better than the ML models and unimodal DL models. Furthermore, we conduct survival analysis and observe that our model could better divide the samples into high-risk and low-risk groups.",
      "authors": "Wang Shuo; Zhang Hao; Liu Zhen; Liu Yuanning",
      "year": "2022",
      "month": "",
      "journal": "Frontiers in genetics",
      "source": "pubmed"
    },
    {
      "pmid": "35360226",
      "doi": "10.3389/fphys.2022.833333",
      "title": "User-Accessible Machine Learning Approaches for Cell Segmentation and Analysis in Tissue.",
      "abstract": "Advanced image analysis with machine and deep learning has improved cell segmentation and classification for novel insights into biological mechanisms. These approaches have been used for the analysis of cells ",
      "authors": "Winfree Seth",
      "year": "2022",
      "month": "",
      "journal": "Frontiers in physiology",
      "source": "pubmed"
    },
    {
      "pmid": "35325548",
      "doi": "10.1089/cmb.2021.0316",
      "title": "Integrating Long-Range Regulatory Interactions to Predict Gene Expression Using Graph Convolutional Networks.",
      "abstract": "",
      "authors": "Bigness Jeremy; Loinaz Xavier; Patel Shalin; Larschan Erica; Singh Ritambhara",
      "year": "2022",
      "month": "May",
      "journal": "Journal of computational biology : a journal of computational molecular cell biology",
      "source": "pubmed"
    },
    {
      "pmid": "35323644",
      "doi": "10.3390/metabo12030202",
      "title": "A Comprehensive Evaluation of Metabolomics Data Preprocessing Methods for Deep Learning.",
      "abstract": "Machine learning has greatly advanced over the past decade, owing to advances in algorithmic innovations, hardware acceleration, and benchmark datasets to train on domains such as computer vision, natural-language processing, and more recently the life sciences. In particular, the subfield of machine learning known as deep learning has found applications in genomics, proteomics, and metabolomics. However, a thorough assessment of how the data preprocessing methods required for the analysis of life science data affect the performance of deep learning is lacking. This work contributes to filling that gap by assessing the impact of commonly used as well as newly developed methods employed in data preprocessing workflows for metabolomics that span from raw data to processed data. The results from these analyses are summarized into a set of best practices that can be used by researchers as a starting point for downstream classification and reconstruction tasks using deep learning.",
      "authors": "Abram Krzysztof Jan; McCloskey Douglas",
      "year": "2022",
      "month": "Feb",
      "journal": "Metabolites",
      "source": "pubmed"
    },
    {
      "pmid": "35089332",
      "doi": "10.1093/bib/bbab569",
      "title": "Multimodal deep learning for biomedical data fusion: a review.",
      "abstract": "Biomedical data are becoming increasingly multimodal and thereby capture the underlying complex relationships among biological processes. Deep learning (DL)-based data fusion strategies are a popular approach for modeling these nonlinear relationships. Therefore, we review the current state-of-the-art of such methods and propose a detailed taxonomy that facilitates more informed choices of fusion strategies for biomedical applications, as well as research on novel methods. By doing so, we find that deep fusion strategies often outperform unimodal and shallow approaches. Additionally, the proposed subcategories of fusion strategies show different advantages and drawbacks. The review of current methods has shown that, especially for intermediate fusion strategies, joint representation learning is the preferred approach as it effectively models the complex interactions of different levels of biological organization. Finally, we note that gradual fusion, based on prior biological knowledge or on search strategies, is a promising future research path. Similarly, utilizing transfer learning might overcome sample size limitations of multimodal data sets. As these data sets become increasingly available, multimodal DL approaches present the opportunity to train holistic models that can learn the complex regulatory dynamics behind health and disease.",
      "authors": "Stahlschmidt Sören Richard; Ulfenborg Benjamin; Synnergren Jane",
      "year": "2022",
      "month": "Mar",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "35058621",
      "doi": "10.1038/s41587-021-01161-6",
      "title": "scJoint integrates atlas-scale single-cell RNA-seq and ATAC-seq data with transfer learning.",
      "abstract": "Single-cell multiomics data continues to grow at an unprecedented pace. Although several methods have demonstrated promising results in integrating several data modalities from the same tissue, the complexity and scale of data compositions present in cell atlases still pose a challenge. Here, we present scJoint, a transfer learning method to integrate atlas-scale, heterogeneous collections of scRNA-seq and scATAC-seq data. scJoint leverages information from annotated scRNA-seq data in a semisupervised framework and uses a neural network to simultaneously train labeled and unlabeled data, allowing label transfer and joint visualization in an integrative framework. Using atlas data as well as multimodal datasets generated with ASAP-seq and CITE-seq, we demonstrate that scJoint is computationally efficient and consistently achieves substantially higher cell-type label accuracy than existing methods while providing meaningful joint visualizations. Thus, scJoint overcomes the heterogeneity of different data modalities to enable a more comprehensive understanding of cellular phenotypes.",
      "authors": "Lin Yingxin; Wu Tung-Yu; Wan Sheng; Yang Jean Y H; Wong Wing H; Wang Y X Rachel",
      "year": "2022",
      "month": "May",
      "journal": "Nature biotechnology",
      "source": "pubmed"
    },
    {
      "pmid": "35022082",
      "doi": "10.1186/s13059-021-02595-6",
      "title": "A deep generative model for multi-view profiling of single-cell RNA-seq and ATAC-seq data.",
      "abstract": "Here, we present a multi-modal deep generative model, the single-cell Multi-View Profiler (scMVP), which is designed for handling sequencing data that simultaneously measure gene expression and chromatin accessibility in the same cell, including SNARE-seq, sci-CAR, Paired-seq, SHARE-seq, and Multiome from 10X Genomics. scMVP generates common latent representations for dimensionality reduction, cell clustering, and developmental trajectory inference and generates separate imputations for differential analysis and cis-regulatory element identification. scMVP can help mitigate data sparsity issues with imputation and accurately identify cell groups for different joint profiling techniques with common latent embedding, and we demonstrate its advantages on several realistic datasets.",
      "authors": "Li Gaoyang; Fu Shaliu; Wang Shuguang; Zhu Chenyu; Duan Bin; Tang Chen; Chen Xiaohan; Chuai Guohui; Wang Ping; Liu Qi",
      "year": "2022",
      "month": "Jan",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "34991450",
      "doi": "10.1186/s12859-021-04547-0",
      "title": "Lerna: transformer architectures for configuring error correction tools for short- and long-read genome sequencing.",
      "abstract": "Sequencing technologies are prone to errors, making error correction (EC) necessary for downstream applications. EC tools need to be manually configured for optimal performance. We find that the optimal parameters (e.g., k-mer size) are both tool- and dataset-dependent. Moreover, evaluating the performance (i.e., Alignment-rate or Gain) of a given tool usually relies on a reference genome, but quality reference genomes are not always available. We introduce Lerna for the automated configuration of k-mer-based EC tools. Lerna first creates a language model (LM) of the uncorrected genomic reads, and then, based on this LM, calculates a metric called the perplexity metric to evaluate the corrected reads for different parameter choices. Next, it finds the one that produces the highest alignment rate without using a reference genome. The fundamental intuition of our approach is that the perplexity metric is inversely correlated with the quality of the assembly after error correction. Therefore, Lerna leverages the perplexity metric for automated tuning of k-mer sizes without needing a reference genome. First, we show that the best k-mer value can vary for different datasets, even for the same EC tool. This motivates our design that automates k-mer size selection without using a reference genome. Second, we show the gains of our LM using its component attention-based transformers. We show the model's estimation of the perplexity metric before and after error correction. The lower the perplexity after correction, the better the k-mer size. We also show that the alignment rate and assembly quality computed for the corrected reads are strongly negatively correlated with the perplexity, enabling the automated selection of k-mer values for better error correction, and hence, improved assembly quality. We validate our approach on both short and long reads. Additionally, we show that our attention-based models have significant runtime improvement for the entire pipeline-18[Formula: see text] faster than previous works, due to parallelizing the attention mechanism and the use of JIT compilation for GPU inferencing. Lerna improves de novo genome assembly by optimizing EC tools. Our code is made available in a public repository at: https://github.com/icanforce/lerna-genomics .",
      "authors": "Sharma Atul; Jain Pranjal; Mahgoub Ashraf; Zhou Zihan; Mahadik Kanak; Chaterji Somali",
      "year": "2022",
      "month": "Jan",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "34890151",
      "doi": "",
      "title": "Precision Medicine: Using Artificial Intelligence to Improve Diagnostics and Healthcare.",
      "abstract": "The continued generation of large amounts of data within healthcare-from imaging to electronic medical health records to genomics and multi-omics -necessitates tools and methods to parse and interpret these data to improve healthcare outcomes. Artificial intelligence, and in particular deep learning, has enabled researchers to gain new insights from large scale and multimodal data. At the 2022 Pacific Symposium on Biocomputing (PSB) session entitled \"Precision Medicine: Using Artificial Intelligence to Improve Diagnostics and Healthcare\", we showcase the latest research, influenced and inspired by the idea of using technology to build a more fair, tailored, and cost-effective healthcare system after the COVID-19 pandemic.",
      "authors": "Daneshjou Roxana; Brenner Steven E; Chen Jonathan H; Crawford Dana C; Finlayson Samuel G; Kidziński Łukasz; Bulyk Martha L",
      "year": "2022",
      "month": "",
      "journal": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
      "source": "pubmed"
    },
    {
      "pmid": "34881778",
      "doi": "10.1042/ETLS20210249",
      "title": "Applied machine learning in Alzheimer's disease research: omics, imaging, and clinical data.",
      "abstract": "Alzheimer's disease (AD) remains a devastating neurodegenerative disease with few preventive or curative treatments available. Modern technology developments of high-throughput omics platforms and imaging equipment provide unprecedented opportunities to study the etiology and progression of this disease. Meanwhile, the vast amount of data from various modalities, such as genetics, proteomics, transcriptomics, and imaging, as well as clinical features impose great challenges in data integration and analysis. Machine learning (ML) methods offer novel techniques to address high dimensional data, integrate data from different sources, model the etiological and clinical heterogeneity, and discover new biomarkers. These directions have the potential to help us better manage the disease progression and develop novel treatment strategies. This mini-review paper summarizes different ML methods that have been applied to study AD using single-platform or multi-modal data. We review the current state of ML applications for five key directions of AD research: disease classification, drug repurposing, subtyping, progression prediction, and biomarker discovery. This summary provides insights about the current research status of ML-based AD research and highlights potential directions for future research.",
      "authors": "Li Ziyi; Jiang Xiaoqian; Wang Yizhuo; Kim Yejin",
      "year": "2021",
      "month": "Dec",
      "journal": "Emerging topics in life sciences",
      "source": "pubmed"
    },
    {
      "pmid": "34858485",
      "doi": "10.3389/fgene.2021.771092",
      "title": "Predicting Bone Metastasis Using Gene Expression-Based Machine Learning Models.",
      "abstract": "Bone is the most common site of distant metastasis from malignant tumors, with the highest prevalence observed in breast and prostate cancers. Such bone metastases (BM) cause many painful skeletal-related events, such as severe bone pain, pathological fractures, spinal cord compression, and hypercalcemia, with adverse effects on life quality. Many bone-targeting agents developed based on the current understanding of BM onset's molecular mechanisms dull these adverse effects. However, only a few studies investigated potential predictors of high risk for developing BM, despite such knowledge being critical for early interventions to prevent or delay BM. This work proposes a computational network-based pipeline that incorporates a ML/DL component to predict BM development. Based on the proposed pipeline we constructed several machine learning models. The deep neural network (DNN) model exhibited the highest prediction accuracy (AUC of 92.11%) using the top 34 featured genes ranked by betweenness centrality scores. We further used an entirely separate, \"external\" TCGA dataset to evaluate the robustness of this DNN model and achieved sensitivity of 85%, specificity of 80%, positive predictive value of 78.10%, negative predictive value of 80%, and AUC of 85.78%. The result shows the models' way of learning allowed it to zoom in on the featured genes that provide the added benefit of the model displaying generic capabilities, that is, to predict BM for samples from different primary sites. Furthermore, existing experimental evidence provides confidence that about 50% of the 34 hub genes have BM-related functionality, which suggests that these common genetic markers provide vital insight about BM drivers. These findings may prompt the transformation of such a method into an artificial intelligence (AI) diagnostic tool and direct us towards mechanisms that underlie metastasis to bone events.",
      "authors": "Albaradei Somayah; Uludag Mahmut; Thafar Maha A; Gojobori Takashi; Essack Magbubah; Gao Xin",
      "year": "2021",
      "month": "",
      "journal": "Frontiers in genetics",
      "source": "pubmed"
    },
    {
      "pmid": "34781902",
      "doi": "10.1186/s12859-021-04430-y",
      "title": "Multi-resBind: a residual network-based multi-label classifier for in vivo RNA binding prediction and preference visualization.",
      "abstract": "Protein-RNA interactions play key roles in many processes regulating gene expression. To understand the underlying binding preference, ultraviolet cross-linking and immunoprecipitation (CLIP)-based methods have been used to identify the binding sites for hundreds of RNA-binding proteins (RBPs) in vivo. Using these large-scale experimental data to infer RNA binding preference and predict missing binding sites has become a great challenge. Some existing deep-learning models have demonstrated high prediction accuracy for individual RBPs. However, it remains difficult to avoid significant bias due to the experimental protocol. The DeepRiPe method was recently developed to solve this problem via introducing multi-task or multi-label learning into this field. However, this method has not reached an ideal level of prediction power due to the weak neural network architecture. Compared to the DeepRiPe approach, our Multi-resBind method demonstrated substantial improvements using the same large-scale PAR-CLIP dataset with respect to an increase in the area under the receiver operating characteristic curve and average precision. We conducted extensive experiments to evaluate the impact of various types of input data on the final prediction accuracy. The same approach was used to evaluate the effect of loss functions. Finally, a modified integrated gradient was employed to generate attribution maps. The patterns disentangled from relative contributions according to context offer biological insights into the underlying mechanism of protein-RNA interactions. Here, we propose Multi-resBind as a new multi-label deep-learning approach to infer protein-RNA binding preferences and predict novel interactions. The results clearly demonstrate that Multi-resBind is a promising tool to predict unknown binding sites in vivo and gain biology insights into why the neural network makes a given prediction.",
      "authors": "Zhao Shitao; Hamada Michiaki",
      "year": "2021",
      "month": "Nov",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "34714871",
      "doi": "10.1371/journal.pone.0259349",
      "title": "SpeCollate: Deep cross-modal similarity network for mass spectrometry data based peptide deductions.",
      "abstract": "Historically, the database search algorithms have been the de facto standard for inferring peptides from mass spectrometry (MS) data. Database search algorithms deduce peptides by transforming theoretical peptides into theoretical spectra and matching them to the experimental spectra. Heuristic similarity-scoring functions are used to match an experimental spectrum to a theoretical spectrum. However, the heuristic nature of the scoring functions and the simple transformation of the peptides into theoretical spectra, along with noisy mass spectra for the less abundant peptides, can introduce a cascade of inaccuracies. In this paper, we design and implement a Deep Cross-Modal Similarity Network called SpeCollate, which overcomes these inaccuracies by learning the similarity function between experimental spectra and peptides directly from the labeled MS data. SpeCollate transforms spectra and peptides into a shared Euclidean subspace by learning fixed size embeddings for both. Our proposed deep-learning network trains on sextuplets of positive and negative examples coupled with our custom-designed SNAP-loss function. Online hardest negative mining is used to select the appropriate negative examples for optimal training performance. We use 4.8 million sextuplets obtained from the NIST and MassIVE peptide libraries to train the network and demonstrate that for closed search, SpeCollate is able to perform better than Crux and MSFragger in terms of the number of peptide-spectrum matches (PSMs) and unique peptides identified under 1% FDR for real-world data. SpeCollate also identifies a large number of peptides not reported by either Crux or MSFragger. To the best of our knowledge, our proposed SpeCollate is the first deep-learning network that can determine the cross-modal similarity between peptides and mass-spectra for MS-based proteomics. We believe SpeCollate is significant progress towards developing machine-learning solutions for MS-based omics data analysis. SpeCollate is available at https://deepspecs.github.io/.",
      "authors": "Tariq Muhammad Usman; Saeed Fahad",
      "year": "2021",
      "month": "",
      "journal": "PloS one",
      "source": "pubmed"
    },
    {
      "pmid": "34711971",
      "doi": "10.1038/s41592-021-01264-7",
      "title": "Deep learning and alignment of spatially resolved single-cell transcriptomes with Tangram.",
      "abstract": "Charting an organs' biological atlas requires us to spatially resolve the entire single-cell transcriptome, and to relate such cellular features to the anatomical scale. Single-cell and single-nucleus RNA-seq (sc/snRNA-seq) can profile cells comprehensively, but lose spatial information. Spatial transcriptomics allows for spatial measurements, but at lower resolution and with limited sensitivity. Targeted in situ technologies solve both issues, but are limited in gene throughput. To overcome these limitations we present Tangram, a method that aligns sc/snRNA-seq data to various forms of spatial data collected from the same region, including MERFISH, STARmap, smFISH, Spatial Transcriptomics (Visium) and histological images. Tangram can map any type of sc/snRNA-seq data, including multimodal data such as those from SHARE-seq, which we used to reveal spatial patterns of chromatin accessibility. We demonstrate Tangram on healthy mouse brain tissue, by reconstructing a genome-wide anatomically integrated spatial map at single-cell resolution of the visual and somatomotor areas.",
      "authors": "Biancalani Tommaso; Scalia Gabriele; Buffoni Lorenzo; Avasthi Raghav; Lu Ziqing; Sanger Aman; Tokcan Neriman; Vanderburg Charles R; Segerstolpe Åsa; Zhang Meng; Avraham-Davidi Inbal; Vickovic Sanja; Nitzan Mor; Ma Sai; Subramanian Ayshwarya; Lipinski Michal; Buenrostro Jason; Brown Nik Bear; Fanelli Duccio; Zhuang Xiaowei; Macosko Evan Z; Regev Aviv",
      "year": "2021",
      "month": "Nov",
      "journal": "Nature methods",
      "source": "pubmed"
    },
    {
      "pmid": "34608321",
      "doi": "10.1038/s41592-021-01283-4",
      "title": "Differentiable biology: using deep learning for biophysics-based and data-driven modeling of molecular mechanisms.",
      "abstract": "Deep learning using neural networks relies on a class of machine-learnable models constructed using 'differentiable programs'. These programs can combine mathematical equations specific to a particular domain of natural science with general-purpose, machine-learnable components trained on experimental data. Such programs are having a growing impact on molecular and cellular biology. In this Perspective, we describe an emerging 'differentiable biology' in which phenomena ranging from the small and specific (for example, one experimental assay) to the broad and complex (for example, protein folding) can be modeled effectively and efficiently, often by exploiting knowledge about basic natural phenomena to overcome the limitations of sparse, incomplete and noisy data. By distilling differentiable biology into a small set of conceptual primitives and illustrative vignettes, we show how it can help to address long-standing challenges in integrating multimodal data from diverse experiments across biological scales. This promises to benefit fields as diverse as biophysics and functional genomics.",
      "authors": "AlQuraishi Mohammed; Sorger Peter K",
      "year": "2021",
      "month": "Oct",
      "journal": "Nature methods",
      "source": "pubmed"
    },
    {
      "pmid": "34607350",
      "doi": "10.1093/bib/bbab374",
      "title": "Assessing deep learning methods in cis-regulatory motif finding based on genomic sequencing data.",
      "abstract": "Identifying cis-regulatory motifs from genomic sequencing data (e.g. ChIP-seq and CLIP-seq) is crucial in identifying transcription factor (TF) binding sites and inferring gene regulatory mechanisms for any organism. Since 2015, deep learning (DL) methods have been widely applied to identify TF binding sites and predict motif patterns, with the strengths of offering a scalable, flexible and unified computational approach for highly accurate predictions. As far as we know, 20 DL methods have been developed. However, without a clear and systematic assessment, users will struggle to choose the most appropriate tool for their specific studies. In this manuscript, we evaluated 20 DL methods for cis-regulatory motif prediction using 690 ENCODE ChIP-seq, 126 cancer ChIP-seq and 55 RNA CLIP-seq data. Four metrics were investigated, including the accuracy of motif finding, the performance of DNA/RNA sequence classification, algorithm scalability and tool usability. The assessment results demonstrated the high complementarity of the existing DL methods. It was determined that the most suitable model should primarily depend on the data size and type and the method's outputs.",
      "authors": "Zhang Shuangquan; Ma Anjun; Zhao Jing; Xu Dong; Ma Qin; Wang Yan",
      "year": "2022",
      "month": "Jan",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "34579788",
      "doi": "10.1186/s13073-021-00968-x",
      "title": "Deep learning in cancer diagnosis, prognosis and treatment selection.",
      "abstract": "Deep learning is a subdiscipline of artificial intelligence that uses a machine learning technique called artificial neural networks to extract patterns and make predictions from large data sets. The increasing adoption of deep learning across healthcare domains together with the availability of highly characterised cancer datasets has accelerated research into the utility of deep learning in the analysis of the complex biology of cancer. While early results are promising, this is a rapidly evolving field with new knowledge emerging in both cancer biology and deep learning. In this review, we provide an overview of emerging deep learning techniques and how they are being applied to oncology. We focus on the deep learning applications for omics data types, including genomic, methylation and transcriptomic data, as well as histopathology-based genomic inference, and provide perspectives on how the different data types can be integrated to develop decision support tools. We provide specific examples of how deep learning may be applied in cancer diagnosis, prognosis and treatment management. We also assess the current limitations and challenges for the application of deep learning in precision oncology, including the lack of phenotypically rich data and the need for more explainable deep learning models. Finally, we conclude with a discussion of how current obstacles can be overcome to enable future clinical utilisation of deep learning.",
      "authors": "Tran Khoa A; Kondrashova Olga; Bradley Andrew; Williams Elizabeth D; Pearson John V; Waddell Nicola",
      "year": "2021",
      "month": "Sep",
      "journal": "Genome medicine",
      "source": "pubmed"
    },
    {
      "pmid": "34490038",
      "doi": "10.3389/fgene.2021.709027",
      "title": "A Multimodal Affinity Fusion Network for Predicting the Survival of Breast Cancer Patients.",
      "abstract": "Accurate survival prediction of breast cancer holds significant meaning for improving patient care. Approaches using multiple heterogeneous modalities such as gene expression, copy number alteration, and clinical data have showed significant advantages over those with only one modality for patient survival prediction. However, existing survival prediction methods tend to ignore the structured information between patients and multimodal data. We propose a multimodal data fusion model based on a novel multimodal affinity fusion network (MAFN) for survival prediction of breast cancer by integrating gene expression, copy number alteration, and clinical data. First, a stack-based shallow self-attention network is utilized to guide the amplification of tiny lesion regions on the original data, which locates and enhances the survival-related features. Then, an affinity fusion module is proposed to map the structured information between patients and multimodal data. The module endows the network with a stronger fusion feature representation and discrimination capability. Finally, the fusion feature embedding and a specific feature embedding from a triple modal network are fused to make the classification of long-term survival or short-term survival for each patient. As expected, the evaluation results on comprehensive performance indicate that MAFN achieves better predictive performance than existing methods. Additionally, our method can be extended to the survival prediction of other cancer diseases, providing a new strategy for other diseases prognosis.",
      "authors": "Guo Weizhou; Liang Wenbin; Deng Qingchun; Zou Xianchun",
      "year": "2021",
      "month": "",
      "journal": "Frontiers in genetics",
      "source": "pubmed"
    },
    {
      "pmid": "34481301",
      "doi": "10.1016/j.ijmedinf.2021.104558",
      "title": "Emergence and evolution of big data science in HIV research: Bibliometric analysis of federally sponsored studies 2000-2019.",
      "abstract": "The rapid growth of inherently complex and heterogeneous data in HIV/AIDS research underscores the importance of Big Data Science. Recently, there have been increasing uptakes of Big Data techniques in basic, clinical, and public health fields of HIV/AIDS research. However, no studies have systematically elaborated on the evolving applications of Big Data in HIV/AIDS research. We sought to explore the emergence and evolution of Big Data Science in HIV/AIDS-related publications that were funded by the US federal agencies. We identified HIV/AIDS and Big Data related publications that were funded by seven federal agencies from 2000 to 2019 by integrating data from National Institutes of Health (NIH) ExPORTER, MEDLINE, and MeSH. Building on bibliometrics and Natural Language Processing (NLP) methods, we constructed co-occurrence networks using bibliographic metadata (e.g., countries, institutes, MeSH terms, and keywords) of the retrieved publications. We then detected clusters among the networks as well as the temporal dynamics of clusters, followed by expert evaluation and clinical implications. We harnessed nearly 600 thousand publications related to HIV/AIDS, of which 19,528 publications relating to Big Data were included in bibliometric analysis. Results showed that (1) the number of Big Data publications has been increasing since 2000, (2) US institutes have been in close collaborations with China, Canada, and Germany, (3) some institutes (e.g., University of California system, MD Anderson Cancer Center, and Harvard Medical School) are among the most productive institutes and started using Big Data in HIV/AIDS research early, (4) Big Data research was not active in public health disciplines until 2015, (5) research topics such as genomics, HIV comorbidities, population-based studies, Electronic Health Records (EHR), social media, precision medicine, and methodologies such as machine learning, Deep Learning, radiomics, and data mining emerge quickly in recent years. We identified a rapid growth in the cross-disciplinary research of HIV/AIDS and Big Data over the past two decades. Our findings demonstrated patterns and trends of prevailing research topics and Big Data applications in HIV/AIDS research and suggested a number of fast-evolving areas of Big Data Science in HIV/AIDS research including secondary analysis of EHR, machine learning, Deep Learning, predictive analysis, and NLP.",
      "authors": "Liang Chen; Qiao Shan; Olatosi Bankole; Lyu Tianchu; Li Xiaoming",
      "year": "2021",
      "month": "Oct",
      "journal": "International journal of medical informatics",
      "source": "pubmed"
    },
    {
      "pmid": "34462589",
      "doi": "10.1038/s41587-021-01001-7",
      "title": "Mapping single-cell data to reference atlases by transfer learning.",
      "abstract": "Large single-cell atlases are now routinely generated to serve as references for analysis of smaller-scale studies. Yet learning from reference data is complicated by batch effects between datasets, limited availability of computational resources and sharing restrictions on raw data. Here we introduce a deep learning strategy for mapping query datasets on top of a reference called single-cell architectural surgery (scArches). scArches uses transfer learning and parameter optimization to enable efficient, decentralized, iterative reference building and contextualization of new datasets with existing references without sharing raw data. Using examples from mouse brain, pancreas, immune and whole-organism atlases, we show that scArches preserves biological state information while removing batch effects, despite using four orders of magnitude fewer parameters than de novo integration. scArches generalizes to multimodal reference mapping, allowing imputation of missing modalities. Finally, scArches retains coronavirus disease 2019 (COVID-19) disease variation when mapping to a healthy reference, enabling the discovery of disease-specific cell states. scArches will facilitate collaborative projects by enabling iterative construction, updating, sharing and efficient use of reference atlases.",
      "authors": "Lotfollahi Mohammad; Naghipourfar Mohsen; Luecken Malte D; Khajavi Matin; Büttner Maren; Wagenstetter Marco; Avsec Žiga; Gayoso Adam; Yosef Nir; Interlandi Marta; Rybakov Sergei; Misharin Alexander V; Theis Fabian J",
      "year": "2022",
      "month": "Jan",
      "journal": "Nature biotechnology",
      "source": "pubmed"
    },
    {
      "pmid": "34429852",
      "doi": "10.1016/j.csbj.2021.07.021",
      "title": "A primer on machine learning techniques for genomic applications.",
      "abstract": "High throughput sequencing technologies have enabled the study of complex biological aspects at single nucleotide resolution, opening the big data era. The analysis of large volumes of heterogeneous \"omic\" data, however, requires novel and efficient computational algorithms based on the paradigm of Artificial Intelligence. In the present review, we introduce and describe the most common machine learning methodologies, and lately deep learning, applied to a variety of genomics tasks, trying to emphasize capabilities, strengths and limitations through a simple and intuitive language. We highlight the power of the machine learning approach in handling big data by means of a real life example, and underline how described methods could be relevant in all cases in which large amounts of multimodal genomic data are available.",
      "authors": "Monaco Alfonso; Pantaleo Ester; Amoroso Nicola; Lacalamita Antonio; Lo Giudice Claudio; Fonzino Adriano; Fosso Bruno; Picardi Ernesto; Tangaro Sabina; Pesole Graziano; Bellotti Roberto",
      "year": "2021",
      "month": "",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "34418954",
      "doi": "10.1186/s12859-021-04325-y",
      "title": "AttentionDDI: Siamese attention-based deep learning method for drug-drug interaction predictions.",
      "abstract": "Drug-drug interactions (DDIs) refer to processes triggered by the administration of two or more drugs leading to side effects beyond those observed when drugs are administered by themselves. Due to the massive number of possible drug pairs, it is nearly impossible to experimentally test all combinations and discover previously unobserved side effects. Therefore, machine learning based methods are being used to address this issue. We propose a Siamese self-attention multi-modal neural network for DDI prediction that integrates multiple drug similarity measures that have been derived from a comparison of drug characteristics including drug targets, pathways and gene expression profiles. Our proposed DDI prediction model provides multiple advantages: (1) It is trained end-to-end, overcoming limitations of models composed of multiple separate steps, (2) it offers model explainability via an Attention mechanism for identifying salient input features and (3) it achieves similar or better prediction performance (AUPR scores ranging from 0.77 to 0.92) compared to state-of-the-art DDI models when tested on various benchmark datasets. Novel DDI predictions are further validated using independent data resources. We find that a Siamese multi-modal neural network is able to accurately predict DDIs and that an Attention mechanism, typically used in the Natural Language Processing domain, can be beneficially applied to aid in DDI model explainability.",
      "authors": "Schwarz Kyriakos; Allam Ahmed; Perez Gonzalez Nicolas Andres; Krauthammer Michael",
      "year": "2021",
      "month": "Aug",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "34406415",
      "doi": "10.1093/gigascience/giab054",
      "title": "RNAProt: an efficient and feature-rich RNA binding protein binding site predictor.",
      "abstract": "Cross-linking and immunoprecipitation followed by next-generation sequencing (CLIP-seq) is the state-of-the-art technique used to experimentally determine transcriptome-wide binding sites of RNA-binding proteins (RBPs). However, it relies on gene expression, which can be highly variable between conditions and thus cannot provide a complete picture of the RBP binding landscape. This creates a demand for computational methods to predict missing binding sites. Although there exist various methods using traditional machine learning and lately also deep learning, we encountered several problems: many of these are not well documented or maintained, making them difficult to install and use, or are not even available. In addition, there can be efficiency issues, as well as little flexibility regarding options or supported features. Here, we present RNAProt, an efficient and feature-rich computational RBP binding site prediction framework based on recurrent neural networks. We compare RNAProt with 1 traditional machine learning approach and 2 deep-learning methods, demonstrating its state-of-the-art predictive performance and better run time efficiency. We further show that its implemented visualizations capture known binding preferences and thus can help to understand what is learned. Since RNAProt supports various additional features (including user-defined features, which no other tool offers), we also present their influence on benchmark set performance. Finally, we show the benefits of incorporating additional features, specifically structure information, when learning the binding sites of an hairpin loop binding RBP. RNAProt provides a complete framework for RBP binding site predictions, from data set generation over model training to the evaluation of binding preferences and prediction. It offers state-of-the-art predictive performance, as well as superior run time efficiency, while at the same time supporting more features and input types than any other tool available so far. RNAProt is easy to install and use, comes with comprehensive documentation, and is accompanied by informative statistics and visualizations. All this makes RNAProt a valuable tool to apply in future RBP binding site research.",
      "authors": "Uhl Michael; Tran Van Dinh; Heyl Florian; Backofen Rolf",
      "year": "2021",
      "month": "Aug",
      "journal": "GigaScience",
      "source": "pubmed"
    },
    {
      "pmid": "34393747",
      "doi": "10.3389/fninf.2021.691918",
      "title": "Supervised Learning With Perceptual Similarity for Multimodal Gene Expression Registration of a Mouse Brain Atlas.",
      "abstract": "The acquisition of high quality maps of gene expression in the rodent brain is of fundamental importance to the neuroscience community. The generation of such datasets relies on registering individual gene expression images to a reference volume, a task encumbered by the diversity of staining techniques employed, and by deformations and artifacts in the soft tissue. Recently, deep learning models have garnered particular interest as a viable alternative to traditional intensity-based algorithms for image registration. In this work, we propose a supervised learning model for general multimodal 2D registration tasks, trained with a perceptual similarity loss on a dataset labeled by a human expert and augmented by synthetic local deformations. We demonstrate the results of our approach on the Allen Mouse Brain Atlas (AMBA), comprising whole brain Nissl and gene expression stains. We show that our framework and design of the loss function result in accurate and smooth predictions. Our model is able to generalize to unseen gene expressions and coronal sections, outperforming traditional intensity-based approaches in aligning complex brain structures.",
      "authors": "Krepl Jan; Casalegno Francesco; Delattre Emilie; Erö Csaba; Lu Huanxiang; Keller Daniel; Rodarie Dimitri; Markram Henry; Schürmann Felix",
      "year": "2021",
      "month": "",
      "journal": "Frontiers in neuroinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "34238220",
      "doi": "10.1186/s12859-021-04278-2",
      "title": "Single-cell classification using graph convolutional networks.",
      "abstract": "Analyzing single-cell RNA sequencing (scRNAseq) data plays an important role in understanding the intrinsic and extrinsic cellular processes in biological and biomedical research. One significant effort in this area is the identification of cell types. With the availability of a huge amount of single cell sequencing data and discovering more and more cell types, classifying cells into known cell types has become a priority nowadays. Several methods have been introduced to classify cells utilizing gene expression data. However, incorporating biological gene interaction networks has been proved valuable in cell classification procedures. In this study, we propose a multimodal end-to-end deep learning model, named sigGCN, for cell classification that combines a graph convolutional network (GCN) and a neural network to exploit gene interaction networks. We used standard classification metrics to evaluate the performance of the proposed method on the within-dataset classification and the cross-dataset classification. We compared the performance of the proposed method with those of the existing cell classification tools and traditional machine learning classification methods. Results indicate that the proposed method outperforms other commonly used methods in terms of classification accuracy and F1 scores. This study shows that the integration of prior knowledge about gene interactions with gene expressions using GCN methodologies can extract effective features improving the performance of cell classification.",
      "authors": "Wang Tianyu; Bai Jun; Nabavi Sheida",
      "year": "2021",
      "month": "Jul",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "34209762",
      "doi": "10.3390/cells10071627",
      "title": "Improving the Utility of Polygenic Risk Scores as a Biomarker for Alzheimer's Disease.",
      "abstract": "The treatment of complex and multifactorial diseases constitutes a big challenge in day-to-day clinical practice. As many parameters influence clinical phenotypes, accurate diagnosis and prompt therapeutic management is often difficult. Significant research and investment focuses on state-of-the-art genomic and metagenomic analyses in the burgeoning field of Precision (or Personalized) Medicine with genome-wide-association-studies (GWAS) helping in this direction by linking patient genotypes at specific polymorphic sites (single-nucleotide polymorphisms, ",
      "authors": "Vlachakis Dimitrios; Papakonstantinou Eleni; Sagar Ram; Bacopoulou Flora; Exarchos Themis; Kourouthanassis Panos; Karyotis Vasileios; Vlamos Panayiotis; Lyketsos Constantine; Avramopoulos Dimitrios; Mahairaki Vasiliki",
      "year": "2021",
      "month": "Jun",
      "journal": "Cells",
      "source": "pubmed"
    },
    {
      "pmid": "34191792",
      "doi": "10.1371/journal.pcbi.1009086",
      "title": "Mixture-of-Experts Variational Autoencoder for clustering and generating from similarity-based representations on single cell data.",
      "abstract": "Clustering high-dimensional data, such as images or biological measurements, is a long-standing problem and has been studied extensively. Recently, Deep Clustering has gained popularity due to its flexibility in fitting the specific peculiarities of complex data. Here we introduce the Mixture-of-Experts Similarity Variational Autoencoder (MoE-Sim-VAE), a novel generative clustering model. The model can learn multi-modal distributions of high-dimensional data and use these to generate realistic data with high efficacy and efficiency. MoE-Sim-VAE is based on a Variational Autoencoder (VAE), where the decoder consists of a Mixture-of-Experts (MoE) architecture. This specific architecture allows for various modes of the data to be automatically learned by means of the experts. Additionally, we encourage the lower dimensional latent representation of our model to follow a Gaussian mixture distribution and to accurately represent the similarities between the data points. We assess the performance of our model on the MNIST benchmark data set and challenging real-world tasks of clustering mouse organs from single-cell RNA-sequencing measurements and defining cell subpopulations from mass cytometry (CyTOF) measurements on hundreds of different datasets. MoE-Sim-VAE exhibits superior clustering performance on all these tasks in comparison to the baselines as well as competitor methods.",
      "authors": "Kopf Andreas; Fortuin Vincent; Somnath Vignesh Ram; Claassen Manfred",
      "year": "2021",
      "month": "Jun",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    },
    {
      "pmid": "34191197",
      "doi": "10.1186/s41824-020-00094-8",
      "title": "Artificial intelligence and hybrid imaging: the best match for personalized medicine in oncology.",
      "abstract": "Artificial intelligence (AI) refers to a field of computer science aimed to perform tasks typically requiring human intelligence. Currently, AI is recognized in the broader technology radar within the five key technologies which emerge for their wide-ranging applications and impact in communities, companies, business, and value chain framework alike. However, AI in medical imaging is at an early phase of development, and there are still hurdles to take related to reliability, user confidence, and adoption. The present narrative review aimed to provide an overview on AI-based approaches (distributed learning, statistical learning, computer-aided diagnosis and detection systems, fully automated image analysis tool, natural language processing) in oncological hybrid medical imaging with respect to clinical tasks (detection, contouring and segmentation, prediction of histology and tumor stage, prediction of mutational status and molecular therapies targets, prediction of treatment response, and outcome). Particularly, AI-based approaches have been briefly described according to their purpose and, finally lung cancer-being one of the most extensively malignancy studied by hybrid medical imaging-has been used as illustrative scenario. Finally, we discussed clinical challenges and open issues including ethics, validation strategies, effective data-sharing methods, regulatory hurdles, educational resources, and strategy to facilitate the interaction among different stakeholders. Some of the major changes in medical imaging will come from the application of AI to workflow and protocols, eventually resulting in improved patient management and quality of life. Overall, several time-consuming tasks could be automatized. Machine learning algorithms and neural networks will permit sophisticated analysis resulting not only in major improvements in disease characterization through imaging, but also in the integration of multiple-omics data (i.e., derived from pathology, genomic, proteomics, and demographics) for multi-dimensional disease featuring. Nevertheless, to accelerate the transition of the theory to practice a sustainable development plan considering the multi-dimensional interactions between professionals, technology, industry, markets, policy, culture, and civil society directed by a mindset which will allow talents to thrive is necessary.",
      "authors": "Sollini Martina; Bartoli Francesco; Marciano Andrea; Zanca Roberta; Slart Riemer H J A; Erba Paola A",
      "year": "2020",
      "month": "Dec",
      "journal": "European journal of hybrid imaging",
      "source": "pubmed"
    },
    {
      "pmid": "34179690",
      "doi": "10.1038/s42256-021-00333-y",
      "title": "Simultaneous deep generative modeling and clustering of single cell genomic data.",
      "abstract": "Recent advances in single-cell technologies, including single-cell ATAC-seq (scATAC-seq), have enabled large-scale profiling of the chromatin accessibility landscape at the single cell level. However, the characteristics of scATAC-seq data, including high sparsity and high dimensionality, have greatly complicated the computational analysis. Here, we proposed scDEC, a computational tool for single cell ATAC-seq analysis with deep generative neural networks. scDEC is built on a pair of generative adversarial networks (GANs), and is capable of learning the latent representation and inferring the cell labels, simultaneously. In a series of experiments, scDEC demonstrates superior performance over other tools in scATAC-seq analysis across multiple datasets and experimental settings. In downstream applications, we demonstrated that the generative power of scDEC helps to infer the trajectory and intermediate state of cells during differentiation and the latent features learned by scDEC can potentially reveal both biological cell types and within-cell-type variations. We also showed that it is possible to extend scDEC for the integrative analysis of multi-modal single cell data.",
      "authors": "Liu Qiao; Chen Shengquan; Jiang Rui; Wong Wing Hung",
      "year": "2021",
      "month": "Jun",
      "journal": "Nature machine intelligence",
      "source": "pubmed"
    },
    {
      "pmid": "34083792",
      "doi": "10.1038/s41587-021-00927-2",
      "title": "Scalable, multimodal profiling of chromatin accessibility, gene expression and protein levels in single cells.",
      "abstract": "Recent technological advances have enabled massively parallel chromatin profiling with scATAC-seq (single-cell assay for transposase accessible chromatin by sequencing). Here we present ATAC with select antigen profiling by sequencing (ASAP-seq), a tool to simultaneously profile accessible chromatin and protein levels. Our approach pairs sparse scATAC-seq data with robust detection of hundreds of cell surface and intracellular protein markers and optional capture of mitochondrial DNA for clonal tracking, capturing three distinct modalities in single cells. ASAP-seq uses a bridging approach that repurposes antibody:oligonucleotide conjugates designed for existing technologies that pair protein measurements with single-cell RNA sequencing. Together with DOGMA-seq, an adaptation of CITE-seq (cellular indexing of transcriptomes and epitopes by sequencing) for measuring gene activity across the central dogma of gene regulation, we demonstrate the utility of systematic multi-omic profiling by revealing coordinated and distinct changes in chromatin, RNA and surface proteins during native hematopoietic differentiation and peripheral blood mononuclear cell stimulation and as a combinatorial decoder and reporter of multiplexed perturbations in primary T cells.",
      "authors": "Mimitou Eleni P; Lareau Caleb A; Chen Kelvin Y; Zorzetto-Fernandes Andre L; Hao Yuhan; Takeshima Yusuke; Luo Wendy; Huang Tse-Shun; Yeung Bertrand Z; Papalexi Efthymia; Thakore Pratiksha I; Kibayashi Tatsuya; Wing James Badger; Hata Mayu; Satija Rahul; Nazor Kristopher L; Sakaguchi Shimon; Ludwig Leif S; Sankaran Vijay G; Regev Aviv; Smibert Peter",
      "year": "2021",
      "month": "Oct",
      "journal": "Nature biotechnology",
      "source": "pubmed"
    },
    {
      "pmid": "34077420",
      "doi": "10.1371/journal.pcbi.1009064",
      "title": "coupleCoC+: An information-theoretic co-clustering-based transfer learning framework for the integrative analysis of single-cell genomic data.",
      "abstract": "Technological advances have enabled us to profile multiple molecular layers at unprecedented single-cell resolution and the available datasets from multiple samples or domains are growing. These datasets, including scRNA-seq data, scATAC-seq data and sc-methylation data, usually have different powers in identifying the unknown cell types through clustering. So, methods that integrate multiple datasets can potentially lead to a better clustering performance. Here we propose coupleCoC+ for the integrative analysis of single-cell genomic data. coupleCoC+ is a transfer learning method based on the information-theoretic co-clustering framework. In coupleCoC+, we utilize the information in one dataset, the source data, to facilitate the analysis of another dataset, the target data. coupleCoC+ uses the linked features in the two datasets for effective knowledge transfer, and it also uses the information of the features in the target data that are unlinked with the source data. In addition, coupleCoC+ matches similar cell types across the source data and the target data. By applying coupleCoC+ to the integrative clustering of mouse cortex scATAC-seq data and scRNA-seq data, mouse and human scRNA-seq data, mouse cortex sc-methylation and scRNA-seq data, and human blood dendritic cells scRNA-seq data from two batches, we demonstrate that coupleCoC+ improves the overall clustering performance and matches the cell subpopulations across multimodal single-cell genomic datasets. coupleCoC+ has fast convergence and it is computationally efficient. The software is available at https://github.com/cuhklinlab/coupleCoC_plus.",
      "authors": "Zeng Pengcheng; Lin Zhixiang",
      "year": "2021",
      "month": "Jun",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    },
    {
      "pmid": "33981311",
      "doi": "10.3389/fimmu.2021.664514",
      "title": "Contribution of T Cell Receptor Alpha and Beta CDR3, MHC Typing, V and J Genes to Peptide Binding Prediction.",
      "abstract": "Predicting the binding specificity of T Cell Receptors (TCR) to MHC-peptide complexes (pMHCs) is essential for the development of repertoire-based biomarkers. This affinity may be affected by different components of the TCR, the peptide, and the MHC allele. Historically, the main element used in TCR-peptide binding prediction was the Complementarity Determining Region 3 (CDR3) of the beta chain. However, recently the contribution of other components, such as the alpha chain and the other V gene CDRs has been suggested. We use a highly accurate novel deep learning-based TCR-peptide binding predictor to assess the contribution of each component to the binding. We have previously developed ERGO-I (pEptide tcR matchinG predictiOn), a sequence-based T-cell receptor (TCR)-peptide binding predictor that employs natural language processing (NLP) -based methods. We improved it to create ERGO-II by adding the CDR3 alpha segment, the MHC typing, V and J genes, and T cell type (CD4+ or CD8+) as to the predictor. We then estimate the contribution of each component to the prediction. ERGO-II provides for the first time high accuracy prediction of TCR-peptide for previously unseen peptides. For most tested peptides and all measures of binding prediction accuracy, the main contribution was from the beta chain CDR3 sequence, followed by the beta chain V and J and the alpha chain, in that order. The MHC allele was the least contributing component. ERGO-II is accessible as a webserver at http://tcr2.cs.biu.ac.il/ and as a standalone code at https://github.com/IdoSpringer/ERGO-II.",
      "authors": "Springer Ido; Tickotsky Nili; Louzoun Yoram",
      "year": "2021",
      "month": "",
      "journal": "Frontiers in immunology",
      "source": "pubmed"
    },
    {
      "pmid": "33917161",
      "doi": "10.3390/jpm11040280",
      "title": "Multi-Layer Picture of Neurodegenerative Diseases: Lessons from the Use of Big Data through Artificial Intelligence.",
      "abstract": "In the big data era, artificial intelligence techniques have been applied to tackle traditional issues in the study of neurodegenerative diseases. Despite the progress made in understanding the complex (epi)genetics signatures underlying neurodegenerative disorders, performing early diagnosis and developing drug repurposing strategies remain serious challenges for such conditions. In this context, the integration of multi-omics, neuroimaging, and electronic health records data can be exploited using deep learning methods to provide the most accurate representation of patients possible. Deep learning allows researchers to find multi-modal biomarkers to develop more effective and personalized treatments, early diagnosis tools, as well as useful information for drug discovering and repurposing in neurodegenerative pathologies. In this review, we will describe how relevant studies have been able to demonstrate the potential of deep learning to enhance the knowledge of neurodegenerative disorders such as Alzheimer's and Parkinson's diseases through the integration of all sources of biomedical data.",
      "authors": "Termine Andrea; Fabrizio Carlo; Strafella Claudia; Caputo Valerio; Petrosini Laura; Caltagirone Carlo; Giardina Emiliano; Cascella Raffaella",
      "year": "2021",
      "month": "Apr",
      "journal": "Journal of personalized medicine",
      "source": "pubmed"
    },
    {
      "pmid": "33767197",
      "doi": "10.1038/s41467-021-22197-x",
      "title": "scGNN is a novel graph neural network framework for single-cell RNA-Seq analyses.",
      "abstract": "Single-cell RNA-sequencing (scRNA-Seq) is widely used to reveal the heterogeneity and dynamics of tissues, organisms, and complex diseases, but its analyses still suffer from multiple grand challenges, including the sequencing sparsity and complex differential patterns in gene expression. We introduce the scGNN (single-cell graph neural network) to provide a hypothesis-free deep learning framework for scRNA-Seq analyses. This framework formulates and aggregates cell-cell relationships with graph neural networks and models heterogeneous gene expression patterns using a left-truncated mixture Gaussian model. scGNN integrates three iterative multi-modal autoencoders and outperforms existing tools for gene imputation and cell clustering on four benchmark scRNA-Seq datasets. In an Alzheimer's disease study with 13,214 single nuclei from postmortem brain tissues, scGNN successfully illustrated disease-related neural development and the differential mechanism. scGNN provides an effective representation of gene expression and cell-cell relationships. It is also a powerful framework that can be applied to general scRNA-Seq analyses.",
      "authors": "Wang Juexin; Ma Anjun; Chang Yuzhou; Gong Jianting; Jiang Yuexu; Qi Ren; Wang Cankun; Fu Hongjun; Ma Qin; Xu Dong",
      "year": "2021",
      "month": "Mar",
      "journal": "Nature communications",
      "source": "pubmed"
    },
    {
      "pmid": "33691024",
      "doi": "",
      "title": "Cross-modal representation alignment of molecular structure and perturbation-induced transcriptional profiles.",
      "abstract": "Modeling the relationship between chemical structure and molecular activity is a key goal in drug development. Many benchmark tasks have been proposed for molecular property prediction, but these tasks are generally aimed at specific, isolated biomedical properties. In this work, we propose a new cross-modal small molecule retrieval task, designed to force a model to learn to associate the structure of a small molecule with the transcriptional change it induces. We develop this task formally as multi-view alignment problem, and present a coordinated deep learning approach that jointly optimizes representations of both chemical structure and perturbational gene expression profiles. We benchmark our results against oracle models and principled baselines, and find that cell line variability markedly influences performance in this domain. Our work establishes the feasibility of this new task, elucidates the limitations of current data and systems, and may serve to catalyze future research in small molecule representation learning.",
      "authors": "Finlayson Samuel G; McDermott Matthew B A; Pickering Alex V; Lipnick Scott L; Kohane Isaac S",
      "year": "2021",
      "month": "",
      "journal": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
      "source": "pubmed"
    },
    {
      "pmid": "33623109",
      "doi": "10.1038/s41422-021-00476-y",
      "title": "Predicting dynamic cellular protein-RNA interactions by deep learning using in vivo RNA structures.",
      "abstract": "Interactions with RNA-binding proteins (RBPs) are integral to RNA function and cellular regulation, and dynamically reflect specific cellular conditions. However, presently available tools for predicting RBP-RNA interactions employ RNA sequence and/or predicted RNA structures, and therefore do not capture their condition-dependent nature. Here, after profiling transcriptome-wide in vivo RNA secondary structures in seven cell types, we developed PrismNet, a deep learning tool that integrates experimental in vivo RNA structure data and RBP binding data for matched cells to accurately predict dynamic RBP binding in various cellular conditions. PrismNet results for 168 RBPs support its utility for both understanding CLIP-seq results and largely extending such interaction data to accurately analyze additional cell types. Further, PrismNet employs an \"attention\" strategy to computationally identify exact RBP-binding nucleotides, and we discovered enrichment among dynamic RBP-binding sites for structure-changing variants (riboSNitches), which can link genetic diseases with dysregulated RBP bindings. Our rich profiling data and deep learning-based prediction tool provide access to a previously inaccessible layer of cell-type-specific RBP-RNA interactions, with clear utility for understanding and treating human diseases.",
      "authors": "Sun Lei; Xu Kui; Huang Wenze; Yang Yucheng T; Li Pan; Tang Lei; Xiong Tuanlin; Zhang Qiangfeng Cliff",
      "year": "2021",
      "month": "May",
      "journal": "Cell research",
      "source": "pubmed"
    },
    {
      "pmid": "33594323",
      "doi": "",
      "title": "A multi-omics-based serial deep learning approach to predict clinical outcomes of single-agent anti-PD-1/PD-L1 immunotherapy in advanced stage non-small-cell lung cancer.",
      "abstract": "Only 20% NSCLC patients benefit from immunotherapy with a durable response. Current biomarkers are limited by the availability of samples and do not accurately predict who will benefit from immunotherapy. To develop a unified deep learning model to integrate multimodal serial information from CT with laboratory and baseline clinical information. We retrospectively analyzed 1633 CT scans and 3414 blood samples from 200 advanced stage NSCLC patients who received single anti-PD-1/PD-L1 agent between April 2016 and December 2019. Multidimensional information, including serial radiomics, laboratory data and baseline clinical data, was used to develop and validate deep learning models to identify immunotherapy responders and nonresponders. A Simple Temporal Attention (SimTA) module was developed to process asynchronous time-series imaging and laboratory data. Using cross-validation, the 90-day deep learning-based predicting model showed a good performance in distinguishing responders from nonresponders, with an area under the curve (AUC) of 0.80 (95% CI: 0.74-0.86). Before immunotherapy, we stratified the patients into high- and low-risk nonresponders using the model. The low-risk group had significantly longer progression-free survival (PFS) (8.4 months, 95% CI: 5.49-11.31 ",
      "authors": "Yang Yi; Yang Jiancheng; Shen Lan; Chen Jiajun; Xia Liliang; Ni Bingbing; Ge Liang; Wang Ying; Lu Shun",
      "year": "2021",
      "month": "",
      "journal": "American journal of translational research",
      "source": "pubmed"
    },
    {
      "pmid": "33588916",
      "doi": "10.1186/s13040-021-00237-y",
      "title": "DASSI: differential architecture search for splice identification from DNA sequences.",
      "abstract": "The data explosion caused by unprecedented advancements in the field of genomics is constantly challenging the conventional methods used in the interpretation of the human genome. The demand for robust algorithms over the recent years has brought huge success in the field of Deep Learning (DL) in solving many difficult tasks in image, speech and natural language processing by automating the manual process of architecture design. This has been fueled through the development of new DL architectures. Yet genomics possesses unique challenges that requires customization and development of new DL models. We proposed a new model, DASSI, by adapting a differential architecture search method and applying it to the Splice Site (SS) recognition task on DNA sequences to discover new high-performance convolutional architectures in an automated manner. We evaluated the discovered model against state-of-the-art tools to classify true and false SS in Homo sapiens (Human), Arabidopsis thaliana (Plant), Caenorhabditis elegans (Worm) and Drosophila melanogaster (Fly). Our experimental evaluation demonstrated that the discovered architecture outperformed baseline models and fixed architectures and showed competitive results against state-of-the-art models used in classification of splice sites. The proposed model - DASSI has a compact architecture and showed very good results on a transfer learning task. The benchmarking experiments of execution time and precision on architecture search and evaluation process showed better performance on recently available GPUs making it feasible to adopt architecture search based methods on large datasets. We proposed the use of differential architecture search method (DASSI) to perform SS classification on raw DNA sequences, and discovered new neural network models with low number of tunable parameters and competitive performance compared with manually engineered architectures. We have extensively benchmarked DASSI model with other state-of-the-art models and assessed its computational efficiency. The results have shown a high potential of using automated architecture search mechanism for solving various problems in the field of genomics.",
      "authors": "Moosa Shabir; Amira Prof Abbes; Boughorbel Dr Sabri",
      "year": "2021",
      "month": "Feb",
      "journal": "BioData mining",
      "source": "pubmed"
    },
    {
      "pmid": "33556002",
      "doi": "10.1109/TMI.2021.3057635",
      "title": "Interpretable Multimodal Fusion Networks Reveal Mechanisms of Brain Cognition.",
      "abstract": "The combination of multimodal imaging and genomics provides a more comprehensive way for the study of mental illnesses and brain functions. Deep network-based data fusion models have been developed to capture their complex associations, resulting in improved diagnosis of diseases. However, deep learning models are often difficult to interpret, bringing about challenges for uncovering biological mechanisms using these models. In this work, we develop an interpretable multimodal fusion model to perform automated diagnosis and result interpretation simultaneously. We name it Grad-CAM guided convolutional collaborative learning (gCAM-CCL), which is achieved by combining intermediate feature maps with gradient-based weights. The gCAM-CCL model can generate interpretable activation maps to quantify pixel-level contributions of the input features. Moreover, the estimated activation maps are class-specific, which can therefore facilitate the identification of biomarkers underlying different groups. We validate the gCAM-CCL model on a brain imaging-genetic study, and demonstrate its applications to both the classification of cognitive function groups and the discovery of underlying biological mechanisms. Specifically, our analysis results suggest that during task-fMRI scans, several object recognition related regions of interests (ROIs) are activated followed by several downstream encoding ROIs. In addition, the high cognitive group may have stronger neurotransmission signaling while the low cognitive group may have problems in brain/neuron development due to genetic variations.",
      "authors": "Hu Wenxing; Meng Xianghe; Bai Yuntong; Zhang Aiying; Qu Gang; Cai Biao; Zhang Gemeng; Wilson Tony W; Stephen Julia M; Calhoun Vince D; Wang Yu-Ping",
      "year": "2021",
      "month": "May",
      "journal": "IEEE transactions on medical imaging",
      "source": "pubmed"
    },
    {
      "pmid": "33420191",
      "doi": "10.1038/s41598-020-80430-x",
      "title": "DNA sequences performs as natural language processing by exploiting deep learning algorithm for the identification of N4-methylcytosine.",
      "abstract": "N4-methylcytosine is a biochemical alteration of DNA that affects the genetic operations without modifying the DNA nucleotides such as gene expression, genomic imprinting, chromosome stability, and the development of the cell. In the proposed work, a computational model, 4mCNLP-Deep, used the word embedding approach as a vector formulation by exploiting deep learning based CNN algorithm to predict 4mC and non-4mC sites on the C.elegans genome dataset. Diversity of ranges employed for the experimental such as corpus k-mer and k-fold cross-validation to obtain the prevailing capabilities. The 4mCNLP-Deep outperform from the state-of-the-art predictor by achieving the results in five evaluation metrics by following; Accuracy (ACC) as 0.9354, Mathew's correlation coefficient (MCC) as 0.8608, Specificity (Sp) as 0.89.96, Sensitivity (Sn) as 0.9563, and Area under curve (AUC) as 0.9731 by using 3-mer corpus word2vec and 3-fold cross-validation and attained the increment of 1.1%, 0.6%, 0.58%, 0.77%, and 4.89%, respectively. At last, we developed the online webserver http://nsclbio.jbnu.ac.kr/tools/4mCNLP-Deep/ , for the experimental researchers to get the results easily.",
      "authors": "Wahab Abdul; Tayara Hilal; Xuan Zhenyu; Chong Kil To",
      "year": "2021",
      "month": "Jan",
      "journal": "Scientific reports",
      "source": "pubmed"
    },
    {
      "pmid": "33316030",
      "doi": "10.1093/bib/bbaa310",
      "title": "Deep learning for brain disorders: from data processing to disease treatment.",
      "abstract": "In order to reach precision medicine and improve patients' quality of life, machine learning is increasingly used in medicine. Brain disorders are often complex and heterogeneous, and several modalities such as demographic, clinical, imaging, genetics and environmental data have been studied to improve their understanding. Deep learning, a subpart of machine learning, provides complex algorithms that can learn from such various data. It has become state of the art in numerous fields, including computer vision and natural language processing, and is also growingly applied in medicine. In this article, we review the use of deep learning for brain disorders. More specifically, we identify the main applications, the concerned disorders and the types of architectures and data used. Finally, we provide guidelines to bridge the gap between research studies and clinical routine.",
      "authors": "Burgos Ninon; Bottani Simona; Faouzi Johann; Thibeau-Sutre Elina; Colliot Olivier",
      "year": "2021",
      "month": "Mar",
      "journal": "Briefings in bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "33260643",
      "doi": "10.3390/ijms21239070",
      "title": "A Computational Framework Based on Ensemble Deep Neural Networks for Essential Genes Identification.",
      "abstract": "Essential genes contain key information of genomes that could be the key to a comprehensive understanding of life and evolution. Because of their importance, studies of essential genes have been considered a crucial problem in computational biology. Computational methods for identifying essential genes have become increasingly popular to reduce the cost and time-consumption of traditional experiments. A few models have addressed this problem, but performance is still not satisfactory because of high dimensional features and the use of traditional machine learning algorithms. Thus, there is a need to create a novel model to improve the predictive performance of this problem from DNA sequence features. This study took advantage of a natural language processing (NLP) model in learning biological sequences by treating them as natural language words. To learn the NLP features, a supervised learning model was consequentially employed by an ensemble deep neural network. Our proposed method could identify essential genes with sensitivity, specificity, accuracy, Matthews correlation coefficient (MCC), and area under the receiver operating characteristic curve (AUC) values of 60.2%, 84.6%, 76.3%, 0.449, and 0.814, respectively. The overall performance outperformed the single models without ensemble, as well as the state-of-the-art predictors on the same benchmark dataset. This indicated the effectiveness of the proposed method in determining essential genes, in particular, and other sequencing problems, in general.",
      "authors": "Le Nguyen Quoc Khanh; Do Duyen Thi; Hung Truong Nguyen Khanh; Lam Luu Ho Thanh; Huynh Tuan-Tu; Nguyen Ngan Thi Kim",
      "year": "2020",
      "month": "Nov",
      "journal": "International journal of molecular sciences",
      "source": "pubmed"
    },
    {
      "pmid": "33193847",
      "doi": "10.3892/ol.2020.12250",
      "title": "A model for predicting prognosis in patients with esophageal squamous cell carcinoma based on joint representation learning.",
      "abstract": "Esophageal squamous cell carcinoma (ESCC) is one of the deadliest cancer types with a poor prognosis due to the lack of symptoms in the early stages and a delayed diagnosis. The present study aimed to identify the risk factors significantly associated with prognosis and to search for novel effective diagnostic modalities for patients with early-stage ESCC. mRNA and methylation data of patients with ESCC and the corresponding clinical information were downloaded from The Cancer Genome Atlas (TCGA) database, and the representation features were screened using deep learning autoencoder. The univariate Cox regression model was used to select the prognosis-related features from the representation features. K-means clustering was used to cluster the TCGA samples. Support vector machine classifier was constructed based on the top 75 features mostly associated with the risk subgroups obtained from K-means clustering. Two ArrayExpress datasets were used to verify the reliability of the obtained risk subgroups. The differentially expressed genes and methylation genes (DEGs and DMGs) between the risk subgroups were analyzed, and pathway enrichment analysis was performed. A total of 500 representation features were produced. Using K-means clustering, the TCGA samples were clustered into two risk subgroups with significantly different overall survival rates. Joint multimodal representation strategy, which showed a good model fitness (C-index=0.760), outperformed early-fusion autoencoder strategy. The joint representation learning-based classification model had good robustness. A total of 1,107 DEGs and 199 DMGs were screened out between the two risk subgroups. The DEGs were involved in 70 pathways, the majority of which were correlated with metastasis and proliferation of various cancer types, including cytokine-cytokine receptor interaction, cell adhesion molecules PPAR signaling pathway, pathways in cancer, transcriptional misregulation in cancer and ECM-receptor interaction pathways. The two survival subgroups obtained via the joint representation learning-based model had good robustness, and had prognostic significance for patients with ESCC.",
      "authors": "Yu Jun; Wu Xiaoliu; Lv Min; Zhang Yuanying; Zhang Xiaomei; Li Jintian; Zhu Ming; Huang Jianfeng; Zhang Qin",
      "year": "2020",
      "month": "Dec",
      "journal": "Oncology letters",
      "source": "pubmed"
    },
    {
      "pmid": "33091314",
      "doi": "10.1139/gen-2020-0131",
      "title": "Machine learning for precision medicine.",
      "abstract": "Precision medicine is an emerging approach to clinical research and patient care that focuses on understanding and treating disease by integrating multi-modal or multi-omics data from an individual to make patient-tailored decisions. With the large and complex datasets generated using precision medicine diagnostic approaches, novel techniques to process and understand these complex data were needed. At the same time, computer science has progressed rapidly to develop techniques that enable the storage, processing, and analysis of these complex datasets, a feat that traditional statistics and early computing technologies could not accomplish. Machine learning, a branch of artificial intelligence, is a computer science methodology that aims to identify complex patterns in data that can be used to make predictions or classifications on new unseen data or for advanced exploratory data analysis. Machine learning analysis of precision medicine's multi-modal data allows for broad analysis of large datasets and ultimately a greater understanding of human health and disease. This review focuses on machine learning utilization for precision medicine's \"big data\", in the context of genetics, genomics, and beyond.",
      "authors": "MacEachern Sarah J; Forkert Nils D",
      "year": "2021",
      "month": "Apr",
      "journal": "Genome",
      "source": "pubmed"
    },
    {
      "pmid": "32881682",
      "doi": "10.1109/TMI.2020.3021387",
      "title": "Pathomic Fusion: An Integrated Framework for Fusing Histopathology and Genomic Features for Cancer Diagnosis and Prognosis.",
      "abstract": "Cancer diagnosis, prognosis, mymargin and therapeutic response predictions are based on morphological information from histology slides and molecular profiles from genomic data. However, most deep learning-based objective outcome prediction and grading paradigms are based on histology or genomics alone and do not make use of the complementary information in an intuitive manner. In this work, we propose Pathomic Fusion, an interpretable strategy for end-to-end multimodal fusion of histology image and genomic (mutations, CNV, RNA-Seq) features for survival outcome prediction. Our approach models pairwise feature interactions across modalities by taking the Kronecker product of unimodal feature representations, and controls the expressiveness of each representation via a gating-based attention mechanism. Following supervised learning, we are able to interpret and saliently localize features across each modality, and understand how feature importance shifts when conditioning on multimodal input. We validate our approach using glioma and clear cell renal cell carcinoma datasets from the Cancer Genome Atlas (TCGA), which contains paired whole-slide image, genotype, and transcriptome data with ground truth survival and histologic grade labels. In a 15-fold cross-validation, our results demonstrate that the proposed multimodal fusion paradigm improves prognostic determinations from ground truth grading and molecular subtyping, as well as unimodal deep networks trained on histology and genomic data alone. The proposed method establishes insight and theory on how to train deep networks on multimodal biomedical data in an intuitive manner, which will be useful for other problems in medicine that seek to combine heterogeneous data streams for understanding diseases and predicting response and resistance to treatment. Code and trained models are made available at: https://github.com/mahmoodlab/PathomicFusion.",
      "authors": "Chen Richard J; Lu Ming Y; Wang Jingwen; Williamson Drew F K; Rodig Scott J; Lindeman Neal I; Mahmood Faisal",
      "year": "2022",
      "month": "Apr",
      "journal": "IEEE transactions on medical imaging",
      "source": "pubmed"
    },
    {
      "pmid": "32779888",
      "doi": "10.15252/msb.20199416",
      "title": "Predicting antigen specificity of single T cells based on TCR CDR3 regions.",
      "abstract": "It has recently become possible to simultaneously assay T-cell specificity with respect to large sets of antigens and the T-cell receptor sequence in high-throughput single-cell experiments. Leveraging this new type of data, we propose and benchmark a collection of deep learning architectures to model T-cell specificity in single cells. In agreement with previous results, we found that models that treat antigens as categorical outcome variables outperform those that model the TCR and antigen sequence jointly. Moreover, we show that variability in single-cell immune repertoire screens can be mitigated by modeling cell-specific covariates. Lastly, we demonstrate that the number of bound pMHC complexes can be predicted in a continuous fashion providing a gateway to disentangle cell-to-dextramer binding strength and receptor-to-pMHC affinity. We provide these models in the Python package TcellMatch to allow imputation of antigen specificities in single-cell RNA-seq studies on T cells without the need for MHC staining.",
      "authors": "Fischer David S; Wu Yihan; Schubert Benjamin; Theis Fabian J",
      "year": "2020",
      "month": "Aug",
      "journal": "Molecular systems biology",
      "source": "pubmed"
    },
    {
      "pmid": "32637044",
      "doi": "10.1016/j.csbj.2020.06.017",
      "title": "Deep learning models in genomics; are we there yet?",
      "abstract": "With the evolution of biotechnology and the introduction of the high throughput sequencing, researchers have the ability to produce and analyze vast amounts of genomics data. Since genomics produce big data, most of the bioinformatics algorithms are based on machine learning methodologies, and lately deep learning, to identify patterns, make predictions and model the progression or treatment of a disease. Advances in deep learning created an unprecedented momentum in biomedical informatics and have given rise to new bioinformatics and computational biology research areas. It is evident that deep learning models can provide higher accuracies in specific tasks of genomics than the state of the art methodologies. Given the growing trend on the application of deep learning architectures in genomics research, in this mini review we outline the most prominent models, we highlight possible pitfalls and discuss future directions. We foresee deep learning accelerating changes in the area of genomics, especially for multi-scale and multimodal data analysis for precision medicine.",
      "authors": "Koumakis Lefteris",
      "year": "2020",
      "month": "",
      "journal": "Computational and structural biotechnology journal",
      "source": "pubmed"
    },
    {
      "pmid": "32615586",
      "doi": "10.1093/ajh/hpaa102",
      "title": "Artificial Intelligence and Hypertension: Recent Advances and Future Outlook.",
      "abstract": "Prevention and treatment of hypertension (HTN) are a challenging public health problem. Recent evidence suggests that artificial intelligence (AI) has potential to be a promising tool for reducing the global burden of HTN, and furthering precision medicine related to cardiovascular (CV) diseases including HTN. Since AI can stimulate human thought processes and learning with complex algorithms and advanced computational power, AI can be applied to multimodal and big data, including genetics, epigenetics, proteomics, metabolomics, CV imaging, socioeconomic, behavioral, and environmental factors. AI demonstrates the ability to identify risk factors and phenotypes of HTN, predict the risk of incident HTN, diagnose HTN, estimate blood pressure (BP), develop novel cuffless methods for BP measurement, and comprehensively identify factors associated with treatment adherence and success. Moreover, AI has also been used to analyze data from major randomized controlled trials exploring different BP targets to uncover previously undescribed factors associated with CV outcomes. Therefore, AI-integrated HTN care has the potential to transform clinical practice by incorporating personalized prevention and treatment approaches, such as determining optimal and patient-specific BP goals, identifying the most effective antihypertensive medication regimen for an individual, and developing interventions targeting modifiable risk factors. Although the role of AI in HTN has been increasingly recognized over the past decade, it remains in its infancy, and future studies with big data analysis and N-of-1 study design are needed to further demonstrate the applicability of AI in HTN prevention and treatment.",
      "authors": "Chaikijurajai Thanat; Laffin Luke J; Tang Wai Hong Wilson",
      "year": "2020",
      "month": "Nov",
      "journal": "American journal of hypertension",
      "source": "pubmed"
    },
    {
      "pmid": "32560708",
      "doi": "10.1186/s13059-020-02055-7",
      "title": "Enhanced Integrated Gradients: improving interpretability of deep learning models using splicing codes as a case study.",
      "abstract": "Despite the success and fast adaptation of deep learning models in biomedical domains, their lack of interpretability remains an issue. Here, we introduce Enhanced Integrated Gradients (EIG), a method to identify significant features associated with a specific prediction task. Using RNA splicing prediction as well as digit classification as case studies, we demonstrate that EIG improves upon the original Integrated Gradients method and produces sets of informative features. We then apply EIG to identify A1CF as a key regulator of liver-specific alternative splicing, supporting this finding with subsequent analysis of relevant A1CF functional (RNA-seq) and binding data (PAR-CLIP).",
      "authors": "Jha Anupama; K Aicher Joseph; R Gazzara Matthew; Singh Deependra; Barash Yoseph",
      "year": "2020",
      "month": "Jun",
      "journal": "Genome biology",
      "source": "pubmed"
    },
    {
      "pmid": "32543653",
      "doi": "10.1093/gigascience/giaa064",
      "title": "Integrative computational epigenomics to build data-driven gene regulation hypotheses.",
      "abstract": "Diseases are complex phenotypes often arising as an emergent property of a non-linear network of genetic and epigenetic interactions. To translate this resulting state into a causal relationship with a subset of regulatory features, many experiments deploy an array of laboratory assays from multiple modalities. Often, each of these resulting datasets is large, heterogeneous, and noisy. Thus, it is non-trivial to unify these complex datasets into an interpretable phenotype. Although recent methods address this problem with varying degrees of success, they are constrained by their scopes or limitations. Therefore, an important gap in the field is the lack of a universal data harmonizer with the capability to arbitrarily integrate multi-modal datasets. In this review, we perform a critical analysis of methods with the explicit aim of harmonizing data, as opposed to case-specific integration. This revealed that matrix factorization, latent variable analysis, and deep learning are potent strategies. Finally, we describe the properties of an ideal universal data harmonization framework. A sufficiently advanced universal harmonizer has major medical implications, such as (i) identifying dysregulated biological pathways responsible for a disease is a powerful diagnostic tool; (2) investigating these pathways further allows the biological community to better understand a disease's mechanisms; and (3) precision medicine also benefits from developments in this area, particularly in the context of the growing field of selective epigenome editing, which can suppress or induce a desired phenotype.",
      "authors": "Chen Tyrone; Tyagi Sonika",
      "year": "2020",
      "month": "Jun",
      "journal": "GigaScience",
      "source": "pubmed"
    },
    {
      "pmid": "32468614",
      "doi": "10.1002/hbm.25037",
      "title": "The ENIGMA-Epilepsy working group: Mapping disease from large data sets.",
      "abstract": "Epilepsy is a common and serious neurological disorder, with many different constituent conditions characterized by their electro clinical, imaging, and genetic features. MRI has been fundamental in advancing our understanding of brain processes in the epilepsies. Smaller-scale studies have identified many interesting imaging phenomena, with implications both for understanding pathophysiology and improving clinical care. Through the infrastructure and concepts now well-established by the ENIGMA Consortium, ENIGMA-Epilepsy was established to strengthen epilepsy neuroscience by greatly increasing sample sizes, leveraging ideas and methods established in other ENIGMA projects, and generating a body of collaborating scientists and clinicians to drive forward robust research. Here we review published, current, and future projects, that include structural MRI, diffusion tensor imaging (DTI), and resting state functional MRI (rsfMRI), and that employ advanced methods including structural covariance, and event-based modeling analysis. We explore age of onset- and duration-related features, as well as phenomena-specific work focusing on particular epilepsy syndromes or phenotypes, multimodal analyses focused on understanding the biology of disease progression, and deep learning approaches. We encourage groups who may be interested in participating to make contact to further grow and develop ENIGMA-Epilepsy.",
      "authors": "Sisodiya Sanjay M; Whelan Christopher D; Hatton Sean N; Huynh Khoa; Altmann Andre; Ryten Mina; Vezzani Annamaria; Caligiuri Maria Eugenia; Labate Angelo; Gambardella Antonio; Ives-Deliperi Victoria; Meletti Stefano; Munsell Brent C; Bonilha Leonardo; Tondelli Manuela; Rebsamen Michael; Rummel Christian; Vaudano Anna Elisabetta; Wiest Roland; Balachandra Akshara R; Bargalló Núria; Bartolini Emanuele; Bernasconi Andrea; Bernasconi Neda; Bernhardt Boris; Caldairou Benoit; Carr Sarah J A; Cavalleri Gianpiero L; Cendes Fernando; Concha Luis; Desmond Patricia M; Domin Martin; Duncan John S; Focke Niels K; Guerrini Renzo; Hamandi Khalid; Jackson Graeme D; Jahanshad Neda; Kälviäinen Reetta; Keller Simon S; Kochunov Peter; Kowalczyk Magdalena A; Kreilkamp Barbara A K; Kwan Patrick; Lariviere Sara; Lenge Matteo; Lopez Seymour M; Martin Pascal; Mascalchi Mario; Moreira José C V; Morita-Sherman Marcia E; Pardoe Heath R; Pariente Jose C; Raviteja Kotikalapudi; Rocha Cristiane S; Rodríguez-Cruces Raúl; Seeck Margitta; Semmelroch Mira K H G; Sinclair Benjamin; Soltanian-Zadeh Hamid; Stein Dan J; Striano Pasquale; Taylor Peter N; Thomas Rhys H; Thomopoulos Sophia I; Velakoulis Dennis; Vivash Lucy; Weber Bernd; Yasuda Clarissa Lin; Zhang Junsong; Thompson Paul M; McDonald Carrie R",
      "year": "2020",
      "month": "May",
      "journal": "Human brain mapping",
      "source": "pubmed"
    },
    {
      "pmid": "32299344",
      "doi": "10.1186/s12859-020-3465-2",
      "title": "PathME: pathway based multi-modal sparse autoencoders for clustering of patient-level multi-omics data.",
      "abstract": "Recent years have witnessed an increasing interest in multi-omics data, because these data allow for better understanding complex diseases such as cancer on a molecular system level. In addition, multi-omics data increase the chance to robustly identify molecular patient sub-groups and hence open the door towards a better personalized treatment of diseases. Several methods have been proposed for unsupervised clustering of multi-omics data. However, a number of challenges remain, such as the magnitude of features and the large difference in dimensionality across different omics data sources. We propose a multi-modal sparse denoising autoencoder framework coupled with sparse non-negative matrix factorization to robustly cluster patients based on multi-omics data. The proposed model specifically leverages pathway information to effectively reduce the dimensionality of omics data into a pathway and patient specific score profile. In consequence, our method allows us to understand, which pathway is a feature of which particular patient cluster. Moreover, recently proposed machine learning techniques allow us to disentangle the specific impact of each individual omics feature on a pathway score. We applied our method to cluster patients in several cancer datasets using gene expression, miRNA expression, DNA methylation and CNVs, demonstrating the possibility to obtain biologically plausible disease subtypes characterized by specific molecular features. Comparison against several competing methods showed a competitive clustering performance. In addition, post-hoc analysis of somatic mutations and clinical data provided supporting evidence and interpretation of the identified clusters. Our suggested multi-modal sparse denoising autoencoder approach allows for an effective and interpretable integration of multi-omics data on pathway level while addressing the high dimensional character of omics data. Patient specific pathway score profiles derived from our model allow for a robust identification of disease subgroups.",
      "authors": "Lemsara Amina; Ouadfel Salima; Fröhlich Holger",
      "year": "2020",
      "month": "Apr",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "31981309",
      "doi": "10.1002/cyto.a.23973",
      "title": "Deep Learning-Based Single-Cell Optical Image Studies.",
      "abstract": "Optical imaging technology that has the advantages of high sensitivity and cost-effectiveness greatly promotes the progress of nondestructive single-cell studies. Complex cellular image analysis tasks such as three-dimensional reconstruction call for machine-learning technology in cell optical image research. With the rapid developments of high-throughput imaging flow cytometry, big data cell optical images are always obtained that may require machine learning for data analysis. In recent years, deep learning has been prevalent in the field of machine learning for large-scale image processing and analysis, which brings a new dawn for single-cell optical image studies with an explosive growth of data availability. Popular deep learning techniques offer new ideas for multimodal and multitask single-cell optical image research. This article provides an overview of the basic knowledge of deep learning and its applications in single-cell optical image studies. We explore the feasibility of applying deep learning techniques to single-cell optical image analysis, where popular techniques such as transfer learning, multimodal learning, multitask learning, and end-to-end learning have been reviewed. Image preprocessing and deep learning model training methods are then summarized. Applications based on deep learning techniques in the field of single-cell optical image studies are reviewed, which include image segmentation, super-resolution image reconstruction, cell tracking, cell counting, cross-modal image reconstruction, and design and control of cell imaging systems. In addition, deep learning in popular single-cell optical imaging techniques such as label-free cell optical imaging, high-content screening, and high-throughput optical imaging cytometry are also mentioned. Finally, the perspectives of deep learning technology for single-cell optical image analysis are discussed. © 2020 International Society for Advancement of Cytometry.",
      "authors": "Sun Jing; Tárnok Attila; Su Xuantao",
      "year": "2020",
      "month": "Mar",
      "journal": "Cytometry. Part A : the journal of the International Society for Analytical Cytology",
      "source": "pubmed"
    },
    {
      "pmid": "31978628",
      "doi": "10.1016/j.psychres.2019.112732",
      "title": "Artificial intelligence approaches to predicting and detecting cognitive decline in older adults: A conceptual review.",
      "abstract": "Preserving cognition and mental capacity is critical to aging with autonomy. Early detection of pathological cognitive decline facilitates the greatest impact of restorative or preventative treatments. Artificial Intelligence (AI) in healthcare is the use of computational algorithms that mimic human cognitive functions to analyze complex medical data. AI technologies like machine learning (ML) support the integration of biological, psychological, and social factors when approaching diagnosis, prognosis, and treatment of disease. This paper serves to acquaint clinicians and other stakeholders with the use, benefits, and limitations of AI for predicting, diagnosing, and classifying mild and major neurocognitive impairments, by providing a conceptual overview of this topic with emphasis on the features explored and AI techniques employed. We present studies that fell into six categories of features used for these purposes: (1) sociodemographics; (2) clinical and psychometric assessments; (3) neuroimaging and neurophysiology; (4) electronic health records and claims; (5) novel assessments (e.g., sensors for digital data); and (6) genomics/other omics. For each category we provide examples of AI approaches, including supervised and unsupervised ML, deep learning, and natural language processing. AI technology, still nascent in healthcare, has great potential to transform the way we diagnose and treat patients with neurocognitive disorders.",
      "authors": "Graham Sarah A; Lee Ellen E; Jeste Dilip V; Van Patten Ryan; Twamley Elizabeth W; Nebeker Camille; Yamada Yasunori; Kim Ho-Cheol; Depp Colin A",
      "year": "2020",
      "month": "Feb",
      "journal": "Psychiatry research",
      "source": "pubmed"
    },
    {
      "pmid": "31905969",
      "doi": "10.3390/biom10010062",
      "title": "Epigenetics Analysis and Integrated Analysis of Multiomics Data, Including Epigenetic Data, Using Artificial Intelligence in the Era of Precision Medicine.",
      "abstract": "To clarify the mechanisms of diseases, such as cancer, studies analyzing genetic mutations have been actively conducted for a long time, and a large number of achievements have already been reported. Indeed, genomic medicine is considered the core discipline of precision medicine, and currently, the clinical application of cutting-edge genomic medicine aimed at improving the prevention, diagnosis and treatment of a wide range of diseases is promoted. However, although the Human Genome Project was completed in 2003 and large-scale genetic analyses have since been accomplished worldwide with the development of next-generation sequencing (NGS), explaining the mechanism of disease onset only using genetic variation has been recognized as difficult. Meanwhile, the importance of epigenetics, which describes inheritance by mechanisms other than the genomic DNA sequence, has recently attracted attention, and, in particular, many studies have reported the involvement of epigenetic deregulation in human cancer. So far, given that genetic and epigenetic studies tend to be accomplished independently, physiological relationships between genetics and epigenetics in diseases remain almost unknown. Since this situation may be a disadvantage to developing precision medicine, the integrated understanding of genetic variation and epigenetic deregulation appears to be now critical. Importantly, the current progress of artificial intelligence (AI) technologies, such as machine learning and deep learning, is remarkable and enables multimodal analyses of big omics data. In this regard, it is important to develop a platform that can conduct multimodal analysis of medical big data using AI as this may accelerate the realization of precision medicine. In this review, we discuss the importance of genome-wide epigenetic and multiomics analyses using AI in the era of precision medicine.",
      "authors": "Hamamoto Ryuji; Komatsu Masaaki; Takasawa Ken; Asada Ken; Kaneko Syuzo",
      "year": "2019",
      "month": "Dec",
      "journal": "Biomolecules",
      "source": "pubmed"
    },
    {
      "pmid": "31847804",
      "doi": "10.1186/s12859-019-3220-8",
      "title": "Modeling aspects of the language of life through transfer-learning protein sequences.",
      "abstract": "Predicting protein function and structure from sequence is one important challenge for computational biology. For 26 years, most state-of-the-art approaches combined machine learning and evolutionary information. However, for some applications retrieving related proteins is becoming too time-consuming. Additionally, evolutionary information is less powerful for small families, e.g. for proteins from the Dark Proteome. Both these problems are addressed by the new methodology introduced here. We introduced a novel way to represent protein sequences as continuous vectors (embeddings) by using the language model ELMo taken from natural language processing. By modeling protein sequences, ELMo effectively captured the biophysical properties of the language of life from unlabeled big data (UniRef50). We refer to these new embeddings as SeqVec (Sequence-to-Vector) and demonstrate their effectiveness by training simple neural networks for two different tasks. At the per-residue level, secondary structure (Q3 = 79% ± 1, Q8 = 68% ± 1) and regions with intrinsic disorder (MCC = 0.59 ± 0.03) were predicted significantly better than through one-hot encoding or through Word2vec-like approaches. At the per-protein level, subcellular localization was predicted in ten classes (Q10 = 68% ± 1) and membrane-bound were distinguished from water-soluble proteins (Q2 = 87% ± 1). Although SeqVec embeddings generated the best predictions from single sequences, no solution improved over the best existing method using evolutionary information. Nevertheless, our approach improved over some popular methods using evolutionary information and for some proteins even did beat the best. Thus, they prove to condense the underlying principles of protein sequences. Overall, the important novelty is speed: where the lightning-fast HHblits needed on average about two minutes to generate the evolutionary information for a target protein, SeqVec created embeddings on average in 0.03 s. As this speed-up is independent of the size of growing sequence databases, SeqVec provides a highly scalable approach for the analysis of big data in proteomics, i.e. microbiome or metaproteome analysis. Transfer-learning succeeded to extract information from unlabeled sequence databases relevant for various protein prediction tasks. SeqVec modeled the language of life, namely the principles underlying protein sequences better than any features suggested by textbooks and prediction methods. The exception is evolutionary information, however, that information is not available on the level of a single sequence.",
      "authors": "Heinzinger Michael; Elnaggar Ahmed; Wang Yu; Dallago Christian; Nechaev Dmitrii; Matthes Florian; Rost Burkhard",
      "year": "2019",
      "month": "Dec",
      "journal": "BMC bioinformatics",
      "source": "pubmed"
    },
    {
      "pmid": "31797610",
      "doi": "",
      "title": "PAGE-Net: Interpretable and Integrative Deep Learning for Survival Analysis Using Histopathological Images and Genomic Data.",
      "abstract": "The integration of multi-modal data, such as histopathological images and genomic data, is essential for understanding cancer heterogeneity and complexity for personalized treatments, as well as for enhancing survival predictions in cancer study. Histopathology, as a clinical gold-standard tool for diagnosis and prognosis in cancers, allows clinicians to make precise decisions on therapies, whereas high-throughput genomic data have been investigated to dissect the genetic mechanisms of cancers. We propose a biologically interpretable deep learning model (PAGE-Net) that integrates histopathological images and genomic data, not only to improve survival prediction, but also to identify genetic and histopathological patterns that cause different survival rates in patients. PAGE-Net consists of pathology/genome/demography-specific layers, each of which provides comprehensive biological interpretation. In particular, we propose a novel patch-wise texture-based convolutional neural network, with a patch aggregation strategy, to extract global survival-discriminative features, without manual annotation for the pathology-specific layers. We adapted the pathway-based sparse deep neural network, named Cox-PASNet, for the genome-specific layers. The proposed deep learning model was assessed with the histopathological images and the gene expression data of Glioblastoma Multiforme (GBM) at The Cancer Genome Atlas (TCGA) and The Cancer Imaging Archive (TCIA). PAGE-Net achieved a C-index of 0.702, which is higher than the results achieved with only histopathological images (0.509) and Cox-PASNet (0.640). More importantly, PAGE-Net can simultaneously identify histopathological and genomic prognostic factors associated with patients survivals. The source code of PAGE-Net is publicly available at https://github.com/DataX-JieHao/PAGE-Net.",
      "authors": "Hao Jie; Kosaraju Sai Chandra; Tsaku Nelson Zange; Song Dae Hyun; Kang Mingon",
      "year": "2020",
      "month": "",
      "journal": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
      "source": "pubmed"
    },
    {
      "pmid": "31618586",
      "doi": "10.1021/acs.molpharmaceut.9b00520",
      "title": "Toward Explainable Anticancer Compound Sensitivity Prediction via Multimodal Attention-Based Convolutional Encoders.",
      "abstract": "In line with recent advances in neural drug design and sensitivity prediction, we propose a novel architecture for interpretable prediction of anticancer compound sensitivity using a multimodal attention-based convolutional encoder. Our model is based on the three key pillars of drug sensitivity: compounds' structure in the form of a SMILES sequence, gene expression profiles of tumors, and prior knowledge on intracellular interactions from protein-protein interaction networks. We demonstrate that our multiscale convolutional attention-based encoder significantly outperforms a baseline model trained on Morgan fingerprints and a selection of encoders based on SMILES, as well as the previously reported state-of-the-art for multimodal drug sensitivity prediction (",
      "authors": "Manica Matteo; Oskooei Ali; Born Jannis; Subramanian Vigneshwari; Sáez-Rodríguez Julio; Rodríguez Martínez María",
      "year": "2019",
      "month": "Dec",
      "journal": "Molecular pharmaceutics",
      "source": "pubmed"
    },
    {
      "pmid": "31483777",
      "doi": "10.1371/journal.pcbi.1007283",
      "title": "Integrating thermodynamic and sequence contexts improves protein-RNA binding prediction.",
      "abstract": "Predicting RNA-binding protein (RBP) specificity is important for understanding gene expression regulation and RNA-mediated enzymatic processes. It is widely believed that RBP binding specificity is determined by both the sequence and structural contexts of RNAs. Existing approaches, including traditional machine learning algorithms and more recently, deep learning models, have been extensively applied to integrate RNA sequence and its predicted or experimental RNA structural probabilities for improving the accuracy of RBP binding prediction. Such models were trained mostly on the large-scale in vitro datasets, such as the RNAcompete dataset. However, in RNAcompete, most synthetic RNAs are unstructured, which makes machine learning methods not effectively extract RBP-binding structural preferences. Furthermore, RNA structure may be variable or multi-modal according to both theoretical and experimental evidence. In this work, we propose ThermoNet, a thermodynamic prediction model by integrating a new sequence-embedding convolutional neural network model over a thermodynamic ensemble of RNA secondary structures. First, the sequence-embedding convolutional neural network generalizes the existing k-mer based methods by jointly learning convolutional filters and k-mer embeddings to represent RNA sequence contexts. Second, the thermodynamic average of deep-learning predictions is able to explore structural variability and improves the prediction, especially for the structured RNAs. Extensive experiments demonstrate that our method significantly outperforms existing approaches, including RCK, DeepBind and several other recent state-of-the-art methods for predictions on both in vitro and in vivo data. The implementation of ThermoNet is available at https://github.com/suyufeng/ThermoNet.",
      "authors": "Su Yufeng; Luo Yunan; Zhao Xiaoming; Liu Yang; Peng Jian",
      "year": "2019",
      "month": "Sep",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    },
    {
      "pmid": "31021325",
      "doi": "10.2196/11499",
      "title": "Adapting State-of-the-Art Deep Language Models to Clinical Information Extraction Systems: Potentials, Challenges, and Solutions.",
      "abstract": "Deep learning (DL) has been widely used to solve problems with success in speech recognition, visual object recognition, and object detection for drug discovery and genomics. Natural language processing has achieved noticeable progress in artificial intelligence. This gives an opportunity to improve on the accuracy and human-computer interaction of clinical informatics. However, due to difference of vocabularies and context between a clinical environment and generic English, transplanting language models directly from up-to-date methods to real-world health care settings is not always satisfactory. Moreover, the legal restriction on using privacy-sensitive patient records hinders the progress in applying machine learning (ML) to clinical language processing. The aim of this study was to investigate 2 ways to adapt state-of-the-art language models to extracting patient information from free-form clinical narratives to populate a handover form at a nursing shift change automatically for proofing and revising by hand: first, by using domain-specific word representations and second, by using transfer learning models to adapt knowledge from general to clinical English. We have described the practical problem, composed it as an ML task known as information extraction, proposed methods for solving the task, and evaluated their performance. First, word representations trained from different domains served as the input of a DL system for information extraction. Second, the transfer learning model was applied as a way to adapt the knowledge learned from general text sources to the task domain. The goal was to gain improvements in the extraction performance, especially for the classes that were topically related but did not have a sufficient amount of model solutions available for ML directly from the target domain. A total of 3 independent datasets were generated for this task, and they were used as the training (101 patient reports), validation (100 patient reports), and test (100 patient reports) sets in our experiments. Our system is now the state-of-the-art in this task. Domain-specific word representations improved the macroaveraged F1 by 3.4%. Transferring the knowledge from general English corpora to the task-specific domain contributed a further 7.1% improvement. The best performance in populating the handover form with 37 headings was the macroaveraged F1 of 41.6% and F1 of 81.1% for filtering out irrelevant information. Performance differences between this system and its baseline were statistically significant (P<.001; Wilcoxon test). To our knowledge, our study is the first attempt to transfer models from general deep models to specific tasks in health care and gain a significant improvement. As transfer learning shows its advantage over other methods, especially on classes with a limited amount of training data, less experts' time is needed to annotate data for ML, which may enable good results even in resource-poor domains.",
      "authors": "Zhou Liyuan; Suominen Hanna; Gedeon Tom",
      "year": "2019",
      "month": "Apr",
      "journal": "JMIR medical informatics",
      "source": "pubmed"
    },
    {
      "pmid": "30959966",
      "doi": "10.3390/cancers11040494",
      "title": "Association Analysis of Deep Genomic Features Extracted by Denoising Autoencoders in Breast Cancer.",
      "abstract": "Artificial intelligence-based unsupervised deep learning (DL) is widely used to mine multimodal big data. However, there are few applications of this technology to cancer genomics. We aim to develop DL models to extract deep features from the breast cancer gene expression data and copy number alteration (CNA) data separately and jointly. We hypothesize that the deep features are associated with patients' clinical characteristics and outcomes. Two unsupervised denoising autoencoders (DAs) were developed to extract deep features from TCGA (The Cancer Genome Atlas) breast cancer gene expression and CNA data separately and jointly. A heat map was used to view and cluster patients into subgroups based on these DL features. Fisher's exact test and Pearson' Chi-square test were applied to test the associations of patients' groups and clinical information. Survival differences between the groups were evaluated by Kaplan⁻Meier (KM) curves. Associations between each of the features and patient's overall survival were assessed using Cox's proportional hazards (COX-PH) model and a risk score for each feature set from the different omics data sets was generated from the survival regression coefficients. The risk scores for each feature set were binarized into high- and low-risk patient groups to evaluate survival differences using KM curves. Furthermore, the risk scores were traced back to their gene level DAs weights so that the three gene lists for each of the genomic data points were generated to perform gene set enrichment analysis. Patients were clustered into two groups based on concatenated features from the gene expression and CNA data and these two groups showed different overall survival rates (",
      "authors": "Liu Qian; Hu Pingzhao",
      "year": "2019",
      "month": "Apr",
      "journal": "Cancers",
      "source": "pubmed"
    },
    {
      "pmid": "30944913",
      "doi": "10.1093/jamiaopen/ooy061",
      "title": "Natural language processing and recurrent network models for identifying genomic mutation-associated cancer treatment change from patient progress notes.",
      "abstract": "Natural language processing (NLP) and machine learning approaches were used to build classifiers to identify genomic-related treatment changes in the free-text visit progress notes of cancer patients. We obtained 5889 deidentified progress reports (2439 words on average) for 755 cancer patients who have undergone a clinical next generation sequencing (NGS) testing in Wake Forest Baptist Comprehensive Cancer Center for our data analyses. An NLP system was implemented to process the free-text data and extract NGS-related information. Three types of recurrent neural network (RNN) namely, gated recurrent unit, long short-term memory (LSTM), and bidirectional LSTM (LSTM_Bi) were applied to classify documents to the treatment-change and no-treatment-change groups. Further, we compared the performances of RNNs to 5 machine learning algorithms including Naive Bayes, K-nearest Neighbor, Support Vector Machine for classification, Random forest, and Logistic Regression. Our results suggested that, overall, RNNs outperformed traditional machine learning algorithms, and LSTM_Bi showed the best performance among the RNNs in terms of accuracy, precision, recall, and F1 score. In addition, pretrained word embedding can improve the accuracy of LSTM by 3.4% and reduce the training time by more than 60%. NLP and RNN-based text mining solutions have demonstrated advantages in information retrieval and document classification tasks for unstructured clinical progress notes.",
      "authors": "Guan Meijian; Cho Samuel; Petro Robin; Zhang Wei; Pasche Boris; Topaloglu Umit",
      "year": "2019",
      "month": "Apr",
      "journal": "JAMIA open",
      "source": "pubmed"
    },
    {
      "pmid": "30671672",
      "doi": "10.1007/s00439-019-01970-5",
      "title": "Translating cancer genomics into precision medicine with artificial intelligence: applications, challenges and future perspectives.",
      "abstract": "In the field of cancer genomics, the broad availability of genetic information offered by next-generation sequencing technologies and rapid growth in biomedical publication has led to the advent of the big-data era. Integration of artificial intelligence (AI) approaches such as machine learning, deep learning, and natural language processing (NLP) to tackle the challenges of scalability and high dimensionality of data and to transform big data into clinically actionable knowledge is expanding and becoming the foundation of precision medicine. In this paper, we review the current status and future directions of AI application in cancer genomics within the context of workflows to integrate genomic analysis for precision cancer care. The existing solutions of AI and their limitations in cancer genetic testing and diagnostics such as variant calling and interpretation are critically analyzed. Publicly available tools or algorithms for key NLP technologies in the literature mining for evidence-based clinical recommendations are reviewed and compared. In addition, the present paper highlights the challenges to AI adoption in digital healthcare with regard to data requirements, algorithmic transparency, reproducibility, and real-world assessment, and discusses the importance of preparing patients and physicians for modern digitized healthcare. We believe that AI will remain the main driver to healthcare transformation toward precision medicine, yet the unprecedented challenges posed should be addressed to ensure safety and beneficial impact to healthcare.",
      "authors": "Xu Jia; Yang Pengwei; Xue Shang; Sharma Bhuvan; Sanchez-Martin Marta; Wang Fang; Beaty Kirk A; Dehan Elinor; Parikh Baiju",
      "year": "2019",
      "month": "Feb",
      "journal": "Human genetics",
      "source": "pubmed"
    },
    {
      "pmid": "30532223",
      "doi": "10.1371/journal.pone.0208924",
      "title": "Distillation of the clinical algorithm improves prognosis by multi-task deep learning in high-risk Neuroblastoma.",
      "abstract": "We introduce the CDRP (Concatenated Diagnostic-Relapse Prognostic) architecture for multi-task deep learning that incorporates a clinical algorithm, e.g., a risk stratification schema to improve prognostic profiling. We present the first application to survival prediction in High-Risk (HR) Neuroblastoma from transcriptomics data, a task that studies from the MAQC consortium have shown to remain the hardest among multiple diagnostic and prognostic endpoints predictable from the same dataset. To obtain a more accurate risk stratification needed for appropriate treatment strategies, CDRP combines a first component (CDRP-A) synthesizing a diagnostic task and a second component (CDRP-N) dedicated to one or more prognostic tasks. The approach leverages the advent of semi-supervised deep learning structures that can flexibly integrate multimodal data or internally create multiple processing paths. CDRP-A is an autoencoder trained on gene expression on the HR/non-HR risk stratification by the Children's Oncology Group, obtaining a 64-node representation in the bottleneck layer. CDRP-N is a multi-task classifier for two prognostic endpoints, i.e., Event-Free Survival (EFS) and Overall Survival (OS). CDRP-A provides the HR embedding input to the CDRP-N shared layer, from which two branches depart to model EFS and OS, respectively. To control for selection bias, CDRP is trained and evaluated using a Data Analysis Protocol (DAP) developed within the MAQC initiative. CDRP was applied on Illumina RNA-Seq of 498 Neuroblastoma patients (HR: 176) from the SEQC study (12,464 Entrez genes) and on Affymetrix Human Exon Array expression profiles (17,450 genes) of 247 primary diagnostic Neuroblastoma of the TARGET NBL cohort. On the SEQC HR patients, CDRP achieves Matthews Correlation Coefficient (MCC) 0.38 for EFS and MCC = 0.19 for OS in external validation, improving over published SEQC models. We show that a CDRP-N embedding is indeed parametrically associated to increasing severity and the embedding can be used to better stratify patients' survival.",
      "authors": "Maggio Valerio; Chierici Marco; Jurman Giuseppe; Furlanello Cesare",
      "year": "2018",
      "month": "",
      "journal": "PloS one",
      "source": "pubmed"
    },
    {
      "pmid": "30005074",
      "doi": "10.1371/journal.pcbi.1006185",
      "title": "miRAW: A deep learning-based approach to predict microRNA targets by analyzing whole microRNA transcripts.",
      "abstract": "MicroRNAs (miRNAs) are small non-coding RNAs that regulate gene expression by binding to partially complementary regions within the 3'UTR of their target genes. Computational methods play an important role in target prediction and assume that the miRNA \"seed region\" (nt 2 to 8) is required for functional targeting, but typically only identify ∼80% of known bindings. Recent studies have highlighted a role for the entire miRNA, suggesting that a more flexible methodology is needed. We present a novel approach for miRNA target prediction based on Deep Learning (DL) which, rather than incorporating any knowledge (such as seed regions), investigates the entire miRNA and 3'TR mRNA nucleotides to learn a uninhibited set of feature descriptors related to the targeting process. We collected more than 150,000 experimentally validated homo sapiens miRNA:gene targets and cross referenced them with different CLIP-Seq, CLASH and iPAR-CLIP datasets to obtain ∼20,000 validated miRNA:gene exact target sites. Using this data, we implemented and trained a deep neural network-composed of autoencoders and a feed-forward network-able to automatically learn features describing miRNA-mRNA interactions and assess functionality. Predictions were then refined using information such as site location or site accessibility energy. In a comparison using independent datasets, our DL approach consistently outperformed existing prediction methods, recognizing the seed region as a common feature in the targeting process, but also identifying the role of pairings outside this region. Thermodynamic analysis also suggests that site accessibility plays a role in targeting but that it cannot be used as a sole indicator for functionality. Data and source code available at: https://bitbucket.org/account/user/bipous/projects/MIRAW.",
      "authors": "Pla Albert; Zhong Xiangfu; Rayner Simon",
      "year": "2018",
      "month": "Jul",
      "journal": "PLoS computational biology",
      "source": "pubmed"
    }
  ]
}