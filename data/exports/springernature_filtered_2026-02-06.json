[
  {
    "source": "springernature",
    "title": "Interpretable deep learning model of circulating genomics for quantitative survival prediction in advanced non-small cell lung cancer",
    "doi": "10.1007/s12094-026-04220-z",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12094-026-04220-z",
    "authors": [
      "Wang, Yu",
      "Li, Yi-Tong",
      "Wang, Ming-Hao",
      "Zhang, Cheng-Yi",
      "Jiang, Ying",
      "Xu, Qi",
      "Liu, Ying-Ping",
      "Li, Can-Jun",
      "Li, Ye-Xiong",
      "Bi, Nan"
    ],
    "publicationDate": "2026-02-06",
    "publicationName": "Clinical and Translational Oncology",
    "contentType": "Article",
    "abstract": "Purpose Accurate quantitative survival prediction in advanced non-small cell lung cancer (NSCLC) remains an unmet clinical need. While liquid biopsy is widely used, single circulating tumor DNA (ctDNA) shows limited predictive power. We developed an interpretable deep-learning model to quantitatively predict outcomes. Methods/patients We integrated data from 1373 advanced NSCLC patients profiled by two ultra-deep ctDNA sequencing assays (MSK-ACCESS and ctDx Lung). Features associated with overall survival (OS) were incorporated into a deep-learning network (DeepSurv), which estimates time-to-event survival probabilities. Model performance was evaluated by time-dependent area under the curve (AUC). SHapley Additive exPlanations (SHAP) were employed to interpret model output. Results A total of 1373 patients were analyzed, with 1012 using MSK-ACCESS (discovery) and 361 using ctDx Lung (validation). Among over 40 clinicopathological features, ctDNA status, cell-free DNA (cfDNA) concentration, age, blood-based TP53 , EGFR , PIK3CA , ARID1A , STK11 and MET mutations significantly predicted OS. In ctDNA-positive patients, TP53/PIK3CA/ARID1A/STK11/MET -mutated patients had significantly inferior OS compared with wildtype patients ( P  < 0.001). Using above variables, DeepSurv was trained and tested in the MSK-ACCESS cohort (12-month AUC = 0.75), outperforming single cfDNA (AUC = 0.66) or ctDNA (AUC = 0.59), and externally validated in the ctDx Lung cohort. Compared with high-risk patients, DeepSurv-identified low-risk patients had significantly longer OS in both discovery (12-month OS 87.8% vs 53.8%, HR 0.32, P  < 0.001) and validation cohorts (73.2% vs 48.4%, HR 0.42, P  < 0.001). SHAP revealed TP53 and cfDNA concentration > 4.8 ng/mL had the most important contributions. Conclusions The interpretable DeepSurv model, integrating multimodal features, enables quantitative survival prediction and risk stratification in advanced NSCLC, facilitating personalized decision-making.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Leveraging multi-modal foundation models for analysing spatial multi-omic and histopathology data",
    "doi": "10.1038/s41551-025-01602-6",
    "url": "https://www.nature.com/articles/s41551-025-01602-6",
    "authors": [
      "Liu, Tianyu",
      "Huang, Tinglin",
      "Ding, Tong",
      "Wu, Hao",
      "Humphrey, Peter",
      "Perincheri, Sudhir",
      "Schalper, Kurt",
      "Ying, Rex",
      "Xu, Hua",
      "Zou, James",
      "Mahmood, Faisal",
      "Zhao, Hongyu"
    ],
    "publicationDate": "2026-02-05",
    "publicationName": "Nature Biomedical Engineering",
    "contentType": "Article",
    "abstract": "Spatial multi-modal data analysis using embeddings from diverse foundation models (spEMO) represents a transformative approach that unifies embeddings from pathology foundation models with those from large language models to advance spatial multi-omics research. Recent advances in pathology foundation models, pre-trained on large-scale histopathology images, have greatly advanced disease-focused applications. At the same time, spatial multi-omic technologies now measure gene and protein expression with high spatial resolution, offering valuable insights into tissue context. Yet, existing models struggle to integrate these complementary data types. Here, to address this challenge, we present spEMO, a computational framework that unifies embeddings from pathology foundation models and large language models for spatial multi-omic analysis. By leveraging multi-modal representations, spEMO surpasses single-modality models across diverse downstream tasks, including spatial domain identification, spot-type classification, whole-slide disease prediction and interpretation, multicellular interaction inference and automated medical reporting. These results highlight spEMO’s strength in both biological discovery and clinical applications. Furthermore, we introduce a new benchmark task—multi-modal alignment—to evaluate how effectively pathology foundation models retrieve complementary information. Together, spEMO establishes a powerful step towards holistic, interpretable and generalizable AI for spatial biology and pathology.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Cosynllm: predicting drug combination synergy with LLM-generated descriptions",
    "doi": "10.1186/s13321-026-01158-w",
    "url": "",
    "authors": [
      "Mao, Suwan",
      "Tang, Wenjie",
      "Li, Li",
      "Jing, Mang",
      "Liu, Yun",
      "Wang, Junjie"
    ],
    "publicationDate": "2026-02-05",
    "publicationName": "Journal of Cheminformatics",
    "contentType": "Article",
    "abstract": "Drug combination therapy is a well-established strategy for treating complex diseases. However, the vast combinatorial space renders exhaustive experimental screening impractical and costly. Recent studies have shown that deep learning techniques can effectively prioritize synergistic drug combinations by leveraging their powerful nonlinear modeling and automatic feature extraction capabilities. Meanwhile, Large Language Models (LLMs) offer great promise in drug discovery. In this paper, we propose CoSynLLM, an LLM-assisted predictive framework for predicting drug combination synergy. We fully leverage the latent knowledge embedded in LLMs to generate semantic-level chemical information, complemented by drug fingerprints to incorporate explicit structural details, while cell line gene expression profiles represent the cellular context. To effectively merge drug and cell line representations, a hierarchical feature fusion strategy is employed to progressively integrate features through multiple stages for predicting drug combination synergy. Extensive experiments on two benchmark datasets, NCI-ALMANAC and O’Neil, demonstrate that CoSynLLM achieves competitive performance, highlighting its effectiveness in predicting drug combination synergy. In summary, CoSynLLM effectively identifies synergistic drug combinations, offering a robust and practical computational framework for predicting drug combination synergy. This paper presents an LLM-assisted predictive framework for predicting drug combination synergy, which incorporates a hierarchical feature fusion strategy. LLMs are employed to generate chemical information for rich feature representations. The proposed hierarchical feature fusion strategy progressively integrates features from drugs and cell lines through multiple stages, enabling effective capture of critical interaction patterns.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "UniSyn: a multi-modal framework with knowledge transfer for anti-cancer drug synergy prediction",
    "doi": "10.1186/s13059-026-03972-9",
    "url": "",
    "authors": [
      "Chen, Yaojia",
      "Zhang, Yumeng",
      "Niu, Mengting",
      "Wang, Jiacheng",
      "Ren, Zhonghao",
      "Zou, Quan",
      "Song, Jiangning",
      "Luo, Ximei"
    ],
    "publicationDate": "2026-02-04",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "Drug combinations can improve cancer therapy by boosting efficacy, limiting dose-related toxicity, and delaying resistance. We present UniSyn, an interpretable multi-modal deep learning framework that transfers knowledge from monotherapy responses to enhance drug-synergy prediction. Through hybrid attention–based integration of drug and cell-line features, UniSyn supports multi-task learning and yields mechanistic insights. It generalizes robustly to unseen drug pairs and cell types, maintaining consistent performance across multiple synergy scoring metrics. Applied at scale to tumor cell lines, UniSyn captures context-specific synergy signals and prioritizes therapeutic combinations with translational potential.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Scaling medical AI across clinical contexts",
    "doi": "10.1038/s41591-025-04184-7",
    "url": "https://www.nature.com/articles/s41591-025-04184-7",
    "authors": [
      "Li, Michelle M.",
      "Reis, Ben Y.",
      "Rodman, Adam",
      "Cai, Tianxi",
      "Dagan, Noa",
      "Balicer, Ran D.",
      "Loscalzo, Joseph",
      "Kohane, Isaac S.",
      "Zitnik, Marinka"
    ],
    "publicationDate": "2026-02-03",
    "publicationName": "Nature Medicine",
    "contentType": "Article",
    "abstract": "To function safely and effectively, medical AI models must adapt automatically to differences in users, health systems, geographies, diseases and populations. This Perspective proposes context switching as the defining paradigm of medical AI, outlining early strategies and opportunities for development. Medical artificial intelligence (AI) tools, including clinical language models, vision–language models and multimodal health record models, are used to summarize clinical notes, answer questions and support decisions. Their adaptation to new populations, specialties or care settings often relies on fine-tuning, prompting or retrieval from external knowledge bases. These strategies can scale poorly and risk contextual errors—outputs that appear plausible but miss critical patient or situational information. We envision context switching as an emergent solution. Context switching adjusts model reasoning at inference, without retraining. Generative models can tailor outputs to patient biology, care setting or disease. Multimodal models can switch between notes, laboratory results, imaging and genomics, even when some data are missing or delayed. Agent models can coordinate tools and roles based on task and user context. In each case, context switching enables medical AI to adapt across specialties, populations and geographies. This approach requires advances in data design, model architectures and evaluation frameworks, and establishes a foundation for medical AI that scales to an infinite number of contexts, while remaining reliable and suited to real-world care.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "GATRSyn: Advancing Anticancer Drug Synergy Prediction Through Graph Attention Networks and Transformer-based Feature Re-embedding",
    "doi": "10.1007/s12539-025-00798-0",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12539-025-00798-0",
    "authors": [
      "Li, Sile",
      "Li, Ziyu",
      "Dong, Chenyang",
      "Li, Yushuang"
    ],
    "publicationDate": "2026-02-03",
    "publicationName": "Interdisciplinary Sciences: Computational Life Sciences",
    "contentType": "Article",
    "abstract": "The integration of deep learning with prior knowledge and multi-omics data enables precise synergy prediction of anticancer drug combinations. However, substantial computational and storage requirements challenge deep learning in managing extensive datasets and multi-scenarios. This study proposes a generalized two-stage framework to address this issue. It decomposes the drug synergy prediction into two key modules: offline feature extraction and multi-scenario adaptive prediction. By integrating drug-cell-associated protein-protein interaction networks with pharmacogenomics data, we first employ an edge-augmented GAT to construct powerful offline feature extractors for drugs and cell lines concurrently, which identify their shared patterns. Next, Transformer-based re-embedding is designed to fine-tune offline features online, which captures cross-modal interactions between specific drugs and cell lines. It can serve as a portable module to seamlessly integrate into various predictive modules. Under this framework, we develop GATRSyn, a dedicated two-stage model for multi-scenario drug synergy prediction. Compared to state-of-the-art deep learning models across multiple high-throughput screening datasets, GATRSyn achieves optimal or near-optimal results across eight distinct prediction scenarios. GATRSyn also effectively screens clinically validated or literature-reported synergistic drug combinations lacking measured scores. Moreover, synergy analysis of eight representative samples and enrichment analysis of pivotal proteins of cell lines and drugs highlights GATRSyn’s ability to model and elucidate targeted therapeutic efficacy of drug combinations against intracellular signaling nodes. Our framework enhances large-scale, multi-scenario drug synergy prediction and provides a comprehensive reference for individualized anticancer treatment. Graphical Abstract ",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Multi-Modal Fusion with Supervised Contrastive Learning Model for Early Alzheimer’s Disease Diagnosis and Multi-Modal Biomarker Identification",
    "doi": "10.1007/s12539-025-00805-4",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12539-025-00805-4",
    "authors": [
      "Xie, Xiaofeng",
      "Xue, Peng",
      "Guo, Yihao",
      "Chen, Huijuan",
      "Fan, Li",
      "Tang, Rongnian",
      "Xu, Zhenkai",
      "Wang, Xuanqi",
      "Liu, Tao",
      "Chen, Feng"
    ],
    "publicationDate": "2026-02-03",
    "publicationName": "Interdisciplinary Sciences: Computational Life Sciences",
    "contentType": "Article",
    "abstract": "Early and accurate diagnosis of mild cognitive impairment (MCI), a prodromal stage of Alzheimer’s disease (AD), is critical for timely intervention and management. Nevertheless, effectively integrating heterogeneous multi-modal data for AD diagnosis remains worthy of further investigation. Therefore, we propose a supervised contrastive learning framework that integrates single nucleotide polymorphisms (SNPs), plasma proteomics, and T1-weighted structural magnetic resonance imaging (sMRI) from a biologically informed perspective, with SNPs influencing protein structure or gene expression levels, ultimately altering brain structure. Through a supervised contrastive learning mechanism, we construct a cross-modal feature space and introduce a similarity-based symmetrical attention mechanism to capture intermodal interactions and mitigate modality heterogeneity. We validate the proposed method on the Alzheimer’s Disease Neuroimaging Initiative dataset, and experimental results demonstrate accuracy of 96.1%, 86.2%, and 86.1% for the AD-NC task, MCI-NC task, and AD-MCI task. In addition, the application of explainable methods to our model identified multi-modal biomarkers related to AD diagnosis. The experimental results validate the effectiveness of our model in the diagnosis of AD and MCI. Graphical Abstract ",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Künstliche Intelligenz und Karzinogenese",
    "doi": "10.1007/s00761-025-01888-w",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00761-025-01888-w",
    "authors": [
      "Schulz, Stefan",
      "Foersch, Sebastian"
    ],
    "publicationDate": "2026-02-01",
    "publicationName": "Die Onkologie",
    "contentType": "Article",
    "abstract": "Background In recent years, artificial intelligence (AI) has emerged as a new tool in oncology that can support in the detection of (pre)neoplastic lesions and deciphering carcinogenesis. In particular, modern AI models open up new perspectives for the identification and characterization of early cancer, for molecular subtyping, and for automated hypothesis generation from large multimodal datasets. Materials and methods This narrative review is based on a selective literature search in PubMed on current developments in the use of AI for early cancer detection, carcinogenesis, and research. For this purpose, the terms “AI early cancer detection/screening,” “AI tumor biomarker,” “AI carcinogenesis,” and “AI hypothesis generation oncology” were used, with a particular focus on recent studies published between 2022 and 2025. Results The scoping assessment reveals a wide range of current and emerging AI approaches, for example for use in early cancer detection. In parallel, multimodal AI methods, serum marker-based tumor screening, and foundation models for histopathology and multi-omics datasets are being intensively studied. Advances in AI agents and hypothesis-generating AI are also being addressed. Conclusion Artificial intelligence is already improving routine cancer diagnostics and can broaden the range of methods available for prevention and early detection. AI systems can furthermore drive precision medicine when combined with clinical, pathological, and molecular genetic data. At the same time, limitations such as model generalizability and safety must be continuously addressed before widespread clinical implementation can be achieved. Hintergrund In den letzten Jahren hat sich künstliche Intelligenz (KI) als neues Instrument in der Onkologie etabliert, welches die Erkennung (prä)neoplastischer Läsionen und die Erforschung der Tumorentstehung unterstützen kann. Gerade im Bereich der Identifikation und Charakterisierung früher Krebsformen, der molekularen Subtypisierung und einer automatisierten Hypothesengenerierung aus großen, multimodalen Datensätzen eröffnen moderne KI-Verfahren neue Perspektiven. Material und Methoden Die vorliegende orientierende Übersichtsarbeit basiert auf einer selektiven Literaturrecherche in PubMed zu aktuellen Entwicklungen im Einsatz von KI für die Krebsfrüherkennung, Karzinogenese und Forschung. Dazu wurden die Begriffe „AI early cancer detection/screening“, „AI tumor biomarker“, „AI carcinogenesis“ und „AI hypothesis generation oncology“ verwendet und insbesondere aktuelle Studien aus den Jahren 2022–2025 betrachtet. Ergebnisse Die repräsentative Sichtung zeigt eine Vielzahl von aktuellen und zukünftigen KI-Ansätzen auf, z. B. zum Einsatz in der Krebsfrüherkennung. Parallel werden multimodale KI-Ansätze, serummarkerbasiertes Tumorscreening sowie Foundation-Modelle für Histopathologie und Multi-Omics-Datenbestände intensiv erforscht. Fortschritte bei KI-Agenten und hypothesengenerierender KI werden ebenfalls adressiert. Schlussfolgerung KI verbessert bereits heute die onkologische Routinediagnostik und kann die Methodenvielfalt der Prävention und Früherkennung erweitern. KI-Systeme können darüber hinaus in Verbindung mit klinischen, histopathologischen und molekularen Daten die Präzisionsmedizin vorantreiben. Gleichzeitig müssen Limitationen wie die Generalisierbarkeit und Sicherheit der Modelle fortlaufend adressiert werden, bevor eine breite klinische Anwendung erfolgen kann.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "A Review on the Applications and Implications of Artificial Intelligence and Machine Learning in Oncology",
    "doi": "10.1007/s44196-026-01164-8",
    "url": "",
    "authors": [
      "Hiwase, Kunal",
      "Verma, Prateek",
      "Zade, Nikita",
      "Kumar, Praveen",
      "Weerarathna, Induni Nayodhara",
      "Gundewar, Swapnil"
    ],
    "publicationDate": "2026-01-30",
    "publicationName": "International Journal of Computational Intelligence Systems",
    "contentType": "Article",
    "abstract": "The use of Artificial Intelligence (AI) and Machine Learning (ML) has rapidly gained popularity in the treatment of oncology, bringing about a significant shift in approaches to initial screening, cancer detection, therapy, and control. This study aims to discuss basic developments in AI and ML, specifically Deep Learning (DL), Natural Language Processing, Radiomics, and multi-omics analysis in Oncology. The use of DL in the diagnosis of various medical images and genomic data has greatly improved diagnostic results and treatment planning. Radiomics contains detailed features of the tumor and its response to the treatment. Multi-omics analysis, which encompasses genomics, proteomics, transcriptomics, and metabolomics, provides a comprehensive understanding of cancer biology and facilitates the development of personalized medicine therapies. However, the use of AI in oncology also presents some ethical and societal concerns, including patients’ privacy, biased algorithms, and the implementation of technology. Addressing these problems is imperative to help in better implementation of the use of AI in Healthcare. The current review also foregrounds the ethical, clinical, and societal implications of AI adoption, emphasizing the need for robust governance, representative datasets, and interdisciplinary collaboration. The future research can be addressed towards the explainability of developed AI models and improvement in the quality of data. Overcoming the mentioned challenges, the efficient use of AIML can offer various benefits such as enhanced accuracy, better treatment and timely intervention for the patients worldwide. Graphical abstract ",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Chemical genomics language model toward reliable and explainable compound-protein interaction exploration",
    "doi": "10.1186/s13321-026-01155-z",
    "url": "",
    "authors": [
      "Koyama, Takuto",
      "Tsumura, Hayato",
      "Okita, Ryunosuke",
      "Yamazaki, Kimihiro",
      "Hasegawa, Aki",
      "Imamura, Keiko",
      "Kato, Takashi",
      "Iwata, Hiroaki",
      "Kojima, Ryosuke",
      "Inoue, Haruhisa",
      "Matsumoto, Shigeyuki",
      "Okuno, Yasushi"
    ],
    "publicationDate": "2026-01-30",
    "publicationName": "Journal of Cheminformatics",
    "contentType": "Article",
    "abstract": "Accurate prediction of compound-protein interactions (CPIs) is crucial for chemical biology and drug discovery. Despite recent advancements, existing deep learning (DL)-based CPI models often struggle to simultaneously achieve high generalization performance, quantify prediction confidence, and ensure explainability. Here, we propose ChemGLaM, a chemical genomics language model designed to address these three crucial challenges, thereby enabling reliable and explainable CPI predictions. ChemGLaM integrates independently pre-trained chemical and protein language models through an interaction block with a cross-attention mechanism, achieving near state-of-the-art performance in predicting novel CPIs at a low computational cost. Incorporating uncertainty estimation and attention visualization enables ChemGLaM to enhance the success rate of virtual screening and to provide molecular insights into CPIs. To demonstrate the practical impact of ChemGLaM, we constructed a publicly available database containing large-scale CPI predictions for every possible pairing between all 20,434 human proteins and all 11,455 drugs and validated its practical applicability in a case study on amyotrophic lateral sclerosis. ChemGLaM marks an important step forward in addressing the challenges of AI-driven CPI exploration and drug discovery. Scientific Contribution This study established a unified CPI prediction framework that simultaneously achieves high generalization performance, confidence quantification, and explainability. We leveraged this framework to create a community resource by constructing a comprehensive CPI database and demonstrated its practical utility by successfully prioritizing hit compounds and deconvoluting their targets in a phenotypic screening for amyotrophic lateral sclerosis.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Identification of diagnostic and prognostic biomarkers in lung adenocarcinoma through integrated bioinformatics analysis and real time PCR validation",
    "doi": "10.1038/s41598-026-35971-y",
    "url": "",
    "authors": [
      "Hossein Zadeh, Rasoul",
      "Hossein Zadeh, Reza",
      "Hajimoradi, Maryam",
      "Islampanah, Muhammad",
      "Zarimeidani, Fatemeh",
      "Rahmati, Rahem",
      "Ahmadinia, Mahdi",
      "Bahrami, Naghmeh",
      "Mohamadnia, Abdolreza",
      "Shafaghi, Shadi",
      "Nazari, Elham"
    ],
    "publicationDate": "2026-01-30",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": "Lung cancer is the third most common cancer in the US with a 5-year survival rate of 17%. Non-small cell lung cancer, especially adenocarcinoma, prevails. Therefore, early detection and biomarker discovery are extremely important. This study uses deep learning to find new biomarkers for lung adenocarcinoma. RNA-Seq data from 522 samples, including 506 lung adenocarcinoma patients and 16 healthy controls, were analyzed. DEGs were identified after strict preprocessing, and deep learning algorithms predicted markers. Functional annotation, pathway, and protein interaction analyses elucidated the biological importance of DEGs. Clinical relevance was assessed by correlation with clinical parameters and survival analysis. External validation was carried out using GDAC and GEO datasets. Blood samples from 30 lung adenocarcinoma patients and 30 healthy people were analyzed by real-time PCR to validate the expression levels of key genes. Among 522 participants(506 cases, 16 controls), the mean age was 62.95 ± 15.71 years. Normalized data showed 3,513 DEGs. The deep learning model had a predictive accuracy of 98.44%, Brier score (probability MSE) = 0.0013, and AUC of 1.0. CYP3A7 had the highest effect size. ROC analysis found diagnostic genes A2M, CYP2C9, and SIRPD (Ensembl ID: 128646) with a sensitivity of 0.96. Real-time PCR showed upregulated CYP2C9, KRT14, and PECAM1 and downregulated A2M in patients compared to controls( P  < 0.001). Bioinformatics-identified genes are potential markers for early lung adenocarcinoma detection and management. RT-PCR validation shows AI’s effectiveness in identifying biomarkers, enabling prompt treatment to halt disease progression.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Large language models for clinical artificial intelligence in healthcare a systematic review",
    "doi": "10.1007/s44163-025-00784-x",
    "url": "",
    "authors": [
      "Ghnemat, Rawan",
      "Saleh, Amro"
    ],
    "publicationDate": "2026-01-28",
    "publicationName": "Discover Artificial Intelligence",
    "contentType": "Article",
    "abstract": "Large Language Models (LLMs) have demonstrated the capacity to process, reason, and generate extensive volumes of data, providing a novel paradigm for integrating generative artificial intelligence (GenAI) into the medical field. Multimodal LLMs (MLLMs) extend these capabilities by incorporating diverse data modalities into unified representations, including genomics, medical imaging, and clinical text. This systematic review synthesizes advancements from 246 records identified between January 2020 and September 2025, of which 90 studies were included after full-text screening, to address critical gaps in understanding the clinical role of LLM and MLLM in healthcare. We trace the evolution from classical natural language processing (NLP) approaches to modern transformer-based architectures, summarize their technical foundations, and examine their construction, evaluation, and deployment in medical workflows. Key contributions include highlighting multimodal integration (e.g., imaging-genomics-text fusion), ethical governance frameworks, and validated domain-specific fine-tuning in clinical settings. We also highlight advances in Prompting, Retrieval-Augmented Generation (RAG), and Multi-Agent (agentic) workflows, providing a critical assessment of their benefits and limitations. In addition, we analyze challenges such as hallucinations, bias, and privacy risks, while providing actionable guidelines for clinicians, developers, and policymakers to improve regulatory compliance. By consolidating the nomenclature and systematically evaluating GenAI in medicine, this review offers evidence-based recommendations and directions for the safe and effective integration of generative AI into healthcare. The findings are intended as an authoritative guide for researchers and practitioners, bridge principles, clinical applications, and policy considerations for LLM and MLLM.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Artificial intelligence (AI) and machine learning (ML) in ovarian cancer: transforming detection, treatment, and prevention",
    "doi": "10.1186/s13048-026-01979-1",
    "url": "",
    "authors": [
      "Singh, Mahavir",
      "Betgeri, Sai N.",
      "Kakar, Sham S."
    ],
    "publicationDate": "2026-01-28",
    "publicationName": "Journal of Ovarian Research",
    "contentType": "Article",
    "abstract": "Ovarian cancer remains a highly lethal malignancy, with advanced-stage diagnosis, recurrence, and chemoresistance, thus limiting clinical outcomes. Traditional biomarkers such as CA-125, BRCA1/2 status, and histopathology offer only a partial view of disease biology, often leading to suboptimal and empiric treatment choices. Recent advances in artificial intelligence (AI) and machine learning (ML) provide new opportunities to improve diagnosis, risk stratification, therapeutic selection, and prevention. By integrating multimodal data, including imaging, clinical records, and multi-omics profiles, AI/ML models can uncover complex patterns that enhance the prediction of treatment response, toxicity, recurrence, and survival. Radiomics and radiomics-based prognostic value (RPV/eRPV) models add further precision by extracting informative imaging phenotypes. Emerging architectures such as graph neural networks (GNNs) and transformer-based models extend these capabilities by modeling interactions among genetic alterations, pathways, and drug responses. Beyond disease management, AI-driven risk prediction and screening tools are gaining exciting relevance in preventive oncology. This review summarizes current and developing AI/ML applications across ovarian cancer care and highlights the translational challenges and opportunities for integrating explainable AI into the clinical workflows. Collectively, these recent innovations support a more personalized, data-integrated approach to reducing morbidity and improving patient outcomes.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "stGCL: a versatile cross-modality fusion method based on multi-modal graph contrastive learning for spatial transcriptomics",
    "doi": "10.1186/s13059-025-03896-w",
    "url": "",
    "authors": [
      "Yu, Na",
      "Zhang, Daoliang",
      "Zhang, Wei",
      "Liu, Zhiping",
      "Qiao, Xu",
      "Wang, Chuanyuan",
      "Zhao, Miaoqing",
      "Yue, Weiming",
      "Li, Wei",
      "Marinis, Yang",
      "Gao, Rui"
    ],
    "publicationDate": "2026-01-28",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "Advances in spatial transcriptomics have enabled high-resolution mapping of tissue architecture at the molecular level, yet integrating its multi-modal data remains challenging. Here, we present stGCL, a framework for accurate and robust integration of gene expression, spatial coordinates, and histological features. stGCL employs a histology-based Vision Transformer to extract morphological features and a multi-modal graph autoencoder with contrastive learning for cross-modal fusion. In addition, we introduce a spatial coordinate correction and registration strategy to support multi-slice integration. We demonstrate that stGCL reliably identifies spatial domains, integrates vertical and horizontal tissue slices, and highlight its generalizability across platforms and resolutions.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Aligned cross-modal integration and regulatory heterogeneity characterization of single-cell multiomic data with deep contrastive learning",
    "doi": "10.1186/s13073-025-01586-7",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13073-025-01586-7",
    "authors": [
      "Cheng, Yue",
      "Su, Yanchi",
      "Fan, Yi",
      "Yang, Yuning",
      "Chen, Xingjian",
      "Wang, Fuzhou",
      "Wong, Ka-Chun",
      "Li, Xiangtao"
    ],
    "publicationDate": "2026-01-26",
    "publicationName": "Genome Medicine",
    "contentType": "Article",
    "abstract": "Background Single-cell multi-omics (scMulti-omics) technologies have revolutionized our understanding of cellular functions and interactions by enabling the simultaneous measurement of diverse cellular modalities. Integrating these heterogeneous data types presents significant challenges due to differences in scale, resolution, and biological variability across the omics layers. Traditional computational methods often fail to reconcile these differences, leading to a loss of critical biological variability and subtle intermolecular interactions. Methods To address these challenges, we have developed a single-cell multi-omics deep learning model (scMDCF) based on contrastive learning, tailored for the efficient characterization and integration of scMulti-omics data. scMDCF features a cross-modality contrastive learning module that harmonizes data representations across different omics types, ensuring consistency and preserving data heterogeneity by accommodating information entropy. Furthermore, a cross-modality feature fusion module extracts common low-dimensional latent representations of scMulti-omics data, effectively balancing the diverse characteristics of these data types. Results Extensive empirical studies demonstrate that scMDCF outperforms existing state-of-the-art scMulti-omics models across various types of scMulti-omics data. In particular, scMDCF exhibits advanced analytical capabilities in extracting cell-type-specific peak-gene associations and cis -regulatory elements from SNARE-seq data, and in elucidating immune regulation from CITE-seq data. In a post-BNT162b2 mRNA SARS-CoV-2 vaccination dataset, scMDCF successfully annotates specific vaccine-induced B cell subpopulations, uncovering dynamic interactions and regulatory mechanisms within the immune system post-vaccination. Most importantly, using Alzheimer’s disease-specific data, scMDCF identifies computational minority Microglia and Endothelial cell populations, revealing ELF1 as a putative candidate transcription factor biomarker in Microglia, which potentially influences GTPase activity and may suppresses Alzheimer’s pathology. Conclusions We propose scMDCF, a contrastive learning based framework for single-cell multi-omics integration that harmonizes cross-modality representations while preserving biological heterogeneity. Applications across diverse scMulti-omics datasets demonstrate improved clustering performance, effective batch-effect mitigation, and mechanistic insights into underlying biological processes. Code and reproducible workflows are openly available.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "The DNA dialect: a comprehensive guide to pretrained genomic language models",
    "doi": "10.1038/s44320-025-00184-4",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1038/s44320-025-00184-4",
    "authors": [
      "Veiner, Marcell",
      "Supek, Fran"
    ],
    "publicationDate": "2026-01-19",
    "publicationName": "Molecular Systems Biology",
    "contentType": "Article",
    "abstract": "Following their success in natural language processing and protein biology, pretrained large language models have started appearing in genomics in large numbers. These genomic language models (gLMs), trained on diverse DNA and RNA sequences, promise improved performance on a variety of downstream prediction and understanding tasks. In this review, we trace the rapid evolution of gLMs, analyze current trends, and offer an overview of their application in genomic research. We investigate each gLM component in detail, from training data curation to the architecture, and highlight the present trends of increasing model complexity. We review major benchmarking efforts, suggesting that no single model dominates, and that task-specific design and pretraining data often outweigh general model scale or architecture. In addition, we discuss requirements for making gLMs practically useful for genomic research. While several applications, ranging from genome annotation to DNA sequence generation, showcase the potential of gLMs, their use highlights gaps and pitfalls that remain unresolved. This guide aims to equip researchers with a grounded understanding of gLM capabilities, limitations, and best practices for their effective use in genomics. This Review provides a guide to help researchers gain a clear understanding of the capabilities, limitations, and best practices of genomic language models for their effective use in genomics.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "CLAMP: predicting specific protein-mediated chromatin loops in diverse species with a chromatin accessibility language model",
    "doi": "10.1186/s13059-026-03948-9",
    "url": "",
    "authors": [
      "He, Zhijie",
      "Sun, Yu",
      "Li, Hao",
      "Sun, Canzhuang",
      "Yang, Xianhui",
      "Chen, Hebing",
      "Liao, Mingzhi",
      "Bo, Xiaochen"
    ],
    "publicationDate": "2026-01-19",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "Emerging DNA language models provide powerful tools to address the challenge of accurately predicting chromatin loops, fundamental structures governing 3D genome organization and gene regulation. Here we present CLAMP, which utilizes a deep language model pre-trained on broad cross-species chromatin accessibility data. CLAMP achieves superior performance compared to existing methods in predicting specific protein-mediated loops across 10 species, 18 proteins, and 24 cell types. CLAMP incorporates a novel CoVE explainer that reveals context-dependent genomic feature contributions, providing insights into the features driving predictions. CLAMP predictions effectively identify functionally significant chromatin loops and associated biological pathways.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Deep learning-based multimodal pathogenomics integration for precision cancer prognosis",
    "doi": "10.1186/s12967-026-07682-5",
    "url": "",
    "authors": [
      "Feng, Xiaobing",
      "Song, Ge",
      "Zhang, Ye",
      "Guo, Lu",
      "Jiang, Yian",
      "Gong, Wangang",
      "Feng, Yue",
      "Xu, Chunwei",
      "Yang, Yang",
      "He, Min"
    ],
    "publicationDate": "2026-01-17",
    "publicationName": "Journal of Translational Medicine",
    "contentType": "Article",
    "abstract": "Background Recent studies have revealed valuable prognostic insights in haematoxylin and eosin (H&E)-stained histological sections and transcriptomic profiles, suggesting potential applications in machine learning. However, existing methods lack sufficient intra- and inter-modal interactions, and face challenges in clinical validation due to incomplete multimodal data. Methods We proposed PathoGems (PathoGenomics-based integrative survival prediction), a weakly-supervised, interpretable multimodal learning framework that integrates histology and genomic profiles for precise cancer prognosis prediction. To evaluate the robustness of PathoGems, we initially curated a dataset of 1965 cases across four cohorts from The Cancer Genome Atlas (TCGA), including breast, colorectal, glioblastoma, and esophageal cancers. For external validation, PathoGems was further evaluated on four independent cohorts, consisting of 76 breast cancer and 41 esophageal squamous cell carcinoma cases from Zhejiang Cancer Hospital, as well as 102 colorectal cancer and 58 glioblastoma cases from the Clinical Proteomic Tumor Analysis Consortium (CPTAC). Results PathoGems effectively stratified patients into favorable and unfavorable risk groups, revealing significant differences in histological patterns, genomic features, and overall survival (log-rank test, p  < 0.05). Moreover, the model’s predictions are further supported by visualization and transcriptomic analysis, enhancing interpretability and reliability. Conclusions By fusing histological and clinicogenomic multimodal models, PathoGems will provide a solid foundation for developing an innovative tool that aids clinicians in making informed decisions and selection personalized treatment strategies for cancer patients.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Semantic design of functional de novo genes from a genomic language model",
    "doi": "10.1038/s41586-025-09749-7",
    "url": "https://www.nature.com/articles/s41586-025-09749-7",
    "authors": [
      "Merchant, Aditi T.",
      "King, Samuel H.",
      "Nguyen, Eric",
      "Hie, Brian L."
    ],
    "publicationDate": "2026-01-15",
    "publicationName": "Nature",
    "contentType": "Article",
    "abstract": "By learning a semantics of gene function based on genomic context, the genomic language model Evo autocompletes DNA prompts to generate novel genes encoding protein and RNA molecules with defined activities, whose sequences generalize beyond those found in nature. Generative genomic models can design increasingly complex biological systems^ 1 . However, controlling these models to generate novel sequences with desired functions remains challenging. Here, we show that Evo, a genomic language model, can leverage genomic context to perform function-guided design that accesses novel regions of sequence space. By learning semantic relationships across prokaryotic genes^ 2 , Evo enables a genomic ‘autocomplete’ in which a DNA prompt encoding genomic context for a function of interest guides the generation of novel sequences enriched for related functions, which we refer to as ‘semantic design’. We validate this approach by experimentally testing the activity of generated anti-CRISPR proteins and type II and III toxin–antitoxin systems, including de novo genes with no significant sequence similarity to natural proteins. In-context design of proteins and non-coding RNAs with Evo achieves robust activity and high experimental success rates even in the absence of structural priors, known evolutionary conservation or task-specific fine-tuning. We then use Evo to complete millions of prompts to produce SynGenome, a database containing over 120 billion base pairs of artificial intelligence-generated genomic sequences that enables semantic design across many functions. More broadly, these results demonstrate that generative genomics with biological language models can extend beyond natural sequences.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Gene-biomarker data-driven deep learning model with m-dman for er, pr, her2 enrichment and breast cancer association prediction",
    "doi": "10.1007/s00521-025-11750-0",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-025-11750-0",
    "authors": [
      "Banupriya, N.",
      "Sethukarasi, T."
    ],
    "publicationDate": "2026-01-14",
    "publicationName": "Neural Computing and Applications",
    "contentType": "Article",
    "abstract": "Breast cancer treatment and prognosis depend on accurate classification of hormone receptors (HR), particularly estrogen receptor (ER), progesterone receptor (PR), and human epidermal growth factor receptor 2 (HER2) enrichment status. Using copy number alteration (CNA or predictor gene) data, model predicts ER, PR, HER2 statuses, and classify breast cancer gene association. A new breast cancer classification model uses the Multi-Instance Learning with Deep Multimodal Attention Network (M-DMAN) to analyze gene (CNA) and biomarker data for breast cancer association. To estimate receptor enrichment status for each sample, the model uses gene expression profiles and biomarkers like ER, PR, and HER2. Predictions are used to classify breast cancer-associated samples. The M-DMAN model blends multimodal data with an attention mechanism that highlights the most informative aspects to fuse gene and biomarker data for accurate prediction. The model achieved 96.23% classification accuracy after extensive labelled data training. Statistics confirm the model’s stability and reliability in identifying breast cancer-associated samples. Multimodality and attention-based feature selection improve interpretability, making the model ideal for complicated medical datasets with essential gene and biomarker interactions. M-DMAN’s biomarker-driven breast cancer prediction capability makes it a promising tool for oncology clinical diagnostics and decision-making.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "A deep learning and large language hybrid workflow for omics interpretation",
    "doi": "10.1038/s41551-025-01576-5",
    "url": "https://www.nature.com/articles/s41551-025-01576-5",
    "authors": [
      "Tang, Dachao",
      "Zhang, Chi",
      "Zhang, Weizhi",
      "Lu, Funian",
      "Xiao, Leming",
      "Huang, Xinhe",
      "Shao, Jiangyi",
      "Liu, Dan",
      "Fu, Shanshan",
      "Zhao, Miaoying",
      "Zhang, Luoying",
      "Jia, Da",
      "Shen, Han-Ming",
      "Sun, Chaoyang",
      "Chen, Gang",
      "Liu, Bin",
      "Peng, Di",
      "Xue, Yu"
    ],
    "publicationDate": "2026-01-08",
    "publicationName": "Nature Biomedical Engineering",
    "contentType": "Article",
    "abstract": "A computational workflow, LyMOI, uses LLM, knowledge graphs and other tools to facilitate ’omic analysis and hypothesis generation related to autophagy. Profiling molecular panorama from massive omics data identifies regulatory networks in cells but requires mechanistic interpretation and experimental follow up. Here we combine deep learning and large language model reasoning to develop a hybrid workflow for omics interpretation, called LyMOI. LyMOI incorporates GPT-3.5 for biological knowledge reasoning and a large graph model with graph convolutional networks (GCNs). The large graph model integrates evolutionarily conserved protein interactions and uses hierarchical fine-tuning to predict context-specific molecular regulators from multi-omics data. GPT-3.5 then generates machine chain-of-thought (CoT) to mechanistically interpret their roles in biological systems. Focusing on autophagy, LyMOI mechanistically interprets 1.3 TB transcriptomic, proteomic and phosphoproteomic data and expands the knowledge of autophagy regulators. We also show that LyMOI highlights two human oncoproteins, CTSL and FAM98A, for enhancing autophagy upon treatment with disulfiram (DSF), an antitumour agent. Silencing these genes in vitro attenuates DSF-mediated autophagy and suppresses cancer cell proliferation. Strikingly, DSF treatment with Z-FY-CHO, a CTSL-specific inhibitor previously used for preventing SARS-CoV-2 infection, potently inhibits tumour growth in vivo.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Emerging computational intelligence based techniques for lung cancer diagnosis and classification on chest CT scan images: a comprehensive survey",
    "doi": "10.1007/s10462-025-11374-9",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10462-025-11374-9",
    "authors": [
      "Kumari, Pankaj",
      "Goel, Lavika"
    ],
    "publicationDate": "2026-01-07",
    "publicationName": "Artificial Intelligence Review",
    "contentType": "Article",
    "abstract": "Worldwide lung cancer is a significant reason for death resulting from cancer with early diagnosis crucial for enhancing patient results. This comprehensive survey looks at the most recent developments in methods for detecting lung cancer by using chest CT scan images. The study describes a broad variety of approaches includes methods for machine learning such random forests support vector machines logistic regression and k-nearest neighbors in addition to deep learning frameworks such as variational autoencoders recurrent neural networks convolutional neural networks and generative adversarial networks. Additionally the survey explores hybrid models that combine deep learning and machine learning with nature-inspired optimization techniques to enhance performance. All the techniques discussed in this paper mainly focus on the diagnosis of NSCLC i.e. non-small cell lung cancer as it is more prevalent. The paper also reviews multiple advanced techniques used in diagnosis of lung cancer, including 3D-CNN i.e. Convolutional Neural Networks, multimodal logistic regression models and Cyclic Variational Autoencoders. It highlights key publicly available datasets frequently used in this research area such as LIDC-IDRI (Lung Image Database Consortium and Image Database Resource Initiative), LUNA16 (Lung Nodule Analysis 2016), the Kaggle lung cancer dataset, NSCLC Radiogenomics and the NIH (National Institutes of Health) chest X-ray database. This survey provides a detailed comparison of each technique, describing their advantages, limitations, and reported performance metrics, especially in terms of classification accuracy. Transfer learning with Vision Transformer achieves the highest accuracy of 94.6%, while 3D Convolutional Neural Network (3D -CNN) achieves an accuracy of 93.7%, both of which are showcasing highest performance on applicable datasets. Furthermore, the research demonstrates the potential of emerging techniques like federated learning and explainable AI in addressing challenges pertaining to data privacy and model interpretability. This survey paper reviews several techniques and finds that deep learning is the most extensively researched area in lung cancer diagnosis. This approach is not only widely used but also exhibits notable success in identifying and categorizing lung cancer with a high degree of accuracy.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "The interpretable multimodal dimension reduction framework SpaHDmap enhances resolution in spatial transcriptomics",
    "doi": "10.1038/s41556-025-01838-z",
    "url": "https://www.nature.com/articles/s41556-025-01838-z",
    "authors": [
      "Tang, Junjie",
      "Chen, Zihao",
      "Qian, Kun",
      "Huang, Siyuan",
      "He, Yang",
      "Yin, Shenyi",
      "He, Xinyu",
      "Ye, Buqing",
      "Zhuang, Yan",
      "Meng, Hongxue",
      "Xi, Jianzhong Jeff",
      "Xi, Ruibin"
    ],
    "publicationDate": "2026-01-06",
    "publicationName": "Nature Cell Biology",
    "contentType": "Article",
    "abstract": "Tang, Chen, Qian et al. present a multimodal, interpretable dimension reduction framework called SpaHDmap, which leverages histology images and enhances the resolution of spatial transcriptomics, thus enabling the dissection of complex tissue structures. Spatial transcriptomics (ST) technologies revolutionized tissue architecture studies by capturing gene expression with spatial context. However, high-dimensional ST data often have limited spatial resolution and exhibit considerable noise and sparsity, posing substantial challenges in deciphering subtle spatial structures and underlying biological activities. Here we introduce ‘spatial high-definition embedding mapping’ (SpaHDmap), an interpretable dimension reduction framework that enhances spatial resolution by integrating ST gene expression with high-resolution histology images. SpaHDmap incorporates non-negative matrix factorization into a deep learning framework, enabling the identification of high-resolution spatial metagenes (embeddings). Furthermore, SpaHDmap can simultaneously analyse multiple samples and is compatible with various types of histology images. Extensive evaluations on synthetic, public and newly sequenced ST datasets from various technologies and tissue types demonstrate that SpaHDmap can effectively produce high-resolution spatial metagenes, and detect refined spatial structures. SpaHDmap represents a powerful approach for integrating ST data and histology images, offering deeper insights into complex tissue structures and functions.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Molecular and multimodal biomarkers in Moyamoya disease: from pathogenic mechanisms to clinical translation",
    "doi": "10.1186/s40001-025-03769-9",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s40001-025-03769-9",
    "authors": [
      "Li, Jinghong",
      "Zhang, Lilei",
      "Zhan, Yanqiang",
      "Han, Xiaohua",
      "Deng, Chunchu"
    ],
    "publicationDate": "2026-01-03",
    "publicationName": "European Journal of Medical Research",
    "contentType": "Article",
    "abstract": "Moyamoya disease (MMD) is a chronic, progressive cerebrovascular condition marked by narrowing or blockage of the terminal segments of the internal carotid arteries, resulting in ischemic and hemorrhagic strokes. Its pathogenesis involves a multifactorial interplay between genetic susceptibility, immune–inflammatory dysregulation, endothelial dysfunction, and aberrant vascular remodeling, influenced by non-genetic and environmental factors. Despite considerable research progress, clinically useful biomarkers remain limited, lacking sufficient sensitivity and specificity for predicting disease onset, progression, or treatment response. Current management relies primarily on surgical revascularization, which restores cerebral perfusion but does not address underlying biological mechanisms, while pharmacological interventions remain largely empirical and nonspecific. This review systematically searched PubMed and Web of Science up to September 2025 using combinations of “Moyamoya disease” and “biomarker” with “genomics,” “transcriptomics,” “proteomics,” “metabolomics,” “neuroimaging,” “artificial intelligence,” and “machine learning.” We summarize recent advances in genetic and molecular biomarker discovery, including the identification of RNF213 as a major susceptibility gene in East Asian populations, alongside emerging roles of variants in MTHFR , DIAPH1 , and GUCY1A3 . Beyond genomics, proteomic and metabolomic profiling have revealed dysregulation of vascular repair pathways, extracellular-matrix remodeling, and lipid–amino acid metabolism, offering new insights into disease heterogeneity and progression. Noncoding RNAs and exosome-derived biomarkers—such as plasma miR-512-3p, miR-328-3p, and miR-125b-5p—have shown potential as minimally invasive tools for diagnosis and monitoring, linking posttranscriptional regulation to vascular pathophysiology. Parallel advances in neuroimaging biomarkers, enhanced by artificial intelligence (AI), are enabling the integration of morphological and hemodynamic data with molecular findings. Deep learning-based models trained on digital subtraction angiography (DSA), computed tomography angiography (CTA), and retinal imaging have achieved diagnostic accuracies exceeding 90%, while multimodal integration approaches are beginning to correlate imaging phenotypes with genetic and metabolic profiles. Future research must transcend single-omics paradigms to establish integrative, multidimensional frameworks that connect genetic variation to cellular function, vascular remodeling, and clinical phenotype. Progress will depend on international multicenter collaboration, open-access biomarker databases, and the incorporation of explainable AI to bridge discovery and clinical application. Together, these developments may usher in biomarker-driven precision diagnosis and personalized therapy for MMD.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Deep Learning in Oncology: A Multi-modality Survey of Diagnostic and Prognostic Models",
    "doi": "10.1007/978-3-032-13203-1_22",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-13203-1_22",
    "authors": [
      "Shaikh, Nishat",
      "Shah, Parth",
      "Patel, Bimal"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Information Systems for Intelligent Systems",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Deep learning has revolutionized oncology by enabling unprecedented integration of multimodal data for cancer diagnosis and prognosis. This comprehensive survey presents the first systematic analysis of deep learning architectures across four major cancer types (lung, breast, skin, and brain) through three critical data modalities: medical imaging, histopathology, and genomics. Our unique contribution lies in providing a structured taxonomy of multimodal fusion strategies and identifying critical architectural innovations that have emerged in the 2021–2025 period. We systematically analyze 60+ recent studies, revealing that attention-based mechanisms and Transformer architectures demonstrate superior performance in handling heterogeneous cancer data compared to traditional CNN approaches. Our analysis uncovers three key research gaps: (1) limited interpretability frameworks for clinical deployment, (2) insufficient standardization across institutions, and (3) scalability challenges for real-world implementation. This survey uniquely bridges the gap between theoretical deep learning advances and practical oncological applications by proposing a unified framework for multimodal cancer analysis. We provide actionable insights for researchers and clinicians, establishing clear directions for future development in AI-driven cancer care that addresses both technical innovation and clinical translation requirements.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Personalized Medicine Through AI-Driven Imaging",
    "doi": "10.1007/978-3-032-02963-8_7",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02963-8_7",
    "authors": [
      "Doke, Rohit",
      "Rajguru, Jeevan",
      "Vinchurkar, Kuldeep"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "AI for Medical Image Analysis",
    "contentType": "Chapter",
    "abstract": "Application of artificial intelligence in medical imaging has transformed patient-specific diagnosis and disease management processes. AI-imaging, which consists of sophisticated algorithms such as machine learning, deep learning, and natural language processing, increases accuracy in detecting diseases, segmentation, classification, and outcome prediction. Application of AI in imaging technologies such as MRI, CT scans, ultrasound, and PET scans improves diagnostic accuracy, operational effectiveness, and decision-making. AI-assisted radiomics measures imaging biomarkers to perform non-invasive diagnosis and treatment planning. The combination of AI with genomics and multi-omics information is revolutionary to create extremely personalized disease models and therapeutic interventions. This book chapter explores the real-time applications of AI in neuroimaging, cardiac, chest, breast, and musculoskeletal imaging are also considered. AI deployment in personalized imaging is, however, hindered by algorithmic bias, data privacy issues, clinical mistrust, and regulatory challenges. Methods to overcome these obstacles are XAI, standardized procedures, and collaborative design processes. AI-based imaging is a key step towards precision diagnosis and personalized care, set to revolutionize the future of modern medicine.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Artificial Intelligence (AI)-Assisted Treatment of Breast Cancer",
    "doi": "10.1007/978-981-95-3682-5_18",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-3682-5_18",
    "authors": [
      "Mubasshira",
      "Rahman, Md Mahbubur",
      "Mondal, Jyotirmoy",
      "Parvez, Md Mahadi Hassan",
      "Uddin, Md Nizam",
      "Akter, Lisa"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Nano Theragnostics in Breast Cancer",
    "contentType": "Chapter",
    "abstract": "Breast cancer ranks among the leading dangerous conditions that affect millions of women throughout the world. The three key elements necessary to enhance breast cancer survival rates include early detection followed by accurate diagnosis, and prompt treatment. Modern healthcare developments through Artificial Intelligence (AI) have introduced substantial benefits for breast cancer therapy during the last several years. The analysis evaluates the role of AI technology for breast cancer diagnosis, as well as treatment strategy planning and patient surveillance tasks. The analysis of images using machine learning and deep learning AI methods like Support Vector Machines (SVMs), Convolutional Neural Networks (CNNs), Random Forest (RF) applications, and Extreme Gradient Boosting (XGBoost) produces high analysis accuracy for mammography and ultrasound tests and histopathology examinations. AI uses large amounts of data in order to forecast and individualize treatment. It enhances accuracy in surgical, immunotherapy, radiation and chemotherapy and limits the side effects. Other innovations used in advancing personalized medicine include the idea of nanoradiogenomics. But there are still hurdles, such as validation in clinical settings and data security, and explainable AI. AI processes big data to make predictions, but its effective utilization and performance should be guided by ethical principles and incorporated in clinical workflows to ensure responsible use in healthcare. The chapter also demonstrates how AI works as a supportive tool for healthcare providers instead of replacing their medical skills by enhancing clinical workflow performance, along with diagnostic precision and healthcare quality in breast cancer care.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Mapping and Interpreting RNA Modifications",
    "doi": "10.1007/978-981-95-5183-5_10",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-5183-5_10",
    "authors": [
      "Krohannon, Alexander",
      "Lanning, Rebekah Eileen",
      "Thuthika, Prasanth Kumar",
      "Thorat, Swaraj Madan",
      "Janga, Sarath Chandra"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Plant Transcriptomics and Epitranscriptomics",
    "contentType": "Chapter",
    "abstract": "RNA modifications constitute a dynamic and multifaceted layer of post-transcriptional regulation with profound implications for cellular function, development, and disease. Once considered rare curiosities, over 170 distinct RNA modifications are now recognized as integral components of gene expression regulation, affecting processes from splicing and translation to RNA stability and localization. This chapter offers a comprehensive overview of the historical evolution, methodological advancements, and future directions in RNA modification detection. It traces the field’s progress from classical chemical assays through the genomics era to modern direct sequencing and machine learning-driven approaches. Emphasis is placed on the convergence of high-throughput experimental platforms and computational innovations—including deep learning, signal processing, and multi-modal integration—that are transforming epitranscriptomic research. The chapter also explores the biological interpretation of RNA modifications, focusing on positional, structural, and comparative analyses across different biological contexts. Special attention is given to databases and bioinformatic resources essential for cataloging and analyzing modifications. Together, these developments are positioning RNA modification studies as a central component of plant genomics and metagenomics, with promising implications for both basic biology and therapeutic discovery.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "AI for Preclinical and Translational Research",
    "doi": "10.1007/978-3-032-10277-5_3",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-10277-5_3",
    "authors": [
      "Shaikh, Khalid",
      "Thanki, Rohit",
      "Shaikh, Affaan"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Artificial Intelligence in Drug Discovery and Development",
    "contentType": "Chapter",
    "abstract": "This chapter explores the transformative role of artificial intelligence (AI) in preclinical and translational research, focusing on its applications in drug development, predictive toxicology, pharmacokinetics, biomarker identification, and multi-omics integration. AI technologies such as machine learning (ML), deep learning (DL), and natural language processing (NLP) are revolutionizing biomedical research by enhancing decision-making, reducing costs, and accelerating timelines. Key advancements include AI-driven toxicity prediction models like DeepTox, pharmacokinetics frameworks such as Chemi-Net, and multi-omics integration tools like MOFA and DeepMOCCA. These innovations enable precise biomarker discovery, patient stratification, and personalized medicine. Despite these achievements, challenges such as data quality, model interpretability, regulatory compliance, and ethical considerations persist. The chapter emphasizes the need for collaborative efforts to ensure AI’s ethical, explainable, and inclusive application in biomedical research, paving the way for improved translational success and public health outcomes. ​.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation.",
    "doi": "10.1007/978-3-032-11317-7_33",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-11317-7_33",
    "authors": [
      "Panaccione, Francesca Pia",
      "Sgaravatti, Carlo",
      "Pinoli, Pietro"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Image Analysis and Processing - ICIAP 2025 Workshops",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN .",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Harnessing the power of single-cell large language models with parameter-efficient fine-tuning using scPEFT",
    "doi": "10.1038/s42256-025-01170-z",
    "url": "https://www.nature.com/articles/s42256-025-01170-z",
    "authors": [
      "He, Fei",
      "Fei, Ruixin",
      "Krull, Jordan E.",
      "Yu, Yang",
      "Zhang, Xinyu",
      "Wang, Xianyu",
      "Cheng, Hao",
      "Gao, Mingyue",
      "Su, Li",
      "Chen, Yibo",
      "Li, Jinpu",
      "Jin, Baichuan",
      "Chang, Yuzhou",
      "Ma, Anjun",
      "Ma, Qin",
      "Xu, Dong"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Nature Machine Intelligence",
    "contentType": "Article",
    "abstract": "Single-cell large language models (scLLMs) capture essential biological insights from vast single-cell atlases but struggle in out-of-context applications, where zero-shot predictions can be unreliable. To address this, here we introduce a single-cell parameter-efficient fine-tuning (scPEFT) framework that integrates learnable, low-dimensional adapters into scLLMs. By freezing the backbone model and updating only the adapter parameters, scPEFT efficiently adapts to specific tasks using limited custom data. This approach mitigates catastrophic forgetting, reduces parameter tuning by over 96% and decreases GPU memory usage by more than half, thus substantially enhancing the accessibility of scLLMs for resource-constrained researchers. When validated across diverse datasets, scPEFT outperformed zero-shot models and traditional fine-tuning in disease-specific, cross-species and undercharacterized cell population tasks. Its attention-mechanism analysis identified COVID-related genes associated with specific cell states and uncovered unique blood cell subpopulations, demonstrating the capacity of scPEFT for condition-specific interpretations. These findings position scPEFT as an efficient solution for enhancing the utility of scLLMs in general single-cell analyses. He et al. present a parameter-efficient fine-tuning method for single-cell language models that improves performance on unseen diseases, treatments and cell types.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "AUTOENCODIX: a generalized and versatile framework to train and evaluate autoencoders for biological representation learning and beyond",
    "doi": "10.1038/s43588-025-00916-4",
    "url": "https://www.nature.com/articles/s43588-025-00916-4",
    "authors": [
      "Joas, Maximilian Josef",
      "Jurenaite, Neringa",
      "Praščević, Dušan",
      "Scherf, Nico",
      "Ewald, Jan"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Nature Computational Science",
    "contentType": "Article",
    "abstract": "An open-source framework called AUTOENCODIX is developed to enable reproducible comparison of vanilla, variational, stacked, ontology-based and cross-modal autoencoders. In recent years, autoencoders, a family of deep learning-based methods for representation learning, are advancing data-driven research owing to their variability and nonlinear power for multimodal data integration. Despite their success, current implementations lack standardization, versatility, comparability and generalizability. Here we present AUTOENCODIX, an open-source framework, designed as a standardized and flexible pipeline for preprocessing, training and evaluation of autoencoder architectures. These architectures, such as ontology-based and cross-modal autoencoders, provide key advantages over traditional methods by offering explainability of embeddings or the ability to translate across data modalities. We apply the method to datasets from pan-cancer studies (The Cancer Genome Atlas) and single-cell sequencing as well as in combination with imaging. Our studies provide important user-centric insights and recommendations to navigate through architectures, hyperparameters and important tradeoffs in representation learning. These include the reconstruction capability of input data, the quality of embedding for downstream machine learning models and the reliability of ontology-based embeddings for explainability.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Scouter predicts transcriptional responses to genetic perturbations with large language model embeddings",
    "doi": "10.1038/s43588-025-00912-8",
    "url": "https://www.nature.com/articles/s43588-025-00912-8",
    "authors": [
      "Zhu, Ouyang",
      "Li, Jun"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Nature Computational Science",
    "contentType": "Article",
    "abstract": "A lightweight AI method called Scouter that predicts genome-wide transcriptional responses to single- and two-gene perturbations using large language model embeddings is presented and achieves substantially higher accuracy than leading approaches. Gene perturbation experiments followed by transcriptomic profiling are vital for uncovering causal gene effects. However, their limited throughput leaves many perturbations of interest unexplored. Computational methods are therefore needed to predict genome-wide transcriptional responses to gene perturbations that were not experimentally assayed within a given dataset. Existing approaches often rely on Gene Ontology graphs to encode prior knowledge, but their predictive power and applicability are constrained by the graphs’ sparsity and incomplete gene coverage. Here we present Scouter, a computational method that uses gene embeddings generated by large language models and a lightweight compressor–generator neural network. Scouter accurately predicts transcriptional responses to both single- and two-gene perturbations, reducing errors from state-of-the-art Gene Ontology-term-based methods (GEARS and biolord) by half or more. Unlike recent approaches based on fine-tuning gene expression foundation models, Scouter offers substantially better accuracy and greater accessibility; it requires no pretraining and runs efficiently on standard hardware.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A Multimodal Fusion Framework Employing Full-Stage Attention for Survival Prediction",
    "doi": "10.1007/978-981-95-3052-6_15",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-3052-6_15",
    "authors": [
      "Liu, Aolei",
      "Guo, Junkang",
      "Wang, Yuhang",
      "Liu, Jian",
      "Tian, Huiyuan",
      "Qin, Tao",
      "Xu, Hangrui",
      "Wei, Haiyan"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Knowledge Science, Engineering and Management",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Current approaches to multimodal survival analysis based on pathology and genomics often apply attention mechanisms at a single stage, thereby missing fine-grained intra-modal details and cross-modal synergies. We propose a novel framework— M ultimodal F usion F ramework with F ull-stage A ttention (MFF-FA)—which integrates attention across three stages: feature extraction, modality alignment, and modality fusion. Specifically, we introduce En-UNI for pathology image sampling and representation, and employ attention modules to enhance latent genomic feature interactions. A convolution-based cross-attention module is further developed to model inter-modal correlations between pathology and genomics. Finally, a gating-attention fusion strategy is applied to retain modality-specific characteristics while enhancing their integration. Comparative evaluations demonstrate that MFF-FA outperforms existing state-of-the-art models in predictive accuracy for cancer survival analysis.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Enhancing Metastatic Breast Cancer Prognostics for Integrated Multi-modal Data Using Deep Learning and Generative Adversarial Networks",
    "doi": "10.1007/978-3-032-02831-0_9",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02831-0_9",
    "authors": [
      "Kaur, Sugandha",
      "Kaur, Manpreet",
      "Khanna, Ashish"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Proceedings of Data Analytics and Management",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Breast cancer is the most prevalent malignancy affecting women globally that poses a significant health burden, contributing to cancer-related mortality. Even though early detection and treatment strategies have improved over the years, Metastatic Breast Cancer (MBC) still remains one of the difficult cancers to treat. This is primarily due to the complexity of prediction and understanding its progression. Traditional prognostic models often depend on single-modal data, such as clinical features, and imaging scans. However, these approaches often fail to capture the complex biological and clinical landscape of the disease. Recent technological advancements have enabled the collection of diverse multi-modal data that can provide a comprehensive molecular and phenotypic characterization of breast tumors. This study leverages the power of deep learning, specifically a Convolutional Neural Network combined with Generative Adversarial Network (GAN) and Transfer Learning, applied to multi-modal data from The Cancer Genome Atlas BRCA (TCGA-BRCA) multi-omics dataset to enhance metastatic breast cancer prediction. Our model achieved an accuracy of 97.4%, demonstrating its potential for improved prognostication. Furthermore, a comparative analysis of state-of-the-art approaches from the past decade (2013–2024) was conducted to contextualize our findings and highlight the advancements offered by our multimodal deep learning approach.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "ActiveVisium: Leveraging Active Learning to Enhance Manual Pathologist Annotation in 10x Visium Spatial Transcriptomics Experiments",
    "doi": "10.1007/978-3-032-06118-8_27",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-06118-8_27",
    "authors": [
      "Vasiljević, Jelica",
      "Veiga, Ines Berenguer",
      "Hahn, Kerstin",
      "Schwalie, Petra",
      "Valdeolivas, Alberto"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Machine Learning and Knowledge Discovery in Databases. Applied Data Science Track",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Spatial transcriptomics (ST) technologies offer valuable insights into tissue organisation by capturing gene expression within its spatial context. Among these, 10x Visium stands out for its capacity to integrate gene expression profiles with histological images, facilitating multi-modal tissue analysis. However, comprehensive analysis requires manual pathologist’s annotations at the capture spot level, a labour-intensive and time-consuming process that demands a significant amount of pathologists’ time. Given the scale of studies involving multiple ST samples, manual annotation becomes impractical, and no automated solutions currently exist. To address this, we introduce ActiveVisium, an active learning framework designed to enhance spot-level annotation in 10x Visium datasets. To the best of our knowledge, ActiveVisium is the first framework to leverage tissue morphology and, optionally, gene expression data to automate large-scale spot annotation while selecting the most informative ones for manual labelling. Furthermore, this approach enables transfer learning across similar samples, thereby reducing annotation time for entire studies. Evaluations across breast cancer, colorectal cancer, and healthy kidney samples demonstrate that ActiveVisium has the potential to significantly improve annotation efficiency and consistency. All code and data are publicly available.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "TileDVP: Decoding the Tissue Proteome from H&E Images",
    "doi": "10.1007/978-3-032-05479-1_3",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-05479-1_3",
    "authors": [
      "Mathian, Émilie",
      "Oldenburg, Lukas",
      "Chelebian, Eduard",
      "Schweizer, Lisa",
      "Zonderland, Gijs",
      "Egebjerg, Kristian",
      "Ummat, Ishani",
      "Mund, Andreas",
      "Strauss, Maximillian T."
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Clinical Image-Based Procedures",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Recent advances in multimodal deep learning have successfully begun to link molecular data with tissue morphology. To date, this work has largely focused on transcriptomics, a limited surrogate for protein expression. The direct prediction of proteins, the functional endpoints of gene expression, remains underexplored, largely due to the difficulty in generating spatially resolved proteomic data. Early efforts to predict proteomic data from tissue morphology were hindered by low specificity and limited multiplexing capacity, constraints inherent to immunohistochemistry and multiplexed immunofluorescence techniques. This proof-of-concept study presents a novel data generation pipeline to address these throughput and specificity challenges and decode the proteome from H&E slides via high-throughput tile-level mass spectrometry profiling. This approach enables a direct one-to-one correspondence between histological features and proteomic measurements, which is an essential prerequisite for training robust foundation models. By applying this pipeline to gastric cancer biopsies, the study demonstrated that morphologically distinct clusters corresponded to distinct proteomic profiles. Notably, tumor regions were enriched for clinically relevant markers such as HMGB1, LGALS3, and ERBB2, all of which are associated with poor prognosis. This work establishes the foundation for a new generation of AI-driven proteomics, demonstrating that routine histological images contain sufficient information to predict thousands of proteins across diverse biological conditions. TileDVP represents a paradigm shift toward accessible, high-throughput spatial proteomics that could transform biomarker discovery and precision medicine applications.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "GE2Hist: Generating Histology Images from Single-Cell Gene Expression via Cross-Modal Generative Network",
    "doi": "10.1007/978-3-032-05141-7_24",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-05141-7_24",
    "authors": [
      "Cai, Hongmin",
      "Ji, Boan",
      "Cai, Shangyan",
      "Liao, Yi",
      "Chen, Jiazhou",
      "Huang, Weitian"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Histological images are essential in biomedical research and diagnosis, extending beyond detailed cell and tissue morphology to provide an intuitive view of the cellular microenvironment and spatial relationships. While single-cell gene expression data reveal molecular distinctions in cell states, their complexity obscures cellular interactions and spatial organization. To overcome this, reconstructing histological images from large-scale single-cell data is essential for intuitively visualizing spatial architecture. This paper proposes a single-cell-level histological image generation method that derives cell state representations from gene expression data using a single-cell foundation model. A conditional diffusion model is leveraged to generate histological images, accurately reconstructing the cellular microenvironment and spatial cell type distribution. By decoupling cellular state into two components, cell type and microenvironment, we propose two complementary approaches for generating pathology images, one conditioned on scRNA-seq data and the other on cell type. Our approach successfully generates high-quality histological images of human breast and colon cancer tissues, capturing key spatial features such as cell density, compositional distribution, and cell spacing within tissues.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Teaching Pathology Foundation Models to Accurately Predict Gene Expression with Parameter Efficient Knowledge Transfer",
    "doi": "10.1007/978-3-032-04981-0_57",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04981-0_57",
    "authors": [
      "Pan, Shi",
      "Chen, Jianan",
      "Secrier, Maria"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Gene expression profiling provides critical insights into cellular heterogeneity, biological processes, and disease mechanisms. There has been an increasing interest in computational approaches that can predict gene expression directly from digitalized histopathology images. While image foundation models have shown promise in a variety of pathology downstream analysis, their performances on gene expression prediction are still limited. Explicitly incorporating information from the transcriptomic models can help image models address domain shift, yet the fine-tuning and alignment of foundation models can be expensive. In this work, we propose Parameter Efficient Knowledge trAnsfer (PEKA), a novel framework that leverages Block-Affine Adaptation and integrates knowledge distillation and structure alignment losses for cross-modal knowledge transfer. We evaluated PEKA for gene expression prediction using multiple spatial transcriptomics datasets (comprising 206,123 image tiles with matched gene expression profiles) that included various types of tissue. PEKA achieved at least 5% performance improvement over baseline foundation models while also outperforming alternative parameter-efficient fine-tuning strategies. We have released the code, datasets and aligned models at Github to facilitate broader adoption and further development for parameter efficient model alignment.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Inferring Super-Resolved Gene Expression by Integrating Histology Images and Spatial Transcriptomics with HISTEX",
    "doi": "10.1007/978-3-032-05169-1_29",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-05169-1_29",
    "authors": [
      "Xue, Shuailin",
      "Wang, Changmiao",
      "Fan, Xiaomao",
      "Min, Wenwen"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "The groundbreaking development of spatial transcriptomics (ST) enables researchers to map gene expression across tissues with spatial precision. However, current next-generation sequencing methods, which theoretically cover the entire transcriptome, face limitations in resolving spatial gene expression at high resolution. The recently introduced Visium HD technology offers a balance between sequencing depth and spatial resolution, but its complex sample preparation and high cost limit its widespread adoption. To address these challenges, we introduce HISTEX, a multimodal fusion approach that leverages a bidirectional cross-attention mechanism and a general-purpose foundation model. HISTEX integrates spot-based ST data with histology images to predict super-resolution (SR) spatial gene expression. Experimental evaluations demonstrate that HISTEX outperforms state-of-the-art methods in accurately predicting SR gene expression across diverse datasets from multiple platforms. Moreover, experimental validation underscores HISTEX’s potential to generate new biological insights. It enhances spatial patterns, enriches biologically significant pathways, and facilitates the SR annotation of tissue structures. These findings highlight HISTEX as a powerful tool for advancing ST research. Our source code is available at: https://github.com/wenwenmin/HISTEX .",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Thread the Needle: Genomics-Guided Prompt-Bridged Attention Model for Survival Prediction of Glioma Based on MRI Images",
    "doi": "10.1007/978-3-032-04981-0_59",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04981-0_59",
    "authors": [
      "Zhong, Yi",
      "Zheng, Xubin",
      "Shen, Xiongri",
      "Wang, Jiaqi",
      "Zhao, Leilei",
      "Song, Zhenxi",
      "Zhang, Zhiguo"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Glioma remains one of the most lethal malignancy, making accurate prognosis crucial for personalized treatment and improved patient outcome. Existing models based on non-invasive magnetic resonance imaging (MRI) offer convenience, but they suffer from the poor performance and generalizability compared to genomic biomarkers, limiting their clinical adoption. Genomic biomarkers, such as IDH mutation and 1p/19q co-deletion, provide superior prognostic value but are restricted by their reliance on invasive surgical sampling. In this study, we hypothesize that these genomic biomarkers can guide the development of more robust MRI-based prognostic models, and propose a genomics-guided prompt learning framework that leverages both MRI and transcriptomic data to enhance survival prediction. Specifically, we introduce a novel visual modeling strategy for comprehensive glioma MRI representation and a Prompt-bridged Attention mechanism that can fuse multiple modalities during training and enhance visual representations during inference. Experimental results demonstrate that our proposed method achieves c-indeces of 0.6709 and 0.6904 on UCSF-PDGM and TCGA-GBM datasets, respectively, with highly significant p-values of $$5.27\\times 10^{-14}$$ 5.27 × 10 - 14 and $$6.72\\times 10^{-7}$$ 6.72 × 10 - 7 . These results substantially outperform existing methods, presenting a promising step toward reliable and non-invasive glioma prognosis prediction.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Deep Association Multimodal Learning for Zero-Shot Spatial Transcriptomics Prediction",
    "doi": "10.1007/978-3-032-04978-0_13",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04978-0_13",
    "authors": [
      "Zhou, Yijing",
      "Lu, Yadong",
      "Li, Qingli",
      "Li, Xinxing",
      "Wang, Yan"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Spatial transcriptomics enables localized gene expression profiling within histological regions. Current supervised methods struggle to infer patterns for novel gene types beyond their training scope, while existing zero-shot frameworks partially address this by incorporating gene semantics, the “independent learning” paradigms hamper their usage in zero-shot gene expression prediction. Specifically, they learn tissue morphology and gene semantics (inter-modality) independently, and treat gene functions (intra-modality) as independent entities. In this paper, we present a deep association multimodal framework which bridges pathological image with gene functionality semantics for zero-shot expression prediction. Concretely, our framework achieves generalized expression prediction by integrating nuclei-aware spatial modeling that preserves tissue microarchitecture, cross-modal alignment of pathological features with gene functionality semantics via iterative vision-language prompt learning, and gene interaction modeling that dynamically captures relationships across gene descriptions. On standard benchmark datasets, we demonstrate competitive zero-shot performance compared to other competitors ( e.g. , outperforms 16.3 $$\\%$$ % in mean Pearson Correlation Coefficient on cSCC dataset), and we show clinical interpretability of our method. Codes is publicly available at https://github.com/DeepMed-Lab-ECNU/ALIGN-ST .",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Language of Stains: Tokenization Enhances Multiplex Immunofluorescence and Histology Image Synthesis",
    "doi": "10.1007/978-3-032-04965-0_26",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04965-0_26",
    "authors": [
      "Sims, Zachary",
      "Govindarajan, Sandhya",
      "Mills, Gordon B.",
      "Eksi, Ece",
      "Chang, Young Hwan"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Multiplex tissue imaging (MTI) is a powerful tool in cancer research, allowing spatially resolved, single-cell phenotype analysis. However, MTI platforms face challenges such as high costs, tissue loss, lengthy acquisition times, and complex analysis of large, multichannel images with batch effects. To address these challenges, we propose a novel computational method to model the interactions between dozens of panel markers and Hematoxylin & Eosin (H&E) staining, enabling in-silico generation of marker stains. This approach reduces the reliance on experimentally measured markers, bridging low-cost H&E data with MTI’s high-content information. Our approach uses a two-stage framework for channel-wise bioimage synthesis: first, vector quantization learns a visual token vocabulary, then a bidirectional transformer infers missing markers through masked language modeling. Comprehensive benchmarking across different MTI platforms and tissue types demonstrates the effectiveness of our method in improving marker prediction while maintaining biological relevance. This advance makes high-dimensional multiplex tissue imaging more accessible and scalable, supporting deeper insights and potential clinical applications in cancer research.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "MoST-IG: Morphology-Guided Spatial Transcriptomics Integration via Visual-Genomic Graph Optimal Transport",
    "doi": "10.1007/978-3-032-05162-2_47",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-05162-2_47",
    "authors": [
      "Yu, Liting",
      "Ma, Tao",
      "Zhao, Weiqin",
      "Liang, Zhuo",
      "Yu, Lequan"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Spatial transcriptomics (ST) is crucial for understanding cellular heterogeneity and tissue organization. However, integrating spatial transcriptomics across multiple slices remains challenging for downstream analyses, as ST slices may exhibit significant batch effects. Current methods mostly depend on forced integration via contrastive learning, which may ignore the inherent biological heterogeneity, thus impacting the performance of downstream analyses. To address these challenges, we introduce MoST-IG , a multimodal framework for morphology-guided multi-slice ST integration. MoST-IG comprises two key components: (1) Cross-modal alignment between histology prior and ST. We integrate histological patterns derived from the pathological foundation model with ST using our proposed Visual-Genomic Graph Optimal Transport (VG-GOT) module. This visual-genomic alignment preserves biological heterogeneity through morphology-guided regularization while enriching the spatial context of ST data with morphological features to provide a more discriminative representation and enhance downstream performance. (2) Integration of Multi ST-Slices. A multi ST-slices Contrastive Learning (mST-CL) module is designed via two complementary triplet losses—one for both inter-slice and intra-slice cell type mapping. Experiments show that MoST-IG outperforms leading methods in both cancer grading and detection, as well as tissue structure clustering, while better preserving tissue landmarks in multi-slice ST integration. The code is available at https://github.com/HKU-MedAI/MoST-IG .",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "ClinGRAD: Clinically-Guided Genomics and Radiomics Interpretable GNN for Dementia Diagnosis",
    "doi": "10.1007/978-3-032-05162-2_20",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-05162-2_20",
    "authors": [
      "Hassan, Salma",
      "Salem, Mostafa",
      "Papineni, Vijay Ram Kumar",
      "Elsayed, Ayman",
      "Yaqub, Mohammad"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Alzheimer’s Disease (AD) remains a major diagnostic challenge due to the complex interplay of genomic, radiomic, and structural factors in disease progression. While deep learning methods can classify AD, current approaches fail to effectively combine multimodal data with clinical knowledge, compromising both accuracy and interpretability. We present ClinGRAD, a clinically-guided heterogeneous graph neural network that combines genomic and radiomic data using connections based on diffusion-weighted imaging (DWI) maps and gene co-expression networks. ClinGRAD’s contributions include: (1) a multimodal fusion architecture that integrates validated structural and genetic connectivity patterns for consistent biological feature analysis; (2) a multi-scale graph framework capturing both local brain structure and global genomic pathway relationships; (3) an attention mechanism that provides clinically relevant explanations of gene-structure interactions; and (4) pathway-based gene clustering that reveals underlying biological mechanisms and their clinical implications. ClinGRAD outperforms existing models, achieving an accuracy of 93.15%, distinguishing AD from control, mild cognitive impaired, and vascular dementia patients while maintaining biological coherence through its clinical guidance framework. The code is available at https://github.com/BioMedIA-MBZUAI/ClinGRAD",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "CoC: Chain-of-Cancer Based on Cross-Modal Autoregressive Traction for Survival Prediction",
    "doi": "10.1007/978-3-032-05182-0_9",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-05182-0_9",
    "authors": [
      "Zhou, Haipeng",
      "Yang, Sicheng",
      "Yang, Sihan",
      "Qin, Jing",
      "Chen, Lei",
      "Zhu, Lei"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Medical Image Computing and Computer Assisted Intervention – MICCAI 2025",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Survival prediction aims to evaluate the risk level of cancer patients. Existing methods primarily rely on pathology and genomics data, either individually or in combination. From the perspective of cancer pathogenesis, epigenetic changes, such as methylation data, could also be crucial for this task. Furthermore, no previous endeavors have utilized textual descriptions to guide the prediction. To this end, we are the first to explore the use of four modalities, including three clinical modalities and language, for conducting survival prediction. In detail, we are motivated by the Chain-of-Thought (CoT) to propose the Chain-of-Cancer (CoC) framework, focusing on intra-learning and inter-learning. We encode the clinical data as the raw features, which remain domain-specific knowledge for intra-learning. In terms of inter-learning, we use language to prompt the raw features and introduce an Autoregressive Mutual Traction module for synergistic representation. This tailored framework facilitates joint learning among multiple modalities. Our approach is evaluated across five public cancer datasets, and extensive experiments validate the effectiveness of our methods and proposed designs, leading to producing state-of-the-art  results. Codes will be released ( https://github.com/haipengzhou856/CoC ).",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Contrastive Learning-Based Method for Single-Cell Multi-omics Data Clustering",
    "doi": "10.1007/978-981-95-0698-9_29",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-0698-9_29",
    "authors": [
      "Liang, Zhenlan",
      "Zheng, Ruiqing",
      "Tao, Huayu",
      "Chen, Yuxuan",
      "Li, Min"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Bioinformatics Research and Applications",
    "contentType": "Chapter ConferencePaper",
    "abstract": "The rapid development of joint profiling methods makes it possible to simultaneously measure multi-modal data from the same cell. It enables the more comprehensive insight of cellular heterogeneity. However, due to the heterogeneity of features across different modalities and the complexity of each modal data, effectively integrating multi-modal data to achieve more accurate cell heterogeneity analysis remains challenging. Here, we propose a novel contrastive learning-based approach for single-cell multi-omics data clustering, named scCLC. Taking contrastive learning as backbone, scCLC integrates scRNA-seq data and scATAC-seq data for cell presentation learning with dedicated data augmentation strategy and self-supervised learning model. scCLC leverages the topological structure derived from single-cell multi-omics data to determine positive pairs, which not only increases the training sample size but also provides basic label priors for the model to learn more cluster-friendly cell representations. The experimental results on single-cell multi-omics datasets show the superior clustering performance of scCLC. When applied to visualization, scCLC can effectively separate the cell subtypes.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "TF-GCNNovo: A Peptide Sequence Prediction Model Integrating Transformer and Graph Convolutional Network",
    "doi": "10.1007/978-981-95-0698-9_7",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-0698-9_7",
    "authors": [
      "Liu, Nan",
      "Jing, Hao",
      "Jia, Xiaotian",
      "Zhu, Binhai"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Bioinformatics Research and Applications",
    "contentType": "Chapter ConferencePaper",
    "abstract": "De novo peptide sequencing is important for proteomics to predict unknown peptide sequences based on mass spectrometry data. Traditional methods for peptide sequence prediction have certain limitations because they often rely on handcrafted feature extraction and statistical models. To enhance prediction accuracy and rationality, a novel de novo peptide prediction model based on Transformer and Graph Convolutional Networks (GCN) is designed. In this model BERT is firstly used to extract peptide embedding features. These extracted features are integrated with physicochemical characteristics such as precursor mass, mass-to-charge ratio (m/z), and intensity to improve global feature representation. A model of the graph structural relationships between peptides using GCN can capture complex interactions to further enhance the capability of representation. Finally, the autoregressive decoder of a GPT-2 generation module is used to generate peptide sequences. And some strategies such as Top-k sampling, Top-p sampling, and temperature control are incorporated to ensure the rationality and diversity of the generated sequences. Experimental results demonstrate that the proposed model achieves an average improvement of 5.29% in amino acid recall and 4.18% in accuracy across multiple datasets compared to DeepNovo. The model effectively enhances the accuracy of de novo peptide sequencing.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "A Survival Prediction Model Integrating Hierarchical Pathological Image and Pathway Features",
    "doi": "10.1007/978-981-95-0695-8_9",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-0695-8_9",
    "authors": [
      "Xu, Xinyue",
      "Peng, Wei",
      "Dai, Wei",
      "Fu, Xiaodong",
      "Liu, Li",
      "Liu, Lijun"
    ],
    "publicationDate": "2026-01-01",
    "publicationName": "Bioinformatics Research and Applications",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Accurate cancer survival prediction is crucial for personalized treatment. Current methods often rely on single-magnification patch features from Whole Slide Images (WSIs), overlooking multi-level image information and facing limitations in patch labeling and feature aggregation. To overcome these challenges, we introduce HiMulti, a novel multi-instance model that integrates pathological images and pathway features for improved survival prediction. HiMulti first processes WSIs into patches and creates a multi-level pyramid through downsampling. It then utilizes an improved mamba-inspired linear attention model and a linear attention transformer for intra- and inter-level feature fusion. Simultaneously, pathway features are constructed from RNA-Seq data. A dual-branch attention mechanism selects key image regions by generating multimodal and single-modal attention weights. Finally, patient-level features are aggregated from these key images for cancer survival prediction. Compared with the existing weakly supervised methods, the average C-Index of HiMulti on the TCGA-LUAD, BRCA, and BLCA datasets increases by 1.39% compared with the sub-optimal value, and the visualization results confirm its superior performance. Implementation is available at: https://github.com/weiba/HiMulti .",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions",
    "doi": "10.1038/s41467-025-66961-9",
    "url": "https://www.nature.com/articles/s41467-025-66961-9",
    "authors": [
      "Dey, Samiran",
      "Banerji, Christopher R. S.",
      "Basuchowdhuri, Partha",
      "Saha, Sanjoy K.",
      "Parashar, Deepak",
      "Chakraborti, Tapabrata"
    ],
    "publicationDate": "2025-12-31",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Multimodal fusion of digital pathology and transcriptomics can improve cancer diagnosis, but remains impractical in clinical settings. Here, the authors develop a crossmodal generative model, PathGen, to synthesise transcriptomic data from histopathology slides, and show how the combination of these multimodal data improves cancer diagnosis and prognosis prediction. Emerging research has highlighted that artificial intelligence-based multimodal fusion of digital pathology and transcriptomic features can improve cancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction. However, such direct fusion is impractical in clinical settings, where histopathology remains the gold standard and transcriptomic tests are rarely requested in public healthcare. We experiment on two publicly available multimodal datasets, The Cancer Genomic Atlas and the Clinical Proteomic Tumor Analysis Consortium, spanning four independent cohorts: glioma-glioblastoma, renal, uterine, and breast, and observe significant performance gains in gradation and risk estimation ( p -value  < 0.05) when incorporating synthesized transcriptomic data with WSIs. Also, predictions using synthesized features were statistically close to those obtained with real transcriptomic data ( p -value  > 0.05), consistently across cohorts. Here we show that with our diffusion based crossmodal generative AI model, PathGen, gene expressions synthesized from digital histopathology jointly predict cancer grading and patient survival risk with high accuracy (state-of-the-art performance), certainty (through conformal coverage guarantee) and interpretability (through distributed co-attention maps). PathGen code is available on GitHub at https://github.com/Samiran-Dey/PathGen for open use.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "AI-based methods for modelling whole-slide imaging data in cancer diagnosis and transcriptome profile prediction",
    "doi": "10.1186/s44398-025-00018-1",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s44398-025-00018-1",
    "authors": [
      "Jabin, Arfa",
      "Kirar, Jyoti Singh",
      "Ahmad, Shandar"
    ],
    "publicationDate": "2025-12-30",
    "publicationName": "BMC Artificial Intelligence",
    "contentType": "Article",
    "abstract": "Background Whole Slide Imaging (WSI) has transformed digital pathology by enabling digitization of histological slides at gigapixel resolution. Artificial intelligence (AI), particularly deep learning (DL), models have leveraged WSIs to improve cancer diagnostics and, more recently, to infer transcriptomic profiles directly from tissue morphology. Although image analysis methods have made rapid progress and been widely reviewed before, specific challenges arise in dealing with domain-specific issues in WSI data. Results This review systematically surveys recent progress in AI-based analysis, focusing on two key predictive tasks namely, (i) cancer diagnosis and characterization and (ii) transcriptome or gene expression profile prediction from WSI samples. Giving a brief overview of WSI data collection and analysis in historical perspective, we review the techniques developed for diagnostic tasks, in the areas of model architectures such as Convolutional Neural Networks (CNNs), Vision Transformers, and Multiple Instance Learning (MIL). For the less studied but emerging problem of transcriptomic prediction, we discuss leading models such as HE2RNA, SEQUOIA, and tRNAsformer, their generalizability, and evaluation metrics (e.g. AUC, C-index, Pearson correlation). We highlight how AI models have achieved high diagnostic accuracy through specific, pan-cancer and multimodal foundation models and how the field is likely to evolve. Conclusions AI-enabled WSI analysis shows substantial promise for both diagnostic and molecular inference tasks in oncology. However, key limitations such as spatial resolution constraints, lack of external validation, biological interpretability and clinical integration barriers need further development of methodologies in both directions. Specifically, future efforts need to address multimodal data integration, improved interpretability, and rigorous validation in diverse cohorts to realise the full potential of their clinical translation.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Interpretable multimodal deep learning improves postoperative risk stratification in intrahepatic cholangiocarcinoma in multicentre cohorts",
    "doi": "10.1038/s41746-025-02282-x",
    "url": "https://www.nature.com/articles/s41746-025-02282-x",
    "authors": [
      "Wan, Mingyu",
      "Ding, Yongfeng",
      "Wang, Yanli",
      "Jia, Yunlu",
      "Wu, Siqi",
      "Qu, Wenxin",
      "Xu, Yifan",
      "Fu, Wenguang",
      "Timko, Michael P.",
      "Wan, Ledong",
      "Ying, Le",
      "Ye, Chanqi",
      "Chen, Ruyin",
      "Li, Qiong",
      "He, Yuqing",
      "Xu, Keyi",
      "Xu, Nong",
      "Chen, Jinzhang",
      "Zheng, Dayong",
      "Shen, Yifei",
      "Ruan, Jian"
    ],
    "publicationDate": "2025-12-29",
    "publicationName": "npj Digital Medicine",
    "contentType": "Article",
    "abstract": "Surgical resection is the primary curative treatment for intrahepatic cholangiocarcinoma (ICC), yet high postoperative recurrence rates pose a significant challenge. We developed an interpretable, transformer-based deep-learning pipeline that integrates multimodal data—including clinical variables, radiomic features, and whole-slide pathology images—by fusing a pre-trained encoder with a transformer network. To biologically validate our model, we leveraged spatial transcriptomics and proteomics to decipher the attention mechanisms underlying its predictions. It demonstrated robust performance in predicting 2-year overall survival, with area under the curve (AUC) values of 0.952 (95% CI: 0.909–0.983), 0.924 (95% CI: 0.804–1.000), and 0.924 (95% CI: 0.828–0.993) in three independent validation cohorts. Interrogation via spatial multi-omics revealed that the model’s attention was preferentially focused on regions histologically and molecularly associated with tumor invasion and aggressive behavior. We present a novel, interpretable multimodal deep-learning framework that achieves superior postoperative risk stratification for ICC patients.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Transforming histologic assessment: artificial intelligence in cancer diagnosis and personalized treatment",
    "doi": "10.1038/s41416-025-03206-y",
    "url": "https://www.nature.com/articles/s41416-025-03206-y",
    "authors": [
      "Takamatsu, Manabu"
    ],
    "publicationDate": "2025-12-28",
    "publicationName": "British Journal of Cancer",
    "contentType": "Article",
    "abstract": "Artificial intelligence (AI) is transforming histologic assessment, evolving from a diagnostic adjunct to an integral component of clinical decision-making. Over the past decade, AI applications have significantly advanced histopathology, facilitating tasks from tissue classification to predicting cancer prognosis, gene alterations, and therapy responses. These developments are supported by the availability of high-quality whole-slide images (WSIs) and publicly accessible databases like The Cancer Genome Atlas (TCGA), which integrate histologic, genomic, and clinical data. Deep learning techniques replicate and enhance pathologists’ decisions, addressing challenges such as inter-observer variability and diagnostic reproducibility. Moreover, AI enables robust predictions of patient prognosis, actionable gene statuses, and therapy responses, offering rapid, cost-effective alternatives to conventional methods. Innovations such as histomorphologic phenotype clusters and spatial transcriptomics have further refined cancer stratification and treatment personalization. In addition, multimodal approaches integrating histologic images with clinical and molecular data have achieved superior predictive accuracy and explainability. Nevertheless, challenges remain in verifying AI predictions, particularly for prognostic applications and ensuring accessibility in resource-limited settings. Addressing these challenges will require standardized datasets, ethical frameworks, and scalable infrastructure. While AI is revolutionizing histologic assessment for cancer diagnosis and treatment, optimizing digital infrastructure and long-term strategies is essential for its widespread adoption in clinical practice.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Multimodal deep learning for cancer prognosis prediction with clinical information prompts integration",
    "doi": "10.1038/s41746-025-02257-y",
    "url": "https://www.nature.com/articles/s41746-025-02257-y",
    "authors": [
      "Hou, Jiaxin",
      "Zhang, Ranran",
      "Xie, Yaoqin",
      "Li, Chao",
      "Qin, Wenjian"
    ],
    "publicationDate": "2025-12-27",
    "publicationName": "npj Digital Medicine",
    "contentType": "Article",
    "abstract": "Survival prediction is crucial for guiding cancer treatment and evaluating therapeutic efficacy. However, tumor heterogeneity presents challenges of accurate prognosis. Multimodal learning, which integrates data from imaging, genomics, and clinical records, offers a promising approach for this complex task. While recent studies mainly focus on imaging and genomic data, clinical information, which reflecting patients’ overall health, remains underutilized due to its discrete, sparse, and low-dimensional characteristics. We propose SurvPGC, an integrated model combining pathology images, genomic data and clinical records for cancer prognosis. Clinical information is transformed into high-dimensional vectors using text templates and foundation models, enabling their integration through a cross-attention module. Validation on three datasets of The Cancer Genome Atlas demonstrated that the model effectively captures modality-specific features, with attention visualization revealing distinct focus areas across data types. This highlights the importance of incorporating diverse information sources for improved survival prediction.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Synthetic Data Generation for Classifying Electrophysiological and Morpho-Electrophysiological Neurons from Mouse Visual Cortex",
    "doi": "10.1007/s12021-025-09761-2",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12021-025-09761-2",
    "authors": [
      "Vasques, Xavier",
      "Cif, Laura"
    ],
    "publicationDate": "2025-12-27",
    "publicationName": "Neuroinformatics",
    "contentType": "Article",
    "abstract": "Accurate classification of neuronal cell types is essential for understanding brain organization, but multimodal neuron datasets are scarce and strongly imbalanced across subclasses. We present a benchmark of synthetic data augmentation methods for predicting electrophysiology-defined neuronal classes (e-types) in the Allen Cell Types mouse visual cortex dataset. Two supervised tasks were evaluated over the same 17 e-type labels: prediction from electrophysiology features alone (E→e-type) and prediction from combined morphology plus electrophysiology features (M + E→e-type). We established real-data baselines across multiple classifier families under a unified preprocessing pipeline, then augmented only the training sets using matched per-class grids with Synthetic Minority Over-sampling Technique (SMOTE) and deep generative models: Variational Autoencoders (VAE), Generative Adversarial Networks (GAN), masked autoregressive normalizing flows, and Denoising Diffusion Probabilistic Models (DDPM). Augmentation produced substantial generalization gains when applied in the native high-dimensional feature space, whereas introducing dimensionality reduction largely suppressed these benefits. SMOTE delivered the most robust and consistent improvements across tasks and augmentation levels. To assess biological realism, we introduced a fidelity framework combining feature-wise distribution comparisons, statistical concordance tests, and distance-based measures that compare synthetic-to-real variability against the natural variability between real classes. Most synthetic datasets stayed within biological diversity bounds, with deviations concentrated in the rarest subclasses. These results provide practical guidance on selecting and validating synthetic augmentation for neuronal subtype classification.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "From lesion detection to outcome prediction: artificial intelligence and deep learning applications in multiple sclerosis",
    "doi": "10.1007/s10072-025-08661-2",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10072-025-08661-2",
    "authors": [
      "Prasad, Akanksha",
      "Sharma, Anuradha"
    ],
    "publicationDate": "2025-12-27",
    "publicationName": "Neurological Sciences",
    "contentType": "Article",
    "abstract": "Artificial intelligence (AI) and its deep-learning (DL) sub-field are reshaping the multiple sclerosis (MS) landscape from image acquisition to drug discovery. This narrative review synthesizes recently published evidence that links technical advances with clinical need. Deep-learning platforms now match experienced neuroradiologists, detecting more than 14% of cortical lesions and generating synthetic contrast-enhanced MR images that eliminate the use of gadolinium. Multimodal prognostic engines with MRI, optical-coherence tomography, serum neurofilament light chain (NfL) and smartphone-based gait metrics can predict relapse or conversion to the secondary-progressive phase months and sometimes years before standard review. Multi-omics classifiers further help refine care by identifying which non-responders to natalizumab have a greater than 80 percent probability of not responding to the therapy; and patient-facing apps turn daily symptom logs into patient-specific advice that reduces unplanned visits and raises quality of life scores. In the lab, generative models compress the design cycle of new compounds, and knowledge-graph analytics identify new indications for existing drugs. Yet gains remain uneven: LMIC clinics lack computational infrastructure, demographic bias skews performance, and regulatory frameworks trail algorithmic evolution. In essence, cloud-optimized deployment, participatory data sharing, explainable outputs and shared liability are necessary for ethical, equitable integration. When these pillars align, AI will move from just being an accessory to an essential scaffold, enabling genuinely anticipatory, precision MS care all while increasing the understanding of disease biology.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Probiotics, Psychobiotics, Paraprobiotics, and Postbiotics in Gut-Brain Axis Modulation: Multi-Omics and AI-Driven Precision Nutrition for Cognitive Health",
    "doi": "10.1007/s12602-025-10886-8",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12602-025-10886-8",
    "authors": [
      "Al-Adham, Ibrahim S. I.",
      "Ali Agha, Ahmed S. A.",
      "Al‐Remawi, Mayyas",
      "Al‑Akayleh, Faisal",
      "Al-Sheikh, Ahmed",
      "Aburub, Faisal",
      "Collier, Phillip J."
    ],
    "publicationDate": "2025-12-26",
    "publicationName": "Probiotics and Antimicrobial Proteins",
    "contentType": "Article",
    "abstract": "The gut-brain axis has emerged as a key regulatory interface in cognitive function and neurological health, influenced by diet-driven microbial metabolism and host-microbiome interactions. Integrating multi-omics approaches with AI-driven precision nutrition offers novel insights into how diet modulates neuroimmune, neuroendocrine, and metabolic pathways. This article explores recent advances in microbiome research, highlighting the role of microbiota-derived extracellular vesicles (MEVs) as bioactive carriers that facilitate gut-brain communication by transporting neuroactive metabolites and immune modulators. These findings reveal an underexplored mechanism by which dietary interventions can reshape brain function at the molecular level. Additionally, synthetic biology and CRISPR-mediated microbiome engineering are advancing targeted interventions, allowing precise modulation of microbial gene expression to enhance neuroprotective pathways and mitigate neuroinflammation. Emerging strategies such as psychobiotics, paraprobiotics, and postbiotics further expand this therapeutic landscape, offering novel microbiome-based tools to influence neurotransmission, neuroimmune regulation, and cognitive resilience. Artificial intelligence (AI)-driven multi-omics integration further enables predictive modeling of microbiome-neurotransmitter interactions, hence refining personalized nutritional strategies for cognitive resilience and neuroprotection. However, challenges such as inter-individual variability, algorithmic biases, and ethical considerations in AI-driven dietary recommendations must be addressed to ensure the suitability of potential therapies. Future research should focus on in vivo validation of AI-guided dietary interventions through multi-modal neuroimaging, metabolomics, and transcriptomics. These advances position precision nutrition as a transformative tool in neuroscience, bridging microbiome science, AI, and personalized medicine to optimize brain health and mitigate neurodegenerative risks.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Applications of artificial intelligence in non–small cell lung cancer: from precision diagnosis to personalized prognosis and therapy",
    "doi": "10.1186/s12967-025-07591-z",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12967-025-07591-z",
    "authors": [
      "Chang, Luyuan",
      "Li, Haipeng",
      "Wu, Wenzong",
      "Liu, Xinyu",
      "Yan, Jiaqi",
      "Chen, Zuo",
      "Wu, Huan",
      "Song, Shilong"
    ],
    "publicationDate": "2025-12-23",
    "publicationName": "Journal of Translational Medicine",
    "contentType": "Article",
    "abstract": "Background Non-small cell lung cancer (NSCLC) carries a major global burden. The rapid growth of multimodal medical data challenges conventional methods to deliver stable, transferable and interpretable decisions across heterogeneous longitudinal high dimensional inputs. Methods This review summarizes advances in artificial intelligence (AI) for NSCLC from 2023 to 2025 and outlines a translation-focused framework that links algorithmic progress to clinical utility. We survey thoracic imaging, digital pathology and multiomics together with evaluation practices and implementation guidance. We also adopt a critical perspective. Results Many high performing deep models remain black boxes, and popular post hoc explanations such as Grad CAM heatmaps are rarely validated for faithfulness or stability, which undermines clinician trust and limits use in high stakes decisions. To address this gap, we propose a minimum evidence package for explainability that comprises sanity checks, quantitative faithfulness tests such as deletion or insertion, ROAR or IROF and infidelity, stability analyses, concept level validation for example TCAV with statistical testing, and prospective human factors studies that demonstrate improved decisions without automation bias. Across modalities, evaluation has expanded beyond discrimination to include calibration, uncertainty quantification (UQ) and subgroup analyses across scanners, sites and populations. However, the evidence base remains constrained by retrospective single center designs, inconsistent external or temporal validation and limited decision curve analysis (DCA). Translational priorities include a staged validation ladder from technical to clinical to prospective deployment, alignment with Software as a Medical Device frameworks, interoperable governance, fairness and economic assessment, and validated explainability coupled with uncertainty aware selective workflows. Conclusions Looking ahead, progress will depend on multimodal foundation models, causal and temporal modeling, and regulatory qualification of computable biomarkers with verified explanations, supported by multicenter prospective studies that demonstrate durable generalizability, clinical value and clinician trust.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Design of an integrated drift-aware generative and predictive modeling for childhood epigenetics: multi-modal, causal, and intervention-aware frameworks for diabetes risk simulations",
    "doi": "10.1007/s41870-025-02968-1",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41870-025-02968-1",
    "authors": [
      "Badre, Rasika S.",
      "Kumar, Ajay"
    ],
    "publicationDate": "2025-12-19",
    "publicationName": "International Journal of Information Technology",
    "contentType": "Article",
    "abstract": "A drift-aware, generative, and intervention-guided paradigm for early risk assessment of childhood type 2 diabetes using longitudinal multi-omics integration is provided in this study. The suggested method simulates developmental methylation patterns using transcriptome and proteome measurements. The hierarchical representation preserves intra-layer structure and inter-layer interactions while combining molecular layers. For temporal drift, adaptive penalties that favor age-aligned biological progression improve coherence across measurements and reduce divergence that commonly arises when multi-omics signals are modeled independently. Developmentally realistic forward trajectories are generated by this architecture. This design finds directionally consistent CpG loci-regulatory driver linkages using causal graph reasoning. Sparse pruning prioritizes metabolic pathway interactions over unlikely edges. To retain biological fidelity and anchor drift magnitude against clinical advancement, diffusion-based denoising refines acquired methylation sequences in the generating stage. Counterfactual simulation layers examine risk trajectories with lifestyle changes including persistent activity and anthropometric improvements. Individualised simulations reveal how preventive strategies improve glycemic outcomes. Cross-modal coherence, temporal consistency, and trajectory stability are better than recent generative benchmarks without drift constraints or intervention-aware simulation using publically accessible pediatric longitudinal datasets. The integrative technique reduces longitudinal projection cross-modal divergence and produces coherent temporal manifolds for early screening and tiered prevention. Privacy-sensitive contexts benefit from downstream augmentation for data-constrained clinical investigations with synthetic, drift-aligned cohorts. Besides risk estimation, the framework may examine molecular reconfiguration during early metabolic dysregulation. Characterizing directional influence shifts over time gives the model mechanistic insights into regulatory perturbations. These computational tools improve early diabetes risk assessment, precision prevention, and translational research in pediatric metabolic health sets by integrating multi-omics, generative modeling, and intervention inference sets.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "High-parameter spatial multi-omics through histology-anchored integration",
    "doi": "10.1038/s41592-025-02926-6",
    "url": "https://www.nature.com/articles/s41592-025-02926-6",
    "authors": [
      "Liu, Yonghao",
      "Wang, Chuyao",
      "Wang, Zhikang",
      "Chen, Liang",
      "Li, Zhi",
      "Song, Jiangning",
      "Zou, Qi",
      "Gao, Rui",
      "Qian, Bin-Zhi",
      "Feng, Xiaoyue",
      "Guan, Renchu",
      "Yuan, Zhiyuan"
    ],
    "publicationDate": "2025-12-17",
    "publicationName": "Nature Methods",
    "contentType": "Article",
    "abstract": "Spatial omics face challenges in achieving high-parameter, multi-omics coprofiling. Serial-section profiling of complementary panels mitigates technical trade-offs but introduces the spatial diagonal integration problem. To address this, here we present SpatialEx and its extension SpatialEx+, computational frameworks leveraging histology as a universal anchor to integrate spatial molecular data across tissue sections. SpatialEx combines a pretrained hematoxylin and eosin foundation model with hypergraph and contrastive learning to predict single-cell omics from histology, encoding multi-neighborhood spatial dependencies and global tissue context. SpatialEx+ further introduces an omics cycle module that encourages cross-omics consistency via slice-invariant mappings, enabling seamless integration without comeasured training data. Extensive validations show superior hematoxylin and eosin-to-omics prediction, panel diagonal integration and omics diagonal integration across various biological scenarios. The frameworks scale to datasets exceeding 1 million cells, maintain robustness with nonoverlapping or heterogeneous sections and support unlimited omics layers in principle. Our work makes multimodal spatial profiling broadly accessible. The SpatialEx(+) framework uses histology to generate and integrate complementary spatial multi-omics data across samples.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "A Representation Fusion Framework for Decoupling Diagnostic Information in Multimodal Learning",
    "doi": "10.1038/s41746-025-02144-6",
    "url": "https://www.nature.com/articles/s41746-025-02144-6",
    "authors": [
      "Tonekaboni, Sana",
      "Friedman, Sam Freesun",
      "Zhang, Xinyi",
      "Maddah, Mahnaz",
      "Uhler, Caroline"
    ],
    "publicationDate": "2025-12-17",
    "publicationName": "npj Digital Medicine",
    "contentType": "Article",
    "abstract": "Modern medicine increasingly relies on multimodal data, ranging from clinical notes to imaging and genomics, to guide diagnosis and treatment. However, integrating these heterogeneous data sources in a principled and interpretable manner remains a major challenge. We present MODES ( M ulti-m O dal D isentangled E mbedding S pace), a representation fusion framework that explicitly separates shared and modality-specific factors of variation, offering a structured latent space for multimodal information that improves both prediction and interpretability. By leveraging pre-trained unimodal foundation models, MODES mitigates the dependency on extensive paired datasets, crucial in data-scarce clinical settings. We introduce a masking strategy that optimizes representation dimensionality by eliminating low-information dimensions, to achieve compact, information-rich representations. Our framework demonstrates superior performance in predicting diagnoses and phenotypes compared to unimodal and conventional fusion models. MODES also enables robust diagnostic inference in missing data scenarios, offering an opportunity toward interpretable and efficient multimodal diagnostics in personalized healthcare.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Advances in the application of artificial intelligence in mass spectrometry-based analysis of traditional Chinese medicine: compound identification and metabolic pathway elucidation",
    "doi": "10.1007/s00216-025-06260-w",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00216-025-06260-w",
    "authors": [
      "Xu, Jiaqi",
      "Bai, Lincheng",
      "Yang, Meng",
      "Yi, Zeyu",
      "Wang, Tiantian",
      "Han, Hua",
      "Dong, Peiliang"
    ],
    "publicationDate": "2025-12-13",
    "publicationName": "Analytical and Bioanalytical Chemistry",
    "contentType": "Article",
    "abstract": "Traditional Chinese medicine (TCM), characterized by its multi-component, multi-target, and multi-pathway nature, presents considerable challenges in the identification of chemical constituents and elucidation of metabolic mechanisms. TCM samples encompass a wide range of materials, including crude herbal parts, processed products, in vitro cell cultures, and in vivo biological specimens, each contributing to the complexity of analysis. MS, as a pivotal analytical tool for uncovering the material basis of TCM, has been widely employed for compound identification and in vivo metabolic pathway analysis, owing to its high throughput, sensitivity, and resolution. However, the inherently high-dimensional, noisy, and complex nature of MS data poses significant limitations to traditional analytical methods in terms of data processing efficiency and structural identification accuracy. In recent years, artificial intelligence (AI) technologies, particularly machine learning (ML), and deep learning (DL) models, have demonstrated remarkable potential in spectral interpretation, structure prediction, and metabolic pathway modeling within the context of MS-based TCM research. This review systematically summarizes the latest advances in the application of AI in TCM MS analysis, with a particular focus on two key areas: the utilization of AI for rapid qualitative analysis of complex TCM compounds, including spectral preprocessing, feature extraction, structural attribution, and isomer differentiation; and the role of AI in metabolite identification and reconstruction of in vivo metabolic pathways (Alvarado, Sci Eng Ethics, 29(5):32, 2023), encompassing metabolite screening, network modeling, and multi-omics integration. Furthermore, we critically discuss current challenges impeding further progress, such as the lack of high-quality MS databases, limited interpretability of AI models, and insufficient capabilities for cross-modal data fusion. Finally, we propose future directions for the field, emphasizing the importance of building interpretable, generalizable, and integrative AI frameworks. In summary, the convergence of AI and MS technologies is reshaping the paradigm of TCM research from empirical investigation to data-driven intelligence, thereby opening new avenues for the modernization of TCM and precision pharmacological studies.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "A multimodal knowledge-enhanced whole-slide pathology foundation model",
    "doi": "10.1038/s41467-025-66220-x",
    "url": "https://www.nature.com/articles/s41467-025-66220-x",
    "authors": [
      "Xu, Yingxue",
      "Wang, Yihui",
      "Zhou, Fengtao",
      "Ma, Jiabo",
      "Jin, Cheng",
      "Yang, Shu",
      "Li, Jinbang",
      "Zhang, Zhengyu",
      "Zhao, Chenglong",
      "Zhou, Huajun",
      "Li, Zhenhui",
      "Lin, Huangjing",
      "Wang, Xin",
      "Wang, Jiguang",
      "Han, Anjia",
      "Chan, Ronald Cheong Kin",
      "Liang, Li",
      "Zhang, Xiuming",
      "Chen, Hao"
    ],
    "publicationDate": "2025-12-12",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Computational pathology has advanced through foundation models, yet faces challenges in multimodal integration and capturing whole-slide context. Current approaches typically utilize either vision-only or image-caption data, overlooking distinct insights from pathology reports and gene expression profiles. Additionally, most models focus on patch-level analysis, failing to capture comprehensive whole-slide patterns. Here we present mSTAR ( M ultimodal S elf- TA ught P R etraining), the pathology foundation model that incorporates three modalities: pathology slides, expert-created reports, and gene expression data, within a unified framework. Our dataset includes 26,169 slide-level modality pairs across 32 cancer types, comprising over 116 million patch images. This approach injects multimodal whole-slide context into patch representations, expanding modeling from single to multiple modalities and from patch-level to slide-level analysis. Across oncological benchmark spanning 97 tasks, mSTAR outperforms previous state-of-the-art models, particularly in molecular prediction and multimodal tasks, revealing that multimodal integration yields greater improvements than simply expanding vision-only datasets. Foundation models have significantly advanced computational pathology, but still face important challenges, particularly when integrating multimodal data. Here, the authors develop mSTAR, an approach that allows injecting multimodal, whole-slide context into pathology foundation models, improving performance in clinical and molecular tasks in oncology.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "scDrugMap: benchmarking large foundation models for drug response prediction",
    "doi": "10.1038/s41467-025-67481-2",
    "url": "https://www.nature.com/articles/s41467-025-67481-2",
    "authors": [
      "Wang, Qing",
      "Pan, Yining",
      "Zhou, Minghao",
      "Tang, Zijia",
      "Wang, Yanfei",
      "Wang, Guangyu",
      "Song, Qianqian"
    ],
    "publicationDate": "2025-12-11",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Drug resistance poses a major challenge in cancer therapy. Here, authors present scDrugMap, a unified framework that systematically compares foundation models for single-cell drug response prediction and highlights models with superior performance. Drug resistance remains a major challenge in cancer treatment. While single-cell profiling offers unprecedented resolution for uncovercovering resistance mechanisms, the potential of emerging foundation models for drug response prediction at the single-cell level is still largely unknown. Here, we introduce scDrugMap, a unified framework featuring both Python toolkits and an interactive web server for benchmarking and predicting drug responses with state-of-the-art foundation models. scDrugMap evaluates eight single-cell foundation models and two large language models across 495,000 cells from 60 datasets, spanning diverse tissues, drugs, cancer types, and treatment conditions. In pooled-data evaluation, scFoundation delivered the strongest performance, particularly in tumor tissue. In cross-data analysis, UCE performed best after fine-tuning, while in zero-shot settings, scGPT achieved the highest accuracy. Together, scDrugMap provides the first systematic benchmark of foundation models for single-cell drug response prediction and offers a powerful, user-friendly platform to accelerate drug discovery and translational precision oncology.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "AI-driven virtual cell models in preclinical research: technical pathways, validation mechanisms, and clinical translation potential",
    "doi": "10.1038/s41746-025-02198-6",
    "url": "https://www.nature.com/articles/s41746-025-02198-6",
    "authors": [
      "Ma, Chunyu",
      "Zhang, Han",
      "Rao, Yiwei",
      "Jiang, Xinyu",
      "Liu, Boheng",
      "Sun, Zhikang",
      "Song, Zhenyu",
      "Gao, Yuan",
      "Cui, Yuhao",
      "Liu, Xinyu",
      "Li, Zedong"
    ],
    "publicationDate": "2025-12-11",
    "publicationName": "npj Digital Medicine",
    "contentType": "Article",
    "abstract": "AI-driven virtual cell models show the potential to transform the paradigm of life sciences research by integrating multimodal omics data (e.g., single-cell transcriptomics and proteomics) with advanced algorithms such as deep generative models and graph neural networks to enable high-precision predictions of drug responses, gene perturbations, and disease progression. These models enable high-precision predictions of drug responses, gene perturbations, and disease progression. This review outlines the technical pathways and validation mechanisms of virtual cells, emphasizing a closed-loop workflow from computational evaluation to experimental verification using CRISPR assays and organoid platforms. The applications of virtual cells in personalized drug screening and disease modeling are highlighted, showcasing their potential to reduce animal testing and optimize therapy. However, challenges in regulatory acceptance, data privacy, and model interpretability remain. Global policy and standardization trends are driving clinical translation, and future advancements will involve cross-disciplinary integration and greater standardization to enhance the impact of virtual cells in precision medicine and drug discovery.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Quantum-entangled neuro-symbolic swarm federation for privacy-preserving IoMT-driven multimodal healthcare",
    "doi": "10.1038/s41598-025-31820-6",
    "url": "https://www.nature.com/articles/s41598-025-31820-6",
    "authors": [
      "Ben Othman, Soufiane",
      "Ali, Obaid"
    ],
    "publicationDate": "2025-12-09",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": "The integration of Internet of Medical Things (IoMT) ecosystems with multimodal data, real-time sensors, fMRI/EEG, genomics, and clinical text, holds transformative potential for rare disease diagnostics and personalized medicine. However, ultra-scarce datasets ( $$n < 15$$ per institution), quantum-era threats (e.g., Shor and Grover algorithms), and stringent regulatory requirements expose critical limitations in centralized AI and classical federated learning. To address these challenges, we propose the Quantum-Entangled Neuro-Symbolic Swarm Federation (QENSSF), a pioneering framework that unifies quantum-entangled differential privacy (QEDP), neuro-symbolic swarm intelligence, and privacy-aware large language model (LLM) fine-tuning within an IoMT-driven architecture. QENSSF introduces four foundational innovations: (1) QEDP, leveraging 9-qubit W-states and variational quantum circuits to achieve $$(\\epsilon ,\\delta )$$ -differential privacy with $$\\epsilon =0.08$$ –0.17 and $$\\delta =10^{-17}$$ , resilient to quantum inference attacks; (2) Neuro-symbolic swarm agents that fuse CNNs, GNNs, LSTMs, and Transformers with symbolic logic, optimized via Quantum-Entangled Particle Swarm Optimization for $$O(\\log (1/\\epsilon ))$$ convergence; (3) Federated LLM adaptation using QEDP-masked gradients and symbolic guards to prevent hallucination-induced leaks; and (4) Ethical, explainable AI via dynamic knowledge graphs secured by quantum multi-party computation. Evaluated on IBM’s 127-qubit Eagle processor ( $$QV=128$$ , $$F_{\\text {gate}}=0.995$$ ) and 128 NVIDIA A100 GPUs across synthetic and real-world datasets (ADNI, UK Biobank, MIMIC-IV), QENSSF achieves 45% higher F1-score, 30% improved ROUGE-L, and $$<0.5\\%$$ attack success rate under membership inference. It delivers 6.3 million ops/s (58% faster than FedAvg), consumes only 0.38 kWh (52% less energy), reduces communication overhead to 2.1 Mb/iter (66% lower), and attains 99% fault recovery, all while ensuring regulatory compliance and clinician-trustworthy explanations. QENSSF sets a new standard for secure, efficient, and interpretable AI in resource-constrained, privacy-sensitive healthcare environments.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multi-modal integration of histopathology and transcriptomics reveals STAB1^+ macrophage-associated efferocytosis as a suppressive immune mechanism in colon adenocarcinoma",
    "doi": "10.1186/s12967-025-07348-8",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12967-025-07348-8",
    "authors": [
      "Chang, Zhanhao",
      "Zhong, Chongli",
      "Xu, Shuo",
      "Zhang, Yuyang",
      "Guo, Xingqi",
      "Yu, Jielin",
      "Xu, Zitong",
      "Han, Shukun",
      "Han, Bing",
      "Lv, Chao",
      "Tian, Yu"
    ],
    "publicationDate": "2025-12-08",
    "publicationName": "Journal of Translational Medicine",
    "contentType": "Article",
    "abstract": "Background Colon adenocarcinoma (COAD) has a limited response to immunotherapy due to its immunologically “cold” tumor microenvironment (TME). Efferocytosis is an important process that regulates the TME, but its mechanism and clinical significance in COAD are unclear. Methods We integrated histopathological images, transcriptomic profiles, and clinical data from 387 COAD patients. Image features were extracted using ResNet50 and CellProfiler, followed by construction of a multimodal machine learning model to evaluate prognostic risk. We further combined bulk RNA-seq, single-cell RNA-seq, and spatial transcriptomics to comprehensively characterize efferocytosis-associated immune cell subsets and signaling pathways. Results The efferocytosis-based risk model demonstrated strong prognostic performance across multiple time points and remained independent of conventional clinical indicators. Mechanistically, we identified a subset of STAB1^+ tumor-associated macrophages (TAMs) enriched in COAD tumors, exhibiting enhanced efferocytosis activity, M2-like polarization, and mTORC1 signaling activation. In vitro, STAB1 expression was essential for IL-4-induced M2 polarization, and its inhibition attenuated the formation of immunosuppressive TAMs. Single-cell and spatial transcriptomic analyses revealed that this macrophage population was transcriptionally distinct and increased in abundance following neoadjuvant therapy. Conclusion This study establishes a multimodal prognostic system that integrates histopathological imaging with molecular profiling, and for the first time reveals the pivotal role of STAB1^+ TAMs in orchestrating the immunosuppressive TME via efferocytosis and mTORC1 activation. Our findings provide both a clinically applicable risk assessment tool and a potential therapeutic target. Targeting STAB1 may broaden the benefit of immunotherapy for COAD patients with limited responses to immune checkpoint blockade. Graphical Abstract  Identification of STAB1^+ tumor-associated macrophages (TAMs) as a central immunosuppressive subpopulation enriched in apoptotic tumor regions and further expanded following neoadjuvant therapy. Demonstration that STAB1 drives M2 macrophage polarization and efferocytosis through activation of the mTORC1 signaling pathway. Revealing a complex cell–cell communication network linking STAB1^+ TAMs, neutrophils, and malignant epithelial cells, forming a positive feedback loop that reinforces immune evasion. Development of a clinically applicable, deep learning–based prognostic model, which translates histopathological features into quantifiable risk indices and demonstrates predictive power comparable to that of the TNM staging system.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "EnsembleAge clock: a reliable and robust epigenetic age clock service reveals epigenetic age acceleration in opioid-overdosed brains",
    "doi": "10.1186/s12864-025-12271-9",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12864-025-12271-9",
    "authors": [
      "Anand, Akshay",
      "Agarwal, Yash",
      "Gupta, Tanisha",
      "Lin, Jason",
      "Ghemrawi, Mirna",
      "Gerhard, Glenn S.",
      "Lee, Hayan"
    ],
    "publicationDate": "2025-12-06",
    "publicationName": "BMC Genomics",
    "contentType": "Article",
    "abstract": "Age is a major risk factor for various diseases, such as cancer, cardiovascular conditions, and neurodegenerative diseases. However, chronological age, the simple number of years one has lived, does not capture individual health differences, prompting the development of methods to accurately estimate biological age instead of relying on chronological age. One of the major molecular approaches exploits DNA methylation (DNAm), which is an essential epigenetic modifier for regulating gene expression, cell differentiation, and aging. DNAm-based aging clocks have been developed to predict biological age, but the prediction is highly dependent on training data, including organs and assay technologies. To address these clocks’ high variance, we present two EnsembleAge clocks, leveraging eight previously developed DNAm clocks, harnessing the strengths of each methylome age clock, smoothing out individual variances, and providing a more robust estimation of biological age. We trained our EnsembleAge clock models using DNA methylation data from nine organs in the Genotype-Tissue Expression (GTEx) dataset. Our EnsembleNaive clock model achieved the lowest median absolute error (MeAE) of 4.04 years in whole blood. The EnsembleLR model demonstrated the lowest MeAE of 6.35 years across multiple tissues, including breast, lung, muscle, ovary, prostate, testis, and colon. The significant reduction in MeAE underscores its high practical value in clinical and forensic applications, especially in contexts where epigenetic changes are subtle. We further applied our models to four public datasets representing diverse biological applications, including administered short-term medical opioid use (GSE151485) and long-term opioid overdose (GSE164822). Our model reveals over 10 years of age acceleration in opioid-overdosed brains but no significant epigenetic age acceleration when opioid usage was well administered. Our EnsembleAge clock models are also implemented as a web service, allowing users to conveniently upload their DNA methylation data and receive predictions of their biological age. This empowers individuals to track their biological/epigenetic age over time, mitigating the effect of variance and promoting healthy aging and a beneficial lifestyle. Our EnsembleAge clock service is available at https://ensemble.epiclock.app/ .",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "AI-based neoadjuvant immunotherapy response prediction across pan-cancer: a comprehensive review",
    "doi": "10.1186/s12935-025-04063-8",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12935-025-04063-8",
    "authors": [
      "Deng, Yishu",
      "Li, Tailin",
      "Wang, Yunze",
      "Chen, Silin",
      "Tang, Feilong",
      "Zhu, Taoyu",
      "Ran, Jiayi",
      "Yang, Bo",
      "Zhang, Xiaohan",
      "Xu, Ruijie",
      "Ray, Manas K.",
      "Zhang, Yimin",
      "Chen, Shuifang",
      "Liu, Jian"
    ],
    "publicationDate": "2025-12-03",
    "publicationName": "Cancer Cell International",
    "contentType": "Article",
    "abstract": "Neoadjuvant immunotherapy (NIT) has emerged as a transformative treatment strategy across various cancer types. However, due to the significant heterogeneity of tumors, patients exhibit highly variable responses to NIT, making the accurate preoperative identification of those who would benefit a pressing clinical challenge. In recent years, artificial intelligence (AI), particularly machine learning (ML) and deep learning (DL), has opened new pathways for predicting treatment response. AI-driven approaches have the ability to extract latent features from high-dimensional, multimodal oncological data, facilitating the construction of efficient predictive models that can optimize individualized treatment strategies. In this review, we systematically summarize existing AI-driven computational approaches for NIT response prediction, categorizing them into indirect and direct predictive paradigms. The indirect paradigm predicts clinically validated surrogate biomarkers to infer therapeutic response to NIT. In contrast, the direct paradigm leverages AI to analyze high-throughput data and establish data-driven biomarkers that directly predict clinical endpoints of NIT. Additionally, we categorize existing AI predictive models based on data modalities, spanning radiomics, pathomics, genomics, and multi-omics approaches, each providing distinct insights into tumor characteristics and treatment response. Despite notable progress, current predictive models still face significant challenges, which we broadly classify into biomarker-based and AI-based limitations. We further discuss potential strategies to address these challenges. This review systematically summarizes recent AI-based predictive models for NIT response across cancer types. By offering a structured analysis of current methodologies and challenges, we aim to guide future research and accelerate the integration of AI into precision immunotherapy.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multimodal foundation transformer models for multiscale genomics",
    "doi": "10.1038/s41592-025-02918-6",
    "url": "https://www.nature.com/articles/s41592-025-02918-6",
    "authors": [
      "Khan, Sumeer Ahmad",
      "Martínez-de-Morentin, Xabier",
      "Alsabbagh, Abdel Rahman",
      "Maillo, Alberto",
      "Lagani, Vincenzo",
      "Gomez-Cabrero, David",
      "Lehmann, Robert",
      "Tegner, Jesper"
    ],
    "publicationDate": "2025-12-01",
    "publicationName": "Nature Methods",
    "contentType": "Article",
    "abstract": "Transformer-based models are rapidly becoming foundational tools for analyzing and integrating multiscale biological data. This Perspective examines recent advances in transformer architectures, tracing their evolution from unimodal and augmented unimodal models to large-scale multimodal foundation models operating across genomic sequences, single-cell transcriptomics and spatial data. We categorize these models into three tiers and evaluate their capabilities for structural learning, representation transfer and tasks such as cell annotation, prediction and imputation. While discussing tokenization, interpretability and scalability challenges, we highlight emerging approaches that leverage masked modeling, contrastive learning and large language models. To support broader adoption, we provide practical guidance through code-based primers, using public datasets and open-source implementations. Finally, we propose designing a modular ‘Super Transformer’ architecture using cross-attention mechanisms to integrate heterogeneous modalities. This Perspective serves as a resource and roadmap for leveraging transformer models in multiscale, multimodal genomics. This Perspective overviews recent and emerging developments in building and using multimodal foundation models based on transformers for analyzing various types of genomics data.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Hypergraph-driven spatial multimodal fusion for precise domain delineation and tumor microenvironment decoding",
    "doi": "10.1038/s42003-025-09312-0",
    "url": "https://www.nature.com/articles/s42003-025-09312-0",
    "authors": [
      "Zhang, Chengyang",
      "Li, Xulong",
      "Li, Bo",
      "Deng, Chenxun",
      "Li, Mengran",
      "Zhang, Shiqi",
      "Yu, Weijiang",
      "Zhang, Hongyu",
      "Wang, Zheng",
      "Yang, Yuedong",
      "Zeng, Yuansong"
    ],
    "publicationDate": "2025-12-01",
    "publicationName": "Communications Biology",
    "contentType": "Article",
    "abstract": "HAST reveals biologically relevant pathways in the tumor microenvironment by integrating gene expression, spatial coordinates, and histology into local and global hypergraphs, capturing complex many-to-many spatial interactions. Recent advancements in spatial transcriptomics have transformed tumor microenvironment research by providing insights into cellular interactions and spatial heterogeneity. A fundamental challenge is the precise delineation of spatial domains. However, existing methods remain limited in accurately identifying spatial domains, partially due to their reliance on single-view features. Moreover, these methods often struggle with many-to-many spot relationships, such as shared biological functions. To this end, we propose HAST, a hypergraph-driven spatial multimodal fusion tool for precise domain delineation and tumor microenvironment decoding. HAST integrates gene expression, spatial coordinates, and histological features to construct local hypergraphs that effectively model many-to-many spatial relationships. These local hypergraphs are dynamically aggregated into a global hypergraph, capturing higher-order interactions. To learn discriminative and biologically meaningful representations, we employ a hypergraph convolutional network, coupled with self-supervised contrastive learning, to fuse multi-view information. Extensive benchmarking across multiple datasets demonstrates that HAST outperforms state-of-the-art methods, accurately delineating spatial domains and uncovering domain-associated genes. Functional enrichment analyses further reveal biologically relevant pathways and provide novel insights into tumor microenvironment. In summary, HAST is a robust framework for decoding the spatial complexity of tumors, paving the way for precise spatial omics analyses in cancer research.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Activated Platelet-Rich Plasma Fibrin Scaffolds Enhance Axonal Regeneration and Functional Recovery Following Spinal Cord Injury",
    "doi": "10.1007/s10439-025-03922-9",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10439-025-03922-9",
    "authors": [
      "Chaudhari, Leena R.",
      "Kawale, Akshay A.",
      "Sonkawade, Omkar",
      "Damle, Mrunal",
      "Patil, Jitendra",
      "Desai, Sangeeta",
      "Joshi, Meghnad G."
    ],
    "publicationDate": "2025-12-01",
    "publicationName": "Annals of Biomedical Engineering",
    "contentType": "Article",
    "abstract": "Purpose Spinal cord injury (SCI) is a devastating condition with limited therapeutic options owing to poor intrinsic regeneration and the formation of glial scars. Platelet-rich plasma (PRP)-based biomaterials have emerged as promising candidates for neural repair; however, their application in complete SCI models with rigorous multimodal validation has not yet been investigated. This study aimed to extend the current knowledge on SCI-PRP based study, by developing and comprehensively validating a clinically translatable PRP-derived fibrin scaffold for spinal cord regeneration. Methods PRP-fibrin scaffolds were synthesized from donor-derived plasma and extensively characterized in terms of their physicochemical properties, degradation profiles, protein release dynamics, and cellular compatibility. Its regenerative potential was evaluated using an integrative pipeline that included in ovo chorioallantoic membrane (CAM) assays, a complete spinal cord transection rat model, and multimodal outcome measures, including magnetic resonance imaging (MRI), retrograde neuronal tract tracing, electrophysiological recordings, and gene expression analyses. Results The scaffold exhibited favorable structural and biochemical characteristics, supported angiogenesis in the CAM assay, and promoted tissue integration in vivo . In an SCI model, the scaffold significantly enhanced neovascularization, reduced glial scarring, and facilitated axonal regeneration. Functional improvements were observed 30 days’ post-implantation. In silico docking further demonstrated stable interactions between scaffold proteins and key neuroregenerative signaling molecules. Conclusion This study provides multimodal validation of the derived fibrin scaffold, establishing it as a robust ECM-mimetic platform for spinal cord repair. These findings lay the groundwork for future clinical translation of SCI therapeutics. Graphical Abstract ",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "From multi-omics to deep learning: advances in cfDNA-based liquid biopsy for multi-cancer screening",
    "doi": "10.1186/s40364-025-00874-z",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s40364-025-00874-z",
    "authors": [
      "Luo, Xinwei",
      "Xie, Sijia",
      "Hong, Feitong",
      "Li, Xiaolong",
      "Wei, Yijie",
      "Zhou, Yuwei",
      "Su, Wei",
      "Yang, Yuhe",
      "Tang, Lixia",
      "Dao, Fuying",
      "Cai, Peiling",
      "Lin, Hao",
      "Lai, Hongyan",
      "Lyu, Hao"
    ],
    "publicationDate": "2025-11-28",
    "publicationName": "Biomarker Research",
    "contentType": "Article",
    "abstract": "Cancer remains a leading cause of mortality worldwide, with early detection being critical for improving survival rates. Traditional diagnostic methods, such as tissue biopsies and imaging, face limitations in invasiveness, cost, and accessibility, making liquid biopsy a compelling non-invasive alternative. Among liquid biopsy approaches, circulating cell-free DNA (cfDNA) analysis has gained prominence for its ability to capture tumor-derived genetic and epigenetic alterations. This review summarizes key cfDNA biomarkers, including gene mutations, copy number variations (CNVs), DNA methylation, fragmentation patterns, and end motifs (EMs), and highlights their utility in cancer detection and monitoring. By integrating these multi-modal cfDNA biomarkers, feature fusion approaches have not only enhanced the performance of cancer classification models but also stabilized low-abundance signals, thus ensuring more reliable cancer detection and monitoring. Furthermore, the diagnostic power of cfDNA analysis has been further amplified by machine learning (ML), with both traditional ML and deep learning (DL) methods demonstrating strong predictive performance in routine clinical liquid biopsy applications. However, challenges remain, including tumor heterogeneity, standardization of data processing, model explainability, and cost constraints. Future advancements should focus on refining multi-modal feature integration, developing explainable AI (XAI) models, and optimizing cost-effective strategies to enhance clinical applicability. As computational methodologies advance, the integration of cfDNA biomarkers with ML frameworks holds great promise to reshape non-invasive cancer detection by enabling earlier diagnostics, more accurate prognostic evaluation and personalized treatment strategies.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "scGALA advances graph link prediction-based cell alignment for comprehensive data integration and harmonization",
    "doi": "10.1038/s41467-025-66644-5",
    "url": "https://www.nature.com/articles/s41467-025-66644-5",
    "authors": [
      "Jiang, Guo",
      "Song, Kailu",
      "Fonseca, Gregory J.",
      "Wagner, Darcy E.",
      "Clark, Iain C.",
      "Wang, Hui",
      "Ding, Jun"
    ],
    "publicationDate": "2025-11-26",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Single-cell technologies have transformed our understanding of cellular heterogeneity through multimodal data acquisition. However, robust cell alignment remains a major challenge for data integration and harmonization, including batch correction, label transfer, and multi-omics integration. Many existing methods constrain alignment based on rigid feature-wise distance metrics, limiting their ability to capture accurate cell correspondence across diverse cell populations and conditions. We introduce scGALA, a graph-based learning framework that redefines cell alignment by combining graph attention networks with a score-driven, task-independent optimization strategy. scGALA constructs enriched graphs of cell-cell relationships by integrating gene expression profiles with auxiliary information, such as spatial coordinates, and iteratively refines alignment via self-supervised graph link prediction, where a deep neural network is trained to identify and reinforce high-confidence correspondences across datasets. In extensive benchmarks, scGALA identifies over 25 percent more high-confidence alignments without compromising accuracy. By improving the core step of cell alignment, scGALA serves as a versatile enhancer for a wide range of single-cell data integration tasks. Single-cell technologies generate complex datasets, but effective cell alignment across studies—within and across modalities—remains challenging. Here, the authors introduce scGALA, a graph-based self-supervised framework that advances cell alignment to improve data integration and harmonization.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Solving the where problem and quantifying geometric variation in neuroanatomy using generative diffeomorphic mapping",
    "doi": "10.1038/s41467-025-65317-7",
    "url": "https://www.nature.com/articles/s41467-025-65317-7",
    "authors": [
      "Tward, Daniel J.",
      "Gray, Bryson D. P.",
      "Li, Xu",
      "Huo, Bing-Xing",
      "Banerjee, Samik",
      "Savoia, Stephen",
      "Mezias, Christopher",
      "Das, Sukhendu",
      "Miller, Michael I.",
      "Mitra, Partha P."
    ],
    "publicationDate": "2025-11-24",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "A current focus in neuroscience is to map neuronal cell types in whole vertebrate brains using different imaging modalities. Mapping modern molecular and anatomical datasets into a common atlas includes challenges that existing workflows do not adequately address: multimodal signals, missing data or non reference signals, and quantification of individual variation. Our solution implements a generative model describing the likelihood of data given a sequence of transforms of an atlas, and a maximum a posteriori estimation framework. Our approach allows composition of mappings across chains of datasets rather than only pairs, and computes metrics for geometric quantification. We study a range of datasets (in/ex-vivo MRI, STP and fMOST, 2D serial histology, snRNAseq prepared tissue), quantifying cell density and geometric fluctuations across covariates, and reveal that individual variation is often greater than differences due to tissue processing techniques. We provide open source code, dataset standards, and a web interface. This establishes a quantitative workflow for unifying multi-modal whole-brain images in an atlas framework, validated using mouse datasets, enabling large scale integration of datasets essential to modern neuroscience. Challenges in mapping modern molecular and anatomical datasets into a common atlas are not fully addressed. Here authors present approaches to aligning multimodal neuroimaging data and quantifying geometric variability. Authors also make sure open-source code, dataset standards, and a web interface are available, enabling large scale integration of datasets essential to modern neuroscience.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Protein Set Transformer: a protein-based genome language model to power high-diversity viromics",
    "doi": "10.1038/s41467-025-66049-4",
    "url": "https://www.nature.com/articles/s41467-025-66049-4",
    "authors": [
      "Martin, Cody",
      "Gitter, Anthony",
      "Anantharaman, Karthik"
    ],
    "publicationDate": "2025-11-23",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "A genome language model, Protein Set Transformer, trained on viral datasets, uncovers evolutionary rules of protein content and organization driving precise virus identification, host prediction, and protein annotation for viral genomics and ecology. Exponential increases in microbial and viral genomic data demand transformational advances in scalable, generalizable frameworks for their interpretation. Standard homology-based functional analyses are hindered by the rapid divergence of microbial and especially viral genomes and proteins that significantly decreases the volume of usable data. Here, we present Protein Set Transformer (PST), a protein-based genome language model that models genomes as sets of proteins without considering sparsely available functional labels. Trained on >100k viruses, PST outperforms other homology- and language model-based approaches for relating viral genomes based on shared protein content. Further, PST demonstrates protein structural and functional awareness by clustering capsid-fold-containing proteins with known capsid proteins and uniquely clustering late gene proteins within related viruses. Our data establish PST as a valuable method for diverse viral genomics, ecology, and evolutionary applications. We posit that the PST framework can be a foundation model for microbial genomics when trained on suitable data.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "AI-driven multi-omics integration in precision oncology: bridging the data deluge to clinical decisions",
    "doi": "10.1007/s10238-025-01965-9",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10238-025-01965-9",
    "authors": [
      "Hsu, Chou-Yi",
      "Askar, Shavan",
      "Alshkarchy, Samer Saleem",
      "Nayak, Priya Priyadarshini",
      "Attabi, Kassem A. L.",
      "Khan, Mohammad Ahmar",
      "Mayan, J. Albert",
      "Sharma, M. K.",
      "Islomov, Sarvar",
      "Soleimani Samarkhazan, Hamed"
    ],
    "publicationDate": "2025-11-21",
    "publicationName": "Clinical and Experimental Medicine",
    "contentType": "Article",
    "abstract": "Cancer’s staggering molecular heterogeneity demands innovative approaches beyond traditional single-omics methods. The integration of multi-omics data, spanning genomics, transcriptomics, proteomics, metabolomics and radiomics, can improve diagnostic and prognostic accuracy when accompanied by rigorous preprocessing and external validation; for example, recent integrated classifiers report AUCs around 0.81–0.87 for difficult early-detection tasks. This review synthesizes how artificial intelligence (AI), particularly deep learning and machine learning, bridges this gap by enabling scalable, non-linear integration of disparate omics layers into clinically actionable insights. We explore cutting-edge AI methodologies, including graph neural networks for biological network modeling, transformers for cross-modal fusion, and explainable AI (XAI) for transparent clinical decision support. Critical applications are highlighted, such as AI-driven therapy selection (e.g., predicting targeted therapy resistance), proteogenomic early detection, and radiogenomic non-invasive diagnostics. We further address translational challenges: data harmonization, batch correction, missing data imputation, and computational scalability. Emerging trends, federated learning for privacy-preserving collaboration, spatial/single-cell omics for microenvironment decoding, quantum computing, and patient-centric “N-of-1” models, signal a paradigm shift toward dynamic, personalized cancer management. Despite persistent hurdles in model generalizability, ethical equity, and regulatory alignment, AI-powered multi-omics integration promises to transform precision oncology from reactive population-based approaches to proactive, individualized care.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Leveraging artificial intelligence in antibody-drug conjugate development: from target identification to clinical translation in oncology",
    "doi": "10.1038/s41698-025-01159-2",
    "url": "https://www.nature.com/articles/s41698-025-01159-2",
    "authors": [
      "Lu, Ye",
      "Huang, Weijun",
      "Li, Yuxuan",
      "Xu, Yanzhi",
      "Wei, Qing",
      "Sha, Chulin",
      "Guo, Peng"
    ],
    "publicationDate": "2025-11-21",
    "publicationName": "npj Precision Oncology",
    "contentType": "Article",
    "abstract": "Artificial intelligence (AI) is opening new frontiers in the development of antibody-drug conjugates (ADCs), offering unprecedented opportunities for precision therapy. This review outlines how AI empowers each stage of the ADC pipeline. In target discovery, multi-omics integration and graph-based learning prioritize tumor-selective and internalizing antigens. In antibody engineering, structure prediction, affinity optimization, and developability modeling streamline candidate selection. For linker-payload design, generative models and multi-objective optimization approaches support the rational design of conjugates that balance potency, stability, and immunogenicity. In absorption, distribution, metabolism, excretion, and toxicity (ADMET) modeling, deep learning and transformer-based frameworks predict pharmacokinetics and toxicity with increasing accuracy and mechanistic clarity. In clinical development, AI facilitates patient stratification, response prediction, and trial simulation through digital twin models, adaptive dosing algorithms, and real-world data integration. These capabilities support a more personalized and efficient pathway from bench to bedside. To further realize the impact of AI in ADC development, we highlight strategic priorities including the creation of curated, multimodal datasets, interpretable model architectures, and closed-loop experimental platforms. Together, these advances will be essential for realizing the full potential of AI to support rational, scalable, and personalized ADC-based therapies in oncology.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Omnireg-gpt: a high-efficiency foundation model for comprehensive genomic sequence understanding",
    "doi": "10.1038/s41467-025-65066-7",
    "url": "https://www.nature.com/articles/s41467-025-65066-7",
    "authors": [
      "Wang, Aowen",
      "Li, Jiaqi",
      "Dong, Hongyu",
      "Xu, Bocheng",
      "Yin, Qingyu",
      "Xu, Yanchao",
      "Fu, Jie",
      "Zhao, Junbo"
    ],
    "publicationDate": "2025-11-19",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Understanding long-range genomic regulation is a key challenge for DNA foundation models. Here, authors develop OmniReg-GPT with a hybrid local-global attention architecture, enabling efficient analysis of multi-scale regulatory features across long DNA sequences. The human genome contains a sophisticated array of elements that regulate gene activity and organismal functions. Developing a large window foundation model capable of efficiently processing long sequence inputs is essential yet challenging for decoding the multi-layered and complex landscape of the cis-regulatory elements. Here, we introduce OmniReg-GPT, a generative foundation model designed for the low-resource pretraining of long genomic sequences by optimized attention mechanism. During pretraining, OmniReg-GPT captures the complete distribution of regulatory elements across nucleotide to megabase scales with efficient training speed and memory usage. We demonstrate exceptional performance in downstream regulotary applications spanning the entire spectrum of genomic scales, including various cis-regulatory elements identification, context dependent gene expression prediction, single-cell chromatin accessibility analysis, and 3D chromatin contact modeling. As a generative model, OmniReg-GPT also holds the potential to generate candidate cell-type-specific enhancers through prompt engineering. Overall, OmniReg-GPT extends the boundaries of foundation models in the genomic field, and provides a valuable pretraining model resource which can be extensively applied for genomic researches.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multimodal learning enables chat-based exploration of single-cell data",
    "doi": "10.1038/s41587-025-02857-9",
    "url": "https://www.nature.com/articles/s41587-025-02857-9",
    "authors": [
      "Schaefer, Moritz",
      "Peneder, Peter",
      "Malzl, Daniel",
      "Lombardo, Salvo Danilo",
      "Peycheva, Mihaela",
      "Burton, Jake",
      "Hakobyan, Anna",
      "Sharma, Varun",
      "Krausgruber, Thomas",
      "Sin, Celine",
      "Menche, Jörg",
      "Tomazou, Eleni M.",
      "Bock, Christoph"
    ],
    "publicationDate": "2025-11-11",
    "publicationName": "Nature Biotechnology",
    "contentType": "Article",
    "abstract": "CellWhisperer uses multimodal learning of transcriptomes and text to answer questions about single-cell RNA-sequencing data. Single-cell sequencing characterizes biological samples at unprecedented scale and detail, but data interpretation remains challenging. Here, we present CellWhisperer, an artificial intelligence (AI) model and software tool for chat-based interrogation of gene expression. We establish a multimodal embedding of transcriptomes and their textual annotations, using contrastive learning on 1 million RNA sequencing profiles with AI-curated descriptions. This embedding informs a large language model that answers user-provided questions about cells and genes in natural-language chats. We benchmark CellWhisperer’s performance for zero-shot prediction of cell types and other biological annotations and demonstrate its use for biological discovery in a meta-analysis of human embryonic development. We integrate a CellWhisperer chat box with the CELLxGENE browser, allowing users to interactively explore gene expression through a combined graphical and chat interface. In summary, CellWhisperer leverages large community-scale data repositories to connect transcriptomes and text, thereby enabling interactive exploration of single-cell RNA-sequencing data with natural-language chats.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Integrating imaging and omics for enhanced subtyping of mild cognitive impairment associated with Alzheimer’s disease",
    "doi": "10.1186/s12967-025-06937-x",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12967-025-06937-x",
    "authors": [
      "Afxenti, Sotiroula",
      "Zachariou, Margarita",
      "Athieniti, Efi",
      "Lambrianides, Anastasia",
      "Pantzaris, Marios",
      "Spyrou, George M."
    ],
    "publicationDate": "2025-11-07",
    "publicationName": "Journal of Translational Medicine",
    "contentType": "Article",
    "abstract": "Background Mild Cognitive Impairment (MCI), considered the prodromal stage of Alzheimer’s disease (AD), is a heterogeneous condition characterised by mild but measurable cognitive decline. However, not all individuals with MCI follow the same trajectory—some remain stable, while others progress rapidly to AD. Understanding variation in clinical, molecular, and imaging features is crucial for reducing disease heterogeneity, improving prognosis, and developing targeted interventions. This study aims to increase MCI subtyping resolution by generating enriched individual-level profiles through the integration of imaging and omics data, facilitating precision medicine approaches for AD prevention and treatment. Methods We used data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI), including structural MRI, CSF peptidomics/proteomics, and clinical indices. Using a multi-modal integration and clustering framework, we identified distinct MCI subgroups, characterised by clinical and neuropsychological scores, AD biomarkers, biological pathway enrichments, and imaging patterns. We further employed supervised multi-modal integration and correlation analyses to explore the links between imaging, peptidomic/proteomic and clinical features within each subgroup. Additionally, we labelled individuals by future conversion to AD and analysed longitudinal cognitive function (CDRSB and MMSE scores). Finally, we performed in silico drug repurposing to identify candidate drugs targeting each subgroup’s molecular profile. Results (1) Multi-modal integration revealed two distinct MCI subgroups. (2) The Resilient Neuronal Hyperplasticity subgroup was characterised by elevated markers of neuronal plasticity, minimal brain atrophy and cortical thinning, better clinical scores, and upregulated peptide/protein markers associated with less severe structural changes. In contrast, the Vulnerable Neurodegenerative subgroup exhibited AD-like disturbances, pronounced atrophy and cortical thinning, primarily affecting executive functions, and downregulation of peptide/protein markers linked to significant structural changes. (3) Future conversion analysis revealed the second subgroup predominantly comprised fast converters, while the first predominantly consisted of stable individuals. (4) Longitudinal cognitive analysis showed a more pronounced decline in the second subgroup compared to the first. (5) Drug repurposing identified both shared and subgroup-specific candidate compounds aligned with the underlying pathologies. Conclusions This study delineates two MCI subgroups, using multi-modal integration, offering insights into disease heterogeneity and laying the foundation for precision medicine and AI-driven strategies in MCI and AD research and clinical care.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A pre-trained large generative model for translating single-cell transcriptomes to proteomes",
    "doi": "10.1038/s41551-025-01528-z",
    "url": "https://www.nature.com/articles/s41551-025-01528-z",
    "authors": [
      "Liu, Linjing",
      "Li, Wei",
      "Wang, Fang",
      "Li, Yiming",
      "Huang, Long-Kai",
      "Wong, Ka-Chun",
      "Yang, Fan",
      "Yao, Jianhua"
    ],
    "publicationDate": "2025-11-05",
    "publicationName": "Nature Biomedical Engineering",
    "contentType": "Article",
    "abstract": "Measuring protein abundance at the single-cell level can facilitate a high-resolution understanding of biological mechanisms in cellular processes and disease progression. However, current single-cell proteomic technologies face challenges such as limited coverage, constrained throughput and sensitivity, batch effects, high costs and stringent experimental operations. Inspired by the translation procedure in both natural language processing and the genetic central dogma, we propose a pre-trained, large generative model named single-cell translator (scTranslator). scTranslator can generate multi-omics data by inferring the missing single-cell proteome based on the transcriptome. Through systematic benchmarking and validation on independent datasets, we have confirmed the accuracy, stability and flexibility of scTranslator across various profiling techniques (for example, CITE-seq, spatial CITE-seq, REAP-seq, NEAT-seq), cell types (for example, monocytes, macrophages, T cells, B cells), tissues (for example, blood, lung, brain) and a wide range of disease contexts, including infectious, metabolic and oncologic conditions. Furthermore, scTranslator shows its superiority in assisting various downstream analyses and applications, including gene/protein interaction inference, perturbation prediction, cell clustering, batch correction and cell origin recognition in pan-cancer data. scTranslator is a large-scale generative model that translates single-cell transcriptomic data to proteomic data and can assess the impact of gene perturbation on protein levels.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Transcriptome-conditioned molecule generation via gene interaction-aware fragment modeling with a GPT-based architecture",
    "doi": "10.1038/s41598-025-17439-7",
    "url": "https://www.nature.com/articles/s41598-025-17439-7",
    "authors": [
      "Koo, Bonil",
      "Park, Bo Kyung",
      "Kim, Sun"
    ],
    "publicationDate": "2025-11-04",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": "Phenotype-driven drug discovery leverages cellular responses to guide the design of therapeutic molecules. Recent advancements in transcriptomics have provided extensive datasets describing how gene expression changes in response to various chemical stimuli, presenting an opportunity to directly link molecular generation to specific cellular phenotypes. However, effectively linking transcriptomic perturbations to chemical structure generation remains challenging due to the complexity of gene interactions and chemical feasibility constraints. We developed GGIFragGPT, a novel generative model that integrates transcriptomic perturbation profiles with biologically informed gene-gene interaction embeddings to guide fragment-based molecular generation. The model employs an autoregressive transformer architecture to sequentially assemble chemically valid fragments, with cross-attention mechanisms highlighting biologically relevant genes guiding the molecular generation process. Comparative analysis confirmed that the proposed approach yields chemically feasible, novel, and diverse molecules. By leveraging transcriptomic profiles, GGIFragGPT successfully generated compounds aligned with the biological context suggested by transcriptomic data, validated through gene-level interpretability analysis that identified key target genes. Case studies demonstrated the model’s capability to produce structurally plausible inhibitors, exemplified by targeted molecule generation against CDK7. This work demonstrates the potential of integrating biological insights into chemical generation processes, offering a promising approach for phenotype-driven therapeutic discovery.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multi-modal single-cell platform for nanoparticle-enhanced time-series metabolic profiles of CD8^+ T cell exhaustion in tumor immunosurveillance",
    "doi": "10.1186/s12951-025-03774-4",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12951-025-03774-4",
    "authors": [
      "Yang, Chenjie",
      "Gao, Mingxia",
      "Zhang, Xiangmin",
      "Yu, Hailong",
      "Deng, Chunhui"
    ],
    "publicationDate": "2025-11-04",
    "publicationName": "Journal of Nanobiotechnology",
    "contentType": "Article",
    "abstract": "Cytotoxic T cells (CD8^+) play a pivotal role in immunosurveillance by identifying and eliminating tumor cells. However, the onset of CD8^+ T cell exhaustion, characterized by overexpression of immune checkpoint receptors, impairs their function, allowing tumor cells to evade immunosurveillance. Single-cell metabolic profiles hold the promise in characterizing intrinsic cellular metabolic heterogeneity of exhausted CD8^+ T cells, even at ultra-early time points. Herein, we developed a multi-modal single-cell platform that integrates nanoparticles-enhanced laser desorption/ionization mass spectrometry and protein number counting platform to elucidate the temporal dynamics of CD8^+ T cell exhaustion. A comprehensive time-series analysis was conducted, with nearly 3000 single cells performing metabolic profile extraction and checkpoint receptors quantification. Our results demonstrated that the onset of exhaustion was as early as 3 h post-stimulation and upon cessation of stimulation, a degree of reversibility was observed in these exhausted cells. Using deep learning algorithms, the discrimination of the different exhausted CD8^+ T cell subpopulations from the control achieved an area under the curve value of more than 0.904, even to 1.000 with 100% sensitivity and specificity. Our work presents a robust, high-throughput, and scalable system for multi-modal single-cell analysis, offering valuable insights into the dynamics of CD8^+ T cell exhaustion.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Redefining oral healthcare through artificial intelligence: a review of current applications and a roadmap for the future of dentistry",
    "doi": "10.1186/s44398-025-00013-6",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s44398-025-00013-6",
    "authors": [
      "Dua, Bharti",
      "Kumar Gupta, Rajiv",
      "Bhargava, Akshay",
      "Bhardwaj, Anupam",
      "Jain, Meena",
      "Tripathi, Siddhi"
    ],
    "publicationDate": "2025-11-03",
    "publicationName": "BMC Artificial Intelligence",
    "contentType": "Article",
    "abstract": "The integration of artificial intelligence (AI) into dental practice represents a significant technological advancement in oral healthcare. This narrative review examines current research across AI domains including machine learning, deep learning, computer vision, natural language processing, and generative modeling to assess how AI is influencing clinical workflows, diagnostic procedures, treatment planning, and surgical interventions in dentistry. The central research question addresses how artificial intelligence is currently being applied in dental practice and what opportunities and challenges exist for its future implementation.  Evidence from peer-reviewed studies demonstrates variable efficacy of AI in supporting diagnostic decisions for caries, periodontal disease, and oral cancer; assisting orthodontic planning and prosthodontic CAD/CAM workflows; and enabling robotic surgery and predictive modeling. While some AI models show promising accuracy metrics, questions remain about their generalizability and real-world performance. The review explores integration of AI through electronic health records, decision-support systems, and emerging digital twin technologies. Interdisciplinary collaborations with biomedical engineering, computational biology, and materials science are examined. Critical challenges including algorithmic bias, data privacy, informed consent, liability frameworks, and adoption barriers such as technological infrastructure, clinician acceptance, and regulatory uncertainties are discussed. Future directions emphasize federated learning for collaborative model development; explainable AI to improve transparency; integration with multi-omics data; and adaptive systems capable of continuous learning. This review provides a balanced assessment of AI's potential in dentistry while acknowledging significant implementation challenges that must be addressed to ensure equitable and effective patient care.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Artificial Intelligence in Biotechnology and Pharmaceuticals: Evolution, Applications, and Regulatory Frontiers",
    "doi": "10.1007/s40778-025-00249-y",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40778-025-00249-y",
    "authors": [
      "Somara, Sita",
      "Joshi, Amol M.",
      "Mitra, Kunal",
      "Desai, Salil",
      "Lundberg, Martha S.",
      "Bhasin, Sanjay",
      "Hunsberger, Joshua"
    ],
    "publicationDate": "2025-11-01",
    "publicationName": "Current Stem Cell Reports",
    "contentType": "Article",
    "abstract": "Purpose of Review This review aims to examine how Artificial Intelligence (AI) is revolutionizing the biotechnology and pharmaceutical industries by transforming traditional drug development processes, enhancing precision medicine, and accelerating healthcare innovation. Specifically, it seeks to trace the historical evolution of AI in this field, evaluate its current applications across the drug development pipeline, and assess the challenges and regulatory considerations influencing its integration. Recent Findings Recent advances have demonstrated AI’s profound impact on drug discovery and development, enabled by deep learning, big data analytics, and natural language processing. Key milestones, such as the Human Genome Project and the emergence of AI-driven biotech startups, have catalyzed applications spanning target identification, molecular design, clinical trials optimization, and regulatory workflows. Notable applications include protein structure prediction, image-based diagnostics, real-world data analysis, gene expression modeling, and gene editing using CRISPR. Concurrently, regulatory agencies such as the FDA, EMA, and MHRA are developing guidelines to address AI’s role in healthcare, distinguishing regulated from unregulated use cases. However, challenges persist regarding data privacy, intellectual property, synthetic data validation, and workforce readiness for AI adoption. Summary This review highlights that AI is poised to unlock transformative personalized therapies through the convergence of generative AI, multi-omics data, and genome editing technologies. While the promise of AI in healthcare is vast, realizing its potential requires robust governance frameworks, ethical standards, and interdisciplinary collaboration to ensure responsible innovation, transparency, and regulatory alignment. Addressing these considerations will be critical to accelerate AI-enabled drug development and deliver impactful, patient-centered solutions in the future.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Integrative deep learning of spatial multi-omics with SWITCH",
    "doi": "10.1038/s43588-025-00891-w",
    "url": "https://www.nature.com/articles/s43588-025-00891-w",
    "authors": [
      "Li, Zhongzhan",
      "Qu, Sanqing",
      "Liang, Haixin",
      "Tang, Ruohui",
      "Zhang, Xudong",
      "Lu, Fan",
      "Yang, Jiani",
      "Gan, Ziling",
      "Gao, Shaorong",
      "Zhang, Yanping",
      "Chen, Guang"
    ],
    "publicationDate": "2025-11-01",
    "publicationName": "Nature Computational Science",
    "contentType": "Article",
    "abstract": "In this study the authors present SWITCH, a deep learning model that integrates unpaired spatial multi-omics data and enables unsupervised cross-modal prediction, aiding spatial domain identification and downstream biological analysis. Advancements in spatial omics permit spatially resolved measurements across several biological modalities. The high cost of acquiring co-profiled multimodal data limits the analysis. This underscores the necessity for computational methods to integrate unpaired spatial multi-omics data and perform cross-modal predictions on single-modality data. The integration of spatial omics is challenging due to typically low signal-to-noise ratios. Here we introduce SWITCH (Spatially Weighted Multi-omics Integration and Cross-modal Translation with Cycle-mapping Harmonization), a deep generative model for spatial multi-omics integration. SWITCH presents a cycle-mapping mechanism that produces dependable cross-modal translations without requiring additional paired data. These cross-modal translations function as pseudo-pairs to provide supplementary signals. Systematic evaluations demonstrate that SWITCH outperforms existing methods in terms of integration accuracy and achieves more precise spatial domain delineation, resolving brain cortical structures at higher resolution. The reliability of cross-modal translations was validated, facilitating various downstream analyses such as differential analysis, trajectory inference and gene regulatory network inference.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Overcoming barriers to the wide adoption of single-cell large language models in biomedical research",
    "doi": "10.1038/s41587-025-02846-y",
    "url": "https://www.nature.com/articles/s41587-025-02846-y",
    "authors": [
      "Xie, Fang",
      "Zhao, Bingkang",
      "Xu, Songxiang",
      "Wang, Zehua",
      "Moon, James J.",
      "Garmire, Lana X."
    ],
    "publicationDate": "2025-11-01",
    "publicationName": "Nature Biotechnology",
    "contentType": "Article",
    "abstract": "Transformer-based large language models are gaining traction in biomedical research, particularly in single-cell omics. Despite their promise, the application of single-cell large language models (scLLMs) remains limited in practice. In this Comment, we examine the current landscape of scLLMs and the benchmark studies that assess their applications in various analytical tasks. We highlight existing technical gaps and practical barriers, and discuss future directions toward a more accessible and effective ecosystem to promote the applications of scLLMs in the biomedical community.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "scooby: modeling multimodal genomic profiles from DNA sequence at single-cell resolution",
    "doi": "10.1038/s41592-025-02854-5",
    "url": "https://www.nature.com/articles/s41592-025-02854-5",
    "authors": [
      "Hingerl, Johannes C.",
      "Martens, Laura D.",
      "Karollus, Alexander",
      "Manz, Trevor",
      "Buenrostro, Jason D.",
      "Theis, Fabian J.",
      "Gagneur, Julien"
    ],
    "publicationDate": "2025-11-01",
    "publicationName": "Nature Methods",
    "contentType": "Article",
    "abstract": "scooby achieves DNA sequence-based single-cell level modeling of RNA-sequencing coverage and ATAC-sequencing insertion profiles by adapting a deep learning model that predicts bulk RNA-sequencing coverage. Understanding how regulatory sequences shape gene expression across individual cells is a fundamental challenge in genomics. Joint RNA sequencing and epigenomic profiling provides opportunities to build models capturing sequence determinants across steps of gene expression. However, current models, developed primarily for bulk omics data, fail to capture the cellular heterogeneity and dynamic processes revealed by single-cell multimodal technologies. Here, we introduce scooby, a framework to model genomic profiles of single-cell RNA-sequencing coverage and single-cell assay for transposase-accessible chromatin using sequencing insertions from sequence at single-cell resolution. For this, we leverage the pretrained multiomics profile predictor Borzoi and equip it with a cell-specific decoder. Scooby recapitulates cell-specific expression levels of held-out genes and identifies regulators and their putative target genes. Moreover, scooby allows resolving single-cell effects of bulk expression quantitative trait loci and delineating their impact on chromatin accessibility and gene expression. We anticipate scooby to aid unraveling the complexities of gene regulation at the resolution of individual cells.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "TDP-43 loss induces cryptic polyadenylation in ALS/FTD",
    "doi": "10.1038/s41593-025-02050-w",
    "url": "https://www.nature.com/articles/s41593-025-02050-w",
    "authors": [
      "Bryce-Smith, Sam",
      "Brown, Anna-Leigh",
      "Chien, Max Z. Y. J.",
      "Dattilo, Dario",
      "Mehta, Puja R.",
      "Mattedi, Francesca",
      "Barattucci, Simone",
      "Mikheenko, Alla",
      "Zanovello, Matteo",
      "Pellegrini, Flaminia",
      "El-Agamy, Sara Emad",
      "Yome, Matthew",
      "Hill, Sarah E.",
      "Qi, Yue A.",
      "Sun, Kai",
      "Ryadnov, Eugeni",
      "Wan, Yixuan",
      "Vargas, Jose Norberto S.",
      "Birsa, Nicol",
      "Raj, Towfique",
      "Humphrey, Jack",
      "Keuss, Matthew",
      "Wilkins, Oscar G.",
      "Ward, Michael",
      "Secrier, Maria",
      "Fratta, Pietro",
      "NYGC ALS Consortium"
    ],
    "publicationDate": "2025-11-01",
    "publicationName": "Nature Neuroscience",
    "contentType": "Article",
    "abstract": "The authors find that TDP-43 loss of function—the pathology defining the neurodegenerative conditions ALS and FTD—induces novel mRNA polyadenylation events, which have different effects, including an increase in RNA stability, leading to higher protein levels. Nuclear depletion and cytoplasmic aggregation of the RNA-binding protein TDP-43 are cellular hallmarks of amyotrophic lateral sclerosis (ALS). TDP-43 nuclear loss causes de-repression of cryptic exons, yet cryptic alternative polyadenylation (APA) events have been largely overlooked. In this study, we developed a bioinformatic pipeline to reliably identify alternative last exons, 3’ untranslated region (3’UTR) extensions and intronic polyadenylation APA event types, and we identified cryptic APA sites induced by TDP-43 loss in induced pluripotent stem cell (iPSC)-derived neurons. TDP-43 binding sites are enriched at sites of these cryptic events, and TDP-43 can both repress and enhance APA. All categories of cryptic APA were also identified in ALS and frontotemporal dementia (FTD) postmortem brain tissue. RNA sequencing (RNA-seq), thiol(SH)-linked alkylation for the metabolic sequencing of RNA (SLAM-seq) and ribosome profiling (Ribo-seq) revealed that distinct cryptic APA categories have different downstream effects on transcript levels and that cryptic 3’UTR extensions can increase RNA stability, leading to increased translation. In summary, we demonstrate that TDP-43 nuclear depletion induces cryptic APA, expanding the palette of known consequences of TDP-43.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "MicroRNA bioinformatics in precision oncology: an integrated pipeline from NGS to AI-based target discovery",
    "doi": "10.1007/s13353-025-01024-9",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13353-025-01024-9",
    "authors": [
      "Dey, Mritunjoy",
      "Remiszewski, Piotr",
      "Piątkowski, Jakub",
      "Golik, Paweł",
      "Teterycz, Paweł",
      "Czarnecka, Anna M."
    ],
    "publicationDate": "2025-10-31",
    "publicationName": "Journal of Applied Genetics",
    "contentType": "Article",
    "abstract": "Despite the growing recognition of microRNAs (miRNAs) as critical biomarkers in cancer, current approaches to their analysis remain fragmented, disjointed, and poorly integrated with emerging computational advances. This lack of cohesion limits progress toward reproducible and clinically actionable biomarker discovery. To address this unmet need, we present a review that unifies the latest findings and tools in bioinformatics, machine learning (ML), and large language models (LLMs) for miRNA analysis in oncology, thereby bridging a significant methodological gap in the field. We begin by critically synthesizing, benchmarking, and evaluating algorithms, including miRDeep2 and DIANA-miRPath, within a functional pipeline that spans next-generation sequencing (NGS) data processing to multi-omics integration. Building on this foundation, we review ML-augmented layers incorporating supervised and deep learning (DL) algorithms, specifically support vector machines (SVMs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs), to enable robust miRNA signature identification, classification, and target prediction. Furthermore, we explore the integration of generative models and LLMs to support hypothesis generation and enhance reproducibility in biomarker discovery workflows. This comprehensive framework enhanced with artificial intelligence (AI) is contextualized through cancer-specific datasets, with particular emphasis on translational applications for early detection, prognosis, and therapy selection. By systematically organizing fragmented methodologies into a scalable and reproducible pipeline, our work provides a strategic roadmap to accelerate the development of miRNA-based precision cancer.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A novel modality contribution confidence-enhanced multimodal deep learning framework for multiomics data",
    "doi": "10.1186/s12859-025-06219-9",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12859-025-06219-9",
    "authors": [
      "Zhang, Duoyi",
      "Bashar, Md Abul",
      "Nayak, Richi",
      "Cuttle, Leila"
    ],
    "publicationDate": "2025-10-31",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": "Multimodal learning for classification tasks has recently gained significant attention in bioinformatics. Current approaches primarily concentrate on devising efficient deep learning architectures to capture features within and across modalities. However, they typically assume that each modality contributes equally to the classification objective, overlooking inherent biases within multimodal learning. This paper presents a modality contribution confidence-enhanced deep learning framework to address this issue, resulting in an improved fusion space and improved classification performance on multiomics data. Specifically, we propose utilising a non-parametric Gaussian Process to assess the unimodal confidence of each modality and learn within-modality features. Additionally, we introduce the use of the Kullback-Leibler divergence to align multiple modalities and learn cross-modality features. Extensive experiments on four multiomics datasets, incorporating modalities such as static information, DNA, mRNA, miRNA, and protein data, validate the effectiveness of the proposed method. Furthermore, a case study on the blister recovery task is included to demonstrate the practical utility of our model.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A novel prediction method for protein-DNA binding sites based on protein language model fusion features with SE-connection pyramidal network and ensemble learning",
    "doi": "10.1186/s12864-025-12196-3",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12864-025-12196-3",
    "authors": [
      "Zhang, Chenrui",
      "Jiang, Jingqing",
      "Zhao, Haiyan",
      "Song, Jiazhi"
    ],
    "publicationDate": "2025-10-30",
    "publicationName": "BMC Genomics",
    "contentType": "Article",
    "abstract": "Protein-DNA interactions are crucial in life processes such as gene expression and regulation. Therefore, the accurate prediction of DNA-binding sites on proteins is highly important for the advancement of scientific understanding in the field of biological activities. In this work, we propose a protein-DNA binding site prediction framework, termed Evolutionary Scale Modeling-SE-Connection Pyramidal (ESM-SECP), which integrates a sequence-feature-based prediction method with a sequence-homology-based predictor via ensemble learning. The sequence-feature-based prediction method is built on two types of input features: ESM-2 protein language model embeddings and evolutionary conservation information computed by PSI-BLAST. These features are fused by a multi-head attention mechanism and processed through the newly proposed SE-Connection Pyramidal(SECP) network for prediction. The sequence-template method, based on sequence homology, serves as a complementary approach to predict DNA-binding residues. The two predictors are combined via ensemble learning to improve overall model performance. Through the experimental validation of the TE46 and TE129 datasets, ESM-SECP outperforms the traditional methods in several evaluation indices, demonstrating its outstanding performance in Protein-DNA binding site prediction.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Transformer-based representation learning for robust gene expression modeling and cancer prognosis",
    "doi": "10.1038/s41598-025-14949-2",
    "url": "https://www.nature.com/articles/s41598-025-14949-2",
    "authors": [
      "Jiang, Shuai",
      "Hassanpour, Saeed"
    ],
    "publicationDate": "2025-10-28",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": "Transformer models have achieved remarkable success in natural language and vision tasks, but their application to gene expression analysis remains limited due to data sparsity, high dimensionality, and missing values. We present GexBERT, a transformer-based encoder-decoder framework for robust representation learning of gene expression data. GexBERT learns context-aware gene embeddings by pretraining on large-scale transcriptomic profiles with a masking and restoration objective that captures co-expression relationships among thousands of genes. We evaluate GexBERT across three critical tasks in cancer research: pan-cancer classification, cancer-specific survival prediction, and missing value imputation. GexBERT achieves state-of-the-art classification accuracy from limited gene subsets, improves survival prediction by restoring expression of prognostic anchor genes, and outperforms conventional imputation methods under high missingness. These findings demonstrate the utility of GexBERT as a scalable and effective tool for gene expression modeling, with translational potential in settings where gene coverage is limited or incomplete.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Transformative advances in single-cell omics: a comprehensive review of foundation models, multimodal integration and computational ecosystems",
    "doi": "10.1186/s12967-025-07091-0",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12967-025-07091-0",
    "authors": [
      "Yiu, Taylor",
      "Chen, Bin",
      "Wang, Haoyu",
      "Feng, Genyi",
      "Fu, Qiangqiang",
      "Hu, Huijing"
    ],
    "publicationDate": "2025-10-27",
    "publicationName": "Journal of Translational Medicine",
    "contentType": "Article",
    "abstract": "Recent advances in single-cell multi-omics technologies have revolutionized cellular analysis, enabling comprehensive exploration of cellular heterogeneity, developmental trajectories, and disease mechanisms at unprecedented resolution. Foundation models, originally developed for natural language processing, are now driving transformative approaches to high-dimensional, multimodal single-cell data analysis. Frameworks such as scGPT and scPlantFormer excel in cross-species cell annotation, in silico perturbation modeling, and gene regulatory network inference. Multimodal integration approaches, including pathology-aligned embeddings and tensor-based fusion, harmonize transcriptomic, epigenomic, proteomic, and spatial imaging data to delineate multilayered regulatory networks across biological scales. Federated computational platforms facilitate decentralized data analysis and standardized, reproducible workflows, fostering global collaboration. Challenges persist, including technical variability across platforms, limited model interpretability, and gaps in translating computational insights into clinical applications. Overcoming these hurdles demands standardized benchmarking, multimodal knowledge graphs, and collaborative frameworks that integrate artificial intelligence with human expertise. This review synthesizes recent technological advancements and proposes actionable strategies to bridge single-cell multi-omics innovations with mechanistic biology and precision medicine.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "MultiGATE: integrative analysis and regulatory inference in spatial multi-omics data via graph representation learning",
    "doi": "10.1038/s41467-025-63418-x",
    "url": "https://www.nature.com/articles/s41467-025-63418-x",
    "authors": [
      "Miao, Jishuai",
      "Li, Jinzhao",
      "Xin, Jingxue",
      "Tu, Jiajuan",
      "Ge, Muyang",
      "Qi, Ji",
      "Zhou, Xiaocheng",
      "Zhu, Ying",
      "Yang, Can",
      "Lin, Zhixiang"
    ],
    "publicationDate": "2025-10-24",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Spatial multi-omics profiles multiple molecular modalities in the native spatial context. Here, authors introduce MultiGATE, a deep learning tool with a two-level graph attention auto-encoder, to integrate these data to uncover cross-modality regulatory interactions and improve spatial clustering. New spatial multi-omics technologies, which jointly profile transcriptome and epigenome/protein markers for the same tissue section, expand the frontiers of spatial techniques. Here, we introduce MultiGATE, which utilizes a two-level graph attention auto-encoder to integrate the multi-modality and spatial information in spatial multi-omics data. The key feature of MultiGATE is that it simultaneously performs embedding of the spatial pixels and infers the cross-modality regulatory relationship, which allows deeper data integration and provides insights on transcriptional regulation. We evaluate the performance of MultiGATE on spatial multi-omics datasets obtained from different tissues and platforms. Through effectively integrating spatial multi-omics data, MultiGATE both enhances the extraction of latent embeddings of the pixels and boosts the inference of transcriptional regulation for cross-modality genomic features.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Advancing non-coding RNA annotation with RNA sequence foundation models: structure and function perspectives",
    "doi": "10.1186/s44398-025-00012-7",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s44398-025-00012-7",
    "authors": [
      "Vahab, Naima",
      "Tyagi, Sonika"
    ],
    "publicationDate": "2025-10-14",
    "publicationName": "BMC Artificial Intelligence",
    "contentType": "Article",
    "abstract": "Noncoding RNAs (ncRNAs) form the major part of the expressed transcriptome. These are critical in regulating gene expression and contributing to disease mechanisms, primarily through their complex secondary and tertiary structures. Despite advances in experimental and computational methodologies, accurate prediction of ncRNA structures and functions remains limited. Knowledge of RNA structures can not only answer basic biological questions but can also be of great help in the design of new types of drugs and therapies, emphasising the urgency for scalable and precise prediction tools. The experimental determination of the structure and function of ncRNAs remains costly and labour-intensive, which has prompted the development of computational approaches, including machine learning. Recent efforts are shifting towards using language modelling and developing generic foundation models (FM) to analyse RNA structure and function. These models leverage widely available unannotated sequence data to improve upon the generalisability and accuracy of earlier thermodynamic and deep learning techniques. A number of RNA FMs have been developed for diverse tasks such as secondary structure prediction, function annotation, RNA design. This review analyses current efforts in developing RNA FMs, evaluating their architectures, training strategies, and predictive capabilities. We highlight key trends, limitations, and outline open challenges, aiming to guide future research in RNA structure-function modelling.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multimodal deep learning model for prediction of breast cancer recurrence risk and correlation with oncotype DX",
    "doi": "10.1186/s13058-025-02129-z",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13058-025-02129-z",
    "authors": [
      "Zhang, Ruixin",
      "Wang, Kaiting",
      "Wang, Shiwei",
      "Wang, Chunjie",
      "Cao, Tingting",
      "Ci, Ce",
      "Xu, Maosheng",
      "Ge, Min"
    ],
    "publicationDate": "2025-10-14",
    "publicationName": "Breast Cancer Research",
    "contentType": "Article",
    "abstract": "Background Proper stratification of recurrence risk in breast cancer is crucial for guiding treatment decisions. This study aims to predict the recurrence risk of breast cancer patients using a multimodal deep learning model that integrates multiple sequence MRI imaging features with clinicopathologic characteristics. Methods In this retrospective study, we enrolled 574 patients with non-metastatic invasive breast cancer from two Chinese institutions between September 2012 and July 2019. We developed a multimodal deep learning (MDL) model by constructing a multi-instance learning framework based on convolutional neural networks. We integrated imaging features from T2WI, DWI, and DCE-MRI sequences with clinicopathologic features for breast cancer recurrence risk stratification. Subsequently, the performance of the MDL model was evaluated using receiver operating characteristic (ROC) curves, the Hosmer–Lemeshow test, calibration curves, and decision curve analysis (DCA). Survival analysis was conducted with Kaplan–Meier survival curves to stratify breast cancer patients into high and low-recurrence risk groups. Time-dependent ROC curves were used to assess 3-year, 5-year, and 7-year recurrence-free survival (RFS) for breast cancer patients. Additionally, we performed differential and enrichment analyses on Oncotype DX genes. We correlated these genes with clinicopathologic features and deep-learning radiographic features using univariate Cox regression and Pearson correlation analysis. Results The MDL model demonstrated good performance in predicting breast cancer recurrence risk and accurately differentiated between high- and low-recurrence risk groups, with an AUC as high as 0.915 (95% CI 0.8448–0.9856). The C-index of prediction models was 0.803 in the testing cohort. The AUCs for 5-year and 7-year RFS were 0.936 (95% CI 0.876–0.997) and 0.956 (95% CI 0.902–1.000) in the validation cohort. In the testing cohort, these AUCs were 0.836 (95% CI 0.763–0.909) and 0.783 (95% CI 0.676–0.891). This study found a significant correlation between Oncotype DX gene expression, clinicopathologic features, and deep-learning radiographic features ( p  < 0.05). Conclusions This study validated the robust predictive accuracy of the MDL model in identifying high- and low-risk groups for recurrence. The correlations identified between Oncotype DX genes, clinicopathologic features, and deep-learning radiographic features offer novel insights for future biomarker research in breast cancer.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Towards smart agriculture: AI-driven prediction of key genes for revolutionizing crop breeding",
    "doi": "10.1007/s00425-025-04841-8",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00425-025-04841-8",
    "authors": [
      "Cai, Shaobo",
      "Sun, Changhui",
      "Tian, Jianhong"
    ],
    "publicationDate": "2025-10-09",
    "publicationName": "Planta",
    "contentType": "Article",
    "abstract": "Main conclusion AI-driven key gene prediction is revolutionizing crop breeding, enhancing precision, efficiency, and sustainability while paving the way for intelligent, data-driven agricultural innovation. Abstract The integration of artificial intelligence (AI) into crop breeding is ushering agriculture into a data-driven era of precision practices, fundamentally reshaping the efficiency and accuracy of crop improvement. This review provides an in-depth analysis of recent advances in AI-based key gene prediction within the field of crop breeding. It comprehensively evaluates the application outcomes and potential impacts, encompassing multi-omics data integration, deep learning model construction, key gene prediction, and variety design. Representative models such as SoyDNGP have significantly improved the coefficient of determination (R^2) for soybean yield prediction to 0.89—substantially outperforming traditional GBLUP models (R^2 = 0.72)—through innovative data transformation and analytical strategies, while accurately pinpointing high-yield associated genomic regions such as qYield-08-3. Moreover, AI has successfully identified key genes across various crops, including cotton (fiber development) and maize (nitrogen use efficiency), thereby enabling targeted trait improvement. Nonetheless, future development faces critical challenges, including the standardization of heterogeneous data sources, data security risks, the black-box nature of deep learning models, and limitations associated with small-sample learning. Looking ahead, it is imperative to establish an intelligent breeding loop encompassing AI prediction–gene editing–robotic execution, advance agricultural large language models (Agri-LLMs) for inclusive applications, build sustainable breeding evaluation systems, and empower smallholder farmers through edge computing technologies. Through interdisciplinary collaboration and global data sharing, AI is poised to break through the limitations of traditional breeding and provide essential technological support for global food security and sustainable agricultural development. In essence, this progress follows three core trajectories: (1) a technological paradigm shift from empirical breeding to precision design; (2) multidimensional application value across efficiency, productivity, and sustainability; and (3) the pursuit of an intelligent, green, and inclusive future for agriculture.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "An intelligent healthcare system for rare disease diagnosis utilizing electronic health records based on a knowledge-guided multimodal transformer framework",
    "doi": "10.1186/s13040-025-00487-0",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13040-025-00487-0",
    "authors": [
      "Abugabah, Ahed",
      "Shukla, Prashant Kumar",
      "Shukla, Piyush Kumar",
      "Pandey, Ankur"
    ],
    "publicationDate": "2025-10-07",
    "publicationName": "BioData Mining",
    "contentType": "Article",
    "abstract": "Rare diseases are a common problem with millions of patients globally, but their diagnosis is difficult because of varied clinical presentations, small sample size, and disparate biomedical data sources. Current diagnostic tools are not able to combine multimodal information effectively, which results in a timely or wrong diagnosis. To fill this gap, this paper suggests a smart multimodal healthcare framework integrating electronic health records (EHRs), genomic sequences, and medical imaging to improve the detection of rare diseases. The framework uses Swin Transformer to extract hierarchical visual features in radiographic scans, Med-BERT and Transformer-XL to learn semantic and long-term temporal relations in longitudinal electronic health record narratives, and a Graph Neural Network (GNN)-based encoder to learn functional and structural relations in genomic sequences. The alignment of the cross-modal representation is further boosted with a Knowledge-Guided Contrastive Learning (KGCL) mechanism, which takes advantage of rare disease ontologies in Orphanet to improve the interpretability of the model and infusion of knowledge. To achieve strong performance, the Nutcracker Optimization Algorithm (NOA) is proposed to optimize hyperparameters, calibrate attention mechanisms, and enhance multimodal fusion. Experimental results on MIMIC-IV (EHR), ClinVar (genomics), and CheXpert (imaging) datasets show that the proposed framework significantly outperforms the state-of-the-art multimodal baselines in terms of accuracy and robustness of early rare disease diagnosis. This paper presents the opportunity to integrate hierarchical vision transformers, domain-specific language models, graph-based genomic encoders, and knowledge-directed optimization to make explainable, accurate, and clinically applicable healthcare decisions in rare disease settings.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Integrating cross-sample and cross-modal data for spatial transcriptomics and metabolomics with SpatialMETA",
    "doi": "10.1038/s41467-025-63915-z",
    "url": "https://www.nature.com/articles/s41467-025-63915-z",
    "authors": [
      "Tian, Ruonan",
      "Xue, Ziwei",
      "Chen, Yiru",
      "Qi, Yicheng",
      "Zhang, Jian",
      "Yuan, Jie",
      "Ruan, Dengfeng",
      "Lin, Junxin",
      "Liu, Jia",
      "Wang, Di",
      "Ye, Youqiong",
      "Liu, Wanlu"
    ],
    "publicationDate": "2025-10-06",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Simultaneous profiling of spatial transcriptomics (ST) and spatial metabolomics (SM) on the same or adjacent tissue sections offers a revolutionary approach to decode tissue microenvironment and identify potential therapeutic targets for cancer immunotherapy. Unlike other spatial omics, cross-modal integration of ST and SM data is challenging due to differences in feature distributions of transcript counts and metabolite intensities, and inherent disparities in spatial morphology and resolution. Furthermore, cross-sample integration is essential for capturing spatial consensus and heterogeneous patterns but is often complicated by batch effects. Here, we introduce SpatialMETA, a conditional variational autoencoder (CVAE)-based framework for cross-modal and cross-sample integration of ST and SM data. SpatialMETA employs tailored decoders and loss functions to enhance modality fusion, batch effect correction and biological conservation, enabling interpretable integration of spatially correlated ST-SM patterns and downstream analysis. SpatialMETA identifies immune spatial clusters with distinct metabolic features in cancer, revealing insights that extend beyond the original study. Compared to existing tools, SpatialMETA demonstrates superior reconstruction capability and fused modality representation, accurately capturing ST and SM feature distributions. In summary, SpatialMETA offers a powerful platform for advancing spatial multi-omics research and refining the understanding of metabolic heterogeneity within the tissue microenvironment. Simultaneous profiling of spatial transcriptomics (ST) and metabolomics (SM) offers a novel way to decode tissue microenvironment heterogeneity. Here, the authors present SpatialMETA, a conditional variational autoencoder-based framework designed for the integration of ST and SM data.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Cisformer: a scalable cross-modality generation framework for decoding transcriptional regulation at single-cell resolution",
    "doi": "10.1186/s13059-025-03823-z",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13059-025-03823-z",
    "authors": [
      "Ji, Luzhang",
      "Zou, Qihang",
      "Tang, Ke",
      "Wang, Chenfei"
    ],
    "publicationDate": "2025-10-06",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "Single-cell multiomic technologies enable the joint analysis of different modalities, but face challenges due to experimental complexity. Current computational methods for single-cell cross-modality translation lack biological interpretability. Here, we present Cisformer, a cross-attention-based generative model tailored for cross-modality generation between gene expression and chromatin accessibility at single-cell resolution. Systematic benchmarking demonstrates the superior accuracy and generalization of Cisformer against existing methods. Cisformer leverages its inherent interpretability to precisely link cis -regulatory elements to target genes, facilitating the identification of functional transcription factors associated with tumorigenesis and aging. Overall, Cisformer is a powerful tool for single-cell multiomic data analysis.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Identification of key genes for fish adaptation to freshwater and seawater based on attention mechanism",
    "doi": "10.1186/s12864-025-12089-5",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12864-025-12089-5",
    "authors": [
      "Qian, Songping",
      "Zhao, Youjie",
      "Liu, Fangrong",
      "Liu, Lei",
      "Zhou, Qingyang",
      "Zhang, Shunrong",
      "Cao, Yong"
    ],
    "publicationDate": "2025-09-29",
    "publicationName": "BMC Genomics",
    "contentType": "Article",
    "abstract": "The evolutionary divergence of freshwater and marine fish reflects their adaptation to distinct ecological environments, with differences evident in their morphological traits, physiological functions, and genomic structures. Traditional molecular methods often fail to uncover the intricate regulatory relationships among genes under environmental stress. This study proposes the weighted attention gene analysis (WAGA) model, a novel approach that integrates natural language processing (NLP) for protein-coding gene feature representation with deep learning and self-attention (SA) mechanisms. WAGA effectively identifies key genes associated with sensory functions, osmoregulation, and growth and development on the basis of attention weights. The experimental results highlight its effectiveness in revealing genes crucial for ecological adaptation and evolution. This approach is essential for elucidating the mechanisms of ecological adaptability and evolutionary processes, while also offering novel insights and tools to support targeted breeding in aquaculture and fish genomics research.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Interpretable Cancer Survival Prediction by Fusing Semantic Labelling of Cell Types and Whole Slide Images",
    "doi": "10.1007/s12539-025-00744-0",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12539-025-00744-0",
    "authors": [
      "Chen, Jinchao",
      "Liu, Pei",
      "Chen, Chen",
      "Su, Ying",
      "Wang, Jiajia",
      "Chen, Cheng",
      "Ai, Xiantao",
      "Lv, Xiaoyi"
    ],
    "publicationDate": "2025-09-26",
    "publicationName": "Interdisciplinary Sciences: Computational Life Sciences",
    "contentType": "Article",
    "abstract": "Survival prediction involves multiple factors, such as histopathological image data and omics data, making it a typical multimodal task. In this work, we introduce semantic annotations for genes in different cell types based on cell biology knowledge, enabling the model to achieve interpretability at the cellular level. Since these cell type annotations are derived from the unique sites of origin for each cancer type, they can be more closely aligned with morphological features in whole slide images (WSIs) and address the issue of genomic annotation ambiguity. We then propose a multimodal fusion model, SurvTransformer, with multi-layer attention to fuse cell type tags (CTTs) and WSIs for survival prediction. Finally, through attention and integrated gradient attribution, the model provides biologically meaningful interpretable analysis at three different levels: cell type, gene, and histopathology image. Comparative experiments show that SurvTransformer achieves the highest consistency index across four cancer datasets. The survival curves generated are also statistically significant. Ablation experiments show that SurvTransformer outperforms models based on different labeling methods and attention representations. In terms of interpretability, case studies validate the effectiveness of SurvTransformer at three levels: cell type, gene, and histopathological image. Graphical Abstract ",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Machine learning combined with omics-based approaches reveals T-lymphocyte cellular fate imbalance in abdominal aortic aneurysm",
    "doi": "10.1186/s12915-025-02400-x",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12915-025-02400-x",
    "authors": [
      "Li, Demin",
      "Zhang, Ge",
      "Du, Pengchong",
      "Cao, Chang",
      "He, Xuyu",
      "Lv, Yan",
      "Yuan, Peiyu",
      "Wang, Yujia",
      "Wu, Ruhao",
      "Cao, Yifan",
      "Yang, Yu",
      "Gao, Jiamin",
      "Lan, Bo",
      "Shi, Guo-Ping",
      "Cui, Xiaolin",
      "Zhang, Jinying",
      "Tang, Junnan"
    ],
    "publicationDate": "2025-09-26",
    "publicationName": "BMC Biology",
    "contentType": "Article",
    "abstract": "Background Abdominal aortic aneurysm (AAA) is typically an asymptomatic disease closely associated with immune mechanisms. A deep understanding of cellular responses within AAA tissues, particularly the molecular changes in T-cell populations, is critical for disease diagnosis and treatment. However, the specific mechanisms inducing T-lymphocyte fate imbalance in AAA remain to be elucidated. Results The analysis revealed the core mechanisms driving T-lymphocyte fate imbalance in AAA. We successfully established a comprehensive regulatory map encompassing T-cell infiltration regulatory features, critical transcription factors, and dysregulated immune signaling pathways. Machine learning algorithms identified transcription factors FOSB and JUNB as key biomarkers. Validation across multiple independent datasets and clinical samples confirmed the feasibility and accuracy of FOSB and JUNB as clinical diagnostic biomarkers for AAA. Conclusions Through the analysis of single-cell and bulk data, hallmarks of human AAA cellular landscape and T-cell comprehensive developmental relationships were recapitulated. This study identified important roles of T-cell and the molecular mechanisms for the dynamic T-cell infiltrating process, which could characterize disease status and landscape of human AAA microenvironment. Using the deep learning algorithms, FOSB and JUNB were demonstrated as pivotal biomarkers of AAA, together with screening the potential pharmacologic agents targeting T-cell polarization. Taken together, this expands the current understanding of AAA pathogenesis and may provide a feasible immune-targeted therapeutic strategy.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multi-modal characterization of metabolic and immune gene clusters in adrenocortical carcinoma treatment",
    "doi": "10.1038/s41698-025-01092-4",
    "url": "https://www.nature.com/articles/s41698-025-01092-4",
    "authors": [
      "Hao, Wenjun",
      "Yao, Luhan",
      "Wang, Yanlong",
      "Wan, Jiayu",
      "Zhu, Yuyan",
      "Dai, Zhihong",
      "Sun, Xu",
      "Fan, Bo",
      "Wang, Yuchao",
      "Xiang, Hao",
      "Gao, Xiang",
      "Liang, Peng",
      "Zhao, Haolin",
      "Wang, Liang",
      "Wang, Ying",
      "Wang, Hongyu",
      "Yang, Deyong",
      "Liu, Zhiyu"
    ],
    "publicationDate": "2025-09-18",
    "publicationName": "npj Precision Oncology",
    "contentType": "Article",
    "abstract": "Adrenocortical carcinoma (ACC) is an uncommon and aggressive endocrine malignancy, characterized by limited therapeutic options and considerable variability in patient outcomes. The challenge is to combine the complex information of ACC with artificial intelligence (AI) and clinical and pathology data to achieve precision medicine and improve patient prognosis. We developed the Steroid-related Immune Score (SIS) using multi-modal analysis of genomics, digital pathology, and artificial intelligence and validated it in external datasets. In addition, we conducted single-cell RNA sequencing (scRNA-seq) of small samples and in vitro functional experiments. SIS delivered a stable performance with an AUC of 0.8 ± 0.01 in the ResNet50 and Vision Transformer-B16 models. We validated the best model in external ACC cohorts. Using Class Activation Maps (CAMs) technology revealed that SIS was associated with lymphocyte infiltration, establishing it as a new feature in addition to the Weiss scoring system. Patients in the high SIS group responded well to immunotherapy, while the low SIS group showed adaptability to hormone inhibition therapy. Single-cell RNA sequencing data revealed the relationship between the tumor microenvironment and drug resistance in ACC. In vitro functional assays demonstrated that elevated DHCR7 gene expression correlated with unfavorable prognosis and treatment sensitivity, identifying it as a prospective therapeutic target. Furthermore, there are similarities between the metabolic characteristics of ACC and schizophrenia, such as calcium and iron ion levels. Our multi-modal analysis comprehensively characterizes the immune microenvironment of ACC, emphasizing the synergistic regulation of metabolic and immune gene clusters that influence ACC patients’ responses to immune and hormone therapies.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Flexynesis: A deep learning toolkit for bulk multi-omics data integration for precision oncology and beyond",
    "doi": "10.1038/s41467-025-63688-5",
    "url": "https://www.nature.com/articles/s41467-025-63688-5",
    "authors": [
      "Uyar, Bora",
      "Savchyn, Taras",
      "Naghsh Nilchi, Amirhossein",
      "Sarigun, Ahmet",
      "Wurmus, Ricardo",
      "Shaik, Mohammed Maqsood",
      "Grüning, Björn",
      "Franke, Vedran",
      "Akalin, Altuna"
    ],
    "publicationDate": "2025-09-12",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Accurate decision making in precision oncology depends on integration of multimodal molecular information, for which various deep learning methods have been developed. However, most deep learning-based bulk multi-omics integration methods lack transparency, modularity, deployability, and are limited to narrow tasks. To address these limitations, we introduce Flexynesis, which streamlines data processing, feature selection, hyperparameter tuning, and marker discovery. Users can choose from deep learning architectures or classical supervised machine learning methods with a standardized input interface for single/multi-task training and evaluation for regression, classification, and survival modeling. We showcase the tool’s capability across diverse use-cases in precision oncology. To maximize accessibility, Flexynesis is available on PyPi, Guix, Bioconda, and the Galaxy Server ( https://usegalaxy.eu/ ). This toolset makes deep-learning based bulk multi-omics data integration in clinical/pre-clinical research more accessible to users with or without deep-learning experience. Flexynesis is available at https://github.com/BIMSBbioinfo/flexynesis . Current multiomics integration methods frequently suffer from limitations in transparency, modularity, deployability, and broad applicability. Here, the authors develop Flexynesis, a framework for multiomics integration that allows users to choose from multiple options and model architectures; it can be used for multiple tasks and pipelines, with applications in precision oncology.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Integration of Artificial Intelligence in Laryngeal Cancer Diagnosis and Prognosis: A Comparative Analysis Bridging Traditional Medical Practices with Modern Computational Techniques",
    "doi": "10.1007/s11831-025-10368-8",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11831-025-10368-8",
    "authors": [
      "Kaur, Pavneet",
      "Chand, Trilok",
      "Rani, Sudesh"
    ],
    "publicationDate": "2025-09-03",
    "publicationName": "Archives of Computational Methods in Engineering",
    "contentType": "Article",
    "abstract": "Laryngeal cancer is a malignancy of the vocal cords and surrounding tissues and creates considerable distress because it interferes with vital functions such as breathing, talking, and swallowing. Early detection and diagnosis play an important role in improving patient outcomes. Existing methods of testing, imaging, and histopathological examination of the tissues still face major challenges in early cancer detection and defining intricate tumor characteristics. With the increasing importance of Artificial Intelligence (AI) in oncology, it holds transformational capabilities that can revolutionize diagnosis and personalized treatment. This research paper presents the latest advances in AI applications in comprehensive data ranges such as videomics, voice analysis, radiomics, genomics, and clinical examination and assesses them against laryngeal cancer management. By application through Machine Learning (ML) and Deep Learning (DL) algorithms, the AI can analyze complex datasets to understand subtle patterns and clinical outcome predictions with unprecedented accuracy. AI-driven methodologies are promising to identify early-stage cases and provide personalized treatment management. Meanwhile, diverse data collection, robust multimodal data integration, and efficient clinical applicability remain challenges. This analysis collates the important results found within the current literature and identifies crucial research gaps and additional aspects for the future development of improved AI-based diagnosis and prognosis. Merging the bifurcation between conventional medical practices and computational advancements, this study highlights AI’s role in optimizing prognosis and survival for patients suffering from laryngeal cancer. The result indicates how promising AI would be in determining oncology’s future and patient care level.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Deep learning-based histomorphological subtyping and risk stratification of small cell lung cancer from hematoxylin and eosin-stained whole slide images",
    "doi": "10.1186/s13073-025-01526-5",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13073-025-01526-5",
    "authors": [
      "Zhang, Yibo",
      "Liu, Shilong",
      "Chen, Jun",
      "Chen, Ruanqi",
      "Yang, Zijian",
      "Sheng, Ruyu",
      "Li, Xin",
      "Wang, Taolue",
      "Liu, Hongyu",
      "Yang, Fan",
      "Ying, Jianming",
      "Yang, Lin",
      "Sun, Jie",
      "Zhou, Meng"
    ],
    "publicationDate": "2025-09-02",
    "publicationName": "Genome Medicine",
    "contentType": "Article",
    "abstract": "Background Accurate subtyping and risk stratification are imperative for prognostication and clinical decision-making in small cell lung cancer (SCLC). However, traditional molecular subtyping is resource-intensive and challenging to translate into clinical practice. Methods A total of 517 SCLC patients and their corresponding hematoxylin and eosin (H&E)-stained whole slide images (WSIs) from three independent medical institutions were analyzed. A hybrid clustering-based unsupervised deep representation learning model was developed to identify histomorphological phenotypes (HIPO) and characterize tumor ecosystem diversity. Consensus clustering and a deep learning-based stratification system were used to define histomorphological subtypes (HIPOS) based on patient-level HIPO features. Survival analysis and Cox proportional hazards regression models were used to assess the clinical significance of HIPOS. An integrated analysis of pathomics, proteomics, and immunohistochemistry was conducted to explore the biological and microenvironmental correlates of HIPOS. Results We performed histomorphological phenotyping of SCLC using unsupervised deep representation learning from WSIs and identified 15 HIPOs. Unsupervised clustering of HIPO profiles stratified SCLCs into two reproducible image-based subtypes: HIPOS-I and HIPOS-II. Patients in the HIPOS-I group had better overall survival and disease-free survival compared to those in HIPOS-II, independent of clinical features and molecular subtypes. Multimodal analyses revealed that HIPOS-I tumors were characterized by enriched immune infiltration and immune activation, whereas HIPOS-II tumors displayed increased fibrosis, cellular pleomorphism, and dysregulated oxidative metabolism. Additionally, we developed a simplified deep-learning model to predict HIPOS subtypes to enhance clinical applications and validated the prognostic value of these subtypes in independent cohorts. Conclusions This study demonstrates the potential of a deep learning-based histomorphological subtyping system to improve patient stratification and prognosis prediction in SCLC. The HIPOS offers a promising and clinically applicable tool for personalized management using routine H&E-stained WSIs.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Deep phenotyping of health–disease continuum in the Human Phenotype Project",
    "doi": "10.1038/s41591-025-03790-9",
    "url": "https://www.nature.com/articles/s41591-025-03790-9",
    "authors": [
      "Reicher, Lee",
      "Shilo, Smadar",
      "Godneva, Anastasia",
      "Lutsker, Guy",
      "Zahavi, Liron",
      "Shoer, Saar",
      "Krongauz, David",
      "Rein, Michal",
      "Kohn, Sarah",
      "Segev, Tomer",
      "Schlesinger, Yishay",
      "Barak, Daniel",
      "Levine, Zachary",
      "Keshet, Ayya",
      "Shaulitch, Rotem",
      "Lotan-Pompan, Maya",
      "Elkan, Matan",
      "Talmor-Barkan, Yeela",
      "Aviv, Yaron",
      "Dadiani, Maya",
      "Tsodyks, Yonatan",
      "Gal-Yam, Einav Nili",
      "Leibovitzh, Haim",
      "Werner, Lael",
      "Tzadok, Roie",
      "Maharshak, Nitsan",
      "Koga, Shin",
      "Glick-Gorman, Yulia",
      "Stossel, Chani",
      "Raitses-Gurevich, Maria",
      "Golan, Talia",
      "Dhir, Raja",
      "Reisner, Yotam",
      "Weinberger, Adina",
      "Rossman, Hagai",
      "Song, Le",
      "Xing, Eric P.",
      "Segal, Eran"
    ],
    "publicationDate": "2025-09-01",
    "publicationName": "Nature Medicine",
    "contentType": "Article",
    "abstract": "Deep phenotyping of an ancestrally diverse group of 13,000 individuals in the Human Phenotype Project highlights diversity and variations in lifestyle factors, clinical features and molecular signatures of health and disease. The Human Phenotype Project (HPP) is a large-scale deep-phenotype prospective cohort. To date, approximately 28,000 participants have enrolled, with more than 13,000 completing their initial visit. The project is aimed at identifying novel molecular signatures with diagnostic, prognostic and therapeutic value, and at developing artificial intelligence (AI)-based predictive models for disease onset and progression. The HPP includes longitudinal profiling encompassing medical history, lifestyle and nutrition, anthropometrics, blood tests, continuous glucose and sleep monitoring, imaging and multi-omics data, including genetics, transcriptomics, microbiome (gut, vaginal and oral), metabolomics and immune profiling. Analysis of these data highlights the variation of phenotypes with age and ethnicity and unravels molecular signatures of disease by comparison with matched healthy controls. Leveraging extensive dietary and lifestyle data, we identify associations between lifestyle factors and health outcomes. Finally, we present a multi-modal foundation AI model, trained using self-supervised learning on diet and continuous-glucose-monitoring data, that outperforms existing methods in predicting disease onset. This framework can be extended to integrate other modalities and act as a personalized digital twin. In summary, we present a deeply phenotyped cohort that serves as a platform for advancing biomarker discovery, enabling the development of multi-modal AI models and personalized medicine approaches.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Deep learning in chromatin organization: from super-resolution microscopy to clinical applications",
    "doi": "10.1007/s00018-025-05837-z",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00018-025-05837-z",
    "authors": [
      "Rotkevich, Mikhail",
      "Viana, Carlotta",
      "Neguembor, Maria Victoria",
      "Cosma, Maria Pia"
    ],
    "publicationDate": "2025-08-29",
    "publicationName": "Cellular and Molecular Life Sciences",
    "contentType": "Article",
    "abstract": "The 3D organization of the genome plays a critical role in regulating gene expression, maintaining cellular identity, and mediating responses to environmental cues. Advances in super-resolution microscopy and genomic technologies have enabled unprecedented insights into chromatin architecture at nanoscale resolution. However, the complexity and volume of data generated by these techniques necessitate innovative computational strategies for effective analysis and interpretation. In this review, we explore the transformative role of deep learning in the analysis of 3D genome organization, highlighting how deep learning models are being leveraged to enhance image reconstruction, segmentation, and dynamic tracking in chromatin research. We provide an overview of deep learning-enhanced methodologies that significantly improve spatial and temporal resolution of images, with a special focus on single-molecule localization microscopy. Furthermore, we discuss deep learning’s contribution to segmentation accuracy, and its application in single-particle tracking for dissecting chromatin dynamics at the single-cell level. These advances are complemented by frameworks that enable multimodal integration and interpretability, pushing the boundaries of chromatin biology into clinical diagnostics and personalized medicine. Finally, we discuss emerging clinical applications where deep learning models, based on chromatin imaging, aid in disease stratification, drug response prediction, and early cancer detection. We also address the challenges of data sparsity, model interpretability and propose future directions to decode genome function with higher precision and impact.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "MyeVAE: a multi-modal variational autoencoder for risk profiling of newly diagnosed multiple myeloma",
    "doi": "10.1186/s44398-025-00009-2",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s44398-025-00009-2",
    "authors": [
      "Chang, Jia Geng",
      "Chen, Jianbin",
      "Chew, Guo-Liang",
      "Chng, Wee Joo"
    ],
    "publicationDate": "2025-08-28",
    "publicationName": "BMC Artificial Intelligence",
    "contentType": "Article",
    "abstract": "Background There is a need for more accurate prognosis in multiple myeloma given the current heterogeneity in survival outcomes. In other cancers, the self-complementary nature of multi-omics is driving to the adoption of multi-omics data in personalized risk models. Simultaneously, deep learning is emerging as a top performing algorithm in risk prediction. These trends motivate us to assess the potential benefits of risk prediction with deep learning and multi-omics in the context of multiple myeloma. Methods We introduce MyeVAE (Myeloma VAE), a personalized multi-omics risk model for newly diagnosed multiple myeloma. MyeVAE is obtained by extending the traditional Variational Auto-Encoder (VAE) to jointly model an arbitrary combination of data modalities. MyeVAE incorporates a sub-task network (“survival network”) to generate risk predictions from omics-derived vector embeddings and directly observed clinical traits. We optimize MyeVAE using semi-supervised learning, combining the traditional evidence lower bound objective with the generalized version of Cox’s partial likelihood to guide the orientation of the latent space along risk-related axes. Results MyeVAE outperforms other algorithms at generalizing to microarray-based gene expression cohorts when trained on RNA-Seq gene expression. MyeVAE achieves a consistent validation C-index of 0.7 on overall survival when trained with multi-omics data. Gene expression emerged as the omics modality with highest predictive value across the four risk algorithms and six omics modalities we tested. Using SHAP, MyeVAE is found to recapitulate existing prognostic events, such as Gain(1q), t(4;14), and APOBEC activity. SHAP also hinted at the 26 S proteasome regulatory subunit PSMD4 to be a key gene implicated in Gain(1q), which was corroborated by validation on four external cohorts. Conclusions We demonstrate the marginal benefits of including multi-omics data—especially RNA-Seq based gene expression—across MyeVAE and other risk algorithms. Our experiments with MyeVAE demonstrate the potential for deep learning-based approaches for risk prediction and biomarker discovery in cancers where omics data is available.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Application of artificial intelligence in medical imaging for tumor diagnosis and treatment: a comprehensive approach",
    "doi": "10.1007/s12672-025-03307-3",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12672-025-03307-3",
    "authors": [
      "Huang, Junyan",
      "Xiang, Yizhen",
      "Gan, Shengqi",
      "Wu, Linrong",
      "Yan, Jiangyu",
      "Ye, Dong",
      "Zhang, Junjun"
    ],
    "publicationDate": "2025-08-26",
    "publicationName": "Discover Oncology",
    "contentType": "Article",
    "abstract": "This narrative review provides a comprehensive and structured overview of recent advances in the application of artificial intelligence (AI) to medical imaging for tumor diagnosis and treatment. By synthesizing evidence from recent literature and clinical reports, we highlight the capabilities, limitations, and translational potential of AI techniques across key imaging modalities such as CT, MRI, and PET. Deep learning (DL) and radiomics have facilitated automated lesion detection, tumour segmentation, and prognostic assessments, improving early cancer detection across various malignancies, including breast, lung, and prostate cancers. AI-driven multi-modal imaging fusion integrates radiomics, genomics, and clinical data, refining precision oncology strategies. Additionally, AI-assisted radiotherapy planning and adaptive dose optimisation have enhanced therapeutic efficacy while minimising toxicity. However, challenges persist regarding data heterogeneity, model generalisability, regulatory constraints, and ethical concerns. The lack of standardised datasets and explainable AI (XAI) frameworks hinders clinical adoption. Future research should focus on improving AI interpretability, fostering multi-centre dataset interoperability, and integrating AI with molecular imaging and real-time clinical decision support. Addressing these challenges will ensure AI’s seamless integration into clinical oncology, optimising cancer diagnosis, prognosis, and treatment outcomes.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A novel sequence-based transformer model architecture for integrating multi-omics data in preterm birth risk prediction",
    "doi": "10.1038/s41746-025-01942-2",
    "url": "https://www.nature.com/articles/s41746-025-01942-2",
    "authors": [
      "Zhou, Si",
      "Guan, Chenchen",
      "Deng, Siwei",
      "Zhu, Yibing",
      "Yang, Wenzhi",
      "Zhang, Xiao",
      "Wang, Xinrui",
      "Yang, Jinying",
      "Zhu, Shida",
      "Jiang, Hui",
      "Zhang, Jianguo",
      "Jin, Yongcheng",
      "Cheng, Danling",
      "Sun, Hai-Xi",
      "Zhao, Lijian",
      "Huang, Hefeng"
    ],
    "publicationDate": "2025-08-20",
    "publicationName": "npj Digital Medicine",
    "contentType": "Article",
    "abstract": "Preterm birth (PTB) significantly contributes to maternal and perinatal mortality and lifelong morbidity. While large language models (LLM) offer considerable potential for disease risk prediction and early detection, their application to PTB prediction using multi-omics data remains limited. We developed a novel transformer-based architecture for integrating cell free (cfDNA) and cfRNA sequencing data for PTB risk prediction. In the test set, the cfDNA LLM model achieved an AUC of 0.822, and the cfRNA LLM model achieved 0.851. Integrating cfDNA and cfRNA data within the transformer-based framework outperformed both, reaching an AUC of 0.890, a significant improvement over single-modality models. Additionally, we explored cfRNA and cfDNA integration using RNA editing and achieved an AUC of 0.82. This underscores the potential of multi-omics data fusion, with transformer-based architectures providing a powerful framework for disease risk assessment, and demonstrates the potential of AI-driven multi-omics for broader applications in precision obstetrics and biomedicine.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A survival prediction network based on multi-scale hypergraph enhancement and cross-modal refinement",
    "doi": "10.1007/s44443-025-00202-3",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s44443-025-00202-3",
    "authors": [
      "Yang, Chaofeng",
      "Liang, Yongjie",
      "Qin, Fan",
      "Cao, Yulong",
      "Wang, Peiyuan",
      "Fan, Jiaying",
      "Wei, Bizhong"
    ],
    "publicationDate": "2025-08-18",
    "publicationName": "Journal of King Saud University Computer and Information Sciences",
    "contentType": "Article",
    "abstract": "Cancer survival prediction, as a critical task in clinical prognosis analysis, holds significant importance for guiding treatment decisions and patient management. This paper proposes a survival prediction network based on multi-scale hypergraph enhancement and cross-modal refinement (MSHG-CMR), which achieves deep joint modeling and efficient information fusion of pathological images and multi-omics data by integrating multi-scale hypergraph enhancement and cross-modal refinement Transformer technology. In the method design, the hypergraph construction module captures high-order feature associations of pathological images at different resolutions and effectively aligns feature distributions across scales through homomorphic nonlinear mapping; subsequently, the cross-modal refinement Transformer module based on rotary encoding achieves dynamic information transfer and complementary refinement between visual features and multi-omics data through attention mechanisms and position decay designs; finally, a feature fusion attention mechanism is introduced to fuse multi-modal features, which both suppresses inter-modal redundancy and effectively mitigates information conflicts, thereby enhancing the precision of individualized prognosis analysis. Experimental results show that MSHG-CMR improves the C-index performance by 1.7% overall compared to existing SOTA methods on the TCGA-BLCA dataset and by 1.1% on the TCGA-LUAD dataset, demonstrating its generalizability across different cancer types. Code is available at: https://github.com/MUYI-XIAN/MSHG-CMR .",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Achieving inclusive healthcare through integrating education and research with AI and personalized curricula",
    "doi": "10.1038/s43856-025-01034-y",
    "url": "https://www.nature.com/articles/s43856-025-01034-y",
    "authors": [
      "Bahmani, Amir",
      "Cha, Kexin",
      "Alavi, Arash",
      "Dixit, Amit",
      "Ross, Antony",
      "Park, Ryan",
      "Goncalves, Francesca",
      "Ma, Shirley",
      "Saxman, Paul",
      "Nair, Ramesh",
      "Akhavan-Sarraf, Ramin",
      "Zhou, Xin",
      "Wang, Meng",
      "Contrepois, Kévin",
      "Li-Pook-Than, Jennifer",
      "Monte, Emma",
      "Rodriguez, David Jose Florez",
      "Lai, Jaslene",
      "Babu, Mohan",
      "Tondar, Abtin",
      "Schüssler-Fiorenza Rose, Sophia Miryam",
      "Akbari, Ilya",
      "Zhang, Xinyue",
      "Yegnashankaran, Kritika",
      "Yracheta, Joseph",
      "Dale, Kali",
      "Miller, Alison Derbenwick",
      "Edmiston, Scott",
      "McGhee, Eva M.",
      "Nebeker, Camille",
      "Wu, Joseph C.",
      "Kundaje, Anshul",
      "Snyder, Michael"
    ],
    "publicationDate": "2025-08-16",
    "publicationName": "Communications Medicine",
    "contentType": "Article",
    "abstract": "Bahmani, Cha, Alavi, Dixit et al. evaluate an AI-facilitated precision medicine learning platform they built, Stanford Data Ocean. The platform, which provided 3594 costfree certification accesses across 93 countries, demonstrates positive training outcomes across bioinformatics topics for low and middle income learners. Background Precision medicine promises significant health benefits but faces challenges such as complex data management and analytics, interdisciplinary collaboration, and education of researchers, healthcare professionals, and participants. Addressing these needs requires the integration of computational experts, engineers, designers, and healthcare professionals to develop user-friendly systems and shared terminologies. The widespread adoption of large language models (LLMs) such as Generative Pretrained Transformer (GPT) and Claude highlights the importance of making complex data accessible to non-specialists. Methods We evaluated the Stanford Data Ocean (SDO) precision medicine training program’s learning outcomes, AI Tutor performance, and learner satisfaction by assessing self-rated competency on key learning objectives through pre- and post-learning surveys, along with formative and summative assessment completion rates. We also analyzed AI Tutor accuracy and learners’ self-reported satisfaction, and post-program academic and career impacts. Additionally, we demonstrated the capabilities of the AI Data Visualization tool. Results SDO demonstrates the ability to improve learning outcomes for learners from broad educational and socioeconomic backgrounds with the support of the AI Tutor. The AI Data Visualization tool enables learners to interpret multi-omics and wearable data and replicate research findings. Conclusions SDO strives to mitigate challenges in precision medicine through a scalable, cloud-based platform that supports data management for various data types, advanced research, and personalized learning. SDO provides AI Tutors and AI-powered data visualization tools to enhance educational and research outcomes and make data analysis accessible to users from broad educational backgrounds. By extending engagement and cutting-edge research capabilities globally, SDO particularly benefits economically disadvantaged and historically marginalized communities, fostering interdisciplinary biomedical research and bridging the gap between education and practical application in the biomedical field. Precision medicine is the use of various types of health data specific to an individual to improve disease prevention, diagnosis, or treatment. We used artificial intelligence to build a precision medicine learning platform for clinicians and researchers in training. Students in 93 countries accessed the platform and found it helpful. It could be particularly helpful for training students in low- and middle-income countries.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Prediction of human pathogenic start loss variants based on self-supervised contrastive learning",
    "doi": "10.1186/s12915-025-02348-y",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12915-025-02348-y",
    "authors": [
      "Liu, Jie",
      "Fan, Henghui",
      "Cheng, Na",
      "Su, Yansen",
      "Xia, Junfeng"
    ],
    "publicationDate": "2025-08-08",
    "publicationName": "BMC Biology",
    "contentType": "Article",
    "abstract": "Background Start loss variants are a class of genetic variants that affect the bases of the start codon, disrupting the normal translation initiation process and leading to protein deletions or the production of different proteins. Accurate assessment of the pathogenicity of these variants is crucial for deciphering disease mechanisms and integrating genomics into clinical practice. However, among the tens of thousands of start loss variants in the human genome, only about 1% have been classified as pathogenic or benign. Computational methods that rely solely on small amounts of labeled data often lack sufficient generalization capabilities, restricting their effectiveness in predicting the impact of start loss variants. Results Here, we introduce StartCLR, a novel prediction method specifically designed for identifying pathogenic start loss variants. StartCLR captures variant context information from different dimensions by integrating embedding features from diverse DNA language models. Moreover, it employs self-supervised pre-training combined with supervised fine-tuning, enabling the effective utilization of both a large amount of unlabeled data and a small amount of labeled data to enhance prediction accuracy. Our experimental results show that StartCLR exhibits strong generalization and superior prediction performance across different test sets. Notably, when trained exclusively on high-confidence labeled data, StartCLR retains or even improves the prediction accuracy despite the reduced amount of labeled data. Conclusions Collectively, these findings highlight the potential of integrating self-supervised contrastive learning with unlabeled data to mitigate the challenge posed by the scarcity of labeled start loss variants.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Thor: a platform for cell-level investigation of spatial transcriptomics and histology",
    "doi": "10.1038/s41467-025-62593-1",
    "url": "https://www.nature.com/articles/s41467-025-62593-1",
    "authors": [
      "Zhang, Pengzhi",
      "Chen, Weiqing",
      "Tran, Tu N.",
      "Zhou, Minghao",
      "Carter, Kaylee N.",
      "Kandel, Ibrahem",
      "Li, Shengyu",
      "Hoi, Xen Ping",
      "Sun, Yuxing",
      "Lai, Li",
      "Youker, Keith",
      "Song, Qianqian",
      "Yang, Yu",
      "Nikolos, Fotis",
      "Li, Zejuan",
      "Chan, Keith Syson",
      "Cooke, John P.",
      "Wang, Guangyu"
    ],
    "publicationDate": "2025-08-05",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Spatial transcriptomics links gene expression with tissue morphology, however, current tools often prioritize genomic analysis, lacking integrated image interpretation. To address this, we present Thor, a comprehensive platform for cell-level analysis of spatial transcriptomics and histological images. Thor employs an anti-shrinking Markov diffusion method to infer single-cell spatial transcriptome from spot-level data, effectively combining gene expression and cell morphology. The platform includes 10 modular tools for genomic and image-based analysis, and is paired with Mjolnir, a web-based interface for interactive exploration of gigapixel images. Thor is validated on simulated data and multiple spatial platforms (ISH, MERFISH, Xenium, Stereo-seq). Thor characterizes regenerative signatures in heart failure, screens breast cancer hallmarks, resolves fine layers in mouse olfactory bulb, and annotates fibrotic heart tissue. In high-resolution Visium HD data, it enhances spatial gene patterns aligned with histology. By bridging transcriptomic and histological analysis, Thor enables holistic tissue interpretation in spatial biology. Zhang, Chen, and colleagues present Thor, a platform that turns spot-level spatial transcriptomics into single-cell gene maps using the paired histology image, without using single-cell RNA-seq data. Thor unveils fine tissue architectures, and it expands our knowledge on fibrosis and vascular-regenerative gene expression.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Integrating genomic and pathological characteristics to enhance prognostic precision in advanced NSCLC",
    "doi": "10.1038/s41698-025-01056-8",
    "url": "https://www.nature.com/articles/s41698-025-01056-8",
    "authors": [
      "Han, Yingjie",
      "Ma, Junxun",
      "Liu, Zhefeng",
      "Wang, Lijie",
      "Zhang, Fan",
      "Huang, Di",
      "Liu, Siyao",
      "Hu, Jifang",
      "Xiao, Wenhua",
      "Wang, Hong",
      "Wen, Juyi",
      "Qin, Haifeng",
      "Gao, Hongjun",
      "Li, Xiaosong",
      "Huang, Ziwei",
      "Zhang, Jiali",
      "Zhang, Yue",
      "Sun, Dawei",
      "Su, Junyan",
      "Chen, Jing",
      "Niu, Beifang",
      "Tao, Haitao",
      "Yang, Bo",
      "Liu, Xiaoqing",
      "Wang, Jinliang",
      "Hu, Yi"
    ],
    "publicationDate": "2025-08-02",
    "publicationName": "npj Precision Oncology",
    "contentType": "Article",
    "abstract": "Although immunotherapy combined with chemotherapy (ICT) is the standard treatment for advanced non-small cell lung cancer (NSCLC), identification of reliable prognostic biomarkers remains challenging. In this multicenter study, we performed next-generation sequencing of tumor samples from 162 patients receiving first-line ICT at the Chinese PLA General Hospital and collected their pathological image information. First, we established a model to predict the risk of tumor progression based on genomic characteristics. Furthermore, a deep learning method was employed to recognize different cell types from pathological images, which significantly improved the accuracy of progression-free survival (PFS) and overall survival (OS) prediction. In summary, we constructed a Prognostic Multimodal Classifier for Progression (PMCP) that possesses the capability to precisely forecast PFS and OS. Patients with the PMCP1 subtype exhibit a low risk of progression and demonstrate a higher proportion of epithelial cells. PMCP highlighted the potential value of multimodal biomarkers in guiding clinical decisions regarding ICT. The area under curve (AUC) for predicting PFS was 0.807. This study revealed the importance of integrating genomic and pathological data to improve prognostic accuracy and enable personalized treatment for patients with advanced NSCLC.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multimodal random subspace for breast cancer molecular subtypes prediction by integrating multi-dimensional data",
    "doi": "10.1007/s11042-024-20504-4",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-024-20504-4",
    "authors": [
      "Nakach, Fatima-Zahrae",
      "Idri, Ali",
      "Tchokponhoue, Gbègninougbo Aurel Davy"
    ],
    "publicationDate": "2025-08-01",
    "publicationName": "Multimedia Tools and Applications",
    "contentType": "Article",
    "abstract": "Accurate identification of breast cancer molecular subtypes significantly impacts patient prognosis and treatment decisions. Multimodal fusion techniques have shown promise in improving the performance of deep learning models by leveraging the complementary strengths of various modalities. However, the integration of multi-dimensional data poses a challenge due to the heterogeneity and complexity of the data sources. Random subspace can improve the robustness and generalization abilities of multimodal classification techniques by reducing variance and making it easier to identify the most informative features. The present study suggests a new approach referred to as Multimodal Random Subspace Support Vector Machine (MRSVM) ensemble that effectively combines multidimensional data encompassing copy number variation, clinical information, gene expression data and histopathological whole slide images to improve the prediction of breast cancer molecular subtypes. To highlight the prowess and distinctive qualities of the newly devised approach, we conducted an extensive comparative examination across all possible combinations of these four modalities, where we were able to address six research questions, which mainly involve identifying the optimal combination of the four available modalities, the most effective fusion strategy, and the most suitable classification technique. Results indicated that early fusion models outperformed late fusion models, notably, the MRSVM ensemble based on early fusion achieved the highest accuracy of 88.07% for molecular subtype prediction over the subtypes (Normal-like, Luminal A, Luminal B, HER2-enriched, and Basal-like). The findings also confirmed that multimodal models performed better than classifiers built on an individual data modality, and therefore allows us to suggest their use in place of monomodal models when multiple data modalities are available especially with ensemble methods.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "A novel multi-modal dual pathway network with hierarchical channel-spatial attention and adaptive feature fusion for viral genomic variant classification",
    "doi": "10.1007/s13721-025-00576-4",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13721-025-00576-4",
    "authors": [
      "Fadia, Love",
      "Shah, Vatsal",
      "Hassanzadeh, Mohammad",
      "Wu, Jonathan",
      "Ahmadi, Majid"
    ],
    "publicationDate": "2025-07-31",
    "publicationName": "Network Modeling Analysis in Health Informatics and Bioinformatics",
    "contentType": "Article",
    "abstract": "Purpose Classification of viral DNA sequences poses significant challenges in computational genomics, particularly in multi-class classification across diverse diseases. Existing studies often focus on binary or small-scale classifications, leaving a gap in addressing large-scale problems. Unbalanced datasets, where certain classes dominate due to limited data availability, further hinder model generalizability and accuracy. This article addresses these challenges and gaps in literature. We selected 17 distinct variants across six viruses: SARS-CoV-2 variants (Alpha, Delta, Omicron), Influenza subtypes (Alpha, Beta, Delta, Gamma), Hepatitis virus variants (B, C, D, E), Dengue Virus (Type1, Type 2, Type 3, Type 4), HIV, and Ebola. This study includes the largest number of distinct variants in a balanced dataset for classification reported in the literature. Methods Using a balanced dataset of 17,000 samples, the study ensures robust model performance while mitigating data imbalance biases. A novel Multi-Modal Dual Pathway Network is proposed, leveraging hierarchical channel-spatial attention and adaptive feature fusion to integrate complementary features. Genomic image processing techniques, including frequency chaos game representation (FCGR), Markov transition fields (MTF), and Gramian angular summation fields (GAF), enhance feature extraction. ResNet-50 pathways with convolutional block attention module (CBAM) refine feature maps for both scratch-trained and pre-trained pathways. Results The proposed model achieves a peak accuracy of 99.17% with MTF Order 2 fused with MTF Order 4. Other combinations, such as FCGR K=2 fused with MTF Order 4, also exceed 99.09% accuracy, demonstrating scalability and effectiveness. Conclusion This work sets a new benchmark for viral DNA classification, addressing data imbalance and advancing computational genomics through innovative methodologies.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "scGPT: end-to-end protocol for fine-tuned retinal cell type annotation",
    "doi": "10.1038/s41596-025-01220-1",
    "url": "https://www.nature.com/articles/s41596-025-01220-1",
    "authors": [
      "Ding, Shanli",
      "Li, Jin",
      "Luo, Rui",
      "Cui, Haotian",
      "Wang, Bo",
      "Chen, Rui"
    ],
    "publicationDate": "2025-07-15",
    "publicationName": "Nature Protocols",
    "contentType": "Article",
    "abstract": "This protocol provides the instructions to automating key steps, including data preprocessing, model fine-tuning and evaluation for single-cell generative pretrained transformer using Python function wrappers within computing clusters and Jupyter notebooks. The single-cell generative pretrained transformer protocol provides a structured framework for single-cell analysis using the pretrained foundation model and serves as an alternative to methods such as Seurat, scPred, scArches or Geneformer. Single-cell generative pretrained transformer is a foundation model based on a transformer architecture for cell-type classification. This protocol enables fine-tuning single-cell generative pretrained transformer for efficient handling of single-cell RNA sequencing data and improving annotation accuracy using retinal cells as working example. Single-cell research faces challenges in accurately annotating cell types at high resolution, especially when dealing with large-scale datasets and rare cell populations. To address this, foundation models such as single-cell generative pretrained transformer (scGPT) offer flexible, scalable solutions by leveraging transformer-based architectures. Here we provide a comprehensive guide to fine-tuning scGPT for cell-type classification in single-cell RNA sequencing data. We demonstrate how to fine-tune scGPT on a custom retina dataset, highlighting the model’s efficiency in handling complex data and improving annotation accuracy achieving 99.5% F1-score. This protocol automates key steps, including data preprocessing, model fine-tuning and evaluation. This protocol enables researchers to efficiently deploy scGPT for their own datasets. The provided tools, including a command-line script and Jupyter Notebook, simplify the customization and exploration of the model, proposing an accessible workflow for users with minimal Python and Linux knowledge. The protocol offers an off-the-shell solution of high-precision cell-type annotation using scGPT for researchers with intermediate bioinformatics. The source code and example datasets are publicly available on GitHub and Zenodo.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Decision level scheme for fusing multiomics and histology slide images using deep neural network for tumor prognosis prediction",
    "doi": "10.1038/s41598-025-09869-0",
    "url": "https://www.nature.com/articles/s41598-025-09869-0",
    "authors": [
      "Zhao, Tingting",
      "Ren, Yongyong",
      "Lu, Hui",
      "Kong, Yan"
    ],
    "publicationDate": "2025-07-15",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": "Molecular biostatistical workflows in oncology often rely on predictive models that use multimodal data. Advances in deep learning and artificial intelligence technologies have enabled the multimodal fusion of large volumes of multimodal data. Here, we presented a decision level multimodal data fusion framework for integrating multiomics and pathological tissue slide images for prognosis prediction. Our approach established the spatial map of instances by connecting the neighboring nuclei in space and calculated the characteristic tensor via graph convolution layers for the input pathological tissue slide images. Global Average Pooling was applied to align and normalize the feature tensors from pathological images and the multiomics data, enabling seamless integration. We tested our proposed approach using Breast Invasive Carcinoma data and Non-Small Cell Lung Cancer data from the Cancer Genome Atlas, which contains paired whole-slide images, transcriptome data, genotype, epienetic, and survival information. In a 10-fold cross-validation, the comparison results demonstrated that the multimodal fusion paradigm improves outcome predictions from single modal data alone with the average C-index increasing from 0.61 to 0.52 to 0.75 and 0.67 for breast cancer and non-small cell lung cancer cohort, respectively. The proposed decision level multimodal data fusion framework is expected to provide insights and technical methodologies for the follow-up studies.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Evaluating the representational power of pre-trained DNA language models for regulatory genomics",
    "doi": "10.1186/s13059-025-03674-8",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13059-025-03674-8",
    "authors": [
      "Tang, Ziqi",
      "Somia, Nirali",
      "Yu, Yiyang",
      "Koo, Peter K."
    ],
    "publicationDate": "2025-07-14",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "Background The emergence of genomic language models (gLMs) offers an unsupervised approach to learning a wide diversity of cis-regulatory patterns in the non-coding genome without requiring labels of functional activity generated by wet-lab experiments. Previous evaluations have shown that pre-trained gLMs can be leveraged to improve predictive performance across a broad range of regulatory genomics tasks, albeit using relatively simple benchmark datasets and baseline models. Since the gLMs in these studies were tested upon fine-tuning their weights for each downstream task, determining whether gLM representations embody a foundational understanding of cis-regulatory biology remains an open question. Results Here, we evaluate the representational power of pre-trained gLMs to predict and interpret cell-type-specific functional genomics data that span DNA and RNA regulation for six major functional genomics prediction tasks. Our findings suggest that probing the representations of current pre-trained gLMs do not offer substantial advantages over conventional machine learning approaches that use one-hot encoded sequences. Nevertheless, highly tuned supervised models trained from scratch using one-hot encoded sequences can achieve performance competitive with or better than pre-trained models across the datasets explored in this study. Discussion This work highlights a major gap with current gLMs, raising potential issues in conventional pre-training strategies for the non-coding genome.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Advancement in public health through machine learning: a narrative review of opportunities and ethical considerations",
    "doi": "10.1186/s40537-025-01201-x",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s40537-025-01201-x",
    "authors": [
      "Dhanda, Sumit Singh",
      "Panwar, Deepak",
      "Lin, Chia-Chen",
      "Sharma, Tarun Kumar",
      "Rastogi, Deependra",
      "Bindewari, Shantanu",
      "Singh, Anand",
      "Li, Yung-Hui",
      "Agarwal, Neha",
      "Agarwal, Saurabh"
    ],
    "publicationDate": "2025-07-04",
    "publicationName": "Journal of Big Data",
    "contentType": "Article",
    "abstract": "This narrative review presents a comprehensive and state-of-the-art synthesis of how machine learning (ML) is transforming public health through enhanced prediction, personalized treatment, real-time surveillance, and intelligent resource optimization. Drawing from 170 peer-reviewed studies published up to 2024/2025, this work uniquely integrates cross-domain insights spanning disease outbreak forecasting, genomic data analysis, personalized medicine, mental health monitoring, and public health infrastructure planning. The novelty of this review lies in its multidimensionality. It merges technical efficacy, ethical challenges, and future trends into a unified narrative. Our findings show substantial performance gains across domains: for example, ML models such as LightGBM, GRU neural networks, and LSTM achieved disease prediction accuracies ranging from 88 to 95%. In genomics, ML methods enabled nuanced disease subtype discovery and improved the accuracy of cancer risk assessment and pharmacogenomic modeling. Mental health prediction systems based on NLP and wearable data delivered up to 91% accuracy in stress and depression detection, while hospital resource forecasting models using deep learning minimized errors in predicting emergency admissions. Ethically, this review surfaces critical issues, including algorithmic bias, data privacy concerns in mental health analytics, and the interpretability of black-box models used in outbreak surveillance. A forward-looking discussion identifies future priorities such as the integration of multi-omics data, deployment of explainable AI, and equitable data inclusion frameworks. This review stands out by not only cataloguing applications but also offering a systems-level perspective on how ML can equitably and ethically scale to support public health strategies globally. It is among the first narrative reviews to concurrently evaluate ML’s predictive power, ethical constraints, and domain-specific improvements across all core pillars of public health.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Integrating multimodal cancer data using deep latent variable path modelling",
    "doi": "10.1038/s42256-025-01052-4",
    "url": "https://www.nature.com/articles/s42256-025-01052-4",
    "authors": [
      "Ing, Alex",
      "Andrades, Alvaro",
      "Cosenza, Marco Raffaele",
      "Korbel, Jan O."
    ],
    "publicationDate": "2025-07-01",
    "publicationName": "Nature Machine Intelligence",
    "contentType": "Article",
    "abstract": "Cancers are commonly characterized by a complex pathology encompassing genetic, microscopic and macroscopic features, which can be probed individually using imaging and omics technologies. Integrating these data to obtain a full understanding of pathology remains challenging. We introduce a method called deep latent variable path modelling, which combines the representational power of deep learning with the capacity of path modelling to identify relationships between interacting elements in a complex system. To evaluate the capabilities of deep latent variable path modelling, we initially trained a model to map dependencies between single-nucleotide variant, methylation profiles, microRNA sequencing, RNA sequencing and histological data using breast cancer data from The Cancer Genome Atlas. This method exhibited superior performance in mapping associations between data types compared with classical path modelling. We additionally performed successful applications of the model to stratify single-cell data, identify synthetic lethal interactions using CRISPR–Cas9 screens derived from cell lines and detect histologic–transcriptional associations using spatial transcriptomic data. Results from each of these data types can then be understood with reference to the same holistic model of illness. Cancers have complex genetic, microscopic and macroscopic features analysed using imaging and omics technologies, but integrating these data is challenging. A framework combining deep learning and path modelling to integrate imaging and omics data is presented, producing a unified model of disease.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A visual–omics foundation model to bridge histopathology with spatial transcriptomics",
    "doi": "10.1038/s41592-025-02707-1",
    "url": "https://www.nature.com/articles/s41592-025-02707-1",
    "authors": [
      "Chen, Weiqing",
      "Zhang, Pengzhi",
      "Tran, Tu N",
      "Xiao, Yiwei",
      "Li, Shengyu",
      "Shah, Vrutant V.",
      "Cheng, Hao",
      "Brannan, Kristopher W.",
      "Youker, Keith",
      "Lai, Li",
      "Fang, Longhou",
      "Yang, Yu",
      "Le, Nhat-Tu",
      "Abe, Jun-ichi",
      "Chen, Shu-Hsia",
      "Ma, Qin",
      "Chen, Ken",
      "Song, Qianqian",
      "Cooke, John P.",
      "Wang, Guangyu"
    ],
    "publicationDate": "2025-07-01",
    "publicationName": "Nature Methods",
    "contentType": "Article",
    "abstract": "OmiCLIP is a visual–omics foundation model that integrates histology and spatial transcriptomics. The associated Loki platform offers accurate and robust tools for alignment, annotation, cell-type decomposition and spatial gene expression prediction. Artificial intelligence has revolutionized computational biology. Recent developments in omics technologies, including single-cell RNA sequencing and spatial transcriptomics, provide detailed genomic data alongside tissue histology. However, current computational models focus on either omics or image analysis, lacking their integration. To address this, we developed OmiCLIP, a visual–omics foundation model linking hematoxylin and eosin images and transcriptomics using tissue patches from Visium data. We transformed transcriptomic data into ‘sentences’ by concatenating top-expressed gene symbols from each patch. We curated a dataset of 2.2 million paired tissue images and transcriptomic data across 32 organs to train OmiCLIP integrating histology and transcriptomics. Building on OmiCLIP, our Loki platform offers five key functions: tissue alignment, annotation via bulk RNA sequencing or marker genes, cell-type decomposition, image–transcriptomics retrieval and spatial transcriptomics gene expression prediction from hematoxylin and eosin-stained images. Compared with 22 state-of-the-art models on 5 simulations, and 19 public and 4 in-house experimental datasets, Loki demonstrated consistent accuracy and robustness.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "CellMemory: hierarchical interpretation of out-of-distribution cells using bottlenecked transformer",
    "doi": "10.1186/s13059-025-03638-y",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13059-025-03638-y",
    "authors": [
      "Wang, Qifei",
      "Zhu, He",
      "Hu, Yiwen",
      "Chen, Yanjie",
      "Wang, Yuwei",
      "Li, Guochao",
      "Li, Yun",
      "Chen, Jinfeng",
      "Zhang, Xuegong",
      "Zou, James",
      "Kellis, Manolis",
      "Li, Yue",
      "Liu, Dianbo",
      "Jiang, Lan"
    ],
    "publicationDate": "2025-06-23",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "Machine learning methods, especially Transformer architectures, have been widely employed in single-cell omics studies. However, interpretability and accurate representation of out-of-distribution (OOD) cells remains challenging. Inspired by the global workspace theory in cognitive neuroscience, we introduce CellMemory, a bottlenecked Transformer with improved generalizability designed for the hierarchical interpretation of OOD cells. Without pre-training, CellMemory outperforms existing single-cell foundation models and accurately deciphers spatial transcriptomics at high resolution. Leveraging its robust representations, we further elucidate malignant cells and their founder cells across patients, providing reliable characterizations of the cellular changes caused by the disease.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multimodal deep learning for predicting neoadjuvant treatment outcomes in breast cancer: a systematic review",
    "doi": "10.1186/s13062-025-00661-8",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13062-025-00661-8",
    "authors": [
      "Krasniqi, Eriseld",
      "Filomeno, Lorena",
      "Arcuri, Teresa",
      "Ferretti, Gianluigi",
      "Gasparro, Simona",
      "Fulvi, Alberto",
      "Roselli, Arianna",
      "D’Onofrio, Loretta",
      "Pizzuti, Laura",
      "Barba, Maddalena",
      "Maugeri-Saccà, Marcello",
      "Botti, Claudio",
      "Graziano, Franco",
      "Puccica, Ilaria",
      "Cappelli, Sonia",
      "Pelle, Fabio",
      "Cavicchi, Flavia",
      "Villanucci, Amedeo",
      "Paris, Ida",
      "Calabrò, Fabio",
      "Rea, Sandra",
      "Costantini, Maurizio",
      "Perracchio, Letizia",
      "Sanguineti, Giuseppe",
      "Takanen, Silvia",
      "Marucci, Laura",
      "Greco, Laura",
      "Kayal, Rami",
      "Moscetti, Luca",
      "Marchesini, Elisa",
      "Calonaci, Nicola",
      "Blandino, Giovanni",
      "Caravagna, Giulio",
      "Vici, Patrizia"
    ],
    "publicationDate": "2025-06-23",
    "publicationName": "Biology Direct",
    "contentType": "Article",
    "abstract": "Background Pathological complete response (pCR) to neoadjuvant systemic therapy (NAST) is an established prognostic marker in breast cancer (BC). Multimodal deep learning (DL), integrating diverse data sources (radiology, pathology, omics, clinical), holds promise for improving pCR prediction accuracy. This systematic review synthesizes evidence on multimodal DL for pCR prediction and compares its performance against unimodal DL. Methods Following PRISMA, we searched PubMed, Embase, and Web of Science (January 2015–April 2025) for studies applying DL to predict pCR in BC patients receiving NAST, using data from radiology, digital pathology (DP), multi-omics, and/or clinical records, and reporting AUC. Data on study design, DL architectures, and performance (AUC) were extracted. A narrative synthesis was conducted due to heterogeneity. Results Fifty-one studies, mostly retrospective (90.2%, median cohort 281), were included. Magnetic resonance imaging and DP were common primary modalities. Multimodal approaches were used in 52.9% of studies, often combining imaging with clinical data. Convolutional neural networks were the dominant architecture (88.2%). Longitudinal imaging improved prediction over baseline-only (median AUC 0.91 vs. 0.82). Overall, the median AUC across studies was 0.88, with 35.3% achieving AUC ≥ 0.90. Multimodal models showed a modest but consistent improvement over unimodal approaches (median AUC 0.88 vs. 0.83). Omics and clinical text were rarely primary DL inputs. Conclusion DL models demonstrate promising accuracy for pCR prediction, especially when integrating multiple modalities and longitudinal imaging. However, significant methodological heterogeneity, reliance on retrospective data, and limited external validation hinder clinical translation. Future research should prioritize prospective validation, integration underutilized data (multi-omics, clinical), and explainable AI to advance DL predictors to the clinical setting.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "spCLUE: a contrastive learning approach to unified spatial transcriptomics analysis across single-slice and multi-slice data",
    "doi": "10.1186/s13059-025-03636-0",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13059-025-03636-0",
    "authors": [
      "Wang, Xiang",
      "Li, Wei Vivian",
      "Li, Hongwei"
    ],
    "publicationDate": "2025-06-23",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "Advances in spatial transcriptomics demand new tools to integrate data across tissue slices and identify consistent spatial domains. We introduce spCLUE, a comprehensive framework combining multi-view graph network, contrastive learning, attention mechanisms, and a batch prompting module to learn informative spot representations and integrate data from both aligned and unaligned samples. spCLUE outperforms nine single-slice and seven multi-slice methods when tested on diverse datasets and reveals biologically relevant domains across different tissues and conditions. spCLUE offers a powerful solution to spatial domain analysis and integration in spatial transcriptomics, enabling more accurate and interpretable studies of tissue organization.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Large language models transform biological research: from architecture to utilization",
    "doi": "10.1007/s11432-024-4466-3",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11432-024-4466-3",
    "authors": [
      "Wang, Tao",
      "Luo, Zeyu"
    ],
    "publicationDate": "2025-06-19",
    "publicationName": "Science China Information Sciences",
    "contentType": "Article",
    "abstract": "Recently, numerous large language models (LLMs) have emerged as foundational models, reshaping biological data modeling and achieving remarkable breakthroughs in both discriminative and generative tasks. The success of these models is largely attributed to the inherent similarities between natural language and biological data, such as DNA, RNA, and amino acid sequences. Through pre-training and fine-tuning phases, LLMs have demonstrated their ability to effectively model these biological datasets. Additionally, while protein structures and RNA-seq expression data are not inherently sequential, they can still be modeled and predicted effectively by LLMs based on the Transformer architecture. Previous research has predominantly focused on architectural innovations in LLMs and their applications to sequential data across various domains. However, there is a notable lack of systematic reviews addressing the reasons and methods behind LLM modifications for fitting biological omics data, particularly for non-sequential data types. Furthermore, comprehensive analyses of LLM applications in synthetic biology remain limited. We first systematically review representative LLMs in the biological domain. Next, we delve into their applications across the genome, transcriptome, and proteome fields, detailing the goals, processes, datasets, and methodologies involved. Finally, we discuss the challenges of applying LLMs to biological omics data and fundamental scientific research. In summary, we aim to provide a comprehensive overview of the technical and conceptual advances in this field, as well as an essential resource for researchers exploring the diverse applications of LLMs across various biological disciplines.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "A multimodal fusion system predicting survival benefits of immune checkpoint inhibitors in unresectable hepatocellular carcinoma",
    "doi": "10.1038/s41698-025-00979-6",
    "url": "https://www.nature.com/articles/s41698-025-00979-6",
    "authors": [
      "Xu, Jun",
      "Wang, Tengfei",
      "Li, Junjun",
      "Wang, Yong",
      "Zhu, Zhangxiang",
      "Fu, Xiao",
      "Wang, Junjie",
      "Zhang, Zhenglin",
      "Cai, Wei",
      "Song, Ruipeng",
      "Hou, Changlong",
      "Yang, Li-Zhuang",
      "Wang, Hongzhi",
      "Wong, Stephen T. C.",
      "Li, Hai"
    ],
    "publicationDate": "2025-06-14",
    "publicationName": "npj Precision Oncology",
    "contentType": "Article",
    "abstract": "Early identification of unresectable hepatocellular carcinoma (HCC) patients who may benefit from immune checkpoint inhibitors (ICIs) is crucial for optimizing outcomes. Here, we developed a multimodal fusion (MMF) system integrating CT-derived deep learning features and clinical data to predict overall survival (OS) and progression-free survival (PFS). Using retrospective multicenter data ( n  = 859), the MMF combining an ensemble deep learning (Ensemble-DL) model with clinical variables achieved strong external validation performance (C-index: OS = 0.74, PFS = 0.69), outperforming radiomics (29.8% OS improvement), mRECIST (27.6% OS improvement), clinical benchmarks (C-index: OS = 0.67, p  = 0.0011; PFS = 0.65, p  = 0.033), and Ensemble-DL (C-index: OS = 0.69, p  = 0.0028; PFS = 0.66, p  = 0.044). The MMF system effectively stratified patients across clinical subgroups and demonstrated interpretability through activation maps and radiomic correlations. Differential gene expression analysis revealed enrichment of the PI3K/Akt pathway in patients identified by the MMF system. The MMF system provides an interpretable, clinically applicable approach to guide personalized ICI treatment in unresectable HCC.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multimodal approaches and AI-driven innovations in dementia diagnosis: a systematic review",
    "doi": "10.1007/s44163-025-00358-x",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s44163-025-00358-x",
    "authors": [
      "Wahul, Revati M.",
      "Ambadekar, Sarita",
      "Dhanvijay, Deepesh M.",
      "Dhanvijay, Mrinai M.",
      "Dudhedia, Manisha A.",
      "Gaikwad, Varsha",
      "Kanawade, Bhavana",
      "Pansare, J. R.",
      "Bodkhe, Balaji",
      "Gawande, S. H."
    ],
    "publicationDate": "2025-06-10",
    "publicationName": "Discover Artificial Intelligence",
    "contentType": "Article",
    "abstract": "Neurodegenerative disorders, such as dementia, present some of the most pressing challenges in the field of medicine today. By causing progressive cognitive and functional decline, Alzheimer’s Disease (AD) and Frontotemporal Dementia (FTD) subtypes are an essential area for urgently needed work. As a systematic literature review, this paper outlines the intricacies of dementia’s pathophysiology of dementia by addressing the complexity of dementia as a construct, how different types of clinical paths can happen, how neuronal atrophy occurs along different cerebral domains, and when the critical diagnostic thresholds are met. A complete review of peer-reviewed papers over the past ten years, with a focus on Machine Learning, Deep Learning, and multimodal fusion approaches to enhance diagnostic and therapeutic precision will focus on neuroimaging biomarkers, EEG-based cognitive profiles, digital phenotyping, and wearable sensor analytics. This survey will compare the study’s algorithms or frameworks on sensitivity, specificity, interpretability, computational efficiency, and clinical transnationality concerning early detection and monitoring progression. Though AI methods are having a continuing rapid surge in progress, the issues of model transparency and generalizability are still lacking, thus meaning the need for XAI. This work builds a multi-disciplinary data agnostic approach for building stronger patient-centered models that can bring together genomics, imaging, behavior and contextual features in the task-driven processes. Overall, this literature survey’s objective is to shine a light on the multi-faceted pathway towards precision-driven, AI augmented dementia care—and ultimately to change the management of neurodegenerative disease by synthesizing current developments and highlighting their shortcomings.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Multimodal cell maps as a foundation for structural and functional genomics",
    "doi": "10.1038/s41586-025-08878-3",
    "url": "https://www.nature.com/articles/s41586-025-08878-3",
    "authors": [
      "Schaffer, Leah V.",
      "Hu, Mengzhou",
      "Qian, Gege",
      "Moon, Kyung-Mee",
      "Pal, Abantika",
      "Soni, Neelesh",
      "Latham, Andrew P.",
      "Pontano Vaites, Laura",
      "Tsai, Dorothy",
      "Mattson, Nicole M.",
      "Licon, Katherine",
      "Bachelder, Robin",
      "Cesnik, Anthony",
      "Gaur, Ishan",
      "Le, Trang",
      "Leineweber, William",
      "Palar, Aji",
      "Pulido, Ernst",
      "Qin, Yue",
      "Zhao, Xiaoyu",
      "Churas, Christopher",
      "Lenkiewicz, Joanna",
      "Chen, Jing",
      "Ono, Keiichiro",
      "Pratt, Dexter",
      "Zage, Peter",
      "Echeverria, Ignacia",
      "Sali, Andrej",
      "Harper, J. Wade",
      "Gygi, Steven P.",
      "Foster, Leonard J.",
      "Huttlin, Edward L.",
      "Lundberg, Emma",
      "Ideker, Trey"
    ],
    "publicationDate": "2025-06-05",
    "publicationName": "Nature",
    "contentType": "Article",
    "abstract": "A global map of human subcellular architecture yields protein complex structures, reveals protein functions, identifies assemblies with multiple localizations or cell-type specificity and decodes paediatric cancer genomes. Human cells consist of a complex hierarchy of components, many of which remain unexplored^ 1 , 2 . Here we construct a global map of human subcellular architecture through joint measurement of biophysical interactions and immunofluorescence images for over 5,100 proteins in U2OS osteosarcoma cells. Self-supervised multimodal data integration resolves 275 molecular assemblies spanning the range of 10^−8 to 10^−5 m, which we validate systematically using whole-cell size-exclusion chromatography and annotate using large language models^ 3 . We explore key applications in structural biology, yielding structures for 111 heterodimeric complexes and an expanded Rag–Ragulator assembly. The map assigns unexpected functions to 975 proteins, including roles for C18orf21 in RNA processing and DPP9 in interferon signalling, and identifies assemblies with multiple localizations or cell type specificity. It decodes paediatric cancer genomes^ 4 , identifying 21 recurrently mutated assemblies and implicating 102 validated new cancer proteins. The associated Cell Visualization Portal and Mapping Toolkit provide a reference platform for structural and functional cell biology.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A multimodal conversational agent for DNA, RNA and protein tasks",
    "doi": "10.1038/s42256-025-01047-1",
    "url": "https://www.nature.com/articles/s42256-025-01047-1",
    "authors": [
      "de Almeida, Bernardo P.",
      "Richard, Guillaume",
      "Dalla-Torre, Hugo",
      "Blum, Christopher",
      "Hexemer, Lorenz",
      "Pandey, Priyanka",
      "Laurent, Stefan",
      "Rajesh, Chandana",
      "Lopez, Marie",
      "Laterre, Alexandre",
      "Lang, Maren",
      "Şahin, Uğur",
      "Beguir, Karim",
      "Pierrot, Thomas"
    ],
    "publicationDate": "2025-06-01",
    "publicationName": "Nature Machine Intelligence",
    "contentType": "Article",
    "abstract": "Language models are thriving, powering conversational agents that assist and empower humans to solve a number of tasks. Recently, these models were extended to support additional modalities including vision, audio and video, demonstrating impressive capabilities across multiple domains, including healthcare. Still, conversational agents remain limited in biology as they cannot yet fully comprehend biological sequences. Meanwhile, high-performance foundation models for biological sequences have been built through self-supervision over sequencing data, but these need to be fine-tuned for each specific application, preventing generalization between tasks. In addition, these models are not conversational, which limits their utility to users with coding capabilities. Here we propose to bridge the gap between biology foundation models and conversational agents by introducing ChatNT, a multimodal conversational agent with an advanced understanding of biological sequences. ChatNT achieves new state-of-the-art results on the Nucleotide Transformer benchmark while being able to solve all tasks at once, in English, and to generalize to unseen questions. In addition, we have curated a set of more biologically relevant instruction tasks from DNA, RNA and proteins, spanning multiple species, tissues and biological processes. ChatNT reaches performance on par with state-of-the-art specialized methods on those tasks. We also present a perplexity-based technique to help calibrate the confidence of our model predictions. By applying attribution methods through the English decoder and DNA encoder, we demonstrate that ChatNT’s answers are based on biologically coherent features such as detecting the promoter TATA motif or splice site dinucleotides. Our framework for genomics instruction tuning can be extended to more tasks and data modalities (for example, structure and imaging), making it a widely applicable tool for biology. ChatNT provides a potential direction for building generally capable agents that understand biology from first principles while being accessible to users with no coding background. De Almeida, Richard and colleagues leverage transfer learning to create ChatNT, a multimodal conversational agent for DNA, RNA and protein sequences that can be instructed in natural language.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A review of enhanced biosignature immunotherapy tools for predicting lung cancer immune phenotypes using deep learning",
    "doi": "10.1007/s12672-025-02771-1",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12672-025-02771-1",
    "authors": [
      "Oliver, A. Sheryl",
      "Sayeed, Md Shohel",
      "Razak, Siti Fatimah Abdul"
    ],
    "publicationDate": "2025-05-30",
    "publicationName": "Discover Oncology",
    "contentType": "Article",
    "abstract": "Cancer has increasingly been recognized as a genetic disease, influenced by lifestyle changes, dietary patterns, and environmental pollutants. Lung cancer remains one of the most lethal malignancies worldwide, necessitating precise diagnostic and therapeutic approaches. Among these types, lung cancer is the third most common cancer, which affects all over the population. Lung cancer is a cancer that forms in tissues of the lung, usually in the cells that line the air passages. There are two main types of lung cancer: small cell and non-small cell lung cancer. These two types grow differently and are treated differently. This review explores the application of advanced deep learning (DL) techniques in enhancing biosignature immunotherapy tools for the prediction of immune phenotypes in lung cancer patients. The study systematically analyses recent research integrating multi-modal biomedical data, such as radiomics, genomics, transcriptomics, and histopathological images, to develop robust DL-based predictive models. A well-defined literature search strategy, inclusion/exclusion criteria, and a PRISMA-guided screening process ensure transparency and reproducibility. Emphasis is placed on identifying key predictive biomarkers, including Programmed Death-Ligand 1 (PD-L1) expression, Tumor Mutational Burden (TMB), Microsatellite Instability (MSI), and APOBEC mutational signatures, which are vital for personalizing immunotherapy. The review also incorporates a quality assessment framework to evaluate the methodological rigor of the included studies. Enhanced technical details, such as model architecture, validation strategies, hyperparameter tuning, and standardized performance metrics like AUC-ROC and Harrell’s C-index, are presented to facilitate cross-study comparisons. This review underscores the transformative role of DL in precision oncology and highlights the potential for integrating biosignatures into clinical workflows to improve immunotherapy outcomes in lung cancer.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "AI-Empowered Genome Decoding: Applications of Large Language Models in Genomics",
    "doi": "10.1007/s44366-025-0051-1",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s44366-025-0051-1",
    "authors": [
      "Li, Shaopeng",
      "Fan, Weiliang",
      "Zhou, Yu"
    ],
    "publicationDate": "2025-05-28",
    "publicationName": "Frontiers of Digital Education",
    "contentType": "Article",
    "abstract": "Large language models (LLMs) have transformed natural language processing with their improved performance compared with previous methods and have shown great potential to be adopted in other fields. The sequential nature of genomics data, such as deoxyribonucleic acid (DNA), ribonucleic acid (RNA), and proteins, makes it akin to human natural language, supporting the application of LLMs. Currently, LLMs have only been applied to genomic research for about four years but have already achieved significant advances in many challenging and important problems. This review summarizes the recent progress of applying LLMs in genomic research, including developing biological foundation models for protein, DNA, and RNA, as well as specialized models for interaction prediction, single-cell analysis, and structure prediction. The review discusses the challenges and potentials of adopting new advancements in LLMs for genomic applications and proposes several practical projects for integrating LLMs into genomics teaching and learning.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "annATAC: automatic cell type annotation for scATAC-seq data based on language model",
    "doi": "10.1186/s12915-025-02244-5",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12915-025-02244-5",
    "authors": [
      "Cui, Lingyu",
      "Wang, Fang",
      "Li, Hongfei",
      "Liu, Qiaoming",
      "Zhou, Murong",
      "Wang, Guohua"
    ],
    "publicationDate": "2025-05-28",
    "publicationName": "BMC Biology",
    "contentType": "Article",
    "abstract": "Background Cell type annotation serves as the cornerstone for downstream analysis of single cell data. Nevertheless, scATAC-seq data is characterized by high sparsity and dimensionality, presenting significant challenges to its annotation process. Results We introduce a novel method based on language model, named annATAC, which is designed for the automatic annotation of cell types in scATAC-seq data. This method primarily consists of three stages. During the pre-training stage, by training on a vast amount of unlabeled data, the model can learn the interaction relationships between peaks, thus building a preliminary understanding of the data features. Subsequently, in the fine-tuning stage, a small quantity of labeled data is utilized to conduct secondary training on the model, which enables the model to identify cell types accurately. Finally, in the prediction stage, the trained model is applied to annotate scATAC-seq data. Conclusions Compared with other automatic annotation methods across multiple datasets, annATAC demonstrates superiority on the annotation performance. Further experiments have validated that annATAC holds great potential in identifying marker peaks and marker motifs. It is expected that annATAC will provide more profound and precise analysis outcomes for scATAC-seq research. As a result, it will effectively promote the progress of relevant biomedical research. Graphical Abstract ",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "LucaPCycle: Illuminating microbial phosphorus cycling in deep-sea cold seep sediments using protein language models",
    "doi": "10.1038/s41467-025-60142-4",
    "url": "https://www.nature.com/articles/s41467-025-60142-4",
    "authors": [
      "Zhang, Chuwen",
      "He, Yong",
      "Wang, Jieni",
      "Chen, Tengkai",
      "Baltar, Federico",
      "Hu, Minjie",
      "Liao, Jing",
      "Xiao, Xi",
      "Li, Zhao-Rong",
      "Dong, Xiyang"
    ],
    "publicationDate": "2025-05-26",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Phosphorus is essential for life and critically influences marine productivity. Despite geochemical evidence of active phosphorus cycling in deep-sea cold seeps, the microbial processes involved remain poorly understood. Traditional sequence-based searches often fail to detect proteins with remote homology. To address this, we developed a deep learning model, LucaPCycle, integrating raw sequences and contextual embeddings based on the protein language model ESM2-3B. LucaPCycle identified 5241 phosphorus-cycling protein families from global cold seep gene and genome catalogs, substantially enhancing our understanding of their diversity, ecology, and function. Among previously unannotated sequences, we discovered three alkaline phosphatase families that feature unique domain organizations and preserved enzymatic capabilities. These results highlight previously overlooked ecological importance of phosphorus cycling within cold seeps, corroborated by data from porewater geochemistry, metatranscriptomics, and metabolomics. We revealed a previously unrecognized diversity of archaea, including Asgardarchaeota, anaerobic methanotrophic archaea and Thermoproteota, which contribute to organic phosphorus mineralization and inorganic phosphorus solubilization through various mechanisms. Additionally, auxiliary metabolic genes of cold seep viruses primarily encode the PhoR-PhoB regulatory system and PhnCDE transporter, potentially enhancing their hosts’ phosphorus utilization. Overall, LucaPCycle are capable of accessing previously ‘hidden’ sequence spaces for microbial phosphorus cycling and can be applied to various ecosystems. The microbial processes involved in deep sea phosphorous cycling are unclear. Here, the authors develop a deep learning model, LucaPCycle, identifying alkaline phosphatase families and archaea that contribute to phosphorous cycling in deep sea cold seeps.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "CREATE: cell-type-specific cis-regulatory element identification via discrete embedding",
    "doi": "10.1038/s41467-025-59780-5",
    "url": "https://www.nature.com/articles/s41467-025-59780-5",
    "authors": [
      "Cui, Xuejian",
      "Yin, Qijin",
      "Gao, Zijing",
      "Li, Zhen",
      "Chen, Xiaoyang",
      "Lv, Hairong",
      "Chen, Shengquan",
      "Liu, Qiao",
      "Zeng, Wanwen",
      "Jiang, Rui"
    ],
    "publicationDate": "2025-05-17",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Cis-regulatory elements (CREs), including enhancers, silencers, promoters and insulators, play pivotal roles in orchestrating gene regulatory mechanisms that drive complex biological traits. However, current approaches for CRE identification are predominantly sequence-based and typically focus on individual CRE types, limiting insights into their cell-type-specific functions and regulatory dynamics. Here, we present CREATE, a multimodal deep learning framework based on Vector Quantized Variational AutoEncoder, tailored for comprehensive CRE identification and characterization. CREATE integrates genomic sequences, chromatin accessibility, and chromatin interaction data to generate discrete CRE embeddings, enabling accurate multi-class classification and robust characterization of CREs. CREATE excels in identifying cell-type-specific CREs, and provides quantitative and interpretable insights into CRE-specific features, uncovering the underlying regulatory codes. By facilitating large-scale prediction of CREs in specific cell types, CREATE enhances the recognition of disease- or phenotype-associated biological variabilities of CREs, thus advancing our understanding of gene regulatory landscapes and their roles in health and disease. Cui et al. present CREATE, a platform for the identification of multi-class cell-type-specific CREs by integrating multi-omics data. CREATE interpretably extracts discrete CRE embeddings, quantitatively unveils CRE-specific features, and effectively enables large scale prediction of CREs.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Extensible Immunofluorescence (ExIF) accessibly generates high-plexity datasets by integrating standard 4-plex imaging data",
    "doi": "10.1038/s41467-025-59592-7",
    "url": "https://www.nature.com/articles/s41467-025-59592-7",
    "authors": [
      "Gunawan, Ihuan",
      "Kohane, Felix V.",
      "Dey, Moumitha",
      "Nguyen, Kathy",
      "Zheng, Ye",
      "Neumann, Daniel P.",
      "Vafaee, Fatemeh",
      "Meijering, Erik",
      "Lock, John G."
    ],
    "publicationDate": "2025-05-17",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Standard immunofluorescence imaging captures just ~4 molecular markers (4-plex) per cell, limiting dissection of complex biology. Inspired by multimodal omics-based data integration approaches, we propose an Extensible Immunofluorescence (ExIF) framework that transforms carefully designed but easily produced panels of 4-plex immunofluorescence into a unified dataset with theoretically unlimited marker plexity, using generative deep learning-based virtual labelling. ExIF enables integrated analyses of complex cell biology, exemplified here through interrogation of the epithelial-mesenchymal transition (EMT), driving significant improvements in downstream quantitative analyses usually reserved for omics data, including: classification of cell phenotypes; manifold learning of cell phenotype heterogeneity; and pseudotemporal inference of molecular marker dynamics. Introducing data integration concepts from omics to microscopy, ExIF empowers life scientists to use routine 4-plex fluorescence microscopy to quantitatively interrogate complex, multimolecular single-cell processes in a manner that approaches the performance of multiplexed labelling methods whose uptake remains limited. Gunawan et al. propose an Extensible Immunofluorescence (ExIF) strategy that integrates distinct 4-plex image panels from routine fluorescence microscopy into multiplexed datasets enabling quantitative interrogation of complex, multimolecular single-cell processes.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "EnGCI: enhancing GPCR-compound interaction prediction via large molecular models and KAN network",
    "doi": "10.1186/s12915-025-02238-3",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12915-025-02238-3",
    "authors": [
      "Liu, Weihao",
      "Li, Xiaoli",
      "Hang, Bo",
      "Wang, Pu"
    ],
    "publicationDate": "2025-05-15",
    "publicationName": "BMC Biology",
    "contentType": "Article",
    "abstract": "Background Identifying GPCR-compound interactions (GCI) plays a significant role in drug discovery and chemogenomics. Machine learning, particularly deep learning, has become increasingly influential in this domain. Large molecular models, due to their ability to capture detailed structural and functional information, have shown promise in enhancing the predictive accuracy of downstream tasks. Consequently, exploring the performance of these models in GCI prediction, as well as evaluating their effectiveness when integrated with other deep learning models, has emerged as a compelling research area. This paper aims to investigate these challenges. Results This study introduces EnGCI, a novel model comprising two distinct modules. The MSBM integrates a graph isomorphism network (GIN) and a convolutional neural network (CNN) to extract features from GPCRs and compounds, respectively. These features are then processed by a Kolmogorov-Arnold network (KAN) for decision-making. The LMMBM utilizes two large-scale pre-trained models to extract features from compounds and GPCRs, and subsequently, KAN is again employed for decision-making. Each module leverages different sources of multimodal information, and their fusion enhances the overall accuracy of GPCR-compound interaction (GCI) prediction. Evaluating the EnGCI model on a rigorously curated GCI dataset, we achieved an AUC of approximately 0.89, significantly outperforming current state-of-the-art benchmark models. Conclusions The EnGCI model integrates two complementary modules: one that learns molecular features from scratch for the GPCR-compound interaction (GCI) prediction task, and another that extracts molecular features using pre-trained large molecular models. After further processing and integration, these multimodal information sources enable a more profound exploration and understanding of the complex interaction relationships between GPCRs and compounds. The EnGCI model offers a robust and efficient framework that enhances GCI predictive capabilities and has the potential to significantly contribute to GPCR drug discovery.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Leveraging pretrained deep protein language model to predict peptide collision cross section",
    "doi": "10.1038/s42004-025-01540-z",
    "url": "https://www.nature.com/articles/s42004-025-01540-z",
    "authors": [
      "Nakai-Kasai, Ayano",
      "Ogata, Kosuke",
      "Ishihama, Yasushi",
      "Tanaka, Toshiyuki"
    ],
    "publicationDate": "2025-05-06",
    "publicationName": "Communications Chemistry",
    "contentType": "Article",
    "abstract": "Collision cross section (CCS) of peptide ions provides an important separation dimension in liquid chromatography/tandem mass spectrometry-based proteomics that incorporates ion mobility spectrometry (IMS), and its accurate prediction is the basis for advanced proteomics workflows. This paper describes experimental data and a prediction model for challenging CCS prediction tasks including longer peptides that tend to have higher charge states. The proposed model is based on a pretrained deep protein language model. While the conventional prediction model requires training from scratch, the proposed model enables training with less amount of time owing to the use of the pretrained model as a feature extractor. Results of experiments with the novel experimental data show that the proposed model succeeds in drastically reducing the training time while maintaining the same or even better prediction performance compared with the conventional method. Our approach presents the possibility of prediction on the basis of “greener” manner training of various peptide properties in proteomic liquid chromatography/tandem mass spectrometry experiments. Accurate prediction of collision cross sections (CCS) in proteomics is crucial for enhancing ion mobility spectrometry in mass spectrometry workflows. Here, the authors introduce a pretrained deep protein language model that significantly reduces training time while maintaining or improving CCS prediction accuracy, offering an efficient approach to proteomic analysis.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Benchmarking foundation cell models for post-perturbation RNA-seq prediction",
    "doi": "10.1186/s12864-025-11600-2",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12864-025-11600-2",
    "authors": [
      "Csendes, Gerold",
      "Sanz, Gema",
      "Szalay, Kristóf Z.",
      "Szalai, Bence"
    ],
    "publicationDate": "2025-04-23",
    "publicationName": "BMC Genomics",
    "contentType": "Article",
    "abstract": "Accurately predicting cellular responses to perturbations is essential for understanding cell behaviour in both healthy and diseased states. While perturbation data is ideal for building such predictive models, its availability is considerably lower than baseline (non-perturbed) cellular data. To address this limitation, several foundation cell models have been developed using large-scale single-cell gene expression data. These models are fine-tuned after pre-training for specific tasks, such as predicting post-perturbation gene expression profiles, and are considered state-of-the-art for these problems. However, proper benchmarking of these models remains an unsolved challenge. In this study, we benchmarked two recently published foundation models, scGPT and scFoundation, against baseline models. Surprisingly, we found that even the simplest baseline model—taking the mean of training examples—outperformed scGPT and scFoundation. Furthermore, basic machine learning models that incorporate biologically meaningful features outperformed scGPT by a large margin. Additionally, we identified that the current Perturb-Seq benchmark datasets exhibit low perturbation-specific variance, making them suboptimal for evaluating such models. Our results highlight important limitations in current benchmarking approaches and provide insights into more effectively evaluating post-perturbation gene expression prediction models.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Deconvolution of cell types and states in spatial multiomics utilizing TACIT",
    "doi": "10.1038/s41467-025-58874-4",
    "url": "https://www.nature.com/articles/s41467-025-58874-4",
    "authors": [
      "Huynh, Khoa L. A.",
      "Tyc, Katarzyna M.",
      "Matuck, Bruno F.",
      "Easter, Quinn T.",
      "Pratapa, Aditya",
      "Kumar, Nikhil V.",
      "Pérez, Paola",
      "Kulchar, Rachel J.",
      "Pranzatelli, Thomas J. F.",
      "Souza, Deiziane",
      "Weaver, Theresa M.",
      "Qu, Xufeng",
      "Soares Junior, Luiz Alberto Valente",
      "Dolhnokoff, Marisa",
      "Kleiner, David E.",
      "Hewitt, Stephen M.",
      "Silva, Luiz Fernando Ferraz",
      "Rocha, Vanderson Geraldo",
      "Warner, Blake M.",
      "Byrd, Kevin M.",
      "Liu, Jinze"
    ],
    "publicationDate": "2025-04-21",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Spatial multi-omics analysis tools have lagged behind advancements in single-cell technologies. Here, authors introduce TACIT, a scalable tool for automated cell type and state deconvolution from spatial multi-omics datasets, improving accuracy and efficiency over existing methods. Identifying cell types and states remains a time-consuming, error-prone challenge for spatial biology. While deep learning increasingly plays a role, it is difficult to generalize due to variability at the level of cells, neighborhoods, and niches in health and disease. To address this, we develop TACIT, an unsupervised algorithm for cell annotation using predefined signatures that operates without training data. TACIT uses unbiased thresholding to distinguish positive cells from background, focusing on relevant markers to identify ambiguous cells in multiomic assays. Using five datasets (5,000,000 cells; 51 cell types) from three niches (brain, intestine, gland), TACIT outperforms existing unsupervised methods in accuracy and scalability. Integrating TACIT-identified cell types reveals new phenotypes in two inflammatory gland diseases. Finally, using combined spatial transcriptomics and proteomics, we discover under- and overrepresented immune cell types and states in regions of interest, suggesting multimodality is essential for translating spatial biology to clinical applications.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Stereopy: modeling comparative and spatiotemporal cellular heterogeneity via multi-sample spatial transcriptomics",
    "doi": "10.1038/s41467-025-58079-9",
    "url": "https://www.nature.com/articles/s41467-025-58079-9",
    "authors": [
      "Fang, Shuangsang",
      "Xu, Mengyang",
      "Cao, Lei",
      "Liu, Xiaobin",
      "Bezulj, Marija",
      "Tan, Liwei",
      "Yuan, Zhiyuan",
      "Li, Yao",
      "Xia, Tianyi",
      "Guo, Longyu",
      "Kovacevic, Vladimir",
      "Hui, Junhou",
      "Guo, Lidong",
      "Liu, Chao",
      "Cheng, Mengnan",
      "Lin, Li’ang",
      "Wen, Zhenbin",
      "Josic, Bojana",
      "Milicevic, Nikola",
      "Qiu, Ping",
      "Lu, Qin",
      "Li, Yumei",
      "Wang, Leying",
      "Hu, Luni",
      "Zhang, Chao",
      "Kang, Qiang",
      "Chen, Fengzhen",
      "Deng, Ziqing",
      "Li, Junhua",
      "Li, Mei",
      "Li, Shengkang",
      "Zhao, Yi",
      "Fan, Guangyi",
      "Zhang, Yong",
      "Chen, Ao",
      "Li, Yuxiang",
      "Xu, Xun"
    ],
    "publicationDate": "2025-04-21",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Understanding complex biological systems requires tracing cellular dynamic changes across conditions, time, and space. However, integrating multi-sample data in a unified way to explore cellular heterogeneity remains challenging. Here, we present Stereopy, a flexible framework for modeling and dissecting comparative and spatiotemporal patterns in multi-sample spatial transcriptomics with interactive data visualization. To optimize this framework, we devise a universal container, a scope controller, and an integrative transformer tailored for multi-sample multimodal data storage, management, and processing. Stereopy showcases three representative applications: investigating specific cell communities and genes responsible for pathological changes, detecting spatiotemporal gene patterns by considering spatial and temporal features, and inferring three-dimensional niche-based cell-gene interaction network that bridges intercellular communications and intracellular regulations. Stereopy serves as both a comprehensive bioinformatics toolbox and an extensible framework that empowers researchers with enhanced data interpretation abilities and new perspectives for mining multi-sample spatial transcriptomics data. Tracing cellular changes in complex biological systems is challenging. Here, authors present a flexible framework that integrates multi-sample data with in-house algorithms to infer comparative and spatiotemporal cell-gene patterns, advancing understanding of cellular dynamics.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Zero-shot evaluation reveals limitations of single-cell foundation models",
    "doi": "10.1186/s13059-025-03574-x",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13059-025-03574-x",
    "authors": [
      "Kedzierska, Kasia Z.",
      "Crawford, Lorin",
      "Amini, Ava P.",
      "Lu, Alex X."
    ],
    "publicationDate": "2025-04-18",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "Foundation models such as scGPT and Geneformer have not been rigorously evaluated in a setting where they are used without any further training (i.e., zero-shot). Understanding the performance of models in zero-shot settings is critical to applications that exclude the ability to fine-tune, such as discovery settings where labels are unknown. Our evaluation of the zero-shot performance of Geneformer and scGPT suggests that, in some cases, these models may face reliability challenges and could be outperformed by simpler methods. Our findings underscore the importance of zero-shot evaluations in development and deployment of foundation models in single-cell research.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Towards multimodal foundation models in molecular cell biology",
    "doi": "10.1038/s41586-025-08710-y",
    "url": "https://www.nature.com/articles/s41586-025-08710-y",
    "authors": [
      "Cui, Haotian",
      "Tejada-Lapuerta, Alejandro",
      "Brbić, Maria",
      "Saez-Rodriguez, Julio",
      "Cristea, Simona",
      "Goodarzi, Hani",
      "Lotfollahi, Mohammad",
      "Theis, Fabian J.",
      "Wang, Bo"
    ],
    "publicationDate": "2025-04-17",
    "publicationName": "Nature",
    "contentType": "Article",
    "abstract": "The development of multimodal foundation models, pretrained on diverse omics datasets, to unravel the intricate complexities of molecular cell biology is envisioned. The rapid advent of high-throughput omics technologies has created an exponential growth in biological data, often outpacing our ability to derive molecular insights. Large-language models have shown a way out of this data deluge in natural language processing by integrating massive datasets into a joint model with manifold downstream use cases. Here we envision developing multimodal foundation models, pretrained on diverse omics datasets, including genomics, transcriptomics, epigenomics, proteomics, metabolomics and spatial profiling. These models are expected to exhibit unprecedented potential for characterizing the molecular states of cells across a broad continuum, thereby facilitating the creation of holistic maps of cells, genes and tissues. Context-specific transfer learning of the foundation models can empower diverse applications from novel cell-type recognition, biomarker discovery and gene regulation inference, to in silico perturbations. This new paradigm could launch an era of artificial intelligence-empowered analyses, one that promises to unravel the intricate complexities of molecular cell biology, to support experimental design and, more broadly, to profoundly extend our understanding of life sciences.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "TRAPT: a multi-stage fused deep learning framework for predicting transcriptional regulators based on large-scale epigenomic data",
    "doi": "10.1038/s41467-025-58921-0",
    "url": "https://www.nature.com/articles/s41467-025-58921-0",
    "authors": [
      "Zhang, Guorui",
      "Song, Chao",
      "Yin, Mingxue",
      "Liu, Liyuan",
      "Zhang, Yuexin",
      "Li, Ye",
      "Zhang, Jianing",
      "Guo, Maozu",
      "Li, Chunquan"
    ],
    "publicationDate": "2025-04-16",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "It is challenging to identify regulatory transcriptional regulators (TRs), which control gene expression via regulatory elements and epigenomic signals, in context-specific studies on the onset and progression of diseases. The use of large-scale multi-omics epigenomic data enables the representation of the complex epigenomic patterns of control of the regulatory elements and the regulators. Herein, we propose Transcription Regulator Activity Prediction Tool (TRAPT), a multi-modality deep learning framework, which infers regulator activity by learning and integrating the regulatory potentials of target gene cis-regulatory elements and genome-wide binding sites. The results of experiments on 570 TR-related datasets show that TRAPT outperformed state-of-the-art methods in predicting the TRs, especially in terms of forecasting transcription co-factors and chromatin regulators. Moreover, we successfully identify key TRs associated with diseases, genetic variations, cell-fate decisions, and tissues. Our method provides an innovative perspective on identifying TRs by using epigenomic data. Here, the authors propose Transcription Regulator Activity Prediction Tool (TRAPT), a multi-modality deep learning framework, which infers regulator activity by learning and integrating the regulatory potentials of target gene cis-regulatory elements and genome-wide binding sites.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Foundation model of neural activity predicts response to new stimulus types",
    "doi": "10.1038/s41586-025-08829-y",
    "url": "https://www.nature.com/articles/s41586-025-08829-y",
    "authors": [
      "Wang, Eric Y.",
      "Fahey, Paul G.",
      "Ding, Zhuokun",
      "Papadopoulos, Stelios",
      "Ponder, Kayla",
      "Weis, Marissa A.",
      "Chang, Andersen",
      "Muhammad, Taliah",
      "Patel, Saumil",
      "Ding, Zhiwei",
      "Tran, Dat",
      "Fu, Jiakun",
      "Schneider-Mizell, Casey M.",
      "Reid, R. Clay",
      "Collman, Forrest",
      "Costa, Nuno Maçarico",
      "Franke, Katrin",
      "Ecker, Alexander S.",
      "Reimer, Jacob",
      "Pitkow, Xaq",
      "Sinz, Fabian H.",
      "Tolias, Andreas S.",
      "MICrONS Consortium"
    ],
    "publicationDate": "2025-04-10",
    "publicationName": "Nature",
    "contentType": "Article",
    "abstract": "A foundation model trained on neural activity of visual cortex from multiple mice accurately predicts responses to video stimuli and cell types, dendritic features and connectivity within the MICrONS functional connectomics dataset. The complexity of neural circuits makes it challenging to decipher the brain’s algorithms of intelligence. Recent breakthroughs in deep learning have produced models that accurately simulate brain activity, enhancing our understanding of the brain’s computational objectives and neural coding. However, it is difficult for such models to generalize beyond their training distribution, limiting their utility. The emergence of foundation models^ 1 trained on vast datasets has introduced a new artificial intelligence paradigm with remarkable generalization capabilities. Here we collected large amounts of neural activity from visual cortices of multiple mice and trained a foundation model to accurately predict neuronal responses to arbitrary natural videos. This model generalized to new mice with minimal training and successfully predicted responses across various new stimulus domains, such as coherent motion and noise patterns. Beyond neural response prediction, the model also accurately predicted anatomical cell types, dendritic features and neuronal connectivity within the MICrONS functional connectomics dataset^ 2 . Our work is a crucial step towards building foundation models of the brain. As neuroscience accumulates larger, multimodal datasets, foundation models will reveal statistical regularities, enable rapid adaptation to new tasks and accelerate research.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "MIDAA: deep archetypal analysis for interpretable multi-omic data integration based on biological principles",
    "doi": "10.1186/s13059-025-03530-9",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13059-025-03530-9",
    "authors": [
      "Milite, Salvatore",
      "Caravagna, Giulio",
      "Sottoriva, Andrea"
    ],
    "publicationDate": "2025-04-08",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "High-throughput multi-omic molecular profiling allows the probing of biological systems at unprecedented resolution. However, integrating and interpreting high-dimensional, sparse, and noisy multimodal datasets remains challenging. Deriving new biological insights with current methods is difficult because they are not rooted in biological principles but prioritise tasks like dimensionality reduction. Here, we introduce a framework that combines archetypal analysis, an approach grounded in biological principles, with deep learning . Using archetypes based on evolutionary trade-offs and Pareto optimality, MIDAA finds extreme data points that define the geometry of the latent space, preserving the complexity of biological interactions while retaining an interpretable output. We demonstrate that these extreme points represent cellular programmes reflecting the underlying biology. Moreover, we show that, compared to alternative methods, MIDAA can identify parsimonious, interpretable, and biologically relevant patterns from real and simulated multi-omics.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A disease-specific language model for variant pathogenicity in cardiac and regulatory genomics",
    "doi": "10.1038/s42256-025-01016-8",
    "url": "https://www.nature.com/articles/s42256-025-01016-8",
    "authors": [
      "Zhan, Huixin",
      "Moore, Jason H.",
      "Zhang, Zijun"
    ],
    "publicationDate": "2025-04-01",
    "publicationName": "Nature Machine Intelligence",
    "contentType": "Article",
    "abstract": "DYNA fine-tunes genomic foundation models with disease specificity using a Siamese network. It generalizes to rare-variant test sets and replicates results in ClinVar, advancing variant effect prediction for cardiovascular diseases and RNA splicing. Clinical variant classification of pathogenic versus benign genetic variants remains a challenge in genetics. Current genomic foundation models have enhanced variant effect prediction (VEP) accuracy through weakly supervised or unsupervised training, yet these models lack disease specificity. Here, to address this, we propose DYNA (disease-specificity fine-tuning via a Siamese neural network), broadly applicable to all genomic foundation models for more effective VEPs in disease contexts. We applied DYNA to the coding VEP in cardiovascular diseases and the non-coding VEP of RNA splicing regulation. These two tasks cover a wide range of specific disease–gene relationships and disease-causing regulatory mechanisms; therefore, their performance will inform the general utility of DYNA. In both cases, DYNA fine-tunes various pretrained genomic foundation models on small rare-variant sets. The DYNA fine-tuned models show superior performance in held-out rare-variant test sets and are further replicated in large, clinically relevant variant annotations in ClinVar. Importantly, we observed that different genomic foundation models excel at different downstream VEP tasks, necessitating a universal tool such as DYNA to fully harness the power of genomic foundation models. Thus, DYNA offers a potent disease-specific VEP method for clinical variant interpretation.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Multimodal learning for mapping genotype–phenotype dynamics",
    "doi": "10.1038/s43588-024-00765-7",
    "url": "https://www.nature.com/articles/s43588-024-00765-7",
    "authors": [
      "Khodaee, Farhan",
      "Zandie, Rohola",
      "Edelman, Elazer R."
    ],
    "publicationDate": "2025-04-01",
    "publicationName": "Nature Computational Science",
    "contentType": "Article",
    "abstract": "How complex phenotypes emerge from intricate gene expression patterns is a fundamental question in biology. Integrating high-content genotyping approaches such as single-cell RNA sequencing and advanced learning methods such as language models offers an opportunity for dissecting this complex relationship. Here we present a computational integrated genetics framework designed to analyze and interpret the high-dimensional landscape of genotypes and their associated phenotypes simultaneously. We applied this approach to develop a multimodal foundation model to explore the genotype–phenotype relationship manifold for human transcriptomics at the cellular level. Analyzing this joint manifold showed a refined resolution of cellular heterogeneity, uncovered potential cross-tissue biomarkers and provided contextualized embeddings to investigate the polyfunctionality of genes shown for the von Willebrand factor ( VWF ) gene in endothelial cells. Overall, this study advances our understanding of the dynamic interplay between gene expression and phenotypic manifestation and demonstrates the potential of integrated genetics in uncovering new dimensions of cellular function and complexity. A multimodal computational framework is proposed to integrate single-cell RNA sequencing data with phenotypic information to map complex genotype–phenotype relationships. This approach helps to refine cellular heterogeneity analysis, identify cross-tissue biomarkers and reveal polyfunctional characteristics of genes with cellular resolution.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Simple and effective embedding model for single-cell biology built from ChatGPT",
    "doi": "10.1038/s41551-024-01284-6",
    "url": "https://www.nature.com/articles/s41551-024-01284-6",
    "authors": [
      "Chen, Yiqun",
      "Zou, James"
    ],
    "publicationDate": "2025-04-01",
    "publicationName": "Nature Biomedical Engineering",
    "contentType": "Article",
    "abstract": "ChatGPT can be leveraged to generate informative embeddings of genes and single cells. Large-scale gene-expression data are being leveraged to pretrain models that implicitly learn gene and cellular functions. However, such models require extensive data curation and training. Here we explore a much simpler alternative: leveraging ChatGPT embeddings of genes based on the literature. We used GPT-3.5 to generate gene embeddings from text descriptions of individual genes and to then generate single-cell embeddings by averaging the gene embeddings weighted by each gene’s expression level. We also created a sentence embedding for each cell by using only the gene names ordered by their expression level. On many downstream tasks used to evaluate pretrained single-cell embedding models—particularly, tasks of gene-property and cell-type classifications—our model, which we named GenePT, achieved comparable or better performance than models pretrained from gene-expression profiles of millions of cells. GenePT shows that large-language-model embeddings of the literature provide a simple and effective path to encoding single-cell biological knowledge.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Enhancing nucleotide sequence representations in genomic analysis with contrastive optimization",
    "doi": "10.1038/s42003-025-07902-6",
    "url": "https://www.nature.com/articles/s42003-025-07902-6",
    "authors": [
      "Refahi, Mohammadsaleh",
      "Sokhansanj, Bahrad A.",
      "Mell, Joshua C.",
      "Brown, James R.",
      "Yoo, Hyunwoo",
      "Hearne, Gavin",
      "Rosen, Gail L."
    ],
    "publicationDate": "2025-03-29",
    "publicationName": "Communications Biology",
    "contentType": "Article",
    "abstract": "Scorpio enhances genomic language models with contrastive learning and hierarchical sampling to improve classification, generalization, and biological representation, enabling transferable embeddings to other domains. Analysis of genomic and metagenomic sequences is inherently more challenging than that of amino acid sequences due to the higher divergence among evolutionarily related nucleotide sequences, variable k-mer and codon usage within and among genomes of diverse species, and poorly understood selective constraints. We introduce Scorpio (Sequence Contrastive Optimization for Representation and Predictive Inference on DNA), a versatile framework designed for nucleotide sequences that employ contrastive learning to improve embeddings. By leveraging pre-trained genomic language models and k-mer frequency embeddings, Scorpio demonstrates competitive performance in diverse applications, including taxonomic and gene classification, antimicrobial resistance (AMR) gene identification, and promoter detection. A key strength of Scorpio is its ability to generalize to novel DNA sequences and taxa, addressing a significant limitation of alignment-based methods. Scorpio has been tested on multiple datasets with DNA sequences of varying lengths (long and short) and shows robust inference capabilities. Additionally, we provide an analysis of the biological information underlying this representation, including correlations between codon adaptation index as a gene expression factor, sequence similarity, and taxonomy, as well as the functional and structural information of genes.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Predicting response to neoadjuvant chemotherapy in muscle-invasive bladder cancer via interpretable multimodal deep learning",
    "doi": "10.1038/s41746-025-01560-y",
    "url": "https://www.nature.com/articles/s41746-025-01560-y",
    "authors": [
      "Bai, Zilong",
      "Osman, Mohamed",
      "Brendel, Matthew",
      "Tangen, Catherine M.",
      "Flaig, Thomas W.",
      "Thompson, Ian M.",
      "Plets, Melissa",
      "Scott Lucia, M.",
      "Theodorescu, Dan",
      "Gustafson, Daniel",
      "Daneshmand, Siamak",
      "Meeks, Joshua J.",
      "Choi, Woonyoung",
      "Dinney, Colin P. N.",
      "Elemento, Olivier",
      "Lerner, Seth P.",
      "McConkey, David J.",
      "Faltas, Bishoy M.",
      "Wang, Fei"
    ],
    "publicationDate": "2025-03-22",
    "publicationName": "npj Digital Medicine",
    "contentType": "Article",
    "abstract": "Building accurate prediction models and identifying predictive biomarkers for treatment response in Muscle-Invasive Bladder Cancer (MIBC) are essential for improving patient survival but remain challenging due to tumor heterogeneity, despite numerous related studies. To address this unmet need, we developed an interpretable Graph-based Multimodal Late Fusion (GMLF) deep learning framework. Integrating histopathology and cell type data from standard H&E images with gene expression profiles derived from RNA sequencing from the SWOG S1314-COXEN clinical trial (ClinicalTrials.gov NCT02177695 2014-06-25), GMLF uncovered new histopathological, cellular, and molecular determinants of response to neoadjuvant chemotherapy. Specifically, we identified key gene signatures that drive the predictive power of our model, including alterations in TP63, CCL5, and DCN. Our discovery can optimize treatment strategies for patients with MIBC, e.g., improving clinical outcomes, avoiding unnecessary treatment, and ultimately, bladder preservation. Additionally, our approach could be used to uncover predictors for other cancers.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "AIM: an accurate and explainable model for ATAC to GEX translation and pathway analysis",
    "doi": "10.1007/s12293-025-00442-w",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12293-025-00442-w",
    "authors": [
      "Nguyen, Quang H.",
      "Tran, Hoang V.",
      "Nguyen, Huu Tien",
      "Le, Phuong T. M.",
      "Nguyen, Phi Le",
      "Nguyen, Binh P."
    ],
    "publicationDate": "2025-03-21",
    "publicationName": "Memetic Computing",
    "contentType": "Article",
    "abstract": "The development of multimodal technologies has enabled the simultaneous measurement of various cellular modalities, such as chromatin accessibility (ATAC), gene expression (GEX), and surface protein abundance in single cells. However, the lack of multimodal datasets requires the development of robust algorithms that can translate data between different modalities. In this study, we present AIM, a framework for accurate and interpretive multimodal translation, specifically designed for the conversion of ATAC data into GEX profiles. AIM introduces a novel two-tier modeling architecture. The upper tier captures the global relationships between ATAC and GEX, generating an initial estimate of gene expression. The lower tier performs a finer-grained analysis by modeling inter-chromosomal interactions to refine the generated GEX representation. This modular structure enhances both the accuracy and adaptability of AIM. Additionally, an integrated attention mechanism provides interpretability by highlighting critical chromatin regions influencing specific gene expressions. Our experimental results demonstrate that AIM achieves state-of-the-art performance, with a per-chromosome RMSE of 0.2206, outperforming existing approaches (0.2232). Furthermore, the attention maps generated by AIM offer a pathway analysis capability, uncovering biologically significant gene-gene interactions such as ARHGAP24-ARAP2 and SYK-PAX5. These findings validate AIM’s effectiveness not only as a data translation tool but also as a platform for deriving mechanistic insights into gene regulatory dynamics.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Investigation of cell development and tissue structure network based on natural Language processing of scRNA-seq data",
    "doi": "10.1186/s12967-025-06263-2",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12967-025-06263-2",
    "authors": [
      "Wei, Suwen",
      "Lu, Yuer",
      "Wang, Peng",
      "Li, Qichao",
      "Shuai, Jianwei",
      "Zhao, Qi",
      "Lin, Hai",
      "Peng, Yuming"
    ],
    "publicationDate": "2025-03-04",
    "publicationName": "Journal of Translational Medicine",
    "contentType": "Article",
    "abstract": "Background Single-cell multi-omics technologies, particularly single-cell RNA sequencing (scRNA-seq), have revolutionized our understanding of cellular heterogeneity and development by providing insights into gene expression at the single-cell level. Investigating the influence of genes on cellular behavior is crucial for elucidating cell fate determination and differentiation, cell development processes, and disease mechanisms. Methods Inspired by NLP, we present a novel scRNA-seq analysis method that treats genes as analogous to words. Using word2vec to embed gene sequences derived from gene networks, we generate vector representations of genes, which are then used to represent cells by summing gene vectors and subsequently tissues by aggregating cell vectors. Results Our NLP-based approach analyzes scRNA-seq data by generating vector representations of genes, cells, and tissues. This multi-scale analysis includes mapping cell states in vector space to reveal developmental trajectories, quantifying cell similarity using Euclidean distance, and constructing inter-tissue relationship networks from aggregated cell vectors. Conclusions This method offers a computationally efficient approach for analyzing scRNA-seq data by constructing embedding representations similar to those used in large language model pre-training, but without requiring high-performance computing clusters. By generating gene embeddings that capture functional relationships, this method facilitates the study of cell development trajectories, the impact of gene perturbations, cell clustering, and the construction and analysis of tissue networks. This provides a valuable tool for single-cell data analysis.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Transformers and genome language models",
    "doi": "10.1038/s42256-025-01007-9",
    "url": "https://www.nature.com/articles/s42256-025-01007-9",
    "authors": [
      "Consens, Micaela E.",
      "Dufault, Cameron",
      "Wainberg, Michael",
      "Forster, Duncan",
      "Karimzadeh, Mehran",
      "Goodarzi, Hani",
      "Theis, Fabian J.",
      "Moses, Alan",
      "Wang, Bo"
    ],
    "publicationDate": "2025-03-01",
    "publicationName": "Nature Machine Intelligence",
    "contentType": "Article",
    "abstract": "Micaela Consens et al. discuss and review the recent rise of transformer-based and large language models in genomics. They also highlight promising directions for genome language models beyond the transformer architecture. Large language models based on the transformer deep learning architecture have revolutionized natural language processing. Motivated by the analogy between human language and the genome’s biological code, researchers have begun to develop genome language models (gLMs) based on transformers and related architectures. This Review explores the use of transformers and language models in genomics. We survey open questions in genomics amenable to the use of gLMs, and motivate the use of gLMs and the transformer architecture for these problems. We discuss the potential of gLMs for modelling the genome using unsupervised pretraining tasks, specifically focusing on the power of zero- and few-shot learning. We explore the strengths and limitations of the transformer architecture, as well as the strengths and limitations of current gLMs more broadly. Additionally, we contemplate the future of genomic modelling beyond the transformer architecture, based on current trends in research. This Review serves as a guide for computational biologists and computer scientists interested in transformers and language models for genomic data.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Histopathology and proteomics are synergistic for high-grade serous ovarian cancer platinum response prediction",
    "doi": "10.1038/s41698-025-00808-w",
    "url": "https://www.nature.com/articles/s41698-025-00808-w",
    "authors": [
      "Kilim, Oz",
      "Olar, Alex",
      "Biricz, András",
      "Madaras, Lilla",
      "Pollner, Péter",
      "Szállási, Zoltán",
      "Sztupinszki, Zsofia",
      "Csabai, István"
    ],
    "publicationDate": "2025-01-26",
    "publicationName": "npj Precision Oncology",
    "contentType": "Article",
    "abstract": "Patients with High-Grade Serous Ovarian Cancer (HGSOC) exhibit varied responses to treatment, with 20–30% showing de novo resistance to platinum-based chemotherapy. While hematoxylin-eosin (H&E)-stained pathological slides are used for routine diagnosis of cancer type, they may also contain diagnostically useful information about treatment response. Our study demonstrates that combining H&E-stained whole slide images (WSIs) with proteomic signatures using a multimodal deep learning framework significantly improves the prediction of platinum response in both discovery and validation cohorts. This method outperforms the Homologous Recombination Deficiency (HRD) score in predicting platinum response and overall patient survival. Our study suggests that histology and proteomics contain complementary information about biological processes determining response to first line platinum treatment in HGSOC. This integrative approach has the potential to improve personalized treatment and provide insights into the therapeutic vulnerabilities of HGSOC.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "A graph neural network approach for hierarchical mapping of breast cancer protein communities",
    "doi": "10.1186/s12859-024-06015-x",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s12859-024-06015-x",
    "authors": [
      "Zhang, Xiao",
      "Liu, Qian"
    ],
    "publicationDate": "2025-01-21",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": "Background Comprehensively mapping the hierarchical structure of breast cancer protein communities and identifying potential biomarkers from them is a promising way for breast cancer research. Existing approaches are subjective and fail to take information from protein sequences into consideration. Deep learning can automatically learn features from protein sequences and protein–protein interactions for hierarchical clustering. Results Using a large amount of publicly available proteomics data, we created a hierarchical tree for breast cancer protein communities using a novel hierarchical graph neural network, with the supervision of gene ontology terms and assistance of a pre-trained deep contextual language model. Then, a group-lasso algorithm was applied to identify protein communities that are under both mutation burden and survival burden, undergo significant alterations when targeted by specific drug molecules, and show cancer-dependent perturbations. The resulting hierarchical map of protein communities shows how gene-level mutations and survival information converge on protein communities at different scales. Internal validity of the model was established through the convergence on BRCA2 as a breast cancer hotspot. Further overlaps with breast cancer cell dependencies revealed SUPT6H and RAD21, along with their respective protein systems, HOST:37 and HOST:861, as potential biomarkers. Using gene-level perturbation data of the HOST:37 and HOST:861 gene sets, three FDA-approved drugs with high therapeutic value were selected as potential treatments to be further evaluated. These drugs include mercaptopurine, pioglitazone, and colchicine. Conclusion The proposed graph neural network approach to analyzing breast cancer protein communities in a hierarchical structure provides a novel perspective on breast cancer prognosis and treatment. By targeting entire gene sets, we were able to evaluate the prognostic and therapeutic value of genes (or gene sets) at different levels, from gene-level to system-level biology. Cancer-specific gene dependencies provide additional context for pinpointing cancer-related systems and drug-induced alterations can highlight potential therapeutic targets. These identified protein communities, in conjunction with other protein communities under strong mutation and survival burdens, can potentially be used as clinical biomarkers for breast cancer.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "DNA promoter task-oriented dictionary mining and prediction model based on natural language technology",
    "doi": "10.1038/s41598-024-84105-9",
    "url": "https://www.nature.com/articles/s41598-024-84105-9",
    "authors": [
      "Zeng, Ruolei",
      "Li, Zihan",
      "Li, Jialu",
      "Zhang, Qingchuan"
    ],
    "publicationDate": "2025-01-02",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": "Promoters are essential DNA sequences that initiate transcription and regulate gene expression. Precisely identifying promoter sites is crucial for deciphering gene expression patterns and the roles of gene regulatory networks. Recent advancements in bioinformatics have leveraged deep learning and natural language processing (NLP) to enhance promoter prediction accuracy. Techniques such as convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and BERT models have been particularly impactful. However, current approaches often rely on arbitrary DNA sequence segmentation during BERT pre-training, which may not yield optimal results. To overcome this limitation, this article introduces a novel DNA sequence segmentation method. This approach develops a more refined dictionary for DNA sequences, utilizes it for BERT pre-training, and employs an Inception neural network as the foundational model. This BERT-Inception architecture captures information across multiple granularities. Experimental results show that the model improves the performance of several downstream tasks and introduces deep learning interpretability, providing new perspectives for interpreting and understanding DNA sequence information. The detailed source code is available at https://github.com/katouMegumiH/Promoter_BERT .",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Creating Recurrent Neural Networks",
    "doi": "10.1007/978-3-032-00488-8_7",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00488-8_7",
    "authors": [
      "Islam, Tanvir"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Hands-on Deep Learning",
    "contentType": "Chapter",
    "abstract": "Recurrent Neural Networks (RNNs) form the backbone of modern sequence modeling, enabling deep learning models to capture temporal dependencies in data such as text, time series, and speech. In this chapter, we first motivate the need for RNNs and describe common architectures—many-to-many, one-to-many, and many-to-one—highlighting when to use each pattern (e.g., named-entity recognition, image captioning, sentiment analysis). We then cover the essential preprocessing step of tokenization, from character-level encoding to padded, one-hot representations. Next, we derive the math and code for RNN forward propagation, detailing single-cell operations, hidden-state updates, and full-sequence passes. We tackle training challenges—vanishing and exploding gradients—and experiment with remedies such as gradient clipping and better weight initialization. Finally, we explore creative text generation with temperature-controlled sampling and walk through an end-to-end case study: training an RNN to invent novel botanical family names. By the chapter’s end, readers will be able to build, train, and apply RNNs for a wide range of sequence-to-sequence tasks.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Statistical QSAR Modeling for Future Drug Design and Discovery",
    "doi": "10.1007/978-3-031-81728-1_9",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-81728-1_9",
    "authors": [
      "Sheikhpour, Razieh",
      "Gharaghani, Sajjad"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Springer Handbook of Chem- and Bioinformatics",
    "contentType": "Chapter",
    "abstract": "The field of drug design and understanding the interactions of drugs with biological systems in medicinal chemistry and pharmacology is crucial. Quantitative structure-activity relationship (QSAR) serves as a powerful tool in this domain, facilitating the establishment of quantitative and predictive relationships between the chemical structure of a molecule and its biological or pharmacological activities. This chapter conducts a comprehensive exploration of QSAR, covering its fundamental principles, evolutionary trajectory in computational chemistry, and current and future applications in the dynamic landscape of drug discovery. A diverse range of methods, encompassing statistical techniques as well as advanced machine learning and deep learning approaches, is presented as influential tools for precise drug design. The chapter emphasizes the significance of model development and validation, ensuring the reliability and accuracy of QSAR predictions. Moreover, it highlights the emerging trends and advanced techniques like deep learning, graph neural networks, multimodal and multi-task learning, transfer learning, multi-target QSAR, chemogenomics, and proteochemometrics that offer innovative possibilities for drug design. QSAR continues to be an important approach in the pharmaceutical and chemical industries, providing predictive capabilities and data-driven insights.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Kabuki Syndrome Diagnosis and Analysis using PhenoBCBERT and PhenoGPT",
    "doi": "10.2991/978-94-6463-831-8_13",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.2991/978-94-6463-831-8_13",
    "authors": [
      "Jagruti, Nikam",
      "Thakre, Kalpana",
      "Chiddarwar, Girija",
      "Chaudhary, Smita"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Proceedings of the 1st International Conference on Lifespan Innovation (ICLI 2025)",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Alterations in the KMT2D or KDM6A genes, which play a role in regulating gene expression, lead to Kabuki syndrome, a rare genetic disorder. Individuals with Kabuki syndrome often face learning difficulties, ranging from mild to severe intellectual disabilities, as well as developmental delays. The diagnosis can be confirmed through genetic testing. This research operates at the convergence of genomics, rare disease diagnostics, natural language processing (NLP), and machine learning, with the goal of enhancing the diagnosis of Kabuki Syndrome (KS). Traditional diagnostic methods, which often depend on expensive genetic testing, can be slow and may produce inconclusive findings. By utilizing generative AI models such as phenoBCBERT and PhenoGPT, this study harnesses advanced NLP to extract and interpret phenotypic data directly from clinical documentation. PhenoBCBERT is specifically designed to identify phenotypic terms related to KS, whereas PhenoGPT synthesizes patient narratives to create potential diagnostic recommendations. This AI-powered strategy aids clinicians by delivering quicker and more precise diagnostic insights, minimizing the dependence on genetic tests, and improving early detection. The study illustrates the capabilities of generative AI in diagnosing rare diseases. Through thorough evaluation on clinical datasets, our method shows significant enhancements in both diagnostic sensitivity and specificity, especially in differentiating KS from phenotypically similar disorders. Furthermore, our models offer transparency by emphasizing the specific phenotypic characteristics that contribute to each diagnostic recommendation, which could assist clinicians in their decision-making process. Our results with accuracy of 92.4% suggest that incorporating phenoBCBERT and PhenoGPT into clinical practices has the potential to improve the early detection and diagnosis of KS, potentially speeding up interventions and resulting in better outcomes for patients. This study highlights the promise of generative AI in the realm of rare disease diagnostics and sets the stage for future applications in other intricate genetic disorders.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Dual-Channel MiRNA Drug Resistance Prediction Model Based on Multimodal Feature Alignment",
    "doi": "10.1007/978-981-95-0030-7_27",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-0030-7_27",
    "authors": [
      "Tang, Runzhou",
      "Zhang, Zimai",
      "Zhang, Jun",
      "Hu, Lun",
      "Zhou, Xi",
      "Hu, Pengwei"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Advanced Intelligent Computing Technology and Applications",
    "contentType": "Chapter ConferencePaper",
    "abstract": "MicroRNAs (miRNAs), as central regulators of gene expression, have been demonstrated to be deeply involved in the pathogenic processes of various diseases. In current clinical practice, modulating microRNA expression through pharmacological intervention has become an important therapeutic approach for various diseases. However, the emergence of miRNA drug resistance during treatment can significantly compromise therapeutic efficacy. Therefore, accurate prediction of miRNA drug resistance not only provides a basis for developing personalized treatment regimens in clinical practice, but also effectively enhances disease treatment outcomes. The inherent complexity of miRNA-target interaction networks and the multifactorial nature of drug resistance mechanisms pose substantial challenges for conventional experimental approaches, which are often limited by high costs and low throughput. Fortunately, the rapid advancement of artificial intelligence technologies in recent years has opened new avenues to address these challenges through computational approaches based on machine learning and deep learning algorithms. In this paper, we propose a dual-channel model based on feature alignment, DCMFA, for miRNA drug resistance prediction. DCMFA enhances its data comprehension and analytical capabilities by integrating multimodal information to comprehensively capture enriched features between nodes, thereby improving its adaptability and generalization performance. Additionally, DCMFA employs a modular learning framework with two independent modules dedicated to processing distinct node feature groups. This architecture effectively prevents noise interference from irrelevant feature interactions while enabling each module to capture latent patterns within specific feature subsets, thereby facilitating cross-type feature alignment. Experimental results demonstrate that through five-fold cross-validation, DCMFA achieved impressive performance metrics: AUC (95.40%), ACC (91.32%), F1 (91.29%), Precision (91.57%), and AUPR (94.60%), outperforming state-of-the-art models by 1.19%, 3.51%, 3.48%, 3.20%, and 0.32% respectively.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Identifying Spatial Domains by Fusing Spatial Transcriptomics and Histological Images Through Contrastive Learning",
    "doi": "10.1007/978-981-95-0036-9_1",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-0036-9_1",
    "authors": [
      "Xue, Li",
      "Liang, Xiao",
      "Wang, Bo",
      "Liu, Wei",
      "Zou, Zhiyi",
      "Xiao, Qiu",
      "Tu, Nguyen Hoang",
      "Luo, Jiawei"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Advanced Intelligent Computing Technology and Applications",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Recent advancements in spatial transcriptomics (ST) technologies have enabled the generation of gene expression profiles alongside histopathological images while preserving spatial context. Effectively integrating gene expression data with spatial information is crucial for accurately identifying spatial domains, a task that is essential for downstream analyses. Several methods have been developed to combine histopathological images with spatial transcriptomics data. However, these approaches often either use images solely to infer spatial relationships between spots or learn embeddings for gene expression and images separately, without fully integrating the information. To address these limitations, we propose a novel deep learning method, named STCON, for spatial domain identification. Specifically, we use Graph Convolutional Neural Network (GCNs) to extract embeddings from two patterns of gene expression profiles and histopathological images. We align gene expression and histopathological information in a low-dimensional space through contrastive learning, and then further optimize the alignment of image information with gene expression through cross-modal prediction. We evaluated STCON on four real spatial transcriptomics datasets. Experimental results demonstrate that STCON achieves competitive performance in spatial domain identification compared with four state-of-the-art methods. Moreover, STCON effectively detects spatially variable genes (SVGs) with enriched expression patterns in the identified domains. Overall, STCON represents a powerful and efficient computational framework for spatial domain identification in spatial transcriptomics data.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "DCFICSH: A Dual-Channel Fusion Model Combining Multi-Modal Data for Identifying Cell-Specific Silencers and Their Strength in the Human Genome",
    "doi": "10.1007/978-981-96-9815-8_4",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-96-9815-8_4",
    "authors": [
      "Yuan, Jingdong",
      "Zhu, Qinqin",
      "Zhou, Haolu",
      "Han, Yu",
      "Zuo, Yun",
      "Bai, Yude",
      "He, Wenying"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Advanced Intelligent Computing Technology and Applications",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Silencers are key gene regulatory elements that control gene expression and maintain genomic stability. Dysregulation of silencers is linked to diseases like cancer and genetic disorders. Traditional silencer identification relies on manually extracted features, which are time-consuming, costly, and inefficient. Moreover, most studies focus on local DNA sequence features, neglecting contextual relationships that limit model accuracy. To address these issues, we propose DCFICSH, a deep learning framework that employs dual-channel fusion with distinct automated encoding methods for DNA sequences, incorporating omics data as an additional modality. This multi-modal approach enriches the model’s understanding by integrating both DNA sequence and omics data, allowing for a more comprehensive identification of silencers by capturing both local and contextual features. We enhance feature extraction with BiGRU, which captures sequence dependencies, and Transformer, which extracts long-range dependencies via self-attention. DCFICSH improves AUROC and AUPR by 1% to 2% over existing methods for silencer recognition in HepG2 and K562 cell lines. Additionally, we have developed a public web server that offers all relevant resources for this study, enabling researchers to quickly perform silencer predictions. The source code can be accessed at https://github.com/1Yjd/DCFICSH.git .",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Landviewer: Characterization of Tissue Landscapes with Multi-View Graph Learning from Spatially Resolved Transcriptomics",
    "doi": "10.1007/978-981-95-0027-7_20",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-95-0027-7_20",
    "authors": [
      "Yu, Na",
      "Han, Jinghong",
      "Li, Wenrui",
      "Zhang, Daoliang",
      "Wang, Shan",
      "Liu, Fen",
      "Gao, Rui",
      "Liu, Zhiping",
      "Zhang, Wei"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Advanced Intelligent Computing Technology and Applications",
    "contentType": "Chapter ConferencePaper",
    "abstract": "The rapid development of spatially resolved transcriptomics (SRT) technologies has provided novel insights for elucidating the spatial architecture of tissue. However, many methods neglecting complementary information among different modalities within SRT datasets, thus limiting the accuracy of spatial domain identification. To address this issue, we propose Landviewer, an end-to-end multi-view graph learning method for spatial domain identification. Landviewer constructs adjacency relationships across gene expression, spatial locations, and histological images, and employs graph convolutional encoders combined with an attention mechanism to achieve automatic fusion of multimodal information. We additionally introduce a self-supervised Kullback-Leibler divergence to enhance the robustness of the Landviewer. This strategy strengthens the influence of high-confidence samples, thereby improving clustering accuracy and stability. Experimental evaluations on multi-platform datasets demonstrate that Landviewer can not only identify functional domains across various tissues, but also decipher region-associated molecular pathways and complex cell-cell interactions.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Personalized Medicine and Treatment Optimization with Artificial Intelligence of Every Medical Thing (AIoEMT)",
    "doi": "10.1007/978-981-96-7202-8_5",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-96-7202-8_5",
    "authors": [
      "Rahmaty, Maryam"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Artificial Intelligence of Everything and Sustainable Development",
    "contentType": "Chapter",
    "abstract": "Integrating Artificial Intelligence of Every Medical Thing (AIoEMT) into personalized medicine represents a transformative shift toward individualized, data-driven healthcare. This research explores the AIoEMT framework's applications in optimizing diagnosis, treatment, and real-time therapeutic adjustments. By leveraging advanced AI techniques such as machine learning, deep learning, and natural language processing, AIoEMT processes vast, heterogeneous datasets to uncover patterns that guide clinical decision-making. Key applications discussed include personalized cancer therapies, adaptive cardiovascular care, dynamic diabetes management, and AI-guided pharmacogenomics. The study also examines the role of data analytics in enhancing decision support systems, enabling proactive, evidence-based care. Furthermore, the research highlights data privacy challenges, algorithmic bias, and system interoperability, offering potential solutions such as federated learning and explainable AI. Real-time monitoring technologies, predictive models, and digital twin simulations demonstrate the potential of AIoEMT to predict disease trajectories and optimize treatments in dynamic environments. The findings underscore the transformative impact of AIoEMT on personalized medicine, enhancing treatment precision, patient outcomes, and healthcare system efficiency. As AI technologies continue to advance, AIoEMT is a critical enabler of precision medicine in the era of smart healthcare systems.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "scPER2P: Parameter-Efficient Single-Cell LLM for Translated Proteome Profiles",
    "doi": "10.1007/978-981-96-6588-4_1",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-96-6588-4_1",
    "authors": [
      "Wang, Yuchen",
      "Chen, Xingjian",
      "Zheng, Zetian",
      "Xie, Weidun",
      "Wang, Fuzhou",
      "Huang, Lei",
      "Wong, Ka-Chun"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Neural Information Processing",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Protein expression levels are crucial for capturing the intricate dynamics of biological processes within cells. Recent advancements in protein sequencing technologies have enabled the simultaneous measurement of transcriptomics and proteomes. However, it is still associated with significant challenges high-throughput sequencing errors, precise quantifications, and high-quality antibodies. To address those challenges, we introduce scPER2P, an end-to-end deep learning framework that translates single-cell RNA-seq data into proteome profiles. Our model includes single-cell language models and incorporates parameter-efficient fine-tuning techniques to facilitate proteome profile inference. Experimental results across multiple datasets reflect that scPER2P not only achieves high correlation coefficients and cosine similarities with true proteomic profiles but also maintains promising performance with significantly fewer parameters than the full fine-tuning methods. Additionally, cell type clustering results underscore the model’s capability to significantly improve the accuracy of cell type annotation tasks. Our approach offers a promising solution to enhance and complement proteome profiling in single-cell studies. Code and data are available at https://github.com/WangyuchenCS/scPER2P .",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Proteomics, Neuropsychological and Demographics Multimodal Machine Learning Approach to Alzheimer’s Disease Prediction on the Bio-Hermes Study Cohort",
    "doi": "10.1007/978-3-031-96235-6_18",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-96235-6_18",
    "authors": [
      "Musto, Henry",
      "Stamate, Daniel",
      "Reeves, David",
      "Morgan, Catharine",
      "Hutanu, Roxana",
      "Mavromati, Kalliopi",
      "Cadar, Dorina",
      "Stahl, Daniel"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Artificial Intelligence Applications and Innovations",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that significantly affects cognitive function. Early and accurate diagnosis is crucial for timely intervention, yet traditional diagnostic methods can be costly and invasive. This study explores a machine learning (ML) approach leveraging the Bio-Hermes dataset, which integrates blood-derived proteomics, neuropsychological test results, and demographic variables to improve the classification of individuals into cognitively normal (CN), mild cognitive impairment (MCI), and AD categories. We implement four ML models: Elastic Net, Classification and Regression Trees (CART), Random Forest, and Extreme Gradient Boosting (XGBoost). The results indicate that XGBoost achieves the highest accuracy (0.81) and a strong area under the receiver operating characteristic curve (AUCROC) (0.94), highlighting the potential of multimodal ML models in dementia classification. Additionally, the Mini-Mental State Exam (MMSE) and the proteomic marker pTau181 emerged as key predictive variables. This study underscores the feasibility of using blood-based proteomics in conjunction with cognitive assessments for early AD detection and advocates for further validation on larger, diverse cohorts.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Advancing Protein-DNA Binding Site Prediction: Integrating Sequence Models and Machine Learning Classifiers",
    "doi": "10.1007/978-981-96-6960-8_25",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-96-6960-8_25",
    "authors": [
      "Murad, Taslim",
      "Chourasia, Prakash",
      "Ali, Sarwan",
      "Patterson, Murray"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Neural Information Processing",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Predicting protein-DNA binding sites is a challenging computational problem in the field of bioinformatics. Identifying the specific residues where proteins bind to DNA is of paramount importance, as it enables the modeling of their interactions and facilitates downstream studies. Nevertheless, the development of accurate and efficient computational methods for this task remains a persistent challenge. Accurate prediction of protein-DNA binding sites has far-reaching implications for understanding molecular mechanisms, disease processes, drug discovery, and synthetic biology applications. It helps bridge the gap between genomics and functional biology, enabling researchers to uncover the intricacies of cellular processes and advance our knowledge of the biological world. The method used to predict DNA binding residues in this study is a potent combination of conventional bioinformatics tools, protein language models, and cutting-edge machine learning and deep learning classifiers. On a dataset of protein-DNA binding sites, our model is meticulously trained, and it is then rigorously examined using several experiments. As indicated by higher predictive behavior with AUC values on two benchmark datasets, the results show superior performance when compared to existing models. The suggested model has a strong capacity for generalization and shows specificity for DNA-binding sites. We further demonstrated the adaptability of our model as a universal framework for binding site prediction by training it on a variety of protein-ligand binding site datasets. In conclusion, our innovative approach for predicting protein-DNA binding residues holds great promise in advancing our understanding of molecular interactions, thus paving the way for several groundbreaking applications in the field of molecular biology and genetics. Our approach demonstrated efficacy and versatility underscore its potential for driving transformative discoveries in biomolecular research.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Simulation of Biological Structures Using Generative Artificial Intelligence",
    "doi": "10.1007/978-981-96-3448-4_19",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-96-3448-4_19",
    "authors": [
      "Siddharth, Dhirendra",
      "Saini, Dilip Kumar Jang Bahadur",
      "Dilip, Kumar",
      "Dwivedi, Upendra"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Artificial Intelligence in Microbial Research",
    "contentType": "Chapter",
    "abstract": "Generative artificial intelligence (AI) is transforming healthcare by creating innovative solutions for medical imaging, education, and drug development. Using advanced models such as generative adversarial networks (GANs) and variational autoencoders (VAEs), generative AI addresses issues such as data augmentation, synthetic image production, and anomaly detection. These characteristics improve diagnosis accuracy, permit more tailored therapy, and accelerate healthcare processes. In medical education, generative AI offers immersive simulations for realistic surgical training, as well as interactive learning experiences, which aid in the bridge between academic knowledge and practical expertise. New technologies, like augmented reality (AR), virtual reality (VR), multimodal data integration, and quantum computing, are broadening the scope of generative AI. These innovations make precision medicine possible by merging imaging and genomics, enhance surgical accuracy with AR/VR applications, and increase computational efficiency when dealing with massive datasets. Privacy-preserving techniques such as federated learning allow for collaborative AI research while protecting data. Meanwhile, explainable AI (XAI) promotes openness and confidence between practitioners and patients.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Transformer-Enhanced Pathogenicity Prediction with Soft Labels in a Semi-supervised Setup",
    "doi": "10.1007/978-3-031-87873-2_5",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-87873-2_5",
    "authors": [
      "Guillem, Pablo Enrique",
      "Zurdo-Tabernero, Marco",
      "Figueroa, Liliana Durón",
      "Canal-Alonso, Ángel",
      "Hernández, Guillermo",
      "Arrieta, Angélica González",
      "Prieta, Fernando"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Practical Applications of Computational Biology and Bioinformatics, 18th International Conference (PACBB 2024)",
    "contentType": "Chapter ConferencePaper",
    "abstract": "The rapid evolution of Next-Generation Sequencing technologies has transformed genomics, generating vast amounts of data that require advanced analysis methods. This paper presents a Deep Learning model developed to predict the pathogenicity of genetic variants, a crucial step towards personalized medicine. Our model is trained on a dataset generated with the analysis of a sample of Next-Generation Sequencing outputs, incorporating a mix of clearly labeled and less certain genetic variants. By adopting a semi-supervised learning approach, the model effectively leverages both soft and hard-labelled data. The core of our methodology is the Feature Tokenizer Transformer architecture, which processes numerical and categorical genomic data. Our preprocessing strategy includes several steps to ensure data quality, such as imputation, scaling, and encoding. Our results demonstrate the model’s exceptional accuracy, especially in identifying hard-labelled variants. The significance of the model’s outputs on the soft labels is also discussed.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Delineating the effective use of self-supervised learning in single-cell genomics",
    "doi": "10.1038/s42256-024-00934-3",
    "url": "https://www.nature.com/articles/s42256-024-00934-3",
    "authors": [
      "Richter, Till",
      "Bahrami, Mojtaba",
      "Xia, Yufan",
      "Fischer, David S.",
      "Theis, Fabian J."
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Nature Machine Intelligence",
    "contentType": "Article",
    "abstract": "Self-supervised learning (SSL) has emerged as a powerful method for extracting meaningful representations from vast, unlabelled datasets, transforming computer vision and natural language processing. In single-cell genomics (SCG), representation learning offers insights into the complex biological data, especially with emerging foundation models. However, identifying scenarios in SCG where SSL outperforms traditional learning methods remains a nuanced challenge. Furthermore, selecting the most effective pretext tasks within the SSL framework for SCG is a critical yet unresolved question. Here we address this gap by adapting and benchmarking SSL methods in SCG, including masked autoencoders with multiple masking strategies and contrastive learning methods. Models trained on over 20 million cells were examined across multiple downstream tasks, including cell-type prediction, gene-expression reconstruction, cross-modality prediction and data integration. Our empirical analyses underscore the nuanced role of SSL, namely, in transfer learning scenarios leveraging auxiliary data or analysing unseen datasets. Masked autoencoders excel over contrastive methods in SCG, diverging from computer vision trends. Moreover, our findings reveal the notable capabilities of SSL in zero-shot settings and its potential in cross-modality prediction and data integration. In summary, we study SSL methods in SCG on fully connected networks and benchmark their utility across key representation learning scenarios. Self-supervised learning techniques are powerful assets for enabling deep insights into complex, unlabelled single-cell genomic data. Richter et al. here benchmark the applicability of self-supervised architectures into key downstream representation learning scenarios.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Unified Modeling Enhanced Multimodal Learning for Precision Neuro-Oncology",
    "doi": "10.1007/978-3-031-73360-4_1",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-73360-4_1",
    "authors": [
      "Yi, Huahui",
      "Wang, Xiaofei",
      "Li, Kang",
      "Li, Chao"
    ],
    "publicationDate": "2025-01-01",
    "publicationName": "Computational Mathematics Modeling in Cancer Analysis",
    "contentType": "Chapter ConferencePaper",
    "abstract": "Multimodal learning, integrating histology images and genomics, promises to enhance precision oncology with comprehensive views at microscopic and molecular levels. However, existing methods may not sufficiently model the shared or complementary information for more effective integration. In this study, we introduce a Unified Modeling Enhanced Multimodal Learning (UMEML) framework that employs a hierarchical attention structure to effectively leverage shared and complementary features of both modalities of histology and genomics. Specifically, to mitigate unimodal bias from modality imbalance, we utilize a query-based cross-attention mechanism for prototype clustering in the pathology encoder. Our prototype assignment and modularity strategy are designed to align shared features and minimizes modality gaps. An additional registration mechanism with learnable tokens is introduced to enhance cross-modal feature integration and robustness in multimodal unified modeling. Our experiments demonstrate that our method surpasses previous state-of-the-art approaches in glioma diagnosis and prognosis tasks, underscoring its superiority in precision neuro-Oncology.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "The Theranostic Genome",
    "doi": "10.1038/s41467-024-55291-x",
    "url": "https://www.nature.com/articles/s41467-024-55291-x",
    "authors": [
      "Xu, Xiaoying",
      "Jané, Pablo",
      "Taelman, Vincent",
      "Jané, Eduardo",
      "Dumont, Rebecca A.",
      "Garama, Yonathan",
      "Kim, Francisco",
      "Val Gómez, María",
      "Gariani, Karim",
      "Walter, Martin A."
    ],
    "publicationDate": "2024-12-30",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Identifying theranostic compounds for precision medicine remains a difficult task. Here, the authors develop a deep learning-based hybrid human-AI pipeline to integrate and analyse multiple databases and multimodal datasets to establish the Theranostic Genome , which can be used to propose targeted theranostics therapies. Theranostic drugs represent an emerging path to deliver on the promise of precision medicine. However, bottlenecks remain in characterizing theranostic targets, identifying theranostic lead compounds, and tailoring theranostic drugs. To overcome these bottlenecks, we present the Theranostic Genome , the part of the human genome whose expression can be utilized to combine therapeutic and diagnostic applications. Using a deep learning-based hybrid human-AI pipeline that cross-references PubMed, the Gene Expression Omnibus, DisGeNET, The Cancer Genome Atlas and the NIH Molecular Imaging and Contrast Agent Database, we bridge individual genes in human cancers with respective theranostic compounds. Cross-referencing the Theranostic Genome with RNAseq data from over 17’000 human tissues identifies theranostic targets and lead compounds for various human cancers, and allows tailoring targeted theranostics to relevant cancer subpopulations. We expect the Theranostic Genome to facilitate the development of new targeted theranostics to better diagnose, understand, treat, and monitor a variety of human cancers.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Towards designing improved cancer immunotherapy targets with a peptide-MHC-I presentation model, HLApollo",
    "doi": "10.1038/s41467-024-54887-7",
    "url": "https://www.nature.com/articles/s41467-024-54887-7",
    "authors": [
      "Thrift, William John",
      "Lounsbury, Nicolas W.",
      "Broadwell, Quade",
      "Heidersbach, Amy",
      "Freund, Emily",
      "Abdolazimi, Yassan",
      "Phung, Qui T.",
      "Chen, Jieming",
      "Capietto, Aude-Hélène",
      "Tong, Ann-Jay",
      "Rose, Christopher M.",
      "Blanchette, Craig",
      "Lill, Jennie R.",
      "Haley, Benjamin",
      "Delamarre, Lélia",
      "Bourgon, Richard",
      "Liu, Kai",
      "Jhunjhunwala, Suchit"
    ],
    "publicationDate": "2024-12-30",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Computational methods are used to predict which peptides or antigens are able to bind to MHC in order to activate T cell receptors in neoantigen-directed immunotherapies. Here the authors present an accurate transformer-based method to consider not only the peptide and MHC but also the source antigenic protein to predict peptides which bind to MHC molecules. Based on the success of cancer immunotherapy, personalized cancer vaccines have emerged as a leading oncology treatment. Antigen presentation on MHC class I (MHC-I) is crucial for the adaptive immune response to cancer cells, necessitating highly predictive computational methods to model this phenomenon. Here, we introduce HLApollo, a transformer-based model for peptide-MHC-I (pMHC-I) presentation prediction, leveraging the language of peptides, MHC, and source proteins. HLApollo provides end-to-end treatment of MHC-I sequences and deconvolution of multi-allelic data, using a negative-set switching strategy to mitigate misassigned negatives in unlabelled ligandome data. HLApollo shows a 12.65% increase in average precision (AP) on ligandome data and a 4.1% AP increase on immunogenicity test data compared to next-best models. Incorporating protein features from protein language models yields further gains and reduces the need for gene expression measurements. Guided by clinical use, we demonstrate pan-allelic generalization which effectively captures rare alleles in underrepresented ancestries.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "EpiGePT: a pretrained transformer-based language model for context-specific human epigenomics",
    "doi": "10.1186/s13059-024-03449-7",
    "url": "https://www.biomedcentral.com/openurl?doi=10.1186/s13059-024-03449-7",
    "authors": [
      "Gao, Zijing",
      "Liu, Qiao",
      "Zeng, Wanwen",
      "Jiang, Rui",
      "Wong, Wing Hung"
    ],
    "publicationDate": "2024-12-18",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": "The inherent similarities between natural language and biological sequences have inspired the use of large language models in genomics, but current models struggle to incorporate chromatin interactions or predict in unseen cellular contexts. To address this, we propose EpiGePT, a transformer-based model designed for predicting context-specific human epigenomic signals. By incorporating transcription factor activities and 3D genome interactions, EpiGePT outperforms existing methods in epigenomic signal prediction tasks, especially in cell-type-specific long-range interaction predictions and genetic variant impacts, advancing our understanding of gene regulation. A free online prediction service is available at http://health.tsinghua.edu.cn/epigept .",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "RNA language models predict mutations that improve RNA function",
    "doi": "10.1038/s41467-024-54812-y",
    "url": "https://www.nature.com/articles/s41467-024-54812-y",
    "authors": [
      "Shulgina, Yekaterina",
      "Trinidad, Marena I.",
      "Langeberg, Conner J.",
      "Nisonoff, Hunter",
      "Chithrananda, Seyone",
      "Skopintsev, Petr",
      "Nissley, Amos J.",
      "Patel, Jaymin",
      "Boger, Ron S.",
      "Shi, Honglue",
      "Yoon, Peter H.",
      "Doherty, Erin E.",
      "Pande, Tara",
      "Iyer, Aditya M.",
      "Doudna, Jennifer A.",
      "Cate, Jamie H. D."
    ],
    "publicationDate": "2024-12-05",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Generating RNA sequences with improved function remains challenging. Here, authors present an RNA database for RNA structural and functional analysis. They use this database and the RNA generative models to identify RNA mutations that increase the thermostability of a bacterial ribosome. Structured RNA lies at the heart of many central biological processes, from gene expression to catalysis. RNA structure prediction is not yet possible due to a lack of high-quality reference data associated with organismal phenotypes that could inform RNA function. We present GARNET (Gtdb Acquired RNa with Environmental Temperatures), a new database for RNA structural and functional analysis anchored to the Genome Taxonomy Database (GTDB). GARNET links RNA sequences to experimental and predicted optimal growth temperatures of GTDB reference organisms. Using GARNET, we develop sequence- and structure-aware RNA generative models, with overlapping triplet tokenization providing optimal encoding for a GPT-like model. Leveraging hyperthermophilic RNAs in GARNET and these RNA generative models, we identify mutations in ribosomal RNA that confer increased thermostability to the Escherichia coli ribosome. The GTDB-derived data and deep learning models presented here provide a foundation for understanding the connections between RNA sequence, structure, and function.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "Deep learning training dynamics analysis for single-cell data",
    "doi": "10.1038/s43588-024-00728-y",
    "url": "https://www.nature.com/articles/s43588-024-00728-y",
    "authors": [],
    "publicationDate": "2024-12-01",
    "publicationName": "Nature Computational Science",
    "contentType": "Article",
    "abstract": "Inspired by recent approaches for natural language processing and computer vision, we developed Annotatability, a framework that analyzes deep neural network training dynamics to interpret pre-annotated single-cell and spatial omics data. Annotatability identified erroneous annotations and ambiguous cell states, inferred trajectories from binary labels, and revealed underlying biological signals.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Chromatin remodelling in damaged intestinal crypts orchestrates redundant TGFβ and Hippo signalling to drive regeneration",
    "doi": "10.1038/s41556-024-01550-4",
    "url": "https://www.nature.com/articles/s41556-024-01550-4",
    "authors": [
      "Fink, Mardi",
      "Njah, Kizito",
      "Patel, Shyam J.",
      "Cook, David P.",
      "Man, Vanessa",
      "Ruso, Francesco",
      "Rajan, Arsheen",
      "Narimatsu, Masahiro",
      "Obersterescu, Andreea",
      "Pye, Melanie J.",
      "Trcka, Daniel",
      "Chan, Kin",
      "Ayyaz, Arshad",
      "Wrana, Jeffrey L."
    ],
    "publicationDate": "2024-12-01",
    "publicationName": "Nature Cell Biology",
    "contentType": "Article",
    "abstract": "Cell state dynamics underlying successful tissue regeneration are undercharacterized. In the intestine, damage prompts epithelial reprogramming into revival stem cells (revSCs) that reconstitute Lgr5^+ intestinal stem cells (ISCs). Here single-nuclear multi-omics of mouse crypts regenerating from irradiation shows revSC chromatin accessibility overlaps with ISCs and differentiated lineages. While revSC genes themselves are accessible throughout homeostatic epithelia, damage-induced remodelling of chromatin in the crypt converges on Hippo and the transforming growth factor-beta (TGFβ) signalling pathway, which we show is transiently activated and directly induces functional revSCs. Combinatorial gene expression analysis further suggests multiple sources of revSCs, and we demonstrate TGFβ can reprogramme enterocytes, goblet and paneth cells into revSCs and show individual revSCs form organoids. Despite this, loss of TGFβ signalling yields mild regenerative defects, whereas interference in both Hippo and TGFβ leads to profound defects and death. Intestinal regeneration is thus poised for activation by a compensatory system of crypt-localized, transient morphogen cues that support epithelial reprogramming and robust intestinal repair. Using deep single-nucleus multi-omics profiling, Fink et al. report transition states between crypt epithelial cells and a revival stem cell lineage. They find that the TGFβ and Hippo signalling pathways cooperatively drive intestinal regeneration.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Transcriptome Analysis Reveals Dynamic Microglial-Induced A1 Astrocyte Reactivity via C3/C3aR/NF-κB Signaling After Ischemic Stroke",
    "doi": "10.1007/s12035-024-04210-8",
    "url": "http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12035-024-04210-8",
    "authors": [
      "Wang, Song",
      "Pan, Yuhualei",
      "Zhang, Chengjie",
      "Zhao, Yushang",
      "Wang, Huan",
      "Ma, Huixuan",
      "Sun, Jinmei",
      "Zhang, Song",
      "Yao, Jingyi",
      "Xie, Dan",
      "Zhang, Yongbo"
    ],
    "publicationDate": "2024-12-01",
    "publicationName": "Molecular Neurobiology",
    "contentType": "Article",
    "abstract": "Microglia and astrocytes are key players in neuroinflammation and ischemic stroke. A1 astrocytes are a subtype of astrocytes that are extremely neurotoxic and quickly kill neurons. Although the detrimental A1 astrocytes are present in many neurodegenerative diseases and are considered to accelerate neurodegeneration, their role in the pathophysiology of ischemic stroke is poorly understood. Here, we combined RNA-seq, molecular and immunological techniques, and behavioral tests to investigate the role of A1 astrocytes in the pathophysiology of ischemic stroke. We found that astrocyte phenotypes change from a beneficial A2 type in the acute phase to a detrimental A1 type in the chronic phase following ischemic stroke. The activated microglial IL1α, TNF, and C1q prompt commitment of A1 astrocytes. Inhibition of A1 astrocytes induction attenuates reactive gliosis and ameliorates morphological and functional defects following ischemic stroke. The crosstalk between astrocytic C3 and microglial C3aR contributes to the formation of A1 astrocytes and morphological and functional defects. In addition, NF-κB is activated following ischemic stroke and governs the formation of A1 astrocytes via direct targeting of inflammatory cytokines and chemokines. Taken together, we discovered that A2 astrocytes and A1 astrocytes are enriched in the acute and chronic phases of ischemic stroke respectively, and that the C3/C3aR/NF-κB signaling leads to A1 astrocytes induction. Therefore, the C3/C3aR/NF-κB signaling is a novel therapeutic target for ischemic stroke treatment.",
    "openaccess": "false"
  },
  {
    "source": "springernature",
    "title": "Enhancing advanced cervical cell categorization with cluster-based intelligent systems by a novel integrated CNN approach with skip mechanisms and GAN-based augmentation",
    "doi": "10.1038/s41598-024-80260-1",
    "url": "https://www.nature.com/articles/s41598-024-80260-1",
    "authors": [
      "Shandilya, Gunjan",
      "Gupta, Sheifali",
      "Almogren, Ahmad",
      "Bharany, Salil",
      "Altameem, Ayman",
      "Rehman, Ateeq Ur",
      "Hussen, Seada"
    ],
    "publicationDate": "2024-11-23",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": "Cervical cancer is one of the biggest challenges in global health, thus it forms a critical need for early detection technologies that could improve patient prognosis and inform treatment decisions. This development in the form of an early detection mechanism increases the chances of successful treatment and survival, as early diagnosis promptly offers interventions that can dramatically reduce the rate of deaths attributed to this disease. Here, a customized Convolutional Neural Network (CNN) model is proposed for cervical cancerous cell detection. It includes three convolutional layers with increasing filter sizes and max-pooling layers, followed by dropout and dense layers for improved feature extraction and robust learning. By using ResNet models as inspiration, the model further innovates by incorporating skip connections into the CNN design. By enabling direct feature transmission from earlier to later layers, skip links enhance gradient flow and help preserve important spatial information. By boosting feature propagation, this integration increases the model’s ability to recognize minute patterns in cervical cell images, hence increasing classification accuracy. In our methodology, the SIPaKMeD dataset has been employed which contains 4049 cervical cell images that are arranged into five different categories. To address class imbalance, Generative Adversarial Networks (GANs) have been applied for data augmentation; that is, synthetic images have been created, that improve the diversity of the dataset and further enhance the robustness of the same. The present model is astonishingly accurate in classifying five cervical cell types: koilocytes, superficial-intermediate, parabasal, dyskeratotic, and metaplastic, thus significantly enhancing early detection and diagnosis of cervical cancer. The model gives an excellent performance because it has a validation accuracy of 99.11% and a training accuracy of 99.82%. It is a reliable model in the diagnosis of cervical cancerous cells because it ensures advancement in the computer-assisted cervical cancer detection system.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "title": "multiDGD: A versatile deep generative model for multi-omics data",
    "doi": "10.1038/s41467-024-53340-z",
    "url": "https://www.nature.com/articles/s41467-024-53340-z",
    "authors": [
      "Schuster, Viktoria",
      "Dann, Emma",
      "Krogh, Anders",
      "Teichmann, Sarah A."
    ],
    "publicationDate": "2024-11-20",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": "Understanding single-cell multi-omics data requires powerful solutions. Here, authors present a data-efficient machine learning approach for paired data. It enables integration from unseen covariates and can link distal regulatory elements to promoters, presenting a computational version of HiC. Recent technological advancements in single-cell genomics have enabled joint profiling of gene expression and alternative modalities at unprecedented scale. Consequently, the complexity of multi-omics data sets is increasing massively. Existing models for multi-modal data are typically limited in functionality or scalability, making data integration and downstream analysis cumbersome. We present multiDGD, a scalable deep generative model providing a probabilistic framework to learn shared representations of transcriptome and chromatin accessibility. It shows outstanding performance on data reconstruction without feature selection. We demonstrate on several data sets from human and mouse that multiDGD learns well-clustered joint representations. We further find that probabilistic modeling of sample covariates enables post-hoc data integration without the need for fine-tuning. Additionally, we show that multiDGD can detect statistical associations between genes and regulatory regions conditioned on the learned representations. multiDGD is available as an scverse-compatible package on GitHub.",
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "scPair: Boosting single cell multimodal analysis by leveraging implicit feature selection and single cell atlases",
    "doi": "10.1038/s41467-024-53971-2",
    "url": "",
    "authors": [
      "Hu, Hongru",
      "Quon, Gerald"
    ],
    "publicationDate": "2024-11-15",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Multimodal single-cell assays profile multiple sets of features in the same cells and are widely used for identifying and mapping cell states between chromatin and mRNA and linking regulatory elements to target genes. However, the high dimensionality of input features and shallow sequencing depth compared to unimodal assays pose challenges in data analysis. Here we present scPair, a multimodal single-cell data framework that overcomes these challenges by employing an implicit feature selection approach. scPair uses dual encoder-decoder structures trained on paired data to align cell states across modalities and predict features from one modality to another. We demonstrate that scPair outperforms existing methods in accuracy and execution time, and facilitates downstream tasks such as trajectory inference. We further show scPair can augment smaller multimodal datasets with larger unimodal atlases to increase statistical power to identify groups of transcription factors active during different stages of neural differentiation.",
        "Multimodal single-cell analysis faces challenges due to high feature dimensionality and shallow sequencing depth. Here, authors present scPair for aligning cell states across modalities with implicit feature selection and enhancing data analysis tasks such as identifying key transcription factors in neural differentiation."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Multi-functional scar tissue discrimination platform construction and exploration of molecular mechanism for scar formation",
    "doi": "10.1007/s10489-024-05625-5",
    "url": "",
    "authors": [
      "Hu, Xiaoqian",
      "Yu, Yaling",
      "Kong, Wei",
      "Wang, Shuaiqun",
      "Wen, Gen"
    ],
    "publicationDate": "2024-11-01",
    "publicationName": "Applied Intelligence",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Scars that form after skin injury can cause structural and functional skin damage. Currently, scar tissue determination relies mainly on doctors’ subjective observations and judgments and lacks objectivity. However, current deep learning models can only achieve specific discrimination using unimodal data, which limits the comprehensive understanding of scar tissue and may reduce accuracy and stability. To solve these problems, in this study, a skin scar recognition platform based on advanced deep learning and a weighted aggregation network fusion method is proposed. It is implemented using a residual network-based CNN model and a logistic regression model with L1 regularization and is suitable for both unimodal and multimodal data. The experimental results showed that the proposed platform achieved a satisfactory accuracy of 98.26% for image discrimination. In the gene discrimination model test performed on a test dataset containing 17 gene expression samples, all samples were accurately discriminated. In addition, the proposed multimodal discrimination model achieved a discrimination accuracy of 98.23%. These results validate the effectiveness of deep feature extraction and multimodal feature fusion techniques for image discrimination tasks. On this basis, to deeply explore the pathogenesis of scar formation, a method with the ability to integrate regularization, sparsity, and orthogonality constraints, multiconstraint joint non-negative matrix factorization (MCJNMF), was used to explore the genetic correlation between collagen micrographic image features and gene expression data. In this study, we confirmed the association between the calcium signaling pathway, MAPK signaling pathway, and collagen fiber repair, and successfully identified 11 potential therapeutic targets, including TRIM59 and TBC1D9, which provide important clues for future scar treatment and prevention strategies."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Modal-nexus auto-encoder for multi-modality cellular data integration and imputation",
    "doi": "10.1038/s41467-024-53355-6",
    "url": "",
    "authors": [
      "Tang, Zhenchao",
      "Chen, Guanxing",
      "Chen, Shouzhi",
      "Yao, Jianhua",
      "You, Linlin",
      "Chen, Calvin Yu-Chian"
    ],
    "publicationDate": "2024-10-18",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "p": "Heterogeneous feature spaces and technical noise hinder the cellular data integration and imputation. The high cost of obtaining matched data across modalities further restricts analysis. Thus, there’s a critical need for deep learning approaches to effectively integrate and impute unpaired multi-modality single-cell data, enabling deeper insights into cellular behaviors. To address these issues, we introduce the Mo dal- N exus A uto- E ncoder (Monae). Leveraging regulatory relationships between modalities and employing contrastive learning within modality-specific auto-encoders, Monae enhances cell representations in the unified space. The integration capability of Monae furnishes it with modality-complementary cellular representations, enabling the generation of precise intra-modal and cross-modal imputation counts for extensive and complex downstream tasks. In addition, we develop Monae-E (Monae-Extension), a variant of Monae that can converge rapidly and support biological discoveries. Evaluations on various datasets have validated Monae and Monae-E’s accuracy and robustness in multi-modality cellular data integration and imputation.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Imputing spatial transcriptomics through gene network constructed from protein language model",
    "doi": "10.1038/s42003-024-06964-2",
    "url": "",
    "authors": [
      "Zeng, Yuansong",
      "Song, Yujie",
      "Zhang, Chengyang",
      "Li, Haoxuan",
      "Zhao, Yongkang",
      "Yu, Weijiang",
      "Zhang, Shiqi",
      "Zhang, Hongyu",
      "Dai, Zhiming",
      "Yang, Yuedong"
    ],
    "publicationDate": "2024-10-05",
    "publicationName": "Communications Biology",
    "contentType": "Article",
    "abstract": {
      "p": "Image-based spatial transcriptomic sequencing technologies have enabled the measurement of gene expression at single-cell resolution, but with a limited number of genes. Current computational approaches attempt to overcome these limitations by imputing missing genes, but face challenges regarding prediction accuracy and identification of cell populations due to the neglect of gene-gene relationships. In this context, we present stImpute, a method to impute spatial transcriptomics according to reference scRNA-seq data based on the gene network constructed from the protein language model ESM-2. Specifically, stImpute employs an autoencoder to create gene expression embeddings for both spatial transcriptomics and scRNA-seq data, which are used to identify the nearest neighboring cells between scRNA-seq and spatial transcriptomics datasets. According to the neighbored cells, the gene expressions of spatial transcriptomics cells are imputed through a graph neural network, where nodes are genes, and edges are based on cosine similarity between the ESM-2 embeddings of the gene-encoding proteins. The gene prediction uncertainty is further measured through a deep learning model. stImpute was shown to consistently outperform state-of-the-art methods across multiple datasets concerning imputation and clustering. stImpute also demonstrates robustness in producing consistent results that are insensitive to model parameters.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Integration of multi-modal datasets to estimate human aging",
    "doi": "10.1007/s10994-024-06588-x",
    "url": "",
    "authors": [
      "Ribeiro, Rogério",
      "Moraes, Athos",
      "Moreno, Marta",
      "Ferreira, Pedro G."
    ],
    "publicationDate": "2024-10-01",
    "publicationName": "Machine Learning",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Aging involves complex biological processes leading to the decline of living organisms. As population lifespan increases worldwide, the importance of identifying factors underlying healthy aging has become critical. Integration of multi-modal datasets is a powerful approach for the analysis of complex biological systems, with the potential to uncover novel aging biomarkers. In this study, we leveraged publicly available epigenomic, transcriptomic and telomere length data along with histological images from the Genotype-Tissue Expression project to build tissue-specific regression models for age prediction. Using data from two tissues, lung and ovary, we aimed to compare model performance across data modalities, as well as to assess the improvement resulting from integrating multiple data types. Our results demostrate that methylation outperformed the other data modalities, with a mean absolute error of 3.36 and 4.36 in the test sets for lung and ovary, respectively. These models achieved lower error rates when compared with established state-of-the-art tissue-agnostic methylation models, emphasizing the importance of a tissue-specific approach. Additionally, this work has shown how the application of Hierarchical Image Pyramid Transformers for feature extraction significantly enhances age modeling using histological images. Finally, we evaluated the benefits of integrating multiple data modalities into a single model. Combining methylation data with other data modalities only marginally improved performance likely due to the limited number of available samples. Combining gene expression with histological features yielded more accurate age predictions compared with the individual performance of these data types. Given these results, this study shows how machine learning applications can be extended to/in multi-modal aging research. Code used is available at https://github.com/zroger49/multi_modal_age_prediction ."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Radiogenomics as an Integrated Approach to Glioblastoma Precision Medicine",
    "doi": "10.1007/s11912-024-01580-z",
    "url": "",
    "authors": [
      "Sanchez, Isabella",
      "Rahman, Ruman"
    ],
    "publicationDate": "2024-10-01",
    "publicationName": "Current Oncology Reports",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Purpose of Review",
        "Isocitrate dehydrogenase wild-type glioblastoma is the most aggressive primary brain tumour in adults. Its infiltrative nature and heterogeneity confer a dismal prognosis, despite multimodal treatment. Precision medicine is increasingly advocated to improve survival rates in glioblastoma management; however, conventional neuroimaging techniques are insufficient in providing the detail required for accurate diagnosis of this complex condition.",
        "Recent Findings",
        "Advanced magnetic resonance imaging allows more comprehensive understanding of the tumour microenvironment. Combining diffusion and perfusion magnetic resonance imaging to create a multiparametric scan enhances diagnostic power and can overcome the unreliability of tumour characterisation by standard imaging. Recent progress in deep learning algorithms establishes their remarkable ability in image-recognition tasks. Integrating these with multiparametric scans could transform the diagnosis and monitoring of patients by ensuring that the entire tumour is captured. As a corollary, radiomics has emerged as a powerful approach to offer insights into diagnosis, prognosis, treatment, and tumour response through extraction of information from radiological scans, and transformation of these tumour characteristics into quantitative data. Radiogenomics, which links imaging features with genomic profiles, has exhibited its ability in characterising glioblastoma, and determining therapeutic response, with the potential to revolutionise management of glioblastoma.",
        "Summary",
        "The integration of deep learning algorithms into radiogenomic models has established an automated, highly reproducible means to predict glioblastoma molecular signatures, further aiding prognosis and targeted therapy. However, challenges including lack of large cohorts, absence of standardised guidelines and the ‘black-box’ nature of deep learning algorithms, must first be overcome before this workflow can be applied in clinical practice."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Mosaic integration and knowledge transfer of single-cell multimodal data with MIDAS",
    "doi": "10.1038/s41587-023-02040-y",
    "url": "",
    "authors": [
      "He, Zhen",
      "Hu, Shuofeng",
      "Chen, Yaowen",
      "An, Sijing",
      "Zhou, Jiahao",
      "Liu, Runyan",
      "Shi, Junfeng",
      "Wang, Jing",
      "Dong, Guohua",
      "Shi, Jinhui",
      "Zhao, Jiaxin",
      "Ou-Yang, Le",
      "Zhu, Yuan",
      "Bo, Xiaochen",
      "Ying, Xiaomin"
    ],
    "publicationDate": "2024-10-01",
    "publicationName": "Nature Biotechnology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Integrating single-cell datasets produced by multiple omics technologies is essential for defining cellular heterogeneity. Mosaic integration, in which different datasets share only some of the measured modalities, poses major challenges, particularly regarding modality alignment and batch effect removal. Here, we present a deep probabilistic framework for the mosaic integration and knowledge transfer (MIDAS) of single-cell multimodal data. MIDAS simultaneously achieves dimensionality reduction, imputation and batch correction of mosaic data by using self-supervised modality alignment and information-theoretic latent disentanglement. We demonstrate its superiority to 19 other methods and reliability by evaluating its performance in trimodal and mosaic integration tasks. We also constructed a single-cell trimodal atlas of human peripheral blood mononuclear cells and tailored transfer learning and reciprocal reference mapping schemes to enable flexible and accurate knowledge transfer from the atlas to new data. Applications in mosaic integration, pseudotime analysis and cross-tissue knowledge transfer on bone marrow mosaic datasets demonstrate the versatility and superiority of MIDAS. MIDAS is available at https://github.com/labomics/midas .",
        "Single-cell, multiomic datasets are integrated using dimensionality reduction, imputation and batch correction."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Detecting anomalous anatomic regions in spatial transcriptomics with STANDS",
    "doi": "10.1038/s41467-024-52445-9",
    "url": "",
    "authors": [
      "Xu, Kaichen",
      "Lu, Yan",
      "Hou, Suyang",
      "Liu, Kainan",
      "Du, Yihang",
      "Huang, Mengqian",
      "Feng, Hao",
      "Wu, Hao",
      "Sun, Xiaobo"
    ],
    "publicationDate": "2024-09-19",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Detection and Dissection of Anomalous Tissue Domains (DDATD) from multi-sample spatial transcriptomics (ST) data provides unprecedented opportunities to characterize anomalous tissue domains (ATDs), revealing both population-level and individual-specific pathogenic factors for understanding pathogenic heterogeneities behind diseases. However, no current methods can perform de novo DDATD from ST data, especially in the multi-sample context. Here, we introduce STANDS, an innovative framework based on Generative Adversarial Networks which integrates three core tasks in multi-sample DDATD: detecting, aligning, and subtyping ATDs. STANDS incorporates multimodal-learning, transfer-learning, and style-transfer techniques to effectively address major challenges in multi-sample DDATD, including complications caused by unalignable ATDs, under-utilization of multimodal information, and scarcity of normal ST datasets necessary for comparative analysis. Extensive benchmarks from diverse datasets demonstrate STAND’s superiority in identifying both common and individual-specific ATDs and further dissecting them into biologically distinct subdomains. STANDS also provides clues to developing ATDs visually indistinguishable from surrounding normal tissues.",
        "The authors introduce STANDS, a GAN-based framework that integrates three core tasks for the multi-sample detection and dissection of anomalous tissue domains from spatial transcriptomics data, revealing pathogenic heterogeneity behind diseases."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Accurately predicting enzyme functions through geometric graph learning on ESMFold-predicted structures",
    "doi": "10.1038/s41467-024-52533-w",
    "url": "",
    "authors": [
      "Song, Yidong",
      "Yuan, Qianmu",
      "Chen, Sheng",
      "Zeng, Yuansong",
      "Zhao, Huiying",
      "Yang, Yuedong"
    ],
    "publicationDate": "2024-09-18",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "p": "Enzymes are crucial in numerous biological processes, with the Enzyme Commission (EC) number being a commonly used method for defining enzyme function. However, current EC number prediction technologies have not fully recognized the importance of enzyme active sites and structural characteristics. Here, we propose GraphEC, a geometric graph learning-based EC number predictor using the ESMFold-predicted structures and a pre-trained protein language model. Specifically, we first construct a model to predict the enzyme active sites, which is utilized to predict the EC number. The prediction is further improved through a label diffusion algorithm by incorporating homology information. In parallel, the optimum pH of enzymes is predicted to reflect the enzyme-catalyzed reactions. Experiments demonstrate the superior performance of our model in predicting active sites, EC numbers, and optimum pH compared to other state-of-the-art methods. Additional analysis reveals that GraphEC is capable of extracting functional information from protein structures, emphasizing the effectiveness of geometric graph learning. This technology can be used to identify unannotated enzyme functions, as well as to predict their active sites and optimum pH, with the potential to advance research in synthetic biology, genomics, and other fields.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Unraveling the key role of chromatin structure in cancer development through epigenetic landscape characterization of oral cancer",
    "doi": "10.1186/s12943-024-02100-0",
    "url": "",
    "authors": [
      "Xue, Yue",
      "Liu, Lu",
      "Zhang, Ye",
      "He, Yueying",
      "Wang, Jingyao",
      "Ma, Zicheng",
      "Li, Tie-jun",
      "Zhang, Jianyun",
      "Huang, Yanyi",
      "Gao, Yi Qin"
    ],
    "publicationDate": "2024-09-06",
    "publicationName": "Molecular Cancer",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Epigenetic alterations, such as those in chromatin structure and DNA methylation, have been extensively studied in a number of tumor types. But oral cancer, particularly oral adenocarcinoma, has received far less attention. Here, we combined laser-capture microdissection and muti-omics mini-bulk sequencing to systematically characterize the epigenetic landscape of oral cancer, including chromatin architecture, DNA methylation, H3K27me3 modification, and gene expression. In carcinogenesis, tumor cells exhibit reorganized chromatin spatial structures, including compromised compartment structures and altered gene-gene interaction networks. Notably, some structural alterations are observed in phenotypically non-malignant paracancerous but not in normal cells. We developed transformer models to identify the cancer propensity of individual genome loci, thereby determining the carcinogenic status of each sample. Insights into cancer epigenetic landscapes provide evidence that chromatin reorganization is an important hallmark of oral cancer progression, which is also linked with genomic alterations and DNA methylation reprogramming. In particular, regions of frequent copy number alternations in cancer cells are associated with strong spatial insulation in both cancer and normal samples. Aberrant methylation reprogramming in oral squamous cell carcinomas is closely related to chromatin structure and H3K27me3 signals, which are further influenced by intrinsic sequence properties. Our findings indicate that structural changes are both significant and conserved in two distinct types of oral cancer, closely linked to transcriptomic alterations and cancer development. Notably, the structural changes remain markedly evident in oral adenocarcinoma despite the considerably lower incidence of genomic copy number alterations and lesser extent of methylation alterations compared to squamous cell carcinoma. We expect that the comprehensive analysis of epigenetic reprogramming of different types and subtypes of primary oral tumors can provide additional guidance to the design of novel detection and therapy for oral cancer."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Deep learning of multimodal networks with topological regularization for drug repositioning",
    "doi": "10.1186/s13321-024-00897-y",
    "url": "",
    "authors": [
      "Ohnuki, Yuto",
      "Akiyama, Manato",
      "Sakakibara, Yasubumi"
    ],
    "publicationDate": "2024-08-23",
    "publicationName": "Journal of Cheminformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Motivation",
        "Computational techniques for drug-disease prediction are essential in enhancing drug discovery and repositioning. While many methods utilize multimodal networks from various biological databases, few integrate comprehensive multi-omics data, including transcriptomes, proteomes, and metabolomes. We introduce STRGNN, a novel graph deep learning approach that predicts drug-disease relationships using extensive multimodal networks comprising proteins, RNAs, metabolites, and compounds. We have constructed a detailed dataset incorporating multi-omics data and developed a learning algorithm with topological regularization. This algorithm selectively leverages informative modalities while filtering out redundancies.",
        "Results",
        "STRGNN demonstrates superior accuracy compared to existing methods and has identified several novel drug effects, corroborating existing literature. STRGNN emerges as a powerful tool for drug prediction and discovery. The source code for STRGNN, along with the dataset for performance evaluation, is available at https://github.com/yuto-ohnuki/STRGNN.git ."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Enhancing recognition and interpretation of functional phenotypic sequences through fine-tuning pre-trained genomic models",
    "doi": "10.1186/s12967-024-05567-z",
    "url": "",
    "authors": [
      "Du, Duo",
      "Zhong, Fan",
      "Liu, Lei"
    ],
    "publicationDate": "2024-08-12",
    "publicationName": "Journal of Translational Medicine",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Decoding human genomic sequences requires comprehensive analysis of DNA sequence functionality. Through computational and experimental approaches, researchers have studied the genotype-phenotype relationship and generate important datasets that help unravel complicated genetic blueprints. Thus, the recently developed artificial intelligence methods can be used to interpret the functions of those DNA sequences.",
        "Methods",
        "This study explores the use of deep learning, particularly pre-trained genomic models like DNA_bert_6 and human_gpt2-v1, in interpreting and representing human genome sequences. Initially, we meticulously constructed multiple datasets linking genotypes and phenotypes to fine-tune those models for precise DNA sequence classification. Additionally, we evaluate the influence of sequence length on classification results and analyze the impact of feature extraction in the hidden layers of our model using the HERV dataset. To enhance our understanding of phenotype-specific patterns recognized by the model, we perform enrichment, pathogenicity and conservation analyzes of specific motifs in the human endogenous retrovirus (HERV) sequence with high average local representation weight ( ALRW ) scores.",
        "Results",
        "We have constructed multiple genotype-phenotype datasets displaying commendable classification performance in comparison with random genomic sequences, particularly in the HERV dataset, which achieved binary and multi-classification accuracies and F1 values exceeding 0.935 and 0.888, respectively. Notably, the fine-tuning of the HERV dataset not only improved our ability to identify and distinguish diverse information types within DNA sequences but also successfully identified specific motifs associated with neurological disorders and cancers in regions with high ALRW scores. Subsequent analysis of these motifs shed light on the adaptive responses of species to environmental pressures and their co-evolution with pathogens.",
        "Conclusions",
        "These findings highlight the potential of pre-trained genomic models in learning DNA sequence representations, particularly when utilizing the HERV dataset, and provide valuable insights for future research endeavors. This study represents an innovative strategy that combines pre-trained genomic model representations with classical methods for analyzing the functionality of genome sequences, thereby promoting cross-fertilization between genomics and artificial intelligence."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Precious2GPT: the combination of multiomics pretrained transformer and conditional diffusion for artificial multi-omics multi-species multi-tissue sample generation",
    "doi": "10.1038/s41514-024-00163-3",
    "url": "",
    "authors": [
      "Sidorenko, Denis",
      "Pushkov, Stefan",
      "Sakip, Akhmed",
      "Leung, Geoffrey Ho Duen",
      "Lok, Sarah Wing Yan",
      "Urban, Anatoly",
      "Zagirova, Diana",
      "Veviorskiy, Alexander",
      "Tihonova, Nina",
      "Kalashnikov, Aleksandr",
      "Kozlova, Ekaterina",
      "Naumov, Vladimir",
      "Pun, Frank W.",
      "Aliper, Alex",
      "Ren, Feng",
      "Zhavoronkov, Alex"
    ],
    "publicationDate": "2024-08-08",
    "publicationName": "npj Aging",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Synthetic data generation in omics mimics real-world biological data, providing alternatives for training and evaluation of genomic analysis tools, controlling differential expression, and exploring data architecture. We previously developed Precious1GPT, a multimodal transformer trained on transcriptomic and methylation data, along with metadata, for predicting biological age and identifying dual-purpose therapeutic targets potentially implicated in aging and age-associated diseases. In this study, we introduce Precious2GPT, a multimodal architecture that integrates Conditional Diffusion (CDiffusion) and decoder-only Multi-omics Pretrained Transformer (MoPT) models trained on gene expression and DNA methylation data. Precious2GPT excels in synthetic data generation, outperforming Conditional Generative Adversarial Networks (CGANs), CDiffusion, and MoPT. We demonstrate that Precious2GPT is capable of generating representative synthetic data that captures tissue- and age-specific information from real transcriptomics and methylomics data. Notably, Precious2GPT surpasses other models in age prediction accuracy using the generated data, and it can generate data beyond 120 years of age. Furthermore, we showcase the potential of using this model in identifying gene signatures and potential therapeutic targets in a colorectal cancer case study."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "MOSBY enables multi-omic inference and spatial biomarker discovery from whole slide images",
    "doi": "10.1038/s41598-024-69198-6",
    "url": "",
    "authors": [
      "Şenbabaoğlu, Yasin",
      "Prabhakar, Vignesh",
      "Khormali, Aminollah",
      "Eastham, Jeff",
      "Liu, Evan",
      "Warner, Elisa",
      "Nabet, Barzin",
      "Srivastava, Minu",
      "Ballinger, Marcus",
      "Liu, Kai"
    ],
    "publicationDate": "2024-08-06",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "The utility of deep neural nets has been demonstrated for mapping hematoxylin-and-eosin (H&E) stained image features to expression of individual genes. However, these models have not been employed to discover clinically relevant spatial biomarkers. Here we develop MOSBY ( M ulti- Omic translation of whole slide images for S patial B iomarker discover Y ) that leverages contrastive self-supervised pretraining to extract improved H&E whole slide images features, learns a mapping between image and bulk omic profiles (RNA, DNA, and protein), and utilizes tile-level information to discover spatial biomarkers. We validate MOSBY gene and gene set predictions with spatial transcriptomic and serially-sectioned CD8 IHC image data. We demonstrate that MOSBY-inferred colocalization features have survival-predictive power orthogonal to gene expression, and enable concordance indices highly competitive with survival-trained multimodal networks. We identify and validate (1) an ER stress-associated colocalization feature as a chemotherapy-specific risk factor in lung adenocarcinoma, and (2) the colocalization of T effector cell vs cysteine signatures as a negative prognostic factor in multiple cancer indications. The discovery of clinically relevant biologically interpretable spatial biomarkers showcases the utility of the model in unraveling novel insights in cancer biology as well as informing clinical decision-making."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Tissue characterization at an enhanced resolution across spatial omics platforms with deep generative model",
    "doi": "10.1038/s41467-024-50837-5",
    "url": "",
    "authors": [
      "Li, Bohan",
      "Bao, Feng",
      "Hou, Yimin",
      "Li, Fengji",
      "Li, Hongjue",
      "Deng, Yue",
      "Dai, Qionghai"
    ],
    "publicationDate": "2024-08-02",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Recent advances in spatial omics have expanded the spectrum of profiled molecular categories beyond transcriptomics. However, many of these technologies are constrained by limited spatial resolution, hindering our ability to deeply characterize intricate tissue architectures. Existing computational methods primarily focus on the resolution enhancement of transcriptomics data, lacking the adaptability to address the emerging spatial omics technologies that profile various omics types. Here, we introduce soScope, a unified generative framework designed to enhance data quality and spatial resolution for molecular profiles obtained from diverse spatial technologies. soScope aggregates multimodal tissue information from omics, spatial relations and images, and jointly infers omics profiles at enhanced resolutions with omics-specific modeling through distribution priors. With comprehensive evaluations on diverse spatial omics platforms, including Visium, Xenium, spatial-CUT&Tag, and slide-DNA/RNA-seq, soScope improves performances in identifying biologically meaningful intestine and kidney architectures, revealing embryonic heart structure that cannot be resolved at the original resolution and correcting sample and technical biases arising from sequencing and sample processing. Furthermore, soScope extends to spatial multiomics technology spatial-CITE-seq and spatial ATAC-RNA-seq, leveraging cross-omics reference for simultaneous multiomics enhancement. soScope provides a versatile tool to improve the utilization of continually expanding spatial omics technologies and resources.",
        "Recent advances in spatial omics have expanded molecular categories beyond transcriptomics. Here, authors introduce soScope, a generative method that jointly models omics, spatial relations, and imaging, enhancing spatial resolution and data quality for multiomics data from diverse technologies."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Toward universal cell embeddings: integrating single-cell RNA-seq datasets across species with SATURN",
    "doi": "10.1038/s41592-024-02191-z",
    "url": "",
    "authors": [
      "Rosen, Yanay",
      "Brbić, Maria",
      "Roohani, Yusuf",
      "Swanson, Kyle",
      "Li, Ziang",
      "Leskovec, Jure"
    ],
    "publicationDate": "2024-08-01",
    "publicationName": "Nature Methods",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Analysis of single-cell datasets generated from diverse organisms offers unprecedented opportunities to unravel fundamental evolutionary processes of conservation and diversification of cell types. However, interspecies genomic differences limit the joint analysis of cross-species datasets to homologous genes. Here we present SATURN, a deep learning method for learning universal cell embeddings that encodes genes’ biological properties using protein language models. By coupling protein embeddings from language models with RNA expression, SATURN integrates datasets profiled from different species regardless of their genomic similarity. SATURN can detect functionally related genes coexpressed across species, redefining differential expression for cross-species analysis. Applying SATURN to three species whole-organism atlases and frog and zebrafish embryogenesis datasets, we show that SATURN can effectively transfer annotations across species, even when they are evolutionarily remote. We also demonstrate that SATURN can be used to find potentially divergent gene functions between glaucoma-associated genes in humans and four other species.",
        "SATURN performs cross-species integration and analysis using both single-cell gene expression and protein representations generated by protein language models."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "scCross: a deep generative model for unifying single-cell multi-omics with seamless integration, cross-modal generation, and in silico exploration",
    "doi": "10.1186/s13059-024-03338-z",
    "url": "",
    "authors": [
      "Yang, Xiuhui",
      "Mann, Koren K.",
      "Wu, Hao",
      "Ding, Jun"
    ],
    "publicationDate": "2024-07-29",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Single-cell multi-omics data reveal complex cellular states, providing significant insights into cellular dynamics and disease. Yet, integration of multi-omics data presents challenges. Some modalities have not reached the robustness or clarity of established transcriptomics. Coupled with data scarcity for less established modalities and integration intricacies, these challenges limit our ability to maximize single-cell omics benefits. We introduce scCross, a tool leveraging variational autoencoders, generative adversarial networks, and the mutual nearest neighbors (MNN) technique for modality alignment. By enabling single-cell cross-modal data generation, multi-omics data simulation, and in silico cellular perturbations, scCross enhances the utility of single-cell multi-omics studies."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "A foundational large language model for edible plant genomes",
    "doi": "10.1038/s42003-024-06465-2",
    "url": "",
    "authors": [
      "Mendoza-Revilla, Javier",
      "Trop, Evan",
      "Gonzalez, Liam",
      "Roller, Maša",
      "Dalla-Torre, Hugo",
      "Almeida, Bernardo P.",
      "Richard, Guillaume",
      "Caton, Jonathan",
      "Lopez Carranza, Nicolas",
      "Skwark, Marcin",
      "Laterre, Alex",
      "Beguir, Karim",
      "Pierrot, Thomas",
      "Lopez, Marie"
    ],
    "publicationDate": "2024-07-09",
    "publicationName": "Communications Biology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Significant progress has been made in the field of plant genomics, as demonstrated by the increased use of high-throughput methodologies that enable the characterization of multiple genome-wide molecular phenotypes. These findings have provided valuable insights into plant traits and their underlying genetic mechanisms, particularly in model plant species. Nonetheless, effectively leveraging them to make accurate predictions represents a critical step in crop genomic improvement. We present AgroNT, a foundational large language model trained on genomes from 48 plant species with a predominant focus on crop species. We show that AgroNT can obtain state-of-the-art predictions for regulatory annotations, promoter/terminator strength, tissue-specific gene expression, and prioritize functional variants. We conduct a large-scale in silico saturation mutagenesis analysis on cassava to evaluate the regulatory impact of over 10 million mutations and provide their predicted effects as a resource for variant characterization. Finally, we propose the use of the diverse datasets compiled here as the Plants Genomic Benchmark (PGB), providing a comprehensive benchmark for deep learning-based methods in plant genomic research. The pre-trained AgroNT model is publicly available on HuggingFace at https://huggingface.co/InstaDeepAI/agro-nucleotide-transformer-1b  for future research purposes.",
        "A DNA-based large language model, AgroNT, trained on multiple plant genomes, can accurately predict various molecular phenotypes within plant species, including important crops."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Mining the interpretable prognostic features from pathological image of intrahepatic cholangiocarcinoma using multi-modal deep learning",
    "doi": "10.1186/s12916-024-03482-0",
    "url": "",
    "authors": [
      "Ding, Guang-Yu",
      "Tan, Wei-Min",
      "Lin, You-Pei",
      "Ling, Yu",
      "Huang, Wen",
      "Zhang, Shu",
      "Shi, Jie-Yi",
      "Luo, Rong-Kui",
      "Ji, Yuan",
      "Wang, Xiao-Ying",
      "Zhou, Jian",
      "Fan, Jia",
      "Cai, Mu-Yan",
      "Yan, Bo",
      "Gao, Qiang"
    ],
    "publicationDate": "2024-07-08",
    "publicationName": "BMC Medicine",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "The advances in deep learning-based pathological image analysis have invoked tremendous insights into cancer prognostication. Still, lack of interpretability remains a significant barrier to clinical application.",
        "Methods",
        "We established an integrative prognostic neural network for intrahepatic cholangiocarcinoma (iCCA), towards a comprehensive evaluation of both architectural and fine-grained information from whole-slide images. Then, leveraging on multi-modal data, we conducted extensive interrogative approaches to the models, to extract and visualize the morphological features that most correlated with clinical outcome and underlying molecular alterations.",
        "Results",
        "The models were developed and optimized on 373 iCCA patients from our center and demonstrated consistent accuracy and robustness on both internal ( n  = 213) and external ( n  = 168) cohorts. The occlusion sensitivity map revealed that the distribution of tertiary lymphoid structures, the geometric traits of the invasive margin, the relative composition of tumor parenchyma and stroma, the extent of necrosis, the presence of the disseminated foci, and the tumor-adjacent micro-vessels were the determining architectural features that impacted on prognosis. Quantifiable morphological vector extracted by CellProfiler demonstrated that tumor nuclei from high-risk patients exhibited significant larger size, more distorted shape, with less prominent nuclear envelope and textural contrast. The multi-omics data ( n  = 187) further revealed key molecular alterations left morphological imprints that could be attended by the network, including glycolysis, hypoxia, apical junction, mTORC1 signaling, and immune infiltration.",
        "Conclusions",
        "We proposed an interpretable deep-learning framework to gain insights into the biological behavior of iCCA. Most of the significant morphological prognosticators perceived by the network are comprehensible to human minds.",
        "Graphical Abstract",
        ""
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Multi-modal generative modeling for joint analysis of single-cell T cell receptor and gene expression data",
    "doi": "10.1038/s41467-024-49806-9",
    "url": "",
    "authors": [
      "Drost, Felix",
      "An, Yang",
      "Bonafonte-Pardàs, Irene",
      "Dratva, Lisa M.",
      "Lindeboom, Rik G. H.",
      "Haniffa, Muzlifah",
      "Teichmann, Sarah A.",
      "Theis, Fabian",
      "Lotfollahi, Mohammad",
      "Schubert, Benjamin"
    ],
    "publicationDate": "2024-07-03",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Recent advances in single-cell immune profiling have enabled the simultaneous measurement of transcriptome and T cell receptor (TCR) sequences, offering great potential for studying immune responses at the cellular level. However, integrating these diverse modalities across datasets is challenging due to their unique data characteristics and technical variations. Here, to address this, we develop the multimodal generative model mvTCR to fuse modality-specific information across transcriptome and TCR into a shared representation. Our analysis demonstrates the added value of multimodal over unimodal approaches to capture antigen specificity. Notably, we use mvTCR to distinguish T cell subpopulations binding to SARS-CoV-2 antigens from bystander cells. Furthermore, when combined with reference mapping approaches, mvTCR can map newly generated datasets to extensive T cell references, facilitating knowledge transfer. In summary, we envision mvTCR to enable a scalable analysis of multimodal immune profiling data and advance our understanding of immune responses.",
        "Although single-cell RNA sequencing analysis now allows simultaneous examination of transcriptome and T cell receptor repertoire sequences, integrating these two modalities remains a challenge. Here, the authors develop mvTCR, a generative deep learning model that integrates transcriptome and T cell receptor data into a joint representation capturing cell functions and phenotypes."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "TMO-Net: an explainable pretrained multi-omics model for multi-task learning in oncology",
    "doi": "10.1186/s13059-024-03293-9",
    "url": "",
    "authors": [
      "Wang, Feng-ao",
      "Zhuang, Zhenfeng",
      "Gao, Feng",
      "He, Ruikun",
      "Zhang, Shaoting",
      "Wang, Liansheng",
      "Liu, Junwei",
      "Li, Yixue"
    ],
    "publicationDate": "2024-06-06",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Cancer is a complex disease composing systemic alterations in multiple scales. In this study, we develop the Tumor Multi-Omics pre-trained Network (TMO-Net) that integrates multi-omics pan-cancer datasets for model pre-training, facilitating cross-omics interactions and enabling joint representation learning and incomplete omics inference. This model enhances multi-omics sample representation and empowers various downstream oncology tasks with incomplete multi-omics datasets. By employing interpretable learning, we characterize the contributions of distinct omics features to clinical outcomes. The TMO-Net model serves as a versatile framework for cross-modal multi-omics learning in oncology, paving the way for tumor omics-specific foundation models."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Multimodal decoding of human liver regeneration",
    "doi": "10.1038/s41586-024-07376-2",
    "url": "",
    "authors": [
      "Matchett, K. P.",
      "Wilson-Kanamori, J. R.",
      "Portman, J. R.",
      "Kapourani, C. A.",
      "Fercoq, F.",
      "May, S.",
      "Zajdel, E.",
      "Beltran, M.",
      "Sutherland, E. F.",
      "Mackey, J. B. G.",
      "Brice, M.",
      "Wilson, G. C.",
      "Wallace, S. J.",
      "Kitto, L.",
      "Younger, N. T.",
      "Dobie, R.",
      "Mole, D. J.",
      "Oniscu, G. C.",
      "Wigmore, S. J.",
      "Ramachandran, P.",
      "Vallejos, C. A.",
      "Carragher, N. O.",
      "Saeidinejad, M. M.",
      "Quaglia, A.",
      "Jalan, R.",
      "Simpson, K. J.",
      "Kendall, T. J.",
      "Rule, J. A.",
      "Lee, W. M.",
      "Hoare, M.",
      "Weston, C. J.",
      "Marioni, J. C.",
      "Teichmann, S. A.",
      "Bird, T. G.",
      "Carlin, L. M.",
      "Henderson, N. C."
    ],
    "publicationDate": "2024-06-06",
    "publicationName": "Nature",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "The liver has a unique ability to regenerate^ 1 , 2 ; however, in the setting of acute liver failure (ALF), this regenerative capacity is often overwhelmed, leaving emergency liver transplantation as the only curative option^ 3 – 5 . Here, to advance understanding of human liver regeneration, we use paired single-nucleus RNA sequencing combined with spatial profiling of healthy and ALF explant human livers to generate a single-cell, pan-lineage atlas of human liver regeneration. We uncover a novel ANXA2^+ migratory hepatocyte subpopulation, which emerges during human liver regeneration, and a corollary subpopulation in a mouse model of acetaminophen (APAP)-induced liver regeneration. Interrogation of necrotic wound closure and hepatocyte proliferation across multiple timepoints following APAP-induced liver injury in mice demonstrates that wound closure precedes hepatocyte proliferation. Four-dimensional intravital imaging of APAP-induced mouse liver injury identifies motile hepatocytes at the edge of the necrotic area, enabling collective migration of the hepatocyte sheet to effect wound closure. Depletion of hepatocyte ANXA2 reduces hepatocyte growth factor-induced human and mouse hepatocyte migration in vitro, and abrogates necrotic wound closure following APAP-induced mouse liver injury. Together, our work dissects unanticipated aspects of liver regeneration, demonstrating an uncoupling of wound closure and hepatocyte proliferation and uncovering a novel migratory hepatocyte subpopulation that mediates wound closure following liver injury. Therapies designed to promote rapid reconstitution of normal hepatic microarchitecture and reparation of the gut–liver barrier may advance new areas of therapeutic discovery in regenerative medicine.",
        "Harnessing single-nucleus RNA sequencing and spatial profiling, this work dissects unanticipated aspects of human liver regeneration to uncover a novel migratory hepatocyte subpopulation mediating wound closure following acute liver injury."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "msBERT-Promoter: a multi-scale ensemble predictor based on BERT pre-trained model for the two-stage prediction of DNA promoters and their strengths",
    "doi": "10.1186/s12915-024-01923-z",
    "url": "",
    "authors": [
      "Li, Yazi",
      "Wei, Xiaoman",
      "Yang, Qinglin",
      "Xiong, An",
      "Li, Xingfeng",
      "Zou, Quan",
      "Cui, Feifei",
      "Zhang, Zilong"
    ],
    "publicationDate": "2024-05-30",
    "publicationName": "BMC Biology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "A promoter is a specific sequence in DNA that has transcriptional regulatory functions, playing a role in initiating gene expression. Identifying promoters and their strengths can provide valuable information related to human diseases. In recent years, computational methods have gained prominence as an effective means for identifying promoter, offering a more efficient alternative to labor-intensive biological approaches.",
        "Results",
        "In this study, a two-stage integrated predictor called “msBERT-Promoter” is proposed for identifying promoters and predicting their strengths. The model incorporates multi-scale sequence information through a tokenization strategy and fine-tunes the DNABERT model. Soft voting is then used to fuse the multi-scale information, effectively addressing the issue of insufficient DNA sequence information extraction in traditional models. To the best of our knowledge, this is the first time an integrated approach has been used in the DNABERT model for promoter identification and strength prediction. Our model achieves accuracy rates of 96.2% for promoter identification and 79.8% for promoter strength prediction, significantly outperforming existing methods. Furthermore, through attention mechanism analysis, we demonstrate that our model can effectively combine local and global sequence information, enhancing its interpretability.",
        "Conclusions",
        "msBERT-Promoter provides an effective tool that successfully captures sequence-related attributes of DNA promoters and can accurately identify promoters and predict their strengths. This work paves a new path for the application of artificial intelligence in traditional biology."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Zero-shot learning enables instant denoising and super-resolution in optical fluorescence microscopy",
    "doi": "10.1038/s41467-024-48575-9",
    "url": "",
    "authors": [
      "Qiao, Chang",
      "Zeng, Yunmin",
      "Meng, Quan",
      "Chen, Xingye",
      "Chen, Haoyu",
      "Jiang, Tao",
      "Wei, Rongfei",
      "Guo, Jiabao",
      "Fu, Wenfeng",
      "Lu, Huaide",
      "Li, Di",
      "Wang, Yuwang",
      "Qiao, Hui",
      "Wu, Jiamin",
      "Li, Dong",
      "Dai, Qionghai"
    ],
    "publicationDate": "2024-05-16",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "p": "Computational super-resolution methods, including conventional analytical algorithms and deep learning models, have substantially improved optical microscopy. Among them, supervised deep neural networks have demonstrated outstanding performance, however, demanding abundant high-quality training data, which are laborious and even impractical to acquire due to the high dynamics of living cells. Here, we develop zero-shot deconvolution networks (ZS-DeconvNet) that instantly enhance the resolution of microscope images by more than 1.5-fold over the diffraction limit with 10-fold lower fluorescence than ordinary super-resolution imaging conditions, in an unsupervised manner without the need for either ground truths or additional data acquisition. We demonstrate the versatile applicability of ZS-DeconvNet on multiple imaging modalities, including total internal reflection fluorescence microscopy, three-dimensional wide-field microscopy, confocal microscopy, two-photon microscopy, lattice light-sheet microscopy, and multimodal structured illumination microscopy, which enables multi-color, long-term, super-resolution 2D/3D imaging of subcellular bioprocesses from mitotic single cells to multicellular embryos of mouse and C. elegans .",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "TEC-miTarget: enhancing microRNA target prediction based on deep learning of ribonucleic acid sequences",
    "doi": "10.1186/s12859-024-05780-z",
    "url": "",
    "authors": [
      "Yang, Tingpeng",
      "Wang, Yu",
      "He, Yonghong"
    ],
    "publicationDate": "2024-04-20",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "MicroRNAs play a critical role in regulating gene expression by binding to specific target sites within gene transcripts, making the identification of microRNA targets a prominent focus of research. Conventional experimental methods for identifying microRNA targets are both time-consuming and expensive, prompting the development of computational tools for target prediction. However, the existing computational tools exhibit limited performance in meeting the demands of practical applications, highlighting the need to improve the performance of microRNA target prediction models.",
        "Results",
        "In this paper, we utilize the most popular natural language processing and computer vision technologies to propose a novel approach, called TEC-miTarget, for microRNA target prediction based on transformer encoder and convolutional neural networks. TEC-miTarget treats RNA sequences as a natural language and encodes them using a transformer encoder, a widely used encoder in natural language processing. It then combines the representations of a pair of microRNA and its candidate target site sequences into a contact map, which is a three-dimensional array similar to a multi-channel image. Therefore, the contact map's features are extracted using a four-layer convolutional neural network, enabling the prediction of interactions between microRNA and its candidate target sites. We applied a series of comparative experiments to demonstrate that TEC-miTarget significantly improves microRNA target prediction, compared with existing state-of-the-art models. Our approach is the first approach to perform comparisons with other approaches at both sequence and transcript levels. Furthermore, it is the first approach compared with both deep learning-based and seed-match-based methods. We first compared TEC-miTarget’s performance with approaches at the sequence level, and our approach delivers substantial improvements in performance using the same datasets and evaluation metrics. Moreover, we utilized TEC-miTarget to predict microRNA targets in long mRNA sequences, which involves two steps: selecting candidate target site sequences and applying sequence-level predictions. We finally showed that TEC-miTarget outperforms other approaches at the transcript level, including the popular seed match methods widely used in previous years.",
        "Conclusions",
        "We propose a novel approach for predicting microRNA targets at both sequence and transcript levels, and demonstrate that our approach outperforms other methods based on deep learning or seed match. We also provide our approach as an easy-to-use software, TEC-miTarget, at https://github.com/tingpeng17/TEC-miTarget . Our results provide new perspectives for microRNA target prediction."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Spatial landmark detection and tissue registration with deep learning",
    "doi": "10.1038/s41592-024-02199-5",
    "url": "",
    "authors": [
      "Ekvall, Markus",
      "Bergenstråhle, Ludvig",
      "Andersson, Alma",
      "Czarnewski, Paulo",
      "Olegård, Johannes",
      "Käll, Lukas",
      "Lundeberg, Joakim"
    ],
    "publicationDate": "2024-04-01",
    "publicationName": "Nature Methods",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Spatial landmarks are crucial in describing histological features between samples or sites, tracking regions of interest in microscopy, and registering tissue samples within a common coordinate framework. Although other studies have explored unsupervised landmark detection, existing methods are not well-suited for histological image data as they often require a large number of images to converge, are unable to handle nonlinear deformations between tissue sections and are ineffective for z -stack alignment, other modalities beyond image data or multimodal data. We address these challenges by introducing effortless landmark detection, a new unsupervised landmark detection and registration method using neural-network-guided thin-plate splines. Our proposed method is evaluated on a diverse range of datasets including histology and spatially resolved transcriptomics, demonstrating superior performance in both accuracy and stability compared to existing approaches.",
        "Effortless landmark detection is an unsupervised deep learning-based approach that addresses key challenges in landmark detection and image registration for accurate performance across diverse tissue imaging datasets."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "A Multimodal Omics Framework to Empower Target Discovery for Cardiovascular Regeneration",
    "doi": "10.1007/s10557-023-07484-7",
    "url": "",
    "authors": [
      "Li, Ziwen",
      "Brittan, Mairi",
      "Mills, Nicholas L."
    ],
    "publicationDate": "2024-04-01",
    "publicationName": "Cardiovascular Drugs and Therapy",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Ischaemic heart disease is a global healthcare challenge with high morbidity and mortality. Early revascularisation in acute myocardial infarction has improved survival; however, limited regenerative capacity and microvascular dysfunction often lead to impaired function and the development of heart failure. New mechanistic insights are required to identify robust targets for the development of novel strategies to promote regeneration. Single-cell RNA sequencing (scRNA-seq) has enabled profiling and analysis of the transcriptomes of individual cells at high resolution. Applications of scRNA-seq have generated single-cell atlases for multiple species, revealed distinct cellular compositions for different regions of the heart, and defined multiple mechanisms involved in myocardial injury-induced regeneration. In this review, we summarise findings from studies of healthy and injured hearts in multiple species and spanning different developmental stages. Based on this transformative technology, we propose a multi-species, multi-omics, meta-analysis framework to drive the discovery of new targets to promote cardiovascular regeneration."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Multimodal artificial intelligence-based pathogenomics improves survival prediction in oral squamous cell carcinoma",
    "doi": "10.1038/s41598-024-56172-5",
    "url": "",
    "authors": [
      "Vollmer, Andreas",
      "Hartmann, Stefan",
      "Vollmer, Michael",
      "Shavlokhova, Veronika",
      "Brands, Roman C.",
      "Kübler, Alexander",
      "Wollborn, Jakob",
      "Hassel, Frank",
      "Couillard-Despres, Sebastien",
      "Lang, Gernot",
      "Saravi, Babak"
    ],
    "publicationDate": "2024-03-07",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "In this study, we aimed to develop a novel prognostic algorithm for oral squamous cell carcinoma (OSCC) using a combination of pathogenomics and AI-based techniques. We collected comprehensive clinical, genomic, and pathology data from a cohort of OSCC patients in the TCGA dataset and used machine learning and deep learning algorithms to identify relevant features that are predictive of survival outcomes. Our analyses included 406 OSCC patients. Initial analyses involved gene expression analyses, principal component analyses, gene enrichment analyses, and feature importance analyses. These insights were foundational for subsequent model development. Furthermore, we applied five machine learning/deep learning algorithms (Random Survival Forest, Gradient Boosting Survival Analysis, Cox PH, Fast Survival SVM, and DeepSurv) for survival prediction. Our initial analyses revealed relevant gene expression variations and biological pathways, laying the groundwork for robust feature selection in model building. The results showed that the multimodal model outperformed the unimodal models across all methods, with c-index values of 0.722 for RSF, 0.633 for GBSA, 0.625 for FastSVM, 0.633 for CoxPH, and 0.515 for DeepSurv. When considering only important features, the multimodal model continued to outperform the unimodal models, with c-index values of 0.834 for RSF, 0.747 for GBSA, 0.718 for FastSVM, 0.742 for CoxPH, and 0.635 for DeepSurv. Our results demonstrate the potential of pathogenomics and AI-based techniques in improving the accuracy of prognostic prediction in OSCC, which may ultimately aid in the development of personalized treatment strategies for patients with this devastating disease."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Drug target prediction through deep learning functional representation of gene signatures",
    "doi": "10.1038/s41467-024-46089-y",
    "url": "",
    "authors": [
      "Chen, Hao",
      "King, Frederick J.",
      "Zhou, Bin",
      "Wang, Yu",
      "Canedy, Carter J.",
      "Hayashi, Joel",
      "Zhong, Yang",
      "Chang, Max W.",
      "Pache, Lars",
      "Wong, Julian L.",
      "Jia, Yong",
      "Joslin, John",
      "Jiang, Tao",
      "Benner, Christopher",
      "Chanda, Sumit K.",
      "Zhou, Yingyao"
    ],
    "publicationDate": "2024-02-29",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "p": "Many machine learning applications in bioinformatics currently rely on matching gene identities when analyzing input gene signatures and fail to take advantage of preexisting knowledge about gene functions. To further enable comparative analysis of OMICS datasets, including target deconvolution and mechanism of action studies, we develop an approach that represents gene signatures projected onto their biological functions, instead of their identities, similar to how the word2vec technique works in natural language processing. We develop the Functional Representation of Gene Signatures (FRoGS) approach by training a deep learning model and demonstrate that its application to the Broad Institute’s L1000 datasets results in more effective compound-target predictions than models based on gene identities alone. By integrating additional pharmacological activity data sources, FRoGS significantly increases the number of high-quality compound-target predictions relative to existing approaches, many of which are supported by in silico and/or experimental evidence. These results underscore the general utility of FRoGS in machine learning-based bioinformatics applications. Prediction networks pre-equipped with the knowledge of gene functions may help uncover new relationships among gene signatures acquired by large-scale OMICs studies on compounds, cell types, disease models, and patient cohorts.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Empowering PET: harnessing deep learning for improved clinical insight",
    "doi": "10.1186/s41747-023-00413-1",
    "url": "",
    "authors": [
      "Artesani, Alessia",
      "Bruno, Alessandro",
      "Gelardi, Fabrizia",
      "Chiti, Arturo"
    ],
    "publicationDate": "2024-02-07",
    "publicationName": "European Radiology Experimental",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "This review aims to take a journey into the transformative impact of artificial intelligence (AI) on positron emission tomography (PET) imaging. To this scope, a broad overview of AI applications in the field of nuclear medicine and a thorough exploration of deep learning (DL) implementations in cancer diagnosis and therapy through PET imaging will be presented. We firstly describe the behind-the-scenes use of AI for image generation, including acquisition (event positioning, noise reduction though time-of-flight estimation and scatter correction), reconstruction (data-driven and model-driven approaches), restoration (supervised and unsupervised methods), and motion correction. Thereafter, we outline the integration of AI into clinical practice through the applications to segmentation, detection and classification, quantification, treatment planning, dosimetry, and radiomics/radiogenomics combined to tumour biological characteristics. Thus, this review seeks to showcase the overarching transformation of the field, ultimately leading to tangible improvements in patient treatment and response assessment. Finally, limitations and ethical considerations of the AI application to PET imaging and future directions of multimodal data mining in this discipline will be briefly discussed, including pressing challenges to the adoption of AI in molecular imaging such as the access to and interoperability of huge amount of data as well as the “black-box” problem, contributing to the ongoing dialogue on the transformative potential of AI in nuclear medicine. Relevance statement AI is rapidly revolutionising the world of medicine, including the fields of radiology and nuclear medicine. In the near future, AI will be used to support healthcare professionals. These advances will lead to improvements in diagnosis, in the assessment of response to treatment, in clinical decision making and in patient management. Key points • Applying AI has the potential to enhance the entire PET imaging pipeline. • AI may support several clinical tasks in both PET diagnosis and prognosis. • Interpreting the relationships between imaging and multiomics data will heavily rely on AI.",
        "Graphical Abstract",
        ""
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "A systematic analysis of deep learning in genomics and histopathology for precision oncology",
    "doi": "10.1186/s12920-024-01796-9",
    "url": "",
    "authors": [
      "Unger, Michaela",
      "Kather, Jakob Nikolas"
    ],
    "publicationDate": "2024-02-05",
    "publicationName": "BMC Medical Genomics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Digitized histopathological tissue slides and genomics profiling data are available for many patients with solid tumors. In the last 5 years, Deep Learning (DL) has been broadly used to extract clinically actionable information and biological knowledge from pathology slides and genomic data in cancer. In addition, a number of recent studies have introduced multimodal DL models designed to simultaneously process both images from pathology slides and genomic data as inputs. By comparing patterns from one data modality with those in another, multimodal DL models are capable of achieving higher performance compared to their unimodal counterparts. However, the application of these methodologies across various tumor entities and clinical scenarios lacks consistency.",
        "Methods",
        "Here, we present a systematic survey of the academic literature from 2010 to November 2023, aiming to quantify the application of DL for pathology, genomics, and the combined use of both data types. After filtering 3048 publications, our search identified 534 relevant articles which then were evaluated by basic (diagnosis, grading, subtyping) and advanced (mutation, drug response and survival prediction) application types, publication year and addressed cancer tissue.",
        "Results",
        "Our analysis reveals a predominant application of DL in pathology compared to genomics. However, there is a notable surge in DL incorporation within both domains. Furthermore, while DL applied to pathology primarily targets the identification of histology-specific patterns in individual tissues, DL in genomics is more commonly used in a pan-cancer context. Multimodal DL, on the contrary, remains a niche topic, evidenced by a limited number of publications, primarily focusing on prognosis predictions.",
        "Conclusion",
        "In summary, our quantitative analysis indicates that DL not only has a well-established role in histopathology but is also being successfully integrated into both genomic and multimodal applications. In addition, there is considerable potential in multimodal DL for harnessing further advanced tasks, such as predicting drug response. Nevertheless, this review also underlines the need for further research to bridge the existing gaps in these fields."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "DCCAFN: deep convolution cascade attention fusion network based on imaging genomics for prediction survival analysis of lung cancer",
    "doi": "10.1007/s40747-023-01204-2",
    "url": "",
    "authors": [
      "Jia, Liye",
      "Ren, Xueting",
      "Wu, Wei",
      "Zhao, Juanjuan",
      "Qiang, Yan",
      "Yang, Qianqian"
    ],
    "publicationDate": "2024-02-01",
    "publicationName": "Complex & Intelligent Systems",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Recently, lung cancer prediction based on imaging genomics has attracted great attention. However, such studies often have many challenges, such as small sample size, high-dimensional information redundancy, and the inefficiency of multimodal fusion. Therefore, in this paper, a deep convolution cascade attention fusion network (DCCAFN) based on imaging genomics is proposed for the prediction of lung cancer patients’ survival. The network consists of three modules: an image feature extraction module (IFEM), a gene feature extraction module (GFEM), and an attention fusion network (AFN). In the IFEM, a pretrained residual network based on transfer learning is used to extract deep image features to fully capture the computed tomography (CT) image information conducive to prognosis prediction. In the GFEM, the F -test is first used for gene screening to eliminate redundant information, and then, a cascade network with the convolution cascade module (CCM) that contains a convolution operation, a pooling operation, and an ensemble forest classifier is designed to better extract the gene features. In the AFN, a bimodal attention fusion mechanism is proposed to fuse deep image features and gene features to improve the performance of predicting lung cancer survival. The experimental results show that the DCCAFN model achieves good performance, and its accuracy and AUC are 0.831 and 0.816, respectively. It indicates that the model is an effective multimodal data fusion method for predicting the survival prognosis of lung cancer, which can greatly help physicians stratify patients' risks, and achieve personalized treatment for improving the quality of patients' lives."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Representing and extracting knowledge from single-cell data",
    "doi": "10.1007/s12551-023-01091-4",
    "url": "",
    "authors": [
      "Mihai, Ionut Sebastian",
      "Chafle, Sarang",
      "Henriksson, Johan"
    ],
    "publicationDate": "2024-02-01",
    "publicationName": "Biophysical Reviews",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Single-cell analysis is currently one of the most high-resolution techniques to study biology. The large complex datasets that have been generated have spurred numerous developments in computational biology, in particular the use of advanced statistics and machine learning. This review attempts to explain the deeper theoretical concepts that underpin current state-of-the-art analysis methods. Single-cell analysis is covered from cell, through instruments, to current and upcoming models. The aim of this review is to spread concepts which are not yet in common use, especially from topology and generative processes, and how new statistical models can be developed to capture more of biology. This opens epistemological questions regarding our ontology and models, and some pointers will be given to how natural language processing (NLP) may help overcome our cognitive limitations for understanding single-cell data."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "InClust+: the deep generative framework with mask modules for multimodal data integration, imputation, and cross-modal generation",
    "doi": "10.1186/s12859-024-05656-2",
    "url": "",
    "authors": [
      "Wang, Lifei",
      "Nie, Rui",
      "Miao, Xuexia",
      "Cai, Yankai",
      "Wang, Anqi",
      "Zhang, Hanwen",
      "Zhang, Jiang",
      "Cai, Jun"
    ],
    "publicationDate": "2024-01-24",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "With the development of single-cell technology, many cell traits can be measured. Furthermore, the multi-omics profiling technology could jointly measure two or more traits in a single cell simultaneously. In order to process the various data accumulated rapidly, computational methods for multimodal data integration are needed.",
        "Results",
        "Here, we present inClust+, a deep generative framework for the multi-omics. It’s built on previous inClust that is specific for transcriptome data, and augmented with two mask modules designed for multimodal data processing: an input-mask module in front of the encoder and an output-mask module behind the decoder. InClust+ was first used to integrate scRNA-seq and MERFISH data from similar cell populations, and to impute MERFISH data based on scRNA-seq data. Then, inClust+ was shown to have the capability to integrate the multimodal data (e.g. tri-modal data with gene expression, chromatin accessibility and protein abundance) with batch effect. Finally, inClust+ was used to integrate an unlabeled monomodal scRNA-seq dataset and two labeled multimodal CITE-seq datasets, transfer labels from CITE-seq datasets to scRNA-seq dataset, and generate the missing modality of protein abundance in monomodal scRNA-seq data. In the above examples, the performance of inClust+ is better than or comparable to the most recent tools in the corresponding task.",
        "Conclusions",
        "The inClust+ is a suitable framework for handling multimodal data. Meanwhile, the successful implementation of mask in inClust+ means that it can be applied to other deep learning methods with similar encoder-decoder architecture to broaden the application scope of these models."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Single-cell spatial multi-omics and deep learning dissect enhancer-driven gene regulatory networks in liver zonation",
    "doi": "10.1038/s41556-023-01316-4",
    "url": "",
    "authors": [
      "Bravo González-Blas, Carmen",
      "Matetovici, Irina",
      "Hillen, Hanne",
      "Taskiran, Ibrahim Ihsan",
      "Vandepoel, Roel",
      "Christiaens, Valerie",
      "Sansores-García, Leticia",
      "Verboven, Elisabeth",
      "Hulselmans, Gert",
      "Poovathingal, Suresh",
      "Demeulemeester, Jonas",
      "Psatha, Nikoleta",
      "Mauduit, David",
      "Halder, Georg",
      "Aerts, Stein"
    ],
    "publicationDate": "2024-01-01",
    "publicationName": "Nature Cell Biology",
    "contentType": "Article",
    "abstract": {
      "p": "In the mammalian liver, hepatocytes exhibit diverse metabolic and functional profiles based on their location within the liver lobule. However, it is unclear whether this spatial variation, called zonation, is governed by a well-defined gene regulatory code. Here, using a combination of single-cell multiomics, spatial omics, massively parallel reporter assays and deep learning, we mapped enhancer-gene regulatory networks across mouse liver cell types. We found that zonation affects gene expression and chromatin accessibility in hepatocytes, among other cell types. These states are driven by the repressors TCF7L1 and TBX3, alongside other core hepatocyte transcription factors, such as HNF4A, CEBPA, FOXA1 and ONECUT1. To examine the architecture of the enhancers driving these cell states, we trained a hierarchical deep learning model called DeepLiver. Our study provides a multimodal understanding of the regulatory code underlying hepatocyte identity and their zonation state that can be used to engineer enhancers with specific activity levels and zonation patterns.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "GPDRP: a multimodal framework for drug response prediction with graph transformer",
    "doi": "10.1186/s12859-023-05618-0",
    "url": "",
    "authors": [
      "Yang, Yingke",
      "Li, Peiluan"
    ],
    "publicationDate": "2023-12-17",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "In the field of computational personalized medicine, drug response prediction (DRP) is a critical issue. However, existing studies often characterize drugs as strings, a representation that does not align with the natural description of molecules. Additionally, they ignore gene pathway-specific combinatorial implication.",
        "Results",
        "In this study, we propose drug Graph and gene Pathway based Drug response prediction method (GPDRP), a new multimodal deep learning model for predicting drug responses based on drug molecular graphs and gene pathway activity. In GPDRP, drugs are represented by molecular graphs, while cell lines are described by gene pathway activity scores. The model separately learns these two types of data using Graph Neural Networks (GNN) with Graph Transformers and deep neural networks. Predictions are subsequently made through fully connected layers.",
        "Conclusions",
        "Our results indicate that Graph Transformer-based model delivers superior performance. We apply GPDRP on hundreds of cancer cell lines’ bulk RNA-sequencing data, and it outperforms some recently published models. Furthermore, the generalizability and applicability of GPDRP are demonstrated through its predictions on unknown drug-cell line pairs and xenografts. This underscores the interpretability achieved by incorporating gene pathways."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Reusability report: Learning the transcriptional grammar in single-cell RNA-sequencing data using transformers",
    "doi": "10.1038/s42256-023-00757-8",
    "url": "",
    "authors": [
      "Khan, Sumeer Ahmad",
      "Maillo, Alberto",
      "Lagani, Vincenzo",
      "Lehmann, Robert",
      "Kiani, Narsis A.",
      "Gomez-Cabrero, David",
      "Tegner, Jesper"
    ],
    "publicationDate": "2023-12-01",
    "publicationName": "Nature Machine Intelligence",
    "contentType": "Article",
    "abstract": {
      "p": "The rise of single-cell genomics is an attractive opportunity for data-hungry machine learning algorithms. The scBERT method, inspired by the success of BERT (‘bidirectional encoder representations from transformers’) in natural language processing, was recently introduced by Yang et al. as a data-driven tool to annotate cell types in single-cell genomics data. Analogous to contextual embedding in BERT, scBERT leverages pretraining and self-attention mechanisms to learn the ‘transcriptional grammar’ of cells. Here we investigate the reusability beyond the original datasets, assessing the generalizability of natural language techniques in single-cell genomics. The degree of imbalance in the cell-type distribution substantially influences the performance of scBERT. Anticipating an increased utilization of transformers, we highlight the necessity to consider data distribution carefully and introduce a subsampling technique to mitigate the influence of an imbalanced distribution. Our analysis serves as a stepping stone towards understanding and optimizing the use of transformers in single-cell genomics.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "PepCNN deep learning tool for predicting peptide binding residues in proteins using sequence, structural, and language model features",
    "doi": "10.1038/s41598-023-47624-5",
    "url": "",
    "authors": [
      "Chandra, Abel",
      "Sharma, Alok",
      "Dehzangi, Iman",
      "Tsunoda, Tatsuhiko",
      "Sattar, Abdul"
    ],
    "publicationDate": "2023-11-28",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Protein–peptide interactions play a crucial role in various cellular processes and are implicated in abnormal cellular behaviors leading to diseases such as cancer. Therefore, understanding these interactions is vital for both functional genomics and drug discovery efforts. Despite a significant increase in the availability of protein–peptide complexes, experimental methods for studying these interactions remain laborious, time-consuming, and expensive. Computational methods offer a complementary approach but often fall short in terms of prediction accuracy. To address these challenges, we introduce PepCNN, a deep learning-based prediction model that incorporates structural and sequence-based information from primary protein sequences. By utilizing a combination of half-sphere exposure, position specific scoring matrices from multiple-sequence alignment tool, and embedding from a pre-trained protein language model, PepCNN outperforms state-of-the-art methods in terms of specificity, precision, and AUC. The PepCNN software and datasets are publicly available at https://github.com/abelavit/PepCNN.git ."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "A novel method for identifying key genes in macroevolution based on deep learning with attention mechanism",
    "doi": "10.1038/s41598-023-47113-9",
    "url": "",
    "authors": [
      "Mao, Jiawei",
      "Cao, Yong",
      "Zhang, Yan",
      "Huang, Biaosheng",
      "Zhao, Youjie"
    ],
    "publicationDate": "2023-11-13",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Macroevolution can be regarded as the result of evolutionary changes of synergistically acting genes. Unfortunately, the importance of these genes in macroevolution is difficult to assess and hence the identification of macroevolutionary key genes is a major challenge in evolutionary biology. In this study, we designed various word embedding libraries of natural language processing (NLP) considering the multiple mechanisms of evolutionary genomics. A novel method (IKGM) based on three types of attention mechanisms (domain attention, kmer attention and fused attention) were proposed to calculate the weights of different genes in macroevolution. Taking 34 species of diurnal butterflies and nocturnal moths in Lepidoptera as an example, we identified a few of key genes with high weights, which annotated to the functions of circadian rhythms, sensory organs, as well as behavioral habits etc. This study not only provides a novel method to identify the key genes of macroevolution at the genomic level, but also helps us to understand the microevolution mechanisms of diurnal butterflies and nocturnal moths in Lepidoptera."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Dynamic characterization and interpretation for protein-RNA interactions across diverse cellular conditions using HDRNet",
    "doi": "10.1038/s41467-023-42547-1",
    "url": "",
    "authors": [
      "Zhu, Haoran",
      "Yang, Yuning",
      "Wang, Yunhe",
      "Wang, Fuzhou",
      "Huang, Yujian",
      "Chang, Yi",
      "Wong, Ka-chun",
      "Li, Xiangtao"
    ],
    "publicationDate": "2023-10-26",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "RNA-binding proteins play crucial roles in the regulation of gene expression, and understanding the interactions between RNAs and RBPs in distinct cellular conditions forms the basis for comprehending the underlying RNA function. However, current computational methods pose challenges to the cross-prediction of RNA-protein binding events across diverse cell lines and tissue contexts. Here, we develop HDRNet, an end-to-end deep learning-based framework to precisely predict dynamic RBP binding events under diverse cellular conditions. Our results demonstrate that HDRNet can accurately and efficiently identify binding sites, particularly for dynamic prediction, outperforming other state-of-the-art models on 261 linear RNA datasets from both eCLIP and CLIP-seq, supplemented with additional tissue data. Moreover, we conduct motif and interpretation analyses to provide fresh insights into the pathological mechanisms underlying RNA-RBP interactions from various perspectives. Our functional genomic analysis further explores the gene-human disease associations, uncovering previously uncharacterized observations for a broad range of genetic disorders.",
        "Predicting dynamic RNA-RBP interactions in diverse cell lines is an important challenge in unravelling RNA function and post-transcriptional regulatory mechanisms. Here, authors develop HDRNet, an end-to-end deep-learning-based framework for accurately predicting dynamic RBP binding events across various cellular conditions."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Microglia in neurodegenerative diseases: mechanism and potential therapeutic targets",
    "doi": "10.1038/s41392-023-01588-0",
    "url": "",
    "authors": [
      "Gao, Chao",
      "Jiang, Jingwen",
      "Tan, Yuyan",
      "Chen, Shengdi"
    ],
    "publicationDate": "2023-09-22",
    "publicationName": "Signal Transduction and Targeted Therapy",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Microglia activation is observed in various neurodegenerative diseases. Recent advances in single-cell technologies have revealed that these reactive microglia were with high spatial and temporal heterogeneity. Some identified microglia in specific states correlate with pathological hallmarks and are associated with specific functions. Microglia both exert protective function by phagocytosing and clearing pathological protein aggregates and play detrimental roles due to excessive uptake of protein aggregates, which would lead to microglial phagocytic ability impairment, neuroinflammation, and eventually neurodegeneration. In addition, peripheral immune cells infiltration shapes microglia into a pro-inflammatory phenotype and accelerates disease progression. Microglia also act as a mobile vehicle to propagate protein aggregates. Extracellular vesicles released from microglia and autophagy impairment in microglia all contribute to pathological progression and neurodegeneration. Thus, enhancing microglial phagocytosis, reducing microglial-mediated neuroinflammation, inhibiting microglial exosome synthesis and secretion, and promoting microglial conversion into a protective phenotype are considered to be promising strategies for the therapy of neurodegenerative diseases. Here we comprehensively review the biology of microglia and the roles of microglia in neurodegenerative diseases, including Alzheimer’s disease, Parkinson’s disease, multiple system atrophy, amyotrophic lateral sclerosis, frontotemporal dementia, progressive supranuclear palsy, corticobasal degeneration, dementia with Lewy bodies and Huntington’s disease. We also summarize the possible microglia-targeted interventions and treatments against neurodegenerative diseases with preclinical and clinical evidence in cell experiments, animal studies, and clinical trials."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "MultiVI: deep generative model for the integration of multimodal data",
    "doi": "10.1038/s41592-023-01909-9",
    "url": "",
    "authors": [
      "Ashuach, Tal",
      "Gabitto, Mariano I.",
      "Koodli, Rohan V.",
      "Saldi, Giuseppe-Antonio",
      "Jordan, Michael I.",
      "Yosef, Nir"
    ],
    "publicationDate": "2023-08-01",
    "publicationName": "Nature Methods",
    "contentType": "Article",
    "abstract": {
      "p": "Jointly profiling the transcriptome, chromatin accessibility and other molecular properties of single cells offers a powerful way to study cellular diversity. Here we present MultiVI, a probabilistic model to analyze such multiomic data and leverage it to enhance single-modality datasets. MultiVI creates a joint representation that allows an analysis of all modalities included in the multiomic input data, even for cells for which one or more modalities are missing. It is available at scvi-tools.org .",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Cell-type-specific prediction of 3D chromatin organization enables high-throughput in silico genetic screening",
    "doi": "10.1038/s41587-022-01612-8",
    "url": "",
    "authors": [
      "Tan, Jimin",
      "Shenker-Tauris, Nina",
      "Rodriguez-Hernaez, Javier",
      "Wang, Eric",
      "Sakellaropoulos, Theodore",
      "Boccalatte, Francesco",
      "Thandapani, Palaniraja",
      "Skok, Jane",
      "Aifantis, Iannis",
      "Fenyö, David",
      "Xia, Bo",
      "Tsirigos, Aristotelis"
    ],
    "publicationDate": "2023-08-01",
    "publicationName": "Nature Biotechnology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Investigating how chromatin organization determines cell-type-specific gene expression remains challenging. Experimental methods for measuring three-dimensional chromatin organization, such as Hi-C, are costly and have technical limitations, restricting their broad application particularly in high-throughput genetic perturbations. We present C.Origami, a multimodal deep neural network that performs de novo prediction of cell-type-specific chromatin organization using DNA sequence and two cell-type-specific genomic features—CTCF binding and chromatin accessibility. C.Origami enables in silico experiments to examine the impact of genetic changes on chromatin interactions. We further developed an in silico genetic screening approach to assess how individual DNA elements may contribute to chromatin organization and to identify putative cell-type-specific trans -acting regulators that collectively determine chromatin architecture. Applying this approach to leukemia cells and normal T cells, we demonstrate that cell-type-specific in silico genetic screening, enabled by C.Origami, can be used to systematically discover novel chromatin regulation circuits in both normal and disease-related biological systems.",
        "Deep learning predicts cell-type-specific 3D chromatin contacts from DNA sequence, chromatin accessibility and CTCF binding."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Assessment of emerging pretraining strategies in interpretable multimodal deep learning for cancer prognostication",
    "doi": "10.1186/s13040-023-00338-w",
    "url": "",
    "authors": [
      "Azher, Zarif L.",
      "Suvarna, Anish",
      "Chen, Ji-Qing",
      "Zhang, Ze",
      "Christensen, Brock C.",
      "Salas, Lucas A.",
      "Vaickus, Louis J.",
      "Levy, Joshua J."
    ],
    "publicationDate": "2023-07-22",
    "publicationName": "BioData Mining",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Deep learning models can infer cancer patient prognosis from molecular and anatomic pathology information. Recent studies that leveraged information from complementary multimodal data improved prognostication, further illustrating the potential utility of such methods. However, current approaches: 1) do not comprehensively leverage biological and histomorphological relationships and 2) make use of emerging strategies to “pretrain” models (i.e., train models on a slightly orthogonal dataset/modeling objective) which may aid prognostication by reducing the amount of information required for achieving optimal performance. In addition, model interpretation is crucial for facilitating the clinical adoption of deep learning methods by fostering practitioner understanding and trust in the technology.",
        "Methods",
        "Here, we develop an interpretable multimodal modeling framework that combines DNA methylation, gene expression, and histopathology (i.e., tissue slides) data, and we compare performance of crossmodal pretraining, contrastive learning, and transfer learning versus the standard procedure.",
        "Results",
        "Our models outperform the existing state-of-the-art method (average 11.54% C-index increase), and baseline clinically driven models (average 11.7% C-index increase). Model interpretations elucidate consideration of biologically meaningful factors in making prognosis predictions.",
        "Discussion",
        "Our results demonstrate that the selection of pretraining strategies is crucial for obtaining highly accurate prognostication models, even more so than devising an innovative model architecture, and further emphasize the all-important role of the tumor microenvironment on disease progression."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Breast cancer prediction using gated attentive multimodal deep learning",
    "doi": "10.1186/s40537-023-00749-w",
    "url": "",
    "authors": [
      "Kayikci, Safak",
      "Khoshgoftaar, Taghi M."
    ],
    "publicationDate": "2023-05-13",
    "publicationName": "Journal of Big Data",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Women are prone to breast cancer, which is a major cause of death. One out of every eight women has a lifetime risk of developing this cancer. Early diagnosis of this disease is critical and enhances the success rate of cure. It is extremely important to determine which genes are associated with the disease. However, too many features make studies on gene data challenging. In this study, an attention-based multimodal deep learning model was created by combining data from clinical, copy number alteration and gene expression sources. Attention-based deep learning models can analyze mammography images and identify subtle patterns or abnormalities that may indicate the presence of cancer. These models can also integrate patient data, such as age and family history, to improve the accuracy of predictions. The objective of this study is to help breast cancer prediction tasks and improve efficiency by incorporating attention mechanisms. Our suggested methodology employs multimodal data and generates insightful characteristics to improve the prediction of the prognosis for breast cancer. It is a two-phase model; the first phase generates the stacked features using a sigmoid gated attention convolutional neural network, and the second phase uses flatten, dense and dropout processes for bi-modal attention. Based on our findings, the proposed model produced successful results and has the potential to significantly improve breast cancer detection and diagnosis, ultimately leading to better patient outcomes."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Discovery of drug–omics associations in type 2 diabetes with generative deep-learning models",
    "doi": "10.1038/s41587-022-01520-x",
    "url": "",
    "authors": [
      "Allesøe, Rosa Lundbye",
      "Lundgaard, Agnete Troen",
      "Hernández Medina, Ricardo",
      "Aguayo-Orozco, Alejandro",
      "Johansen, Joachim",
      "Nissen, Jakob Nybo",
      "Brorsson, Caroline",
      "Mazzoni, Gianluca",
      "Niu, Lili",
      "Biel, Jorge Hernansanz",
      "Leal Rodríguez, Cristina",
      "Brasas, Valentas",
      "Webel, Henry",
      "Benros, Michael Eriksen",
      "Pedersen, Anders Gorm",
      "Chmura, Piotr Jaroslaw",
      "Jacobsen, Ulrik Plesner",
      "Mari, Andrea",
      "Koivula, Robert",
      "Mahajan, Anubha",
      "Vinuela, Ana",
      "Tajes, Juan Fernandez",
      "Sharma, Sapna",
      "Haid, Mark",
      "Hong, Mun-Gwan",
      "Musholt, Petra B.",
      "Masi, Federico",
      "Vogt, Josef",
      "Pedersen, Helle Krogh",
      "Gudmundsdottir, Valborg",
      "Jones, Angus",
      "Kennedy, Gwen",
      "Bell, Jimmy",
      "Thomas, E. Louise",
      "Frost, Gary",
      "Thomsen, Henrik",
      "Hansen, Elizaveta",
      "Hansen, Tue Haldor",
      "Vestergaard, Henrik",
      "Muilwijk, Mirthe",
      "Blom, Marieke T.",
      "‘t Hart, Leen M.",
      "Pattou, Francois",
      "Raverdy, Violeta",
      "Brage, Soren",
      "Kokkola, Tarja",
      "Heggie, Alison",
      "McEvoy, Donna",
      "Mourby, Miranda",
      "Kaye, Jane",
      "Hattersley, Andrew",
      "McDonald, Timothy",
      "Ridderstråle, Martin",
      "Walker, Mark",
      "Forgie, Ian",
      "Giordano, Giuseppe N.",
      "Pavo, Imre",
      "Ruetten, Hartmut",
      "Pedersen, Oluf",
      "Hansen, Torben",
      "Dermitzakis, Emmanouil",
      "Franks, Paul W.",
      "Schwenk, Jochen M.",
      "Adamski, Jerzy",
      "McCarthy, Mark I.",
      "Pearson, Ewan",
      "Banasik, Karina",
      "Rasmussen, Simon",
      "Brunak, Søren",
      "IMI DIRECT Consortium"
    ],
    "publicationDate": "2023-03-01",
    "publicationName": "Nature Biotechnology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "The application of multiple omics technologies in biomedical cohorts has the potential to reveal patient-level disease characteristics and individualized response to treatment. However, the scale and heterogeneous nature of multi-modal data makes integration and inference a non-trivial task. We developed a deep-learning-based framework, multi-omics variational autoencoders (MOVE), to integrate such data and applied it to a cohort of 789 people with newly diagnosed type 2 diabetes with deep multi-omics phenotyping from the DIRECT consortium. Using in silico perturbations, we identified drug–omics associations across the multi-modal datasets for the 20 most prevalent drugs given to people with type 2 diabetes with substantially higher sensitivity than univariate statistical tests. From these, we among others, identified novel associations between metformin and the gut microbiota as well as opposite molecular responses for the two statins, simvastatin and atorvastatin. We used the associations to quantify drug–drug similarities, assess the degree of polypharmacy and conclude that drug effects are distributed across the multi-omics modalities.",
        "Clinical multi-omics data are integrated and analyzed using a generative deep-learning model."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "A multimodal deep learning model to infer cell-type-specific functional gene networks",
    "doi": "10.1186/s12859-023-05146-x",
    "url": "",
    "authors": [
      "Afshar, Shiva",
      "Braun, Patricia R.",
      "Han, Shizhong",
      "Lin, Ying"
    ],
    "publicationDate": "2023-02-14",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Functional gene networks (FGNs) capture functional relationships among genes that vary across tissues and cell types. Construction of cell-type-specific FGNs enables the understanding of cell-type-specific functional gene relationships and insights into genetic mechanisms of human diseases in disease-relevant cell types. However, most existing FGNs were developed without consideration of specific cell types within tissues.",
        "Results",
        "In this study, we created a multimodal deep learning model (MDLCN) to predict cell-type-specific FGNs in the human brain by integrating single-nuclei gene expression data with global protein interaction networks. We systematically evaluated the prediction performance of the MDLCN and showed its superior performance compared to two baseline models (boosting tree and convolutional neural network). Based on the predicted cell-type-specific FGNs, we observed that cell-type marker genes had a higher level of hubness than non-marker genes in their corresponding cell type. Furthermore, we showed that risk genes underlying autism and Alzheimer’s disease were more strongly connected in disease-relevant cell types, supporting the cellular context of predicted cell-type-specific FGNs.",
        "Conclusions",
        "Our study proposes a powerful deep learning approach (MDLCN) to predict FGNs underlying a diverse set of cell types in human brain. The MDLCN model enhances prediction accuracy of cell-type-specific FGNs compared to single modality convolutional neural network (CNN) and boosting tree models, as shown by higher areas under both receiver operating characteristic (ROC) and precision-recall curves for different levels of independent test datasets. The predicted FGNs also show evidence for the cellular context and distinct topological features (i.e. higher hubness and topological score) of cell-type marker genes. Moreover, we observed stronger modularity among disease-associated risk genes in FGNs of disease-relevant cell types. For example, the strength of connectivity among autism risk genes was stronger in neurons, but risk genes underlying Alzheimer’s disease were more connected in microglia."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Multilingual translation for zero-shot biomedical classification using BioTranslator",
    "doi": "10.1038/s41467-023-36476-2",
    "url": "",
    "authors": [
      "Xu, Hanwen",
      "Woicik, Addie",
      "Poon, Hoifung",
      "Altman, Russ B.",
      "Wang, Sheng"
    ],
    "publicationDate": "2023-02-10",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Existing annotation paradigms rely on controlled vocabularies, where each data instance is classified into one term from a predefined set of controlled vocabularies. This paradigm restricts the analysis to concepts that are known and well-characterized. Here, we present the novel multilingual translation method BioTranslator to address this problem. BioTranslator takes a user-written textual description of a new concept and then translates this description to a non-text biological data instance. The key idea of BioTranslator is to develop a multilingual translation framework, where multiple modalities of biological data are all translated to text. We demonstrate how BioTranslator enables the identification of novel cell types using only a textual description and how BioTranslator can be further generalized to protein function prediction and drug target identification. Our tool frees scientists from limiting their analyses within predefined controlled vocabularies, enabling them to interact with biological data using free text.",
        "Here, the authors develop the cross-modal translation method BioTranslator to translate the textual description to non-text biological data. This approach frees scientists from limiting their analysis within predefined controlled vocabularies."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Clustering of single-cell multi-omics data with a multimodal deep learning method",
    "doi": "10.1038/s41467-022-35031-9",
    "url": "",
    "authors": [
      "Lin, Xiang",
      "Tian, Tian",
      "Wei, Zhi",
      "Hakonarson, Hakon"
    ],
    "publicationDate": "2022-12-13",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "p": "Single-cell multimodal sequencing technologies are developed to simultaneously profile different modalities of data in the same cell. It provides a unique opportunity to jointly analyze multimodal data at the single-cell level for the identification of distinct cell types. A correct clustering result is essential for the downstream complex biological functional studies. However, combining different data sources for clustering analysis of single-cell multimodal data remains a statistical and computational challenge. Here, we develop a novel multimodal deep learning method, scMDC, for single-cell multi-omics data clustering analysis. scMDC is an end-to-end deep model that explicitly characterizes different data sources and jointly learns latent features of deep embedding for clustering analysis. Extensive simulation and real-data experiments reveal that scMDC outperforms existing single-cell single-modal and multimodal clustering methods on different single-cell multimodal datasets. The linear scalability of running time makes scMDC a promising method for analyzing large multimodal datasets.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Artificial intelligence-based methods for fusion of electronic health records and imaging data",
    "doi": "10.1038/s41598-022-22514-4",
    "url": "",
    "authors": [
      "Mohsen, Farida",
      "Ali, Hazrat",
      "El Hajj, Nady",
      "Shah, Zubair"
    ],
    "publicationDate": "2022-10-26",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Healthcare data are inherently multimodal, including electronic health records (EHR), medical images, and multi-omics data. Combining these multimodal data sources contributes to a better understanding of human health and provides optimal personalized healthcare. The most important question when using multimodal data is how to fuse them—a field of growing interest among researchers. Advances in artificial intelligence (AI) technologies, particularly machine learning (ML), enable the fusion of these different data modalities to provide multimodal insights. To this end, in this scoping review, we focus on synthesizing and analyzing the literature that uses AI techniques to fuse multimodal medical data for different clinical applications. More specifically, we focus on studies that only fused EHR with medical imaging data to develop various AI methods for clinical applications. We present a comprehensive analysis of the various fusion strategies, the diseases and clinical outcomes for which multimodal fusion was used, the ML algorithms used to perform multimodal fusion for each clinical application, and the available multimodal medical datasets. We followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines. We searched Embase, PubMed, Scopus, and Google Scholar to retrieve relevant studies. After pre-processing and screening, we extracted data from 34 studies that fulfilled the inclusion criteria. We found that studies fusing imaging data with EHR are increasing and doubling from 2020 to 2021. In our analysis, a typical workflow was observed: feeding raw data, fusing different data modalities by applying conventional machine learning (ML) or deep learning (DL) algorithms, and finally, evaluating the multimodal fusion through clinical outcome predictions. Specifically, early fusion was the most used technique in most applications for multimodal learning (22 out of 34 studies). We found that multimodality fusion models outperformed traditional single-modality models for the same task. Disease diagnosis and prediction were the most common clinical outcomes (reported in 20 and 10 studies, respectively) from a clinical outcome perspective. Neurological disorders were the dominant category (16 studies). From an AI perspective, conventional ML models were the most used (19 studies), followed by DL models (16 studies). Multimodal data used in the included studies were mostly from private repositories (21 studies). Through this scoping review, we offer new insights for researchers interested in knowing the current state of knowledge within this research field."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Deciphering microbial gene function using natural language processing",
    "doi": "10.1038/s41467-022-33397-4",
    "url": "",
    "authors": [
      "Miller, Danielle",
      "Stern, Adi",
      "Burstein, David"
    ],
    "publicationDate": "2022-09-29",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "p": "Revealing the function of uncharacterized genes is a fundamental challenge in an era of ever-increasing volumes of sequencing data. Here, we present a concept for tackling this challenge using deep learning methodologies adopted from natural language processing (NLP). We repurpose NLP algorithms to model “gene semantics” based on a biological corpus of more than 360 million microbial genes within their genomic context. We use the language models to predict functional categories for 56,617 genes and find that out of 1369 genes associated with recently discovered defense systems, 98% are inferred correctly. We then systematically evaluate the “discovery potential” of different functional categories, pinpointing those with the most genes yet to be characterized. Finally, we demonstrate our method’s ability to discover systems associated with microbial interaction and defense. Our results highlight that combining microbial genomics and language models is a promising avenue for revealing gene functions in microbes.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "A review of brain imaging biomarker genomics in Alzheimer’s disease: implementation and perspectives",
    "doi": "10.1186/s40035-022-00315-z",
    "url": "",
    "authors": [
      "Li, Lanlan",
      "Yu, Xianfeng",
      "Sheng, Can",
      "Jiang, Xueyan",
      "Zhang, Qi",
      "Han, Ying",
      "Jiang, Jiehui"
    ],
    "publicationDate": "2022-09-15",
    "publicationName": "Translational Neurodegeneration",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Alzheimer’s disease (AD) is a progressive neurodegenerative disease with phenotypic changes closely associated with both genetic variants and imaging pathology. Brain imaging biomarker genomics has been developed in recent years to reveal potential AD pathological mechanisms and provide early diagnoses. This technique integrates multimodal imaging phenotypes with genetic data in a noninvasive and high-throughput manner. In this review, we summarize the basic analytical framework of brain imaging biomarker genomics and elucidate two main implementation scenarios of this technique in AD studies: (1) exploring novel biomarkers and seeking mutual interpretability and (2) providing a diagnosis and prognosis for AD with combined use of machine learning methods and brain imaging biomarker genomics. Importantly, we highlight the necessity of brain imaging biomarker genomics, discuss the strengths and limitations of current methods, and propose directions for development of this research field."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "scDART: integrating unmatched scRNA-seq and scATAC-seq data and learning cross-modality relationship simultaneously",
    "doi": "10.1186/s13059-022-02706-x",
    "url": "",
    "authors": [
      "Zhang, Ziqi",
      "Yang, Chengkai",
      "Zhang, Xiuwei"
    ],
    "publicationDate": "2022-06-27",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "It is a challenging task to integrate scRNA-seq and scATAC-seq data obtained from different batches. Existing methods tend to use a pre-defined gene activity matrix to convert the scATAC-seq data into scRNA-seq data. The pre-defined gene activity matrix is often of low quality and does not reflect the dataset-specific relationship between the two data modalities. We propose scDART, a deep learning framework that integrates scRNA-seq and scATAC-seq data and learns cross-modalities relationships simultaneously. Specifically, the design of scDART allows it to preserve cell trajectories in continuous cell populations and can be applied to trajectory inference on integrated data."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "A deep generative model for multi-view profiling of single-cell RNA-seq and ATAC-seq data",
    "doi": "10.1186/s13059-021-02595-6",
    "url": "",
    "authors": [
      "Li, Gaoyang",
      "Fu, Shaliu",
      "Wang, Shuguang",
      "Zhu, Chenyu",
      "Duan, Bin",
      "Tang, Chen",
      "Chen, Xiaohan",
      "Chuai, Guohui",
      "Wang, Ping",
      "Liu, Qi"
    ],
    "publicationDate": "2022-01-12",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Here, we present a multi-modal deep generative model, the single-cell Multi-View Profiler (scMVP), which is designed for handling sequencing data that simultaneously measure gene expression and chromatin accessibility in the same cell, including SNARE-seq, sci-CAR, Paired-seq, SHARE-seq, and Multiome from 10X Genomics. scMVP generates common latent representations for dimensionality reduction, cell clustering, and developmental trajectory inference and generates separate imputations for differential analysis and cis-regulatory element identification. scMVP can help mitigate data sparsity issues with imputation and accurately identify cell groups for different joint profiling techniques with common latent embedding, and we demonstrate its advantages on several realistic datasets."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Lerna: transformer architectures for configuring error correction tools for short- and long-read genome sequencing",
    "doi": "10.1186/s12859-021-04547-0",
    "url": "",
    "authors": [
      "Sharma, Atul",
      "Jain, Pranjal",
      "Mahgoub, Ashraf",
      "Zhou, Zihan",
      "Mahadik, Kanak",
      "Chaterji, Somali"
    ],
    "publicationDate": "2022-01-06",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Sequencing technologies are prone to errors, making error correction (EC) necessary for downstream applications. EC tools need to be manually configured for optimal performance. We find that the optimal parameters (e.g., k -mer size) are both tool- and dataset-dependent. Moreover, evaluating the performance (i.e., Alignment-rate or Gain) of a given tool usually relies on a reference genome, but quality reference genomes are not always available. We introduce Lerna for the automated configuration of k -mer-based EC tools. Lerna first creates a language model (LM) of the uncorrected genomic reads, and then, based on this LM, calculates a metric called the perplexity metric to evaluate the corrected reads for different parameter choices. Next, it finds the one that produces the highest alignment rate without using a reference genome. The fundamental intuition of our approach is that the perplexity metric is inversely correlated with the quality of the assembly after error correction. Therefore, Lerna leverages the perplexity metric for automated tuning of k -mer sizes without needing a reference genome.",
        "Results",
        "First, we show that the best k -mer value can vary for different datasets, even for the same EC tool. This motivates our design that automates k -mer size selection without using a reference genome. Second, we show the gains of our LM using its component attention-based transformers. We show the model’s estimation of the perplexity metric before and after error correction. The lower the perplexity after correction, the better the k -mer size. We also show that the alignment rate and assembly quality computed for the corrected reads are strongly negatively correlated with the perplexity, enabling the automated selection of k -mer values for better error correction, and hence, improved assembly quality. We validate our approach on both short and long reads. Additionally, we show that our attention-based models have significant runtime improvement for the entire pipeline—18 $$\\times$$ × faster than previous works, due to parallelizing the attention mechanism and the use of JIT compilation for GPU inferencing.",
        "Conclusion",
        "Lerna improves de novo genome assembly by optimizing EC tools. Our code is made available in a public repository at: https://github.com/icanforce/lerna-genomics ."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Mapping single-cell data to reference atlases by transfer learning",
    "doi": "10.1038/s41587-021-01001-7",
    "url": "",
    "authors": [
      "Lotfollahi, Mohammad",
      "Naghipourfar, Mohsen",
      "Luecken, Malte D.",
      "Khajavi, Matin",
      "Büttner, Maren",
      "Wagenstetter, Marco",
      "Avsec, Žiga",
      "Gayoso, Adam",
      "Yosef, Nir",
      "Interlandi, Marta",
      "Rybakov, Sergei",
      "Misharin, Alexander V.",
      "Theis, Fabian J."
    ],
    "publicationDate": "2022-01-01",
    "publicationName": "Nature Biotechnology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Large single-cell atlases are now routinely generated to serve as references for analysis of smaller-scale studies. Yet learning from reference data is complicated by batch effects between datasets, limited availability of computational resources and sharing restrictions on raw data. Here we introduce a deep learning strategy for mapping query datasets on top of a reference called single-cell architectural surgery (scArches). scArches uses transfer learning and parameter optimization to enable efficient, decentralized, iterative reference building and contextualization of new datasets with existing references without sharing raw data. Using examples from mouse brain, pancreas, immune and whole-organism atlases, we show that scArches preserves biological state information while removing batch effects, despite using four orders of magnitude fewer parameters than de novo integration. scArches generalizes to multimodal reference mapping, allowing imputation of missing modalities. Finally, scArches retains coronavirus disease 2019 (COVID-19) disease variation when mapping to a healthy reference, enabling the discovery of disease-specific cell states. scArches will facilitate collaborative projects by enabling iterative construction, updating, sharing and efficient use of reference atlases.",
        "Single-cell data are readily integrated with cell atlases using scArches."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Deep learning and alignment of spatially resolved single-cell transcriptomes with Tangram",
    "doi": "10.1038/s41592-021-01264-7",
    "url": "",
    "authors": [
      "Biancalani, Tommaso",
      "Scalia, Gabriele",
      "Buffoni, Lorenzo",
      "Avasthi, Raghav",
      "Lu, Ziqing",
      "Sanger, Aman",
      "Tokcan, Neriman",
      "Vanderburg, Charles R.",
      "Segerstolpe, Åsa",
      "Zhang, Meng",
      "Avraham-Davidi, Inbal",
      "Vickovic, Sanja",
      "Nitzan, Mor",
      "Ma, Sai",
      "Subramanian, Ayshwarya",
      "Lipinski, Michal",
      "Buenrostro, Jason",
      "Brown, Nik Bear",
      "Fanelli, Duccio",
      "Zhuang, Xiaowei",
      "Macosko, Evan Z.",
      "Regev, Aviv"
    ],
    "publicationDate": "2021-11-01",
    "publicationName": "Nature Methods",
    "contentType": "Article",
    "abstract": {
      "p": "Charting an organs’ biological atlas requires us to spatially resolve the entire single-cell transcriptome, and to relate such cellular features to the anatomical scale. Single-cell and single-nucleus RNA-seq (sc/snRNA-seq) can profile cells comprehensively, but lose spatial information. Spatial transcriptomics allows for spatial measurements, but at lower resolution and with limited sensitivity. Targeted in situ technologies solve both issues, but are limited in gene throughput. To overcome these limitations we present Tangram, a method that aligns sc/snRNA-seq data to various forms of spatial data collected from the same region, including MERFISH, STARmap, smFISH, Spatial Transcriptomics (Visium) and histological images. Tangram can map any type of sc/snRNA-seq data, including multimodal data such as those from SHARE-seq, which we used to reveal spatial patterns of chromatin accessibility. We demonstrate Tangram on healthy mouse brain tissue, by reconstructing a genome-wide anatomically integrated spatial map at single-cell resolution of the visual and somatomotor areas.",
      "h1": "Abstract"
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Structural and functional radiomics for lung cancer",
    "doi": "10.1007/s00259-021-05242-1",
    "url": "",
    "authors": [
      "Wu, Guangyao",
      "Jochems, Arthur",
      "Refaee, Turkey",
      "Ibrahim, Abdalla",
      "Yan, Chenggong",
      "Sanduleanu, Sebastian",
      "Woodruff, Henry C.",
      "Lambin, Philippe"
    ],
    "publicationDate": "2021-11-01",
    "publicationName": "European Journal of Nuclear Medicine and Molecular Imaging",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Introduction",
        "Lung cancer ranks second in new cancer cases and first in cancer-related deaths worldwide. Precision medicine is working on altering treatment approaches and improving outcomes in this patient population. Radiological images are a powerful non-invasive tool in the screening and diagnosis of early-stage lung cancer, treatment strategy support, prognosis assessment, and follow-up for advanced-stage lung cancer. Recently, radiological features have evolved from solely semantic to include (handcrafted and deep) radiomic features. Radiomics entails the extraction and analysis of quantitative features from medical images using mathematical and machine learning methods to explore possible ties with biology and clinical outcomes.",
        "Methods",
        "Here, we outline the latest applications of both structural and functional radiomics in detection, diagnosis, and prediction of pathology, gene mutation, treatment strategy, follow-up, treatment response evaluation, and prognosis in the field of lung cancer.",
        "Conclusion",
        "The major drawbacks of radiomics are the lack of large datasets with high-quality data, standardization of methodology, the black-box nature of deep learning, and reproducibility. The prerequisite for the clinical implementation of radiomics is that these limitations are addressed. Future directions include a safer and more efficient model-training mode, merge multi-modality images, and combined multi-discipline or multi-omics to form “Medomics.”"
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Deep GONet: self-explainable deep neural network based on Gene Ontology for phenotype prediction from gene expression data",
    "doi": "10.1186/s12859-021-04370-7",
    "url": "",
    "authors": [
      "Bourgeais, Victoria",
      "Zehraoui, Farida",
      "Ben Hamdoune, Mohamed",
      "Hanczar, Blaise"
    ],
    "publicationDate": "2021-09-22",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "With the rapid advancement of genomic sequencing techniques, massive production of gene expression data is becoming possible, which prompts the development of precision medicine. Deep learning is a promising approach for phenotype prediction (clinical diagnosis, prognosis, and drug response) based on gene expression profile. Existing deep learning models are usually considered as black-boxes that provide accurate predictions but are not interpretable. However, accuracy and interpretation are both essential for precision medicine. In addition, most models do not integrate the knowledge of the domain. Hence, making deep learning models interpretable for medical applications using prior biological knowledge is the main focus of this paper.",
        "Results",
        "In this paper, we propose a new self-explainable deep learning model, called Deep GONet, integrating the Gene Ontology into the hierarchical architecture of the neural network. This model is based on a fully-connected architecture constrained by the Gene Ontology annotations, such that each neuron represents a biological function. The experiments on cancer diagnosis datasets demonstrate that Deep GONet is both easily interpretable and highly performant to discriminate cancer and non-cancer samples.",
        "Conclusions",
        "Our model provides an explanation to its predictions by identifying the most important neurons and associating them with biological functions, making the model understandable for biologists and physicians."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "AttentionDDI: Siamese attention-based deep learning method for drug–drug interaction predictions",
    "doi": "10.1186/s12859-021-04325-y",
    "url": "",
    "authors": [
      "Schwarz, Kyriakos",
      "Allam, Ahmed",
      "Perez Gonzalez, Nicolas Andres",
      "Krauthammer, Michael"
    ],
    "publicationDate": "2021-08-21",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Drug–drug interactions (DDIs) refer to processes triggered by the administration of two or more drugs leading to side effects beyond those observed when drugs are administered by themselves. Due to the massive number of possible drug pairs, it is nearly impossible to experimentally test all combinations and discover previously unobserved side effects. Therefore, machine learning based methods are being used to address this issue.",
        "Methods",
        "We propose a Siamese self-attention multi-modal neural network for DDI prediction that integrates multiple drug similarity measures that have been derived from a comparison of drug characteristics including drug targets, pathways and gene expression profiles.",
        "Results",
        "Our proposed DDI prediction model provides multiple advantages: (1) It is trained end-to-end, overcoming limitations of models composed of multiple separate steps, (2) it offers model explainability via an Attention mechanism for identifying salient input features and (3) it achieves similar or better prediction performance (AUPR scores ranging from 0.77 to 0.92) compared to state-of-the-art DDI models when tested on various benchmark datasets. Novel DDI predictions are further validated using independent data resources.",
        "Conclusions",
        "We find that a Siamese multi-modal neural network is able to accurately predict DDIs and that an Attention mechanism, typically used in the Natural Language Processing domain, can be beneficially applied to aid in DDI model explainability."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Single-cell classification using graph convolutional networks",
    "doi": "10.1186/s12859-021-04278-2",
    "url": "",
    "authors": [
      "Wang, Tianyu",
      "Bai, Jun",
      "Nabavi, Sheida"
    ],
    "publicationDate": "2021-07-08",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Analyzing single-cell RNA sequencing (scRNAseq) data plays an important role in understanding the intrinsic and extrinsic cellular processes in biological and biomedical research. One significant effort in this area is the identification of cell types. With the availability of a huge amount of single cell sequencing data and discovering more and more cell types, classifying cells into known cell types has become a priority nowadays. Several methods have been introduced to classify cells utilizing gene expression data. However, incorporating biological gene interaction networks has been proved valuable in cell classification procedures.",
        "Results",
        "In this study, we propose a multimodal end-to-end deep learning model, named sigGCN, for cell classification that combines a graph convolutional network (GCN) and a neural network to exploit gene interaction networks. We used standard classification metrics to evaluate the performance of the proposed method on the within-dataset classification and the cross-dataset classification. We compared the performance of the proposed method with those of the existing cell classification tools and traditional machine learning classification methods.",
        "Conclusions",
        "Results indicate that the proposed method outperforms other commonly used methods in terms of classification accuracy and F1 scores. This study shows that the integration of prior knowledge about gene interactions with gene expressions using GCN methodologies can extract effective features improving the performance of cell classification."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Predicting dynamic cellular protein–RNA interactions by deep learning using in vivo RNA structures",
    "doi": "10.1038/s41422-021-00476-y",
    "url": "",
    "authors": [
      "Sun, Lei",
      "Xu, Kui",
      "Huang, Wenze",
      "Yang, Yucheng T.",
      "Li, Pan",
      "Tang, Lei",
      "Xiong, Tuanlin",
      "Zhang, Qiangfeng Cliff"
    ],
    "publicationDate": "2021-05-01",
    "publicationName": "Cell Research",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Interactions with RNA-binding proteins (RBPs) are integral to RNA function and cellular regulation, and dynamically reflect specific cellular conditions. However, presently available tools for predicting RBP–RNA interactions employ RNA sequence and/or predicted RNA structures, and therefore do not capture their condition-dependent nature. Here, after profiling transcriptome-wide in vivo RNA secondary structures in seven cell types, we developed PrismNet, a deep learning tool that integrates experimental in vivo RNA structure data and RBP binding data for matched cells to accurately predict dynamic RBP binding in various cellular conditions. PrismNet results for 168 RBPs support its utility for both understanding CLIP-seq results and largely extending such interaction data to accurately analyze additional cell types. Further, PrismNet employs an “attention” strategy to computationally identify exact RBP-binding nucleotides, and we discovered enrichment among dynamic RBP-binding sites for structure-changing variants (riboSNitches), which can link genetic diseases with dysregulated RBP bindings. Our rich profiling data and deep learning-based prediction tool provide access to a previously inaccessible layer of cell-type-specific RBP–RNA interactions, with clear utility for understanding and treating human diseases."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "scGNN is a novel graph neural network framework for single-cell RNA-Seq analyses",
    "doi": "10.1038/s41467-021-22197-x",
    "url": "",
    "authors": [
      "Wang, Juexin",
      "Ma, Anjun",
      "Chang, Yuzhou",
      "Gong, Jianting",
      "Jiang, Yuexu",
      "Qi, Ren",
      "Wang, Cankun",
      "Fu, Hongjun",
      "Ma, Qin",
      "Xu, Dong"
    ],
    "publicationDate": "2021-03-25",
    "publicationName": "Nature Communications",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Single-cell RNA-sequencing (scRNA-Seq) is widely used to reveal the heterogeneity and dynamics of tissues, organisms, and complex diseases, but its analyses still suffer from multiple grand challenges, including the sequencing sparsity and complex differential patterns in gene expression. We introduce the scGNN (single-cell graph neural network) to provide a hypothesis-free deep learning framework for scRNA-Seq analyses. This framework formulates and aggregates cell–cell relationships with graph neural networks and models heterogeneous gene expression patterns using a left-truncated mixture Gaussian model. scGNN integrates three iterative multi-modal autoencoders and outperforms existing tools for gene imputation and cell clustering on four benchmark scRNA-Seq datasets. In an Alzheimer’s disease study with 13,214 single nuclei from postmortem brain tissues, scGNN successfully illustrated disease-related neural development and the differential mechanism. scGNN provides an effective representation of gene expression and cell–cell relationships. It is also a powerful framework that can be applied to general scRNA-Seq analyses.",
        "Single-cell RNA-Seq suffers from heterogeneity in sequencing sparsity and complex differential patterns in gene expression. Here, the authors introduce a graph neural network based on a hypothesis-free deep learning framework as an effective representation of gene expression and cell–cell relationships."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "DASSI: differential architecture search for splice identification from DNA sequences",
    "doi": "10.1186/s13040-021-00237-y",
    "url": "",
    "authors": [
      "Moosa, Shabir",
      "Amira, Prof. Abbes",
      "Boughorbel, Dr. Sabri"
    ],
    "publicationDate": "2021-02-15",
    "publicationName": "BioData Mining",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "The data explosion caused by unprecedented advancements in the field of genomics is constantly challenging the conventional methods used in the interpretation of the human genome. The demand for robust algorithms over the recent years has brought huge success in the field of Deep Learning (DL) in solving many difficult tasks in image, speech and natural language processing by automating the manual process of architecture design. This has been fueled through the development of new DL architectures. Yet genomics possesses unique challenges that requires customization and development of new DL models.",
        "Methods",
        "We proposed a new model, DASSI, by adapting a differential architecture search method and applying it to the Splice Site (SS) recognition task on DNA sequences to discover new high-performance convolutional architectures in an automated manner. We evaluated the discovered model against state-of-the-art tools to classify true and false SS in Homo sapiens (Human), Arabidopsis thaliana (Plant), Caenorhabditis elegans (Worm) and Drosophila melanogaster (Fly).",
        "Results",
        "Our experimental evaluation demonstrated that the discovered architecture outperformed baseline models and fixed architectures and showed competitive results against state-of-the-art models used in classification of splice sites. The proposed model - DASSI has a compact architecture and showed very good results on a transfer learning task. The benchmarking experiments of execution time and precision on architecture search and evaluation process showed better performance on recently available GPUs making it feasible to adopt architecture search based methods on large datasets.",
        "Conclusions",
        "We proposed the use of differential architecture search method (DASSI) to perform SS classification on raw DNA sequences, and discovered new neural network models with low number of tunable parameters and competitive performance compared with manually engineered architectures. We have extensively benchmarked DASSI model with other state-of-the-art models and assessed its computational efficiency. The results have shown a high potential of using automated architecture search mechanism for solving various problems in the field of genomics."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Self-organizing maps with variable neighborhoods facilitate learning of chromatin accessibility signal shapes associated with regulatory elements",
    "doi": "10.1186/s12859-021-03976-1",
    "url": "",
    "authors": [
      "Eicher, Tara",
      "Chan, Jany",
      "Luu, Han",
      "Machiraju, Raghu",
      "Mathé, Ewy A."
    ],
    "publicationDate": "2021-01-30",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Assigning chromatin states genome-wide (e.g. promoters, enhancers, etc.) is commonly performed to improve functional interpretation of these states. However, computational methods to assign chromatin state suffer from the following drawbacks: they typically require data from multiple assays, which may not be practically feasible to obtain, and they depend on peak calling algorithms, which require careful parameterization and often exclude the majority of the genome. To address these drawbacks, we propose a novel learning technique built upon the Self-Organizing Map (SOM), Self-Organizing Map with Variable Neighborhoods (SOM-VN), to learn a set of representative shapes from a single, genome-wide, chromatin accessibility dataset to associate with a chromatin state assignment in which a particular RE is prevalent. These shapes can then be used to assign chromatin state using our workflow.",
        "Results",
        "We validate the performance of the SOM-VN workflow on 14 different samples of varying quality, namely one assay each of A549 and GM12878 cell lines and two each of H1 and HeLa cell lines, primary B-cells, and brain, heart, and stomach tissue. We show that SOM-VN learns shapes that are (1) non-random, (2) associated with known chromatin states, (3) generalizable across sets of chromosomes, and (4) associated with magnitude and multimodality. We compare the accuracy of SOM-VN chromatin states against the Clustering Aggregation Tool (CAGT), an unsupervised method that learns chromatin accessibility signal shapes but does not associate these shapes with REs, and we show that overall precision and recall is increased when learning shapes using SOM-VN as compared to CAGT. We further compare enhancer state assignments from SOM-VN in signals above a set threshold to enhancer state assignments from Predicting Enhancers from ATAC-seq Data (PEAS), a deep learning method that assigns enhancer chromatin states to peaks. We show that the precision-recall area under the curve for the assignment of enhancer states is comparable to PEAS.",
        "Conclusions",
        "Our work shows that the SOM-VN workflow can learn relationships between REs and chromatin accessibility signal shape, which is an important step toward the goal of assigning and comparing enhancer state across multiple experiments and phenotypic states."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Classification and specific primer design for accurate detection of SARS-CoV-2 using deep learning",
    "doi": "10.1038/s41598-020-80363-5",
    "url": "",
    "authors": [
      "Lopez-Rincon, Alejandro",
      "Tonda, Alberto",
      "Mendoza-Maldonado, Lucero",
      "Mulders, Daphne G. J. C.",
      "Molenkamp, Richard",
      "Perez-Romero, Carmina A.",
      "Claassen, Eric",
      "Garssen, Johan",
      "Kraneveld, Aletta D."
    ],
    "publicationDate": "2021-01-13",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "In this paper, deep learning is coupled with explainable artificial intelligence techniques for the discovery of representative genomic sequences in SARS-CoV-2. A convolutional neural network classifier is first trained on 553 sequences from the National Genomics Data Center repository, separating the genome of different virus strains from the Coronavirus family with 98.73% accuracy. The network’s behavior is then analyzed, to discover sequences used by the model to identify SARS-CoV-2, ultimately uncovering sequences exclusive to it. The discovered sequences are validated on samples from the National Center for Biotechnology Information and Global Initiative on Sharing All Influenza Data repositories, and are proven to be able to separate SARS-CoV-2 from different virus strains with near-perfect accuracy. Next, one of the sequences is selected to generate a primer set, and tested against other state-of-the-art primer sets, obtaining competitive results. Finally, the primer is synthesized and tested on patient samples (n = 6 previously tested positive), delivering a sensitivity similar to routine diagnostic methods, and 100% specificity. The proposed methodology has a substantial added value over existing methods, as it is able to both automatically identify promising primer sets for a virus from a limited amount of data, and deliver effective results in a minimal amount of time. Considering the possibility of future pandemics, these characteristics are invaluable to promptly create specific detection methods for diagnostics."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "DNA sequences performs as natural language processing by exploiting deep learning algorithm for the identification of N4-methylcytosine",
    "doi": "10.1038/s41598-020-80430-x",
    "url": "",
    "authors": [
      "Wahab, Abdul",
      "Tayara, Hilal",
      "Xuan, Zhenyu",
      "Chong, Kil To"
    ],
    "publicationDate": "2021-01-08",
    "publicationName": "Scientific Reports",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "N4-methylcytosine is a biochemical alteration of DNA that affects the genetic operations without modifying the DNA nucleotides such as gene expression, genomic imprinting, chromosome stability, and the development of the cell. In the proposed work, a computational model, 4mCNLP-Deep, used the word embedding approach as a vector formulation by exploiting deep learning based CNN algorithm to predict 4mC and non-4mC sites on the C.elegans genome dataset. Diversity of ranges employed for the experimental such as corpus k-mer and k-fold cross-validation to obtain the prevailing capabilities. The 4mCNLP-Deep outperform from the state-of-the-art predictor by achieving the results in five evaluation metrics by following; Accuracy (ACC) as 0.9354, Mathew’s correlation coefficient (MCC) as 0.8608, Specificity (Sp) as 0.89.96, Sensitivity (Sn) as 0.9563, and Area under curve (AUC) as 0.9731 by using 3-mer corpus word2vec and 3-fold cross-validation and attained the increment of 1.1%, 0.6%, 0.58%, 0.77%, and 4.89%, respectively. At last, we developed the online webserver http://nsclbio.jbnu.ac.kr/tools/4mCNLP-Deep/ , for the experimental researchers to get the results easily."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Deep learning based feature-level integration of multi-omics data for breast cancer patients survival analysis",
    "doi": "10.1186/s12911-020-01225-8",
    "url": "",
    "authors": [
      "Tong, Li",
      "Mitchel, Jonathan",
      "Chatlin, Kevin",
      "Wang, May D."
    ],
    "publicationDate": "2020-09-15",
    "publicationName": "BMC Medical Informatics and Decision Making",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Breast cancer is the most prevalent and among the most deadly cancers in females. Patients with breast cancer have highly variable survival lengths, indicating a need to identify prognostic biomarkers for personalized diagnosis and treatment. With the development of new technologies such as next-generation sequencing, multi-omics information are becoming available for a more thorough evaluation of a patient’s condition. In this study, we aim to improve breast cancer overall survival prediction by integrating multi-omics data (e.g., gene expression, DNA methylation, miRNA expression, and copy number variations (CNVs)).",
        "Methods",
        "Motivated by multi-view learning, we propose a novel strategy to integrate multi-omics data for breast cancer survival prediction by applying complementary and consensus principles. The complementary principle assumes each -omics data contains modality-unique information. To preserve such information, we develop a concatenation autoencoder (ConcatAE) that concatenates the hidden features learned from each modality for integration. The consensus principle assumes that the disagreements among modalities upper bound the model errors. To get rid of the noises or discrepancies among modalities, we develop a cross-modality autoencoder (CrossAE) to maximize the agreement among modalities to achieve a modality-invariant representation. We first validate the effectiveness of our proposed models on the MNIST simulated data. We then apply these models to the TCCA breast cancer multi-omics data for overall survival prediction.",
        "Results",
        "For breast cancer overall survival prediction, the integration of DNA methylation and miRNA expression achieves the best overall performance of 0.641 ± 0.031 with ConcatAE, and 0.63 ± 0.081 with CrossAE. Both strategies outperform baseline single-modality models using only DNA methylation (0.583 ± 0.058) or miRNA expression (0.616 ± 0.057).",
        "Conclusions",
        "In conclusion, we achieve improved overall survival prediction performance by utilizing either the complementary or consensus information among multi-omics data. The proposed ConcatAE and CrossAE models can inspire future deep representation-based multi-omics integration techniques. We believe these novel multi-omics integration models can benefit the personalized diagnosis and treatment of breast cancer patients."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Predicting antigen specificity of single T cells based on TCR CDR3 regions",
    "doi": "10.15252/msb.20199416",
    "url": "",
    "authors": [
      "Fischer, David S",
      "Wu, Yihan",
      "Schubert, Benjamin",
      "Theis, Fabian J"
    ],
    "publicationDate": "2020-08-11",
    "publicationName": "Molecular Systems Biology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "It has recently become possible to simultaneously assay T‐cell specificity with respect to large sets of antigens and the T‐cell receptor sequence in high‐throughput single‐cell experiments. Leveraging this new type of data, we propose and benchmark a collection of deep learning architectures to model T‐cell specificity in single cells. In agreement with previous results, we found that models that treat antigens as categorical outcome variables outperform those that model the TCR and antigen sequence jointly. Moreover, we show that variability in single‐cell immune repertoire screens can be mitigated by modeling cell‐specific covariates. Lastly, we demonstrate that the number of bound pMHC complexes can be predicted in a continuous fashion providing a gateway to disentangle cell‐to‐dextramer binding strength and receptor‐to‐pMHC affinity. We provide these models in the Python package TcellMatch to allow imputation of antigen specificities in single‐cell RNA‐seq studies on T cells without the need for MHC staining."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Enhanced Integrated Gradients: improving interpretability of deep learning models using splicing codes as a case study",
    "doi": "10.1186/s13059-020-02055-7",
    "url": "",
    "authors": [
      "Jha, Anupama",
      "K. Aicher, Joseph",
      "R. Gazzara, Matthew",
      "Singh, Deependra",
      "Barash, Yoseph"
    ],
    "publicationDate": "2020-06-19",
    "publicationName": "Genome Biology",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "Despite the success and fast adaptation of deep learning models in biomedical domains, their lack of interpretability remains an issue. Here, we introduce Enhanced Integrated Gradients (EIG), a method to identify significant features associated with a specific prediction task. Using RNA splicing prediction as well as digit classification as case studies, we demonstrate that EIG improves upon the original Integrated Gradients method and produces sets of informative features. We then apply EIG to identify A1CF as a key regulator of liver-specific alternative splicing, supporting this finding with subsequent analysis of relevant A1CF functional (RNA-seq) and binding data (PAR-CLIP)."
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Deconvolution of autoencoders to learn biological regulatory modules from single cell mRNA sequencing data",
    "doi": "10.1186/s12859-019-2952-9",
    "url": "",
    "authors": [
      "Kinalis, Savvas",
      "Nielsen, Finn Cilius",
      "Winther, Ole",
      "Bagger, Frederik Otzen"
    ],
    "publicationDate": "2019-07-08",
    "publicationName": "BMC Bioinformatics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": [
        "Background",
        "Unsupervised machine learning methods (deep learning) have shown their usefulness with noisy single cell mRNA-sequencing data (scRNA-seq), where the models generalize well, despite the zero-inflation of the data. A class of neural networks, namely autoencoders, has been useful for denoising of single cell data, imputation of missing values and dimensionality reduction.",
        "Results",
        "Here, we present a striking feature with the potential to greatly increase the usability of autoencoders: With specialized training, the autoencoder is not only able to generalize over the data, but also to tease apart biologically meaningful modules, which we found encoded in the representation layer of the network. Our model can, from scRNA-seq data, delineate biological meaningful modules that govern a dataset, as well as give information as to which modules are active in each single cell. Importantly, most of these modules can be explained by known biological functions, as provided by the Hallmark gene sets.",
        "Conclusions",
        "We discover that tailored training of an autoencoder makes it possible to deconvolute biological modules inherent in the data, without any assumptions. By comparisons with gene signatures of canonical pathways we see that the modules are directly interpretable. The scope of this discovery has important implications, as it makes it possible to outline the drivers behind a given effect of a cell. In comparison with other dimensionality reduction methods, or supervised models for classification, our approach has the benefit of both handling well the zero-inflated nature of scRNA-seq, and validating that the model captures relevant information, by establishing a link between input and decoded data. In perspective, our model in combination with clustering methods is able to provide information about which subtype a given single cell belongs to, as well as which biological functions determine that membership."
      ]
    },
    "openaccess": "true"
  },
  {
    "source": "springernature",
    "api": "openaccess",
    "title": "Translating cancer genomics into precision medicine with artificial intelligence: applications, challenges and future perspectives",
    "doi": "10.1007/s00439-019-01970-5",
    "url": "",
    "authors": [
      "Xu, Jia",
      "Yang, Pengwei",
      "Xue, Shang",
      "Sharma, Bhuvan",
      "Sanchez-Martin, Marta",
      "Wang, Fang",
      "Beaty, Kirk A.",
      "Dehan, Elinor",
      "Parikh, Baiju"
    ],
    "publicationDate": "2019-02-08",
    "publicationName": "Human Genetics",
    "contentType": "Article",
    "abstract": {
      "h1": "Abstract",
      "p": "In the field of cancer genomics, the broad availability of genetic information offered by next-generation sequencing technologies and rapid growth in biomedical publication has led to the advent of the big-data era. Integration of artificial intelligence (AI) approaches such as machine learning, deep learning, and natural language processing (NLP) to tackle the challenges of scalability and high dimensionality of data and to transform big data into clinically actionable knowledge is expanding and becoming the foundation of precision medicine. In this paper, we review the current status and future directions of AI application in cancer genomics within the context of workflows to integrate genomic analysis for precision cancer care. The existing solutions of AI and their limitations in cancer genetic testing and diagnostics such as variant calling and interpretation are critically analyzed. Publicly available tools or algorithms for key NLP technologies in the literature mining for evidence-based clinical recommendations are reviewed and compared. In addition, the present paper highlights the challenges to AI adoption in digital healthcare with regard to data requirements, algorithmic transparency, reproducibility, and real-world assessment, and discusses the importance of preparing patients and physicians for modern digitized healthcare. We believe that AI will remain the main driver to healthcare transformation toward precision medicine, yet the unprecedented challenges posed should be addressed to ensure safety and beneficial impact to healthcare."
    },
    "openaccess": "true"
  }
]