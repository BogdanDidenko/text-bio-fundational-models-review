[
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Single-cell foundation models: bringing artificial intelligence into cell biology",
    "authors": [
      "S Baek",
      "K Song",
      "I Lee"
    ],
    "year": "2025",
    "abstract": "scFM as a large language model for single-cell biology  -seq) data, learning from gene  expression matrices. However,  of single-cell genomics and AI as a foundation model thus stands",
    "venue": "Experimental & Molecular Medicine",
    "url": "https://www.nature.com/articles/s12276-025-01547-5",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=16680933151275431048&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CELLama: foundation model for single cell and spatial transcriptomics by cell embedding leveraging language model abilities",
    "authors": [
      "J Park",
      "S Kim",
      "J Kim",
      "D Lee",
      "S Bae",
      "H Shin"
    ],
    "year": "2024",
    "abstract": "This feature allows for the creation of flexible sentences from single-cell  gene expression  data and various metadata. A key distinction between CELLama and existing foundation model",
    "venue": "Advanced …",
    "url": "https://advanced.onlinelibrary.wiley.com/doi/abs/10.1002/advs.202513210",
    "num_citations": 13,
    "citedby_url": "/scholar?cites=12998093352871555518&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Large-scale foundation model on single-cell transcriptomics",
    "authors": [
      "M Hao",
      "J Gong",
      "X Zeng",
      "C Liu",
      "Y Guo",
      "X Cheng"
    ],
    "year": "2024",
    "abstract": "We trained the model with an RDA gene expression prediction task. For each raw  pretraining single-cell gene expression vector, we used a hierarchical Bayesian downsampling",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41592-024-02305-7",
    "num_citations": 514,
    "citedby_url": "/scholar?cites=3502489894628727473&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "General-purpose pre-trained large cellular models for single-cell transcriptomics",
    "authors": [
      "H Bian",
      "Y Chen",
      "E Luo",
      "X Wu",
      "M Hao"
    ],
    "year": "2024",
    "abstract": "-based LCM or foundation model for single-cell transcriptomics.  It used the pretrained  protein language model ESM2 [16] to  Since single-cell gene expression lacks a natural order,",
    "venue": "National Science …",
    "url": "https://academic.oup.com/nsr/article-abstract/11/11/nwae340/7775526",
    "num_citations": 15,
    "citedby_url": "/scholar?cites=1146354247990101586&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "BioLLM: A standardized framework for integrating and benchmarking single-cell foundation models",
    "authors": [
      "P Qiu",
      "Q Chen",
      "H Qin",
      "S Fang",
      "Y Zhang",
      "Y Zhang",
      "T Xia"
    ],
    "year": "2025",
    "abstract": "BioLLM (biological large language model), a unified  At the core of BioLLM lies its foundation  model loader, which  , we focused on leveraging gene expression data from the CCLE",
    "venue": "Patterns",
    "url": "https://www.cell.com/patterns/fulltext/S2666-3899(25)00174-6",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=5803519370297508502&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "RegFormer: A Single-Cell Foundation Model Powered by Gene Regulatory Hierarchies",
    "authors": [
      "L Hu",
      "H Qin",
      "Y Zhang",
      "Y Lu",
      "P Qiu",
      "Z Guo",
      "L Cao"
    ],
    "year": "2025",
    "abstract": "modeling to learn the regulatory principles underlying single-cell gene expression.  -scale  pretrained deep language model for cell type annotation of single-cell RNA-seq data.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.01.24.634217.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Fundamental Limitations of Foundation Models in Single-Cell Transcriptomics",
    "authors": [
      "S Atti",
      "S Subramaniam"
    ],
    "year": "2025",
    "abstract": "by foundation models for single-cell tasks consistently 15  controlled Gaussian noise to  gene expression values before  ability of each foundation model, we performed test-time 169",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.06.26.661767.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=10156459295034217770&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Towards Applying Large Language Models to Complement Single-Cell Foundation Models",
    "authors": [
      "S Palayew",
      "B Wang",
      "G Bader"
    ],
    "year": "2025",
    "abstract": "training a linear model to accurately predict gene expression from gene rank, and motivates   performance was comparable to this specialized foundation model, and notably much better",
    "venue": "arXiv preprint arXiv:2507.10039",
    "url": "https://arxiv.org/abs/2507.10039",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A survey on foundation language models for single-cell biology",
    "authors": [
      "F Zhang",
      "H Chen",
      "Z Zhu",
      "Z Zhang",
      "Z Lin"
    ],
    "year": "2025",
    "abstract": "scmulan: a multitask generative pre-trained language model for single-cell analysis. In   Geneswitches: ordering gene expression and functional events in single-cell experiments.",
    "venue": "Proceedings of the …",
    "url": "https://aclanthology.org/2025.acl-long.26/",
    "num_citations": 13,
    "citedby_url": "/scholar?cites=7697504443957981277&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Deeper evaluation of a single-cell foundation model",
    "authors": [
      "R Boiarsky",
      "NM Singh",
      "A Buendia",
      "AP Amini"
    ],
    "year": "2024",
    "abstract": "-transformed, library size-normalized gene-expression values in the Zheng68K peripheral  blood  These results highlight the fact that while foundation models for single-cell data are an",
    "venue": "Nature Machine …",
    "url": "https://www.nature.com/articles/s42256-024-00949-w",
    "num_citations": 17,
    "citedby_url": "/scholar?cites=8325305607763556465&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "GenePT: a simple but effective foundation model for genes and cells built from ChatGPT",
    "authors": [
      "Y Chen",
      "J Zou"
    ],
    "year": "2024",
    "abstract": "Gather extensive single-cell gene expression datasets for pretraining the model in a self-  -scale pretrained deep language model for cell type annotation of single-cell RNA-seq data.",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10614824/",
    "num_citations": 124,
    "citedby_url": "/scholar?cites=3116431034009956825&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Single-Cell Language Model for Transcriptomics & Cell Type Annotation",
    "authors": [
      "V Lin"
    ],
    "year": "2025",
    "abstract": "gene expression data. It offers a unified interface to access and download curated single-cell   (sCT) [35], a recently proposed foundation model from InstaDeep for single-cell and spatial",
    "venue": "NA",
    "url": "https://dspace.mit.edu/handle/1721.1/162990",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scGPT: toward building a foundation model for single-cell multi-omics using generative AI",
    "authors": [
      "H Cui",
      "C Wang",
      "H Maan",
      "K Pang",
      "F Luo",
      "N Duan"
    ],
    "year": "2024",
    "abstract": "Specifically, we are interested in two tasks: (1) generating unknown gene expression values  based on known gene expression, that is, generation by ‘gene prompts’, and (2) generating",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41592-024-02201-0",
    "num_citations": 1026,
    "citedby_url": "/scholar?cites=10248781463423403006&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Foundation Models in Omics Research: A Comprehensive Survey",
    "authors": [
      "H Liu",
      "W Cai",
      "Y Sun",
      "H Liu",
      "Z Zou",
      "Q Zhao"
    ],
    "year": "2026",
    "abstract": "biologically coherent foundation model representations.  [37], and increasingly comprehensive  single-cell RNA-seq datasets  through high-dimensional gene expression profiles, spatial",
    "venue": "Authorea …",
    "url": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.176827205.56282524",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Current opinions on large cellular models.",
    "authors": [
      "M Hao",
      "L Wei",
      "F Yang",
      "J Yao"
    ],
    "year": "2024",
    "abstract": "pretrained language model designed to transform single‐cell  BW: scGPT [7] is a single‐cell  foundation model pretrained  single‐cell data are static snapshots of the gene expression at",
    "venue": "Quantitative …",
    "url": "https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=20954689&asa=N&AN=179998244&h=HSnQiPGe0Sx2%2FOTUl6Xwo2pfQp%2Fz0%2BvDyS0WFMhzPG%2FFnSfmDP86fXaPsMcR1BJXlKAcVJEIylA1Me%2BhJg1Zew%3D%3D&crl=c",
    "num_citations": 24,
    "citedby_url": "/scholar?cites=12013858700681595646&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Assessing the limits of zero-shot foundation models in single-cell biology",
    "authors": [
      "KZ Kedzierska",
      "L Crawford",
      "AP Amini",
      "AX Lu"
    ],
    "year": "2023",
    "abstract": "In single-cell biology, the foundation model framework offers  type identification and gene  expression prediction. Emerging  in single-cell biology, particularly in single-cell transcriptomics",
    "venue": "BioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2023.10.16.561085.abstract",
    "num_citations": 58,
    "citedby_url": "/scholar?cites=16757069968936440916&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Towards multimodal foundation models in molecular cell biology",
    "authors": [
      "H Cui",
      "A Tejada-Lapuerta",
      "M Brbić",
      "J Saez-Rodriguez"
    ],
    "year": "2025",
    "abstract": "and diverse data at single-cell resolution and with spatial  by the concept of a foundation  model 21 . The model should thus  -billion parameter language model demonstrating strong few-",
    "venue": "Nature",
    "url": "https://www.nature.com/articles/s41586-025-08710-y",
    "num_citations": 59,
    "citedby_url": "/scholar?cites=15655438271917281808&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Harnessing the Foundation Model for Exploration of Single-cell Expression Atlases in Plants",
    "authors": [
      "G Cao",
      "H Chao",
      "W Zheng",
      "Y Lan",
      "K Lu"
    ],
    "year": "2025",
    "abstract": "(Single-cell Plant Large Language Model), a transformer-based model [6] 72 specifically  designed for the exploration of single-cell  , with corresponding gene expression values. These",
    "venue": "Genomics …",
    "url": "https://academic.oup.com/gpb/advance-article-abstract/doi/10.1093/gpbjnl/qzaf024/8081791",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=9417682848980901173&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scPlantLLM: A Foundation Model for Exploring Single-cell Expression Atlases in Plants.",
    "authors": [
      "W Zheng",
      "Y Lan",
      "K Lu",
      "Y Wang"
    ],
    "year": "2025",
    "abstract": "of gene expression at the single-cell level.  Single-cell Plant Large Language Model (scPlantLLM),  a transformer-based model [7] specifically designed for the exploration of single-cell",
    "venue": "Genomics, Proteomics & …",
    "url": "https://europepmc.org/article/med/40094454",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Biology-driven insights into the power of single-cell foundation models",
    "authors": [
      "J Wu",
      "Q Ye",
      "Y Wang",
      "R Hu",
      "Y Zhu",
      "M Yin",
      "T Wang"
    ],
    "year": "2025",
    "abstract": "to use a complex foundation model versus a simpler  the cell ontology terms and single-cell  transcriptomes into the same  the original gene expression profiles as the input of OnClass.",
    "venue": "Genome Biology",
    "url": "https://link.springer.com/article/10.1186/s13059-025-03781-6",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=13130895211922276630&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scKGBERT: a knowledge-enhanced foundation model for single-cell transcriptomics",
    "authors": [
      "Y Li",
      "G Qiao",
      "H Du",
      "X Gao",
      "G Wang"
    ],
    "year": "2025",
    "abstract": "pre-trained language model designed specifically for single-cell transcriptomic data (Fig. 1).   masks 15% of gene expression tokens from single-cell transcriptomic sequences and learns",
    "venue": "Genome Biology",
    "url": "https://link.springer.com/article/10.1186/s13059-025-03862-6",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Pre-training of single-cell language models through genetic pathway learning",
    "authors": [
      "X Chen",
      "Z Wang",
      "M Zitnik",
      "M Kellis"
    ],
    "year": "2024",
    "abstract": "novel Single-cell Pre-trained Language Model  foundation model pretrained on single-cell  RNA-seq data. We devise several novel techniques that efficiently represent gene expression",
    "venue": "ICML 2024 Workshop on …",
    "url": "https://openreview.net/forum?id=SSpDWhOfUM",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=15237170168904149876&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Foundation Model for Single-Cell Omics",
    "authors": [
      "H Cui"
    ],
    "year": "2024",
    "abstract": "Specifically, we are in- terested in two tasks: (1) generating unknown gene expression  values based on known gene expression, ie, generation by “gene prompts”, and (2) generating",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/3c72c3f28c74f512f25ab6deaad10333/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=13965642030547144573&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CellFM: a large-scale foundation model pre-trained on transcriptomics of 100 million human cells",
    "authors": [
      "Y Zeng",
      "J Xie",
      "N Shangguan",
      "Z Wei",
      "W Li",
      "Y Su"
    ],
    "year": "2025",
    "abstract": "the rich gene expression data in large single-cell datasets,  We proposed a robust single-cell  foundation model CellFM ( -projection-based single-cell foundation model, as it aims to",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41467-025-59926-5",
    "num_citations": 40,
    "citedby_url": "/scholar?cites=3718354092740802942&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Zero-shot evaluation reveals limitations of single-cell foundation models",
    "authors": [
      "KZ Kedzierska",
      "L Crawford",
      "AP Amini",
      "AX Lu"
    ],
    "year": "2025",
    "abstract": "First, it could be that the masked language model  single-cell embeddings. While scGPT  does not outperform averaged bin prediction and struggles with accurate gene expression",
    "venue": "Genome Biology",
    "url": "https://link.springer.com/article/10.1186/s13059-025-03574-x",
    "num_citations": 48,
    "citedby_url": "/scholar?cites=1824608467787037960&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Advancing plant single-cell genomics with foundation models",
    "authors": [
      "TN Chau",
      "X Wang",
      "JM McDowell",
      "S Li"
    ],
    "year": "2024",
    "abstract": "pretraining, BERT employs masked language model pretraining, learning bidirectionally to   , considering gene expression as controlled by related genes and using both single-cell and",
    "venue": "Current Opinion in Plant Biology",
    "url": "https://www.sciencedirect.com/science/article/pii/S1369526624001572",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=1894487773744250231&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Progress and opportunities of foundation models in bioinformatics",
    "authors": [
      "Q Li",
      "Z Hu",
      "Y Wang",
      "L Li",
      "Y Fan",
      "I King"
    ],
    "year": "2024",
    "abstract": "a pretrained protein language model and constructive learning to  Transformer An extensive  single-cell foundation model pre- For instance, gene expression embodies the functional",
    "venue": "Briefings in …",
    "url": "https://academic.oup.com/bib/article-abstract/25/6/bbae548/7842778",
    "num_citations": 49,
    "citedby_url": "/scholar?cites=8041213336260770308&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Deep Embedding Models for Oncology Gene Expression: Investigating Single-cell Foundation Models for Bulk RNA-seq Classification",
    "authors": [
      "C TASSOTTI"
    ],
    "year": "NA",
    "abstract": ", we assessed whether single-cell foundation model embeddings provide an advantage   processing, tGPT operates as an autoregressive language model, predicting each gene in a se",
    "venue": "NA",
    "url": "https://thesis.unipd.it/handle/20.500.12608/94423",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Transformative advances in single-cell omics: a comprehensive review of foundation models, multimodal integration and computational ecosystems",
    "authors": [
      "T Yiu",
      "B Chen",
      "H Wang",
      "G Feng",
      "Q Fu",
      "H Hu"
    ],
    "year": "2025",
    "abstract": "Foundation Model: A pretrained model capturing upregulated and repressed gene expression   Development of ontology-driven annotation tools, supported by language model-assisted",
    "venue": "Journal of Translational …",
    "url": "https://link.springer.com/article/10.1186/s12967-025-07091-0",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Simple and effective embedding model for single-cell biology built from chatgpt",
    "authors": [
      "Y Chen",
      "J Zou"
    ],
    "year": "2025",
    "abstract": "from gene-expression profiles of millions of cells. GenePT shows that large-language-model  embeddings of the literature provide a simple and effective path to encoding single-cell",
    "venue": "Nature biomedical engineering",
    "url": "https://www.nature.com/articles/s41551-024-01284-6",
    "num_citations": 70,
    "citedby_url": "/scholar?cites=16829796221925542956&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A unified framework enables accessible deployment and comprehensive benchmarking of single-cell foundation models",
    "authors": [
      "S Hou",
      "P Yang",
      "W Ma",
      "JX Wang",
      "X Zhou"
    ],
    "year": "2026",
    "abstract": "framework for modeling gene expression patterns, enabling a  is not a transformer-based  foundation model 184 but a large- We employ the all-MiniLM-L6-v2 pretrained language model",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2026.01.06.698060.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Nephrobase Cell+: Multimodal Single-Cell Foundation Model for Decoding Kidney Biology",
    "authors": [
      "C Li",
      "E Ziyadeh",
      "Y Sharma",
      "B Dumoulin"
    ],
    "year": "2025",
    "abstract": "Our model, Nephrobase Cell+, is designed for single-cell gene expression analysis and  cell type classification. It employs Transformer-based encoder-decoder architecture with",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2509.26223",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=853087354874268785&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scDrugMap: Benchmarking Large Foundation Models for Drug Response Prediction",
    "authors": [
      "Q Wang",
      "Y Pan",
      "M Zhou",
      "Z Tang",
      "Y Wang"
    ],
    "year": "2025",
    "abstract": "from single-cell transcriptomic data, we also included a general-purpose foundation model,   To avoid the problem of hallucination caused by too long input in the large language model,",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2505.05612",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=16978127384670928058&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Toward a privacy-preserving predictive foundation model of single-cell transcriptomics with federated learning and tabular modeling",
    "authors": [
      "J Ding",
      "J Lin",
      "S Jiang",
      "Y Wang",
      "Z Miao",
      "Z Fang",
      "J Tang"
    ],
    "year": "2025",
    "abstract": "seq data, often naively converting gene expression within a single cell to gene sequences to  mimic word  large language model techniques originally designed for sequential text data to",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.01.06.631427.abstract",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=6315825685912773863&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Cell-GraphCompass: Modeling Single Cells with Graph Structure Foundation Model",
    "authors": [
      "C Fang",
      "W Cui",
      "Z Hu",
      "W Liu",
      "S Chen"
    ],
    "year": "2025",
    "abstract": "a foundation model 44 for single-cell analysis. 45  randomly masks 40% of gene expression  values for each input and  deep language model for cell type 573 annotation of single-cell",
    "venue": "National Science …",
    "url": "https://academic.oup.com/nsr/advance-article-abstract/doi/10.1093/nsr/nwaf255/8172492",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=8409820987422804727&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Single Cells Are Biological Tokens: Towards Cell Language Models",
    "authors": [
      "H Wen"
    ],
    "year": "2024",
    "abstract": "-based foundation model, Cell Pre-trained Language Model ( -based foundation model  for multimodal single-cell data,  work, we focus on using gene expression (RNA) to predict",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/4a8bb7008693c584334f0ac855eae486/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=7767485978654188097&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Representation Learning for Natural Language and Biological Data: Using contrastive learning to find a joint representation for single-cell RNA data and gene …",
    "authors": [
      "A Banaei Mobarak Abadi"
    ],
    "year": "2024",
    "abstract": "architecture to develop a foundation model for single-cell data. They  , briefly describing the  gene expression process and  documents in pretraining the Language Model to enhance its",
    "venue": "NA",
    "url": "https://www.diva-portal.org/smash/record.jsf?pid=diva2:1894752",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Evaluating the utilities of foundation models in single-cell data analysis",
    "authors": [
      "T Liu",
      "K Li",
      "Y Wang",
      "H Li",
      "H Zhao"
    ],
    "year": "2023",
    "abstract": "to build a Foundation Model (FM) which can benefit from prior knowledge for single-cell data  analysis For this task, we intend to impute gene expression profiles of different datasets. We",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2023.09.08.555192.abstract",
    "num_citations": 56,
    "citedby_url": "/scholar?cites=18207466669694256662&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Unlocking biological insight from single-cell data with an interpretable dual-stream foundation model",
    "authors": [
      "H Guo",
      "Q Cui",
      "X Zhang",
      "C Chen",
      "W Zheng",
      "C Cai"
    ],
    "year": "2025",
    "abstract": "During this process, the model takes the ranked single-cell gene expression sequence  as  An outstanding single-cell language model must not only perform accurate cell-level",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.09.05.674596.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell Biology",
    "authors": [
      "SA Dip",
      "A Zafor",
      "BK Paul",
      "UA Shuvo",
      "MI Emon"
    ],
    "year": "2025",
    "abstract": "cells, LLMs promise to unify gene expression, chromatin accessibility,  pre-trained language  model for singlecell analysis. In  scmamba: A scalable foundation model for single-cell multi-",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2510.07793",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scMulan: a multitask generative pre-trained language model for single-cell analysis",
    "authors": [
      "H Bian",
      "Y Chen",
      "X Dong",
      "C Li",
      "M Hao",
      "S Chen"
    ],
    "year": "2024",
    "abstract": "the language of gene expression and metadata of single cells, and developed a new  foundation model scMulan to facilitate multiple downstream single-cell analysis tasks using a",
    "venue": "… on Research in …",
    "url": "https://link.springer.com/chapter/10.1007/978-1-0716-3989-4_57",
    "num_citations": 30,
    "citedby_url": "/scholar?cites=14152919657951392385&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Multiomic foundation model predicts epigenetic regulation by zero-shot",
    "authors": [
      "Z Yang",
      "X Fan",
      "M Lan",
      "X Li",
      "Y You",
      "L Tian",
      "G Church"
    ],
    "year": "2024",
    "abstract": "9 has sequenced paired gene expression and 26 chromatin accessibility profiles at single cell  or  To overcome the limitations inherent in both bulk and single-cell datasets as well as the",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.19.629561.abstract",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=10693685317632215894&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Single-Cell Omics Arena: A Benchmark Study for Large Language Models on Cell Type Annotation Using Single-Cell Data",
    "authors": [
      "J Liu",
      "S Xu",
      "L Zhang",
      "J Zhang"
    ],
    "year": "2024",
    "abstract": "In our experiments, we used Differential Gene Expression (DGE) analysis to select the k   While the proposed benchmark has significant influence within the large language model for",
    "venue": "arXiv preprint arXiv:2412.02915",
    "url": "https://arxiv.org/abs/2412.02915",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=2925820692405353635&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scMPT: towards applying large language models to complement single-cell foundation models",
    "authors": [
      "S Palayew",
      "BO WANG",
      "GD Bader"
    ],
    "year": "NA",
    "abstract": "only on gene expression data,  art foundation model, we find that fusion with LLMs can  improve upon its performance, indicating that cell representations derived from text and single-cell",
    "venue": "NA",
    "url": "https://openreview.net/forum?id=nUpM7egYFd",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Foundation models in bioinformatics",
    "authors": [
      "F Guo",
      "R Guan",
      "Y Li",
      "Q Liu",
      "X Wang"
    ],
    "year": "2025",
    "abstract": ", proteomics, drug discovery and single-cell analysis. Our aim is  [28] is a long-context  foundation model that facilitates both  Masked language model (MLM) objectives are used to build",
    "venue": "National science …",
    "url": "https://academic.oup.com/nsr/article-abstract/12/4/nwaf028/7979309",
    "num_citations": 65,
    "citedby_url": "/scholar?cites=3437283098704210197&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Large language models for translational cancer informatics",
    "authors": [
      "Y Pan",
      "Y Wang",
      "G Wang",
      "J Su",
      "U Topaloglu"
    ],
    "year": "2025",
    "abstract": "single-cell transcriptome 100M Continuous gene expression  -tune Yes It is a foundation  model for cancer diagnosis and  single-cell language model (CellLM) 26 is the first single-cell",
    "venue": "JCO Clinical Cancer …",
    "url": "https://ascopubs.org/doi/abs/10.1200/CCI-25-00108",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=8400822586932139319&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Scaling large language models for next-generation single-cell analysis",
    "authors": [
      "SA Rizvi",
      "D Levine",
      "A Patel",
      "S Zhang",
      "E Wang",
      "CJ Perry"
    ],
    "year": "2025",
    "abstract": "of the language model to include genes,  foundation model to embed single-cell gene  expression profiles. Notably, scFID is flexible and can incorporate any suitable foundation model",
    "venue": "BioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.04.14.648850.abstract",
    "num_citations": 22,
    "citedby_url": "/scholar?cites=5998770937752595628&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "OmniCell: Unified Foundation Modeling of Single-Cell and Spatial Transcriptomics for Cellular and Molecular Insights",
    "authors": [
      "J Pang",
      "P Qiu",
      "Y He",
      "B Li",
      "Y Deng",
      "J Wang Sr",
      "A Lin"
    ],
    "year": "2025",
    "abstract": "maps gene expression in tissues with limited single-cell  OmniCell, a foundation model  for single-cell and spatial  , a unified foundation model pretrained on 67 million single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.29.696804.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Leveraging Single-Cell ATAC-Seq for Genomic Language Models and Multimodal Foundation Models",
    "authors": [
      "DY Kim"
    ],
    "year": "2025",
    "abstract": "Second, we introduce a novel multimodal foundation model  an existing genomic language  model on DNA segmentation task.  tool for studying gene expression at the single-cell level.",
    "venue": "NA",
    "url": "https://dspace.mit.edu/handle/1721.1/159110",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scKEPLM: Knowledge enhanced large-scale pre-trained language model for single-cell transcriptomics",
    "authors": [
      "Y Li",
      "G Qiao",
      "G Wang"
    ],
    "year": "2024",
    "abstract": "In the context of scRNA-seq, gene expression sequences are  in four aspects of single-cell  gene expression analysis. Firstly scKEPLM is the first single-cell foundation model to integrate",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.07.09.602633.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=8965210955624643826&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "OKR-Cell: Open World Knowledge Aided Single-Cell Foundation Model with Robust Cross-Modal Cell-Language Pre-training",
    "authors": [
      "H Wang",
      "X Zhang",
      "S Fang",
      "L Ran",
      "Z Deng",
      "Y Zhang"
    ],
    "year": "2026",
    "abstract": "-trained language model (PLM) paradigm based single-cell  KnowledgeAided Robust  Single-Cell Foundation Model (OKR- by tampering with the gene expression values of a certain",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2026.01.09.698573.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Heimdall: A Modular Framework for Tokenization in Single-Cell Foundation Models",
    "authors": [
      "E Haber",
      "S Alam",
      "N Ho",
      "R Liu",
      "E Trop",
      "S Liang",
      "M Yang"
    ],
    "year": "2025",
    "abstract": "overlapped with a linear baseline using raw gene expression (0.40), indicating that tokenizer   -scale pretrained deep language model for cell type annotation of single-cell rna-seq data.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.09.687403.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=8263222809184883556&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scLong: A billion-parameter foundation model for capturing long-range gene context in single-cell transcriptomics",
    "authors": [
      "D Bai",
      "S Mo",
      "R Zhang",
      "Y Luo",
      "J Gao",
      "JP Yang",
      "Q Wu"
    ],
    "year": "2024",
    "abstract": "by providing gene expression data at single-cell resolution,  a billion-parameter foundation  model pretrained on 48 million  deep language model for cell type annotation of single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.11.09.622759.abstract",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=3634589880842567707&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Transformer-based single-cell language model: A survey",
    "authors": [
      "W Lan",
      "G He",
      "M Liu",
      "Q Chen",
      "J Cao"
    ],
    "year": "2024",
    "abstract": "Exploring the gene expression, gene function and gene-gene  Single-cell large language  model based on single-cell multi-omics The scGPT[39] is the first single-cell foundation model",
    "venue": "Big Data Mining and …",
    "url": "https://ieeexplore.ieee.org/abstract/document/10778140/",
    "num_citations": 31,
    "citedby_url": "/scholar?cites=11753197747778542411&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "GENEPT: ASimple BUT HARD-TO-BEAT FOUNDATION MODEL FOR GENES AND CELLS BUILT FROM CHATGPT",
    "authors": [
      "YT Chen",
      "J Zou"
    ],
    "year": "NA",
    "abstract": "On many downstream tasks used to evaluate recent single-cell  GenePT demonstrates  that large language model  Gather extensive single-cell gene expression datasets for pre-",
    "venue": "NA",
    "url": "https://storage.prod.researchhub.com/uploads/papers/2023/10/20/2023.10.16.562533.full.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Universal cell embeddings: A foundation model for cell biology",
    "authors": [
      "Y Rosen",
      "Y Roohani",
      "A Agarwal",
      "L Samotorčan"
    ],
    "year": "2023",
    "abstract": "(UCE), a foundation model for single-cell gene expression that is  representations of new  single-cell gene expression datasets with  The ESM2 protein language model takes amino acid",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2023.11.28.568918.abstract",
    "num_citations": 103,
    "citedby_url": "/scholar?cites=3465496927538567669&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Parameter-efficient fine-tuning enhances adaptation of single cell large language model for cell type identification",
    "authors": [
      "F He",
      "R Fei",
      "M Gao",
      "L Su",
      "X Zhang",
      "D Xu"
    ],
    "year": "2024",
    "abstract": "This PEFT approach effectively tailors the model to capture specific data traits, such as  unique gene expression patterns, enhancing the model’s precision in identifying hard-to-classify",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10862733/",
    "num_citations": 9,
    "citedby_url": "/scholar?cites=5553957643138470288&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Foundation models in molecular biology",
    "authors": [
      "Y Si",
      "J Zou",
      "Y Gao",
      "G Chuai",
      "Q Liu"
    ],
    "year": "2024",
    "abstract": "of a single cell contains both gene types and corresponding gene expressions, an ideal  transcriptome language model  Another important issue regarding the foundation model is its",
    "venue": "Biophysics reports",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11252241/",
    "num_citations": 12,
    "citedby_url": "/scholar?cites=13254560183994177341&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Identifying Biological Priors and Structure in Single-Cell Foundation Models",
    "authors": [
      "F Pedrocchi",
      "S Stark",
      "G Ratsch",
      "A Joudaki"
    ],
    "year": "NA",
    "abstract": "This combination is inputted into a neural network to predict gene expression status. Thus,  the CLS  identification tokens used, which are not generated by the protein language model.",
    "venue": "ICML 2024 Workshop on …",
    "url": "https://openreview.net/forum?id=UFiLmIiLYC",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=14804349394983167330&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Tabula: A Tabular Self-Supervised Foundation Model for Single-Cell Transcriptomics",
    "authors": [
      "J Ding",
      "J Lin",
      "S Jiang",
      "Y Wang",
      "Z Miao",
      "Z Fang"
    ],
    "year": "NA",
    "abstract": "gene expression within a single cell to gene sequences to mimic word sequences used in  NLP. While this adapts the NLP paradigm to single-cell  of a large language model), releasing",
    "venue": "The Thirty-ninth Annual …",
    "url": "https://openreview.net/forum?id=Vk2sfKAdeu",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Gene Regulatory Network Inference with Joint Representation from Graph Neural Network and Single-Cell Foundation Model",
    "authors": [
      "S Kommu",
      "Y Wang",
      "Y Wang",
      "X Wang"
    ],
    "year": "2024",
    "abstract": "gene expression profiling at an unprecedented single-cell  However, the conversion of gene  expression profiles into  deep language model for cell type annotation of single-cell rna-seq",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.16.628715.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=7572453679757698700&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Reinforcement learning enables single-cell foundation models to learn cellular differentiation",
    "authors": [
      "KL Chang",
      "H Chen",
      "Z Liu"
    ],
    "year": "2025",
    "abstract": "leverage foundation model predictions to  single-cell critic values and experimental time  points to assess temporal consistency. Second, we evaluated the recovery of gene expression",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.09.693267.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Biological Large Language Models",
    "authors": [
      "V Dhillon",
      "D Metcalf",
      "M Hooper"
    ],
    "year": "2025",
    "abstract": "RNA-FM is a foundation model for RNA sequence analysis, pre- Evo is a multi-omic language  model designed to handle  are pushing boundaries in single-cell analysis, while platforms",
    "venue": "AI Frameworks Enabled by Blockchain …",
    "url": "https://link.springer.com/chapter/10.1007/979-8-8688-1402-0_10",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Single-cell omics arena: evaluation of large language models for automatic cell-type annotations on single-cell omics data via RNA-seq bridging",
    "authors": [
      "J Liu",
      "S Xu",
      "Y Wu",
      "J Zhang"
    ],
    "year": "2025",
    "abstract": "To guide LLMs in annotating cell types based on the provided gene expression profile,  we  Given a cell |$\\boldsymbol{x}$| to be annotated and its gene expression profile |$\\mathtt{X}$|",
    "venue": "Briefings in Bioinformatics",
    "url": "https://academic.oup.com/bib/article-abstract/26/6/bbaf622/8341160",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Towards Network-Guided Large-Scale Foundation Models on Single-Cell Transcriptomics",
    "authors": [
      "S Kommu"
    ],
    "year": "2025",
    "abstract": "module that converts continuous gene expression scalars into high pretraining process  of single-cell foundation model. We use  where LMLM is the standard masked-language-model",
    "venue": "NA",
    "url": "https://vtechworks.lib.vt.edu/items/5abc4877-9404-4e68-9864-574a55ecc9f5",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Cell ontology guided transcriptome foundation model",
    "authors": [
      "X Yuan",
      "Z Zhan",
      "Z Zhang",
      "M Zhou"
    ],
    "year": "2024",
    "abstract": "learning on large-scale single-cell gene expression data, and ultimately unraveling  foundation  model for downstream zero-shot and fine-tuning tasks. To this end, we present single cell,",
    "venue": "Advances in …",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/0be40478ab6ee0006ee3b38b158bbc8f-Abstract-Conference.html",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=4309957036506458551&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Integrating Large Language Models and Single-Cell Omics Analysis for Target Discovery in Pancreatic Ductal Adenocarcinoma",
    "authors": [
      "Z Xu"
    ],
    "year": "2025",
    "abstract": "be contrasted directly at the level of gene expression. Because each meta-cell summarises  a  and for defining the single-cell evidence layer against which large language model (LLM)",
    "venue": "NA",
    "url": "https://openscholarship.wustl.edu/eng_etds/1304/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Gene-Family Encoding Boosts Domain-Adapted Single-Cell Language Models",
    "authors": [
      "H Ma",
      "C Xu",
      "SWT Ho",
      "JJ Zhao",
      "Y Chu",
      "ALK Tan"
    ],
    "year": "2025",
    "abstract": "To construct the GC single-cell foundation model, we then  the ability of large language  model backbones to capture  , and innovations in how gene expression is represented remains",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.09.16.676672.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery",
    "authors": [
      "Y Gao",
      "Z Wang",
      "J Chen",
      "M Antkowiak",
      "M Hu"
    ],
    "year": "NA",
    "abstract": "large language model (LLM) converses in natural language while directly inspecting single-cell  RNA SCPILOT converts core single-cell analyses, ie, cell-type annotation, developmental",
    "venue": "The Thirty-ninth Annual …",
    "url": "https://openreview.net/forum?id=Vzi96rTe4w",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Transcriptomic Neural Networks Architecture and Applications to Functional and Aging Research",
    "authors": [
      "A PINAROLI"
    ],
    "year": "NA",
    "abstract": "deep language model for cell type annotation of single-cell RNA We constructed a  comprehensive single-cell dataset by  , a large-scale foundation model with 100 million",
    "venue": "NA",
    "url": "https://thesis.unipd.it/handle/20.500.12608/91971",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A deep dive into single-cell RNA sequencing foundation models",
    "authors": [
      "R Boiarsky",
      "N Singh",
      "A Buendia",
      "G Getz",
      "D Sontag"
    ],
    "year": "2023",
    "abstract": "log-transformed, library size-normalized gene expression values in the Zheng68K peripheral   A strong foundation model trains data representations that can easily adapt to downstream",
    "venue": "BioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2023.10.19.563100.abstract",
    "num_citations": 45,
    "citedby_url": "/scholar?cites=3467288160874688230&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scWGBS-GPT: A Foundation Model for Capturing Long-Range CpG Dependencies in Single-Cell Whole-Genome Bisulfite Sequencing to Enhance Epigenetic …",
    "authors": [
      "C Liang",
      "P Ye",
      "H Yan",
      "P Zheng",
      "J Sun",
      "Y Wang",
      "Y Li"
    ],
    "year": "2025",
    "abstract": "specific methylation patterns and their regulatory roles in gene expression. By incorporating   the first large language model specifically designed for single-cell DNA methylation analysis",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.02.19.638959.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=5580119096905943097&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Foundation models meet imbalanced single-cell data when learning cell type annotations",
    "authors": [
      "AR Alsabbagh",
      "AMR de Infante",
      "D Gomez-Cabrero"
    ],
    "year": "2023",
    "abstract": "rather than actual raw gene expression values. To mitigate the  scBERT is a specialized  Large Language Model (LLM) built  for a foundation model when dealing with imbalanced data.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2023.10.24.563625.abstract",
    "num_citations": 18,
    "citedby_url": "/scholar?cites=5409402996928872167&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Embeddings from language models are good learners for single-cell data analysis",
    "authors": [
      "T Liu",
      "T Chen",
      "W Zheng",
      "X Luo",
      "Y Chen",
      "H Zhao"
    ],
    "year": "2026",
    "abstract": "informed by the intrinsic noise characteristics of single-cell RNA sequencing (scRNA-seq)  data. By compressing high-dimensional gene expression profiles into a lower-dimensional",
    "venue": "Patterns",
    "url": "https://www.cell.com/patterns/fulltext/S2666-3899(25)00279-X",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Foundation models for translational cancer biology",
    "authors": [
      "KK Tsang",
      "S Kivelson"
    ],
    "year": "2025",
    "abstract": "ESM3 (51) is the latest and largest protein language model,  models and take in the gene  expression profile of each cell to do  new addition to the single-cell foundation model space is",
    "venue": "Annual Review of …",
    "url": "https://www.annualreviews.org/content/journals/10.1146/annurev-biodatasci-103123-095633",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=8751312228174834511&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Multimodal foundation transformer models for multiscale genomics",
    "authors": [
      "SA Khan",
      "X Martínez-de-Morentin",
      "AR Alsabbagh"
    ],
    "year": "2025",
    "abstract": "models operating across genomic sequences, single-cell transcriptomics and spatial data.   foundation model for genes and cells from ChatGPT using OpenAI’s GPT-3.5 language model",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41592-025-02918-6",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=5164337508146626508&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Cell2Text: Multimodal LLM for Generating Single-Cell Descriptions from RNA-Seq Data",
    "authors": [
      "O Kharouiche",
      "A Markogiannakis",
      "X Fei"
    ],
    "year": "2025",
    "abstract": "of Cell2Text, responsible for converting raw single-cell gene expression data into meaningful,  context-aware embeddings that our language model can effectively interpret. We chose",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2509.24840",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=12917855364622624603&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A Multi-Modal Foundation Model Across Species for Interpreting Gene Functions",
    "authors": [
      "T Liu"
    ],
    "year": "NA",
    "abstract": "In this work, we develop a multi-modal foundation model,  and gene expression levels based  on single-cell transcriptomics.  HyenaDNA is a genomic language model pre-trained with",
    "venue": "NeurIPS 2025 2nd Workshop on Multi-modal …",
    "url": "https://openreview.net/forum?id=U1DWJKbNte",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Nicheformer: a foundation model for single-cell and spatial omics",
    "authors": [
      "AC Schaar",
      "A Tejada-Lapuerta",
      "G Palla",
      "R Gutgesell"
    ],
    "year": "2024",
    "abstract": "interplay between gene expression patterns within a single cell via  Foundation model  approaches build upon the idea of representing data in a way that allows a large language model,",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.04.15.589472",
    "num_citations": 66,
    "citedby_url": "/scholar?cites=14456813304529803516&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Does your model understand genes? A benchmark of gene properties for biological and text models",
    "authors": [
      "Y Kan-Tor",
      "MM Danziger",
      "E Zohar",
      "M Ninio"
    ],
    "year": "2024",
    "abstract": "from each model, including single-cell RNA-seq (scRNA)  description with a language  model supporting text embedding A transformer based foundation model for single cell biology",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2412.04075",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=1655595802033396445&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A framework to extract and interpret biological concepts from scRNAseq generative foundation models",
    "authors": [
      "C Claye",
      "P Marschall",
      "W Ouerdane"
    ],
    "year": "2025",
    "abstract": "We introduce two novel approaches to interpret latent concepts from single-cell RNAseq  models.  Singlecell RNAseq captures information about gene expression within individual cells,",
    "venue": "… 2025 Generative AI …",
    "url": "https://openreview.net/forum?id=wZpxbCwEe4",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=16807067902604957301&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A Generalizable Transformer Framework for Gene Regulatory Network Inference from Single‐Cell Transcriptomes",
    "authors": [
      "G Weng",
      "H Kim",
      "P Martin",
      "J Kim",
      "TH Kim"
    ],
    "year": "2026",
    "abstract": "Fine-Tuning Label Construction: The process of selecting fine-tuning labels from single-cell  data employs a hybrid scoring approach that combines gene expression ranking with a",
    "venue": "Advanced Intelligent …",
    "url": "https://advanced.onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202500781",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "How do large language models understand genes and cells",
    "authors": [
      "C Fang",
      "Y Wang",
      "Y Song",
      "Q Long",
      "W Lu"
    ],
    "year": "2025",
    "abstract": "a crucial step in single-cell data analysis essential for understanding the functions and  characteristics of different cells. First, we transformed the single-cell gene expression profiles into",
    "venue": "ACM Transactions on …",
    "url": "https://dl.acm.org/doi/abs/10.1145/3702234",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=11264099649161195887&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scelmo: Embeddings from language models are good learners for single-cell data analysis",
    "authors": [
      "T Liu",
      "T Chen",
      "W Zheng",
      "X Luo",
      "Y Chen",
      "H Zhao"
    ],
    "year": "2025",
    "abstract": "Different from GenePT, we treated the gene expression  generalizing a foundation model in  the single-cell research area,  deep language model for cell type annotation of single-cell rna-",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12393277/",
    "num_citations": 33,
    "citedby_url": "/scholar?cites=18324540309835466594&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Generative single-cell transcriptomics via large language models",
    "authors": [
      "H Choi",
      "H Shin",
      "D Lee",
      "D Lee"
    ],
    "year": "2026",
    "abstract": "Language, a framework that reframes single-cell transcriptomes as a language generation   gene–expression tokens and uses a large language model to synthesize complete single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2026.01.12.699186.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models",
    "authors": [
      "B Dandala",
      "MM Danziger",
      "E Barkan",
      "T Biswas"
    ],
    "year": "2025",
    "abstract": "To construct a robust, generalizable foundation model for single-cell transcriptomics, we   Gene expression in single cell data is a zero-inflated phenomenon with a large number of",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2506.14861",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=11420121136892098237&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Contrastive Learning Enhances Language Model Based Cell Embeddings for Low-Sample Single Cell Transcriptomics",
    "authors": [
      "L Zhang",
      "D Jiang",
      "Q Wang",
      "H Sun",
      "F Tian"
    ],
    "year": "2025",
    "abstract": "potential biases inherent in large-scale foundation model training. Models are pretrained  on all  and cell embeddings by integrating single-cell gene expression data with protein–protein",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2509.23543",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Efficient Fine-Tuning of Single-Cell Foundation Models Enables Zero-Shot Molecular Perturbation Prediction",
    "authors": [
      "S Maleki",
      "JC Huetter",
      "KV Chuang",
      "D Richmond"
    ],
    "year": "2024",
    "abstract": "less than 1% of the original foundation model, thus enabling molecular conditioning while   In this study, as we focus on single-cell data, we observe that the gene expression of only a",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2412.13478",
    "num_citations": 9,
    "citedby_url": "/scholar?cites=1741712910291990268&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Discovering interpretable biological concepts in single-cell rna-seq foundation models",
    "authors": [
      "C Claye",
      "P Marschall",
      "W Ouerdane",
      "C Hudelot"
    ],
    "year": "2025",
    "abstract": "ities, single-cell RNA sequencing (scRNA-seq) captures information about gene expression  within  Learning biologically relevant features in a pathology foundation model using sparse",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2510.25807",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=15998395821470910257&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Single Cell Foundation Models Evaluation (scFME) for In-Silico Perturbation",
    "authors": [
      "J Boylan",
      "E Solovyeva",
      "T Bouiller",
      "X Liu",
      "S Hoersch"
    ],
    "year": "2025",
    "abstract": "To address these limitations, we propose Single-Cell Foundation Model  RNA sequencing  reveal differences in gene expression at  biology that leverages large language model (LLM)",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.09.22.677811.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=3925710671985778313&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CellTok: Early-Fusion Multimodal Large Language Model for Single-Cell Transcriptomics via Tokenization",
    "authors": [
      "C Xiao",
      "H Bian",
      "Y Chen",
      "L Wei",
      "X Zhang"
    ],
    "year": "2025",
    "abstract": "gene expression at the single-cell level through single-cell  models (LCMs) for the single-cell  domain by directly projecting cells  utilizing LLMs to analyze single-cell data, as explored in",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.10.22.684047.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "sciLaMA: A Single-Cell Representation Learning Framework to Leverage Prior Knowledge from Large Language Models",
    "authors": [
      "H Hu",
      "S Zhang",
      "Y Choi",
      "VS Malladi",
      "G Quon"
    ],
    "year": "2025",
    "abstract": "gene expression data. Here, we introduce sciL-aMA (single-cell interpretable Language Model   To explore this, we directly compared the transformerbased foundation model scGPT that",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.01.28.635153.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=13352098264064936621&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "EpiAgent: foundation model for single-cell epigenomics",
    "authors": [
      "X Chen",
      "K Li",
      "X Cui",
      "Z Wang",
      "Q Jiang",
      "J Lin",
      "Z Li"
    ],
    "year": "2025",
    "abstract": "single-cell transcriptomics demonstrate a promising approach to tackling these limitations.  With a cellular language model  governs transcription than gene expression, the development",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41592-025-02822-z",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=2702433257130243716&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CAPTAIN: A multimodal foundation model pretrained on co-assayed single-cell RNA and protein",
    "authors": [
      "B Ji",
      "T Hu",
      "J Wang",
      "M Liu",
      "L Xu",
      "Q Zhang",
      "S Zhong"
    ],
    "year": "2025",
    "abstract": "of millions of single-cell RNA profiles by a large-scale single-cell language model, conferring   Prior to fine-tuning, we used Scanpy to normalise, log-transform, and bin gene expression",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.07.07.663366.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Universal Cell Embeddings",
    "authors": [
      "Y Rosen",
      "Y Roohani",
      "A Agrawal",
      "L Samotorcan"
    ],
    "year": "NA",
    "abstract": "(UCE), a foundation model for single-cell gene 69 expression that is  foundation model for  single cell gene expression. Integrating  The ESM2 protein language model takes amino acid",
    "venue": "NA",
    "url": "https://www-cs.stanford.edu/~jure/pubs/uce-bioarxiv23.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "TissueNarrator: Generative Modeling of Spatial Transcriptomics with Large Language Models",
    "authors": [
      "S Liu",
      "J Tang",
      "J Ma",
      "S Liang"
    ],
    "year": "2025",
    "abstract": "natural language can transfer their biological knowledge to single-cell analysis [18, 19]. LLMs  the gene expression profile of a query cell using its cell type and the gene expression of its",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.24.690325.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Foundation models in plant molecular biology: advances, challenges, and future directions",
    "authors": [
      "F Xu",
      "T Wu",
      "Q Cheng",
      "X Wang",
      "J Yan"
    ],
    "year": "2025",
    "abstract": "have evolved from basic gene expression prediction and cell type  scGPT: toward building  a foundation model for single-cell  deep language model for cell type annotation of single-cell",
    "venue": "Frontiers in Plant Science",
    "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2025.1611992/abstract",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=43264929001830184&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Harnessing the power of single-cell large language models with parameter-efficient fine-tuning using scPEFT",
    "authors": [
      "F He",
      "R Fei",
      "JE Krull",
      "Y Yu",
      "X Zhang",
      "X Wang"
    ],
    "year": "2025",
    "abstract": "These scLLMs treat single-cell expression profiles as a form  as predicting randomly masked  gene expression values from the  In general, scLLMs used the masked language model",
    "venue": "Nature Machine …",
    "url": "https://www.nature.com/articles/s42256-025-01170-z",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=1976116568299318501&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Advancing bioinformatics with large language models: components, applications and perspectives",
    "authors": [
      "J Liu",
      "M Yang",
      "Y Yu",
      "H Xu",
      "T Wang",
      "K Li",
      "X Zhou"
    ],
    "year": "2025",
    "abstract": "genes in single-cell RNA-seq data, where multiple aspects of  [53], a foundation model  specifically designed for spatial  ] is the latest large language model in spatial transcriptomics.",
    "venue": "ArXiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10802675/",
    "num_citations": 13,
    "citedby_url": "/scholar?cites=17822282629366811062&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "GeneBag: training a cell foundation model for broad-spectrum cancer diagnosis and prognosis with bulk RNA-seq data",
    "authors": [
      "Y Liang",
      "D Li",
      "AG Xu",
      "Y Shao",
      "K Tang"
    ],
    "year": "2024",
    "abstract": "and potential in advancing single-cell biology research.  single-cell RNA-Seq sequences.  Each cell sequence was firstly processed with masking, where 15% of the gene expression",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.06.27.601098.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Celler: A Genomic Language Model for Long-Tailed Single-Cell Annotation",
    "authors": [
      "H Zhao",
      "Y Liu",
      "J Yao",
      "L Xiong",
      "Z Zhou"
    ],
    "year": "2025",
    "abstract": "It contains a wealth of single-cell transcriptomic gene expression data, with 10,600 samples  in the training set and 4,218 samples in the test set. These data are widely used in research",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2504.00020",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=18063260796970974264&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Evaluating the Utilities of Foundation Models in",
    "authors": [
      "T Liu",
      "K Li",
      "Y Wang",
      "H Li",
      "H Zhao"
    ],
    "year": "NA",
    "abstract": "methods, we found that single-cell FMs may not consistently  Therefore, there is a need to  build a Foundation Model (FM)  a)), termed as Single-cell Large Language Model Evaluation (",
    "venue": "NA",
    "url": "https://www.biorxiv.org/content/10.1101/2023.09.08.555192.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Langcell: Language-cell pre-training for cell identity understanding",
    "authors": [
      "S Zhao",
      "J Zhang",
      "Y Wu",
      "Y Luo",
      "Z Nie"
    ],
    "year": "2024",
    "abstract": "a unified representation of single-cell data and natural language  Firstly, we normalize the  gene expression of each cell  Domain-specific language model pretraining for biomedical",
    "venue": "arXiv preprint arXiv:2405.06708",
    "url": "https://arxiv.org/abs/2405.06708",
    "num_citations": 34,
    "citedby_url": "/scholar?cites=6990365007182481925&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Large Language Models in Genomics—A Perspective on Personalized Medicine",
    "authors": [
      "S Ali",
      "YA Qadri",
      "K Ahmad",
      "Z Lin",
      "MF Leung",
      "SW Kim"
    ],
    "year": "2025",
    "abstract": "language model that falls into this category [37].  Single-cell genomics is a novel discipline  that allows for the  GROVER, a foundation model with an optimized vocabulary for the",
    "venue": "Bioengineering",
    "url": "https://www.mdpi.com/2306-5354/12/5/440",
    "num_citations": 15,
    "citedby_url": "/scholar?cites=4893585164490283898&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "SCARF: Single Cell ATAC-seq and RNA-seq Foundation model",
    "authors": [
      "G Liu",
      "Y Zhao",
      "Y Zhao",
      "T Wang",
      "Q Cai",
      "X Wang",
      "Z Wen"
    ],
    "year": "2025",
    "abstract": "single-cell multiome (ATAC + Gene Expression) datasets from the Gene Expression  -scale  pretrained deep language model for cell type annotation of single-cell RNA-seq data.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.04.07.647689.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=15310161313896540338&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scATD: a high-throughput and interpretable framework for single-cell cancer drug resistance prediction and biomarker identification",
    "authors": [
      "M Zhou",
      "Z Luo",
      "YH Yin",
      "Q Liu",
      "G Wang"
    ],
    "year": "2025",
    "abstract": "",
    "venue": "Briefings in …",
    "url": "https://academic.oup.com/bib/article/26/3/bbaf268/8160682",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=3436142793911368074&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scELMo: Embeddings from Language Models",
    "authors": [
      "T Liu",
      "T Chen",
      "W Zheng",
      "X Luo",
      "Y Chen",
      "H Zhao"
    ],
    "year": "NA",
    "abstract": "as a pipeline for analyzing single-cell multi- 81 omic data  Different from GenePT, we treated  the 201 gene expression  the development of a foundation model that may be informative to",
    "venue": "NA",
    "url": "https://www.biorxiv.org/content/10.1101/2023.12.07.569910.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Multi-modal single-cell foundation models via dynamic token adaptation",
    "authors": [
      "W Zhao",
      "A Solaguren-Beascoa",
      "G Neilson"
    ],
    "year": "2025",
    "abstract": "single-cell transcriptome as an input text token and do not integrate genetic information, making  it hard to interpret gene expression  language model with a single-cell foundation model",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2504.13049",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Prediction of Gene Regulatory Connections with Joint Single-Cell Foundation Models and Graph-Based Learning",
    "authors": [
      "S Kommu",
      "Y Wang",
      "Y Wang",
      "X Wang"
    ],
    "year": "2025",
    "abstract": "scRegNet utilizes a pre-trained single-cell foundation model (top; Section 2.1) to  single-cell  data. It also includes an embedding module that converts continuous gene expression",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11838224/",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=5748683280802064799&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CellPLM: Pre-training of cell language model beyond single cells",
    "authors": [
      "H Wen",
      "W Tang",
      "X Dai",
      "J Ding",
      "W Jin",
      "Y Xie",
      "J Tang"
    ],
    "year": "2023",
    "abstract": "a novel single-Cell Pre-trained Language Model (CellPLM),  language model, where parts  of the input gene expression  essential property for a single-cell foundation model. The goal of",
    "venue": "BioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2023.10.03.560734.abstract",
    "num_citations": 69,
    "citedby_url": "/scholar?cites=15887212670928548591&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Omnireg-gpt: a high-efficiency foundation model for comprehensive genomic sequence understanding",
    "authors": [
      "A Wang",
      "J Li",
      "H Dong",
      "B Xu",
      "Q Yin",
      "Y Xu",
      "J Fu"
    ],
    "year": "2025",
    "abstract": "Single-cell atlas have characterized comprehensive  Following a binarized single cell gene  expression dataset of Nvwa 26 ,  We employed an autoregressive form of a language model",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41467-025-65066-7",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=4481487868127560999&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Language-Enhanced Representation Learning for Single-Cell Transcriptomics",
    "authors": [
      "Y Shi",
      "J Yang",
      "C Nai",
      "S Li",
      "J Fang",
      "X Wang"
    ],
    "year": "2025",
    "abstract": "abundance, producing gene expression matrices that record  ], a state-of-the-art single-cell  language model pre-trained on large- Since absolute gene expression values can vary across",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2503.09427",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=2571304593926557975&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "How different AI models understand cells differently",
    "authors": [
      "Y Zhao",
      "D Sun",
      "M Hao",
      "Y Xiong",
      "C Li",
      "T Gong",
      "L Wei"
    ],
    "year": "2026",
    "abstract": "Single-cell foundation model  As gene expression profiles are treated as permutation-invariant  sets, no  This paper aims to improve the understanding and interpretability of single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2026.01.29.702682.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "To transformers and beyond: large language models for the genome",
    "authors": [
      "ME Consens",
      "C Dufault",
      "M Wainberg",
      "D Forster"
    ],
    "year": "2023",
    "abstract": "from observing gene expression values for a single cell many  multiple single-cell omic data  modalities, or single-cell multi- multiple single-cell data modalities in one foundation model",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2311.07621",
    "num_citations": 67,
    "citedby_url": "/scholar?cites=6397702822956066166&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "TEDDY: A Family Of Foundation Models For Understanding Single Cell Biology",
    "authors": [
      "A Chevalier",
      "S Ghosh",
      "U Awasthi",
      "J Watkins"
    ],
    "year": "2025",
    "abstract": "scmulan: a multitask generative pre-trained language model for single-cell analysis. In   each cell to 10,000 gene expression counts. We then scale each gene expression by this median",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2503.03485",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=5657236302846216917&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "AI-empowered genome decoding: Applications of large language models in genomics",
    "authors": [
      "S Li",
      "W Fan",
      "Y Zhou"
    ],
    "year": "2025",
    "abstract": "language model on single-cell data processing, researchers use different approaches, such  as converting gene expression  foundation (scFoundation), an even larger foundation model",
    "venue": "Frontiers of Digital Education",
    "url": "https://link.springer.com/article/10.1007/s44366-025-0051-1",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=843997604162657315&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "BrainBeacon: A Cross-Species Foundation Model for Single-cell Resolved Brain Spatial Transcriptomics",
    "authors": [
      "C Zhang",
      "Y Yang",
      "Y Jiao",
      "Q Yang",
      "X Guo",
      "J Xu",
      "J Li"
    ],
    "year": "2025",
    "abstract": "expression values at the single-cell level, we used gene expression rankings within each cell   embeddings derived from the ESM2 protein language model, enabling the model to learn",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.07.08.663729.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=11167423364351741572&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Application of foundation models for molecular representation in cancer drug discovery and precision oncology",
    "authors": [
      "K Khokhlov"
    ],
    "year": "2025",
    "abstract": "application of cell representation learning, utilizing a cell foundation model trained on   transformer elements of the language model and the downstream model FFN, similarly",
    "venue": "NA",
    "url": "https://dspace.mit.edu/handle/1721.1/158915",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A Transformer-Based Foundation Model for Human Microbiome Analysis",
    "authors": [
      "NA Medearis"
    ],
    "year": "2025",
    "abstract": "gave rise to LLaMA (Large Language Model Meta AI) [12], which  that this loss of gene  expression data can cause the rank- single-cell data is sparse, small changes in gene expression",
    "venue": "NA",
    "url": "https://dspace.mit.edu/handle/1721.1/162973",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scinterpreter: Training large language models to interpret scrna-seq data for cell type annotation",
    "authors": [
      "C Li",
      "M Xiao",
      "P Wang",
      "G Feng",
      "X Li",
      "Y Zhou"
    ],
    "year": "2024",
    "abstract": "as the Foundation Model. This research focuses on how to train and adapt the Large  Language Model with the capability to interpret and distinguish cell types in singlecell RNA",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2402.12405",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=8550002402258129107&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scPlantFormer: A Lightweight Foundation Model for Plant Single-Cell Omics Analysis",
    "authors": [
      "X Zhang",
      "J Xu",
      "D Chen",
      "LN Chen"
    ],
    "year": "2024",
    "abstract": "After the preprocessing of the gene expression matrix within the single-cell dataset, we  performed a series of operations to derive the sub-vectors.. Let X c =( X c,1, X c,2,, X c,v )",
    "venue": "NA",
    "url": "https://www.researchsquare.com/article/rs-5219487/latest",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=13655896986969394936&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "ZerOmics: Toward General Models for Single-Cell Analysis with Instruction Tuning",
    "authors": [
      "K Xu",
      "Y Ding"
    ],
    "year": "NA",
    "abstract": "• We introduce an innovative dual-alignment strategy that aligns SC gene expression data   mplug-owl2: Revolutionizing multi-modal large language model with modality collaboration.",
    "venue": "NA",
    "url": "https://openreview.net/forum?id=J1xtkJmFY3",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CLM-access: A Specialized Foundation Model for High-dimensional Single-cell ATAC-seq analysis",
    "authors": [
      "Z Liu",
      "B Li",
      "Z Xu",
      "Y Li",
      "J Zhang",
      "C Sha",
      "X Li"
    ],
    "year": "2025",
    "abstract": ", treating each patch as a language model token to aggregate regional cCRE signals.  -access  model exhibits great performance in gene expression prediction tasks, with the predicted",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.08.10.669570.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CellReasoner: A reasoning-enhanced large language model for cell type annotation",
    "authors": [
      "G Cao",
      "Y Shen",
      "J Wu",
      "H Chao",
      "M Chen",
      "D Chen"
    ],
    "year": "2025",
    "abstract": "large language model (LLM) tailored for 16 single-cell type  of evidence — such as gene  expression 26 profiles, canonical  scGPT: toward building a foundation model for single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.05.20.655112.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=14072301689527717937&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Language may be all omics needs: Harmonizing multimodal data for omics understanding with CellHermes",
    "authors": [
      "Y Gao",
      "W Wang",
      "Y Zhao",
      "K Dong",
      "C Shan",
      "W Zheng"
    ],
    "year": "2025",
    "abstract": "Here we present CellHermes, a biological language model  the capability of the single-cell  foundation model it used. Exploring  Next, we ranked the gene expression values for each cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.07.687322.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Batch Effects Remain a Fundamental Barrier to Universal Embeddings in Single-Cell Foundation Models",
    "authors": [
      "L Wang",
      "C Zhang",
      "S Zhang"
    ],
    "year": "2025",
    "abstract": "by profiling gene expression at single-cell resolution [4-6]. Yet,  CellPLM [22] introduces a  cell-language model paradigm  23] is a self-supervised foundation model designed to produce",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.19.695371.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Transformers in single-cell omics: a review and new perspectives",
    "authors": [
      "A Szałata",
      "K Hrovatin",
      "S Becker",
      "A Tejada-Lapuerta"
    ],
    "year": "2024",
    "abstract": "Transformers applied to single-cell data usually encode gene expression  A single-cell  foundation model is a machine learning model  relevant for single-cell studies. A number of recent",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41592-024-02353-z",
    "num_citations": 140,
    "citedby_url": "/scholar?cites=5726219154241218082&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Evaluating the utilities of large language models in single-cell data analysis",
    "authors": [
      "H Zhao",
      "T Liu",
      "K Li",
      "Y Wang",
      "H Li"
    ],
    "year": "2023",
    "abstract": "others aim to create a foundation model in this area that can  1 (a)), termed Single-cell Large  Language Model Evaluation ( intend to predict the gene expression level after gene editing",
    "venue": "NA",
    "url": "https://www.researchsquare.com/article/rs-3376641/latest",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=10807071806417928405&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A large-scale foundation model for bulk transcriptomes",
    "authors": [
      "B Kang",
      "R Fan",
      "M Yi",
      "C Cui",
      "Q Cui"
    ],
    "year": "2025",
    "abstract": "single-cell RNA sequencing (scRNA-seq). Bulk RNA-seq 41 measures the average gene  expression  pretrained deep language model for cell type 627 annotation of single-cell RNA-",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.06.11.659222.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=4707899544272209365&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Classifying epithelial-mesenchymal transition states in single cell cancer data using large language models",
    "authors": [
      "S Pan",
      "E Withnell",
      "M Secrier"
    ],
    "year": "2024",
    "abstract": "single-cell large language model (LLM) to develop an EMT- introduces a pre-trained  foundation model that is able to 340  of the language model as a weight of raw gene expression",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.08.16.608311.abstract",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=16423846453428973070&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Large language models in bioinformatics: applications and perspectives",
    "authors": [
      "J Liu",
      "M Yang",
      "Y Yu",
      "H Xu",
      "K Li",
      "X Zhou"
    ],
    "year": "2024",
    "abstract": "in single-cell analysis focus on LLMs using gene expression  currently largest large language  model in single-cell field,  on a generative pre-trained foundation model to learn cell and",
    "venue": "arXiv preprint arXiv:2401.04155",
    "url": "https://arxiv.org/abs/2401.04155",
    "num_citations": 70,
    "citedby_url": "/scholar?cites=9038958032781643454&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Unveiling Phenotype–Genotype Interplay with Deep Learning Foundation Models for scRNA-seq: A Quantitative Perspective",
    "authors": [
      "P Thadawasin"
    ],
    "year": "2025",
    "abstract": "as powerful tools for analyzing single-cell RNA sequencing ( considered a multimodal  foundation model. Masked language  deep language model for cell type annotation of single-cell",
    "venue": "NA",
    "url": "https://dspace.mit.edu/handle/1721.1/162920",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A Cross-Species Generative Cell Atlas Across 1.5 Billion Years of Evolution: The TranscriptFormer Single-cell Model",
    "authors": [
      "JD Pearce",
      "SE Simmonds",
      "G Mahmoudabadi"
    ],
    "year": "2025",
    "abstract": "strong universal single-cell RNA foundation model that captures  , similar to a generative  language model. We exploited this  gene level, we define a gene expression profile instead as a",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.04.25.650731.abstract",
    "num_citations": 13,
    "citedby_url": "/scholar?cites=2467743520946151601&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models",
    "authors": [
      "Y Fang",
      "H Xu",
      "J Han",
      "S Ding",
      "Y Wang",
      "Y Wang"
    ],
    "year": "2025",
    "abstract": "to other modalities such as RNA and single-cell data.  For task embeddings, a pretrained  language model (PLM) is  architecture yield a foundation model that outperforms existing",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2512.00283",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scMOBA: A conversational single-cell Multi-Omics Brain Agent across species",
    "authors": [
      "R Wei",
      "Z Zhang",
      "J Sun",
      "Y Sun",
      "J Meng",
      "P Zheng"
    ],
    "year": "2025",
    "abstract": "established by a large language model, a gene encoder, and  the single-cell transcriptome  foundation model to single cell  gene expression representations, while the language model",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.01.691565.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A long range foundation model for zero-shot predictions in single-cell and spatial transcriptomics data",
    "authors": [
      "A Joshi",
      "R Boige",
      "L Zamparo",
      "U Tanielian"
    ],
    "year": "NA",
    "abstract": "Large transformers pretrained with language model objectives have demonstrated  gene  expression as discrete levels allows us to mitigate the high sparsity present in single-cell data",
    "venue": "NA",
    "url": "https://openreview.net/forum?id=VdX9tL3VXH",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CancerFoundation: A single-cell RNA sequencing foundation model to decipher drug resistance in cancer",
    "authors": [
      "A Theus",
      "F Barkmann",
      "D Wissel",
      "V Boeva"
    ],
    "year": "2024",
    "abstract": "and interpreting single-cell datasets across different conditions and experimental settings.   as “bags of RNA” by transforming the RNA gene expression of a single cell into a sample of its",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.11.01.621087.abstract",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=207652068950506026&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Benchmarking DNA foundation models for genomic and genetic tasks",
    "authors": [
      "H Feng",
      "L Wu",
      "B Zhao",
      "C Huff",
      "J Zhang",
      "J Wu"
    ],
    "year": "2025",
    "abstract": "codes, protein sequences and single-cell sequencing 4,5,6,7 .  to predict gene expression  from DNA foundation model zero- -range DNA foundation language model that leverages the",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41467-025-65823-8",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=4696745448976647602&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scGenePT: Is language all you need for modeling single-cell perturbations?",
    "authors": [
      "AM Istrate",
      "D Li",
      "T Karaletsos"
    ],
    "year": "2024",
    "abstract": "of single-cell biology. Predicting the effect of up or down gene regulation or drug treatment  on the gene expression  the popular scGPT model, a foundation model trained on scRNA-seq",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.10.23.619972.abstract",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=2041832547672742227&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Investigation of cell development and tissue structure network based on natural Language processing of scRNA-seq data",
    "authors": [
      "S Wei",
      "Y Lu",
      "P Wang",
      "Q Li",
      "J Shuai",
      "Q Zhao"
    ],
    "year": "2025",
    "abstract": "providing insights into gene expression at the single-cell level.  In contrast, language  model-based embeddings are learned  trajectories in gene expression data, language",
    "venue": "Journal of Translational …",
    "url": "https://link.springer.com/article/10.1186/s12967-025-06263-2",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=8483279608277130314&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "eSPred: Explainable scRNA-seq Prediction via Customized Foundation Models and Pathway-Aware Fine-tuning",
    "authors": [
      "L Sun",
      "Q Yang",
      "J Zhang",
      "W Guo",
      "L Lin"
    ],
    "year": "2025",
    "abstract": "For instance, pseudobulk approaches aggregate gene expression across cells, effectively   scGPT foundation model, to improve clinical prediction and interpretability in single-cell RNA",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.05.14.654052.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "screader: Prompting large language models to interpret scrna-seq data",
    "authors": [
      "C Li",
      "Q Long",
      "Y Zhou",
      "M Xiao"
    ],
    "year": "2024",
    "abstract": "LLM to understand and analyze single-cell RNA sequencing ( language model to facilitate  understanding of the single-cell  : Towards building a foundation model for single-cell multi-",
    "venue": "2024 IEEE International …",
    "url": "https://ieeexplore.ieee.org/abstract/document/10917306/",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=8654951797349558270&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "spEMO: Leveraging Multi-Modal Foundation Models for Analyzing Spatial Multi-Omic and Histopathology Data",
    "authors": [
      "T Liu",
      "T Huang",
      "T Ding",
      "H Wu",
      "P Humphrey"
    ],
    "year": "2025",
    "abstract": "a spatial transcriptomics foundation model for clustering.  the gene expression embeddings  from single-cell foundation  and its embeddings from a large language model as two mapping",
    "venue": "BioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.01.13.632818.abstract",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=820277581886597854&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Scaling dense representations for single cell with transcriptome-scale context",
    "authors": [
      "N Ho",
      "CN Ellington",
      "J Hou",
      "S Addagudi",
      "S Mo",
      "T Tao"
    ],
    "year": "2024",
    "abstract": "Cell, a scalable transformer-based foundation model for single cell gene expression, and  a  Efficient large-scale language model training on gpu clusters using megatron-lm. In",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.11.28.625303.abstract",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=14938520482273245248&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CellVerse: Do Large Language Models Really Understand Cell Biology?",
    "authors": [
      "F Zhang",
      "T Liu",
      "Z Zhu",
      "H Wu",
      "H Wang",
      "D Zhou"
    ],
    "year": "2025",
    "abstract": "a novel perspective: transforming single-cell data into natural  the modality, single-cell data  may capture gene expression (scRNA Scieval: A multi-level large language model evaluation",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2505.07865",
    "num_citations": 9,
    "citedby_url": "/scholar?cites=11752996642086029052&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Spatial Cell-Guided Pretraining for Scalable Spatial Transcriptomics Foundation Model",
    "authors": [
      "J Gong",
      "Y Wang",
      "N Ho",
      "X Cheng",
      "L Song"
    ],
    "year": "NA",
    "abstract": "Single-cell spatial transcriptomics enables highresolution  been exposed to both single-cell  and spatial transcriptomics  exclusively on reconstructing the gene expression of the center",
    "venue": "ICML 2025 Generative AI …",
    "url": "https://openreview.net/forum?id=ywMEiJyV0m",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scChat: A large language model-powered co-pilot for contextualized single-cell RNA sequencing analysis",
    "authors": [
      "HH Chiu",
      "A Varghese",
      "K Shao",
      "YC Lu",
      "R Nahar"
    ],
    "year": "2024",
    "abstract": "utilized scRNA-seq to examine tumor-infiltrating T cells’ gene expression and clonal landscape  across 31 patients with gliomas, including isocitrate dehydrogenase (IDH) wild-type GBM",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.10.01.616063.abstract",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=10436522255536879306&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Transformers and genome language models",
    "authors": [
      "ME Consens",
      "C Dufault",
      "M Wainberg"
    ],
    "year": "2025",
    "abstract": "single-cell  , gene expression, and transcription factor binding 26,108,109 . Some transformer  models have recently been proposed to mitigate the bias of cross-cell-line gene expression",
    "venue": "Nature Machine …",
    "url": "https://www.nature.com/articles/s42256-025-01007-9",
    "num_citations": 70,
    "citedby_url": "/scholar?cites=7240802530008956302&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "MoRE: Batch-Robust Multi-Omics Representations from Frozen Language Models",
    "authors": [
      "APH Chen"
    ],
    "year": "NA",
    "abstract": "framework repurposes frozen language-model backbones for  the current landscape of  single-cell computational methods,  to build a biological foundation model using the transformer",
    "venue": "NA",
    "url": "https://openreview.net/forum?id=w1My2NsKd7",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CELLama: cell embedding leveraging language model abilities for analyzing cell types and spatial relationship in tumor",
    "authors": [
      "J Kim",
      "J Park",
      "S Kim",
      "D Lee",
      "S Bae",
      "H Shin"
    ],
    "year": "2025",
    "abstract": "Single-cell RNA sequencing (scRNA-seq) and spatial  Leverage Language Model Abilities),  a foundation model that  , with major focus on gene expression and including metadata on",
    "venue": "Cancer …",
    "url": "https://aacrjournals.org/cancerres/article/85/8_Supplement_1/2416/754835",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Evaluating the role of pre-training dataset size and diversity on single-cell foundation model performance",
    "authors": [
      "A DenAdel",
      "M Hughes",
      "A Thoutam",
      "A Gupta",
      "AW Navia"
    ],
    "year": "2024",
    "abstract": "In this study, we calculate the Vendi Score of the gene expression matrix for each 440 dataset.   -scale pretrained deep language model for cell type annotation of 529 single-cell rna-seq",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.13.628448.abstract",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=17625385067980468583&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "The cell as a token: high-dimensional geometry in language models and cell embeddings",
    "authors": [
      "W Gilpin"
    ],
    "year": "2025",
    "abstract": "models built upon language model architectures—represent the  , mirroring findings from  single-cell biology in identifying  foundation model paradigm in both language modelling and",
    "venue": "Bioinformatics",
    "url": "https://academic.oup.com/bioinformatics/article/doi/10.1093/bioinformatics/btaf595/8306768",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=12190454203389380416&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "GPTAnno: Ontology-tree-guided hierarchical cell type annotation based on GPT models for single-cell data",
    "authors": [
      "Y Song",
      "M Tang",
      "Q Liu",
      "H Wang",
      "L Qian",
      "F Zou",
      "W Hou"
    ],
    "year": "2025",
    "abstract": "Cell type annotation is critical for interpreting single-cell transcriptomic data but remains   gene expression matrices, integrates multi-resolution clustering with large language model",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.27.690951.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CART-GPT: AT Cell-Informed AI Linguistic Framework for Interpreting Neurotoxicity and Therapeutic Outcomes in CAR-T Therapy",
    "authors": [
      "T Mao",
      "X Shao",
      "W Guo",
      "Z Jiang",
      "R Jing",
      "X Li",
      "Y Zhu"
    ],
    "year": "2025",
    "abstract": ", the first foundation model-driven framework fine-tuned on single-cell transcriptomic data   model that learns latent representations of gene expression while integrating across datasets.",
    "venue": "…",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12363796/",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=4633719828376065961&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Biomedical foundation model: A survey",
    "authors": [
      "X Liu",
      "Y Zhang",
      "Y Lu",
      "C Yin",
      "X Hu",
      "X Liu",
      "L Chen"
    ],
    "year": "2025",
    "abstract": "Following this work, a series of DNA language model has been  foundation models for  single-cell profiles, enabling the  our understanding of gene expression dynamics across diverse",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2503.02104",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=10385415915079014453&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Representation learning of single-cell RNA-seq data",
    "authors": [
      "C Ahlmann-Eltze",
      "F Barkmann",
      "J Lause",
      "V Boeva"
    ],
    "year": "2026",
    "abstract": ", with gene expression data for over  foundation model emerged during the rise of large  language models (LLMs) and has since spread across many other domains, including single-cell",
    "venue": "RNA",
    "url": "https://rnajournal.cshlp.org/content/early/2026/01/08/rna.080889.125.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Gp-gpt: Large language model for gene-phenotype mapping",
    "authors": [
      "Y Lyu",
      "Z Wu",
      "L Zhang",
      "J Zhang",
      "Y Li",
      "W Ruan"
    ],
    "year": "2024",
    "abstract": "such as transcriptomics and gene expression analysis. In the  powerful tools for integrating  single-cell data and other omics  of the biological context of gene expression and, ultimately,",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2409.09825",
    "num_citations": 20,
    "citedby_url": "/scholar?cites=18155204338309205541&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Transforming Biological Foundation Model Representations for Out-of-Distribution Data",
    "authors": [
      "A Pratapa",
      "PR Tata",
      "R Singh"
    ],
    "year": "2025",
    "abstract": "For single-cell data, we correct scGPT embeddings from  For the two domains explored  in this study (gene expression  a language model. Science , 379(6637):1123–1130, 3 2023.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.20.689462.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "STPath: a generative foundation model for integrating spatial transcriptomics and whole-slide images",
    "authors": [
      "T Huang",
      "T Liu",
      "M Babadi",
      "R Ying",
      "W Jin"
    ],
    "year": "2025",
    "abstract": ", a generative foundation model pretrained  gene expression across 38,984 genes and 17  organs without downstream fine-tuning. STPath integrates histology images, gene expression,",
    "venue": "NPJ Digital Medicine",
    "url": "https://www.nature.com/articles/s41746-025-02020-3",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=10805447728455116898&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Lemur: A Single-Cell Foundation Model with Fine-Tuning-Free Hierarchical Cell-Type Generation for Drosophila melanogaster",
    "authors": [
      "J Botas",
      "J Jia",
      "S Pasupuleti",
      "H Chen",
      "X Hu",
      "Z Xu",
      "Z Liu"
    ],
    "year": "2025",
    "abstract": "-seq), a single-cell foundation model specifically designed for  The exponential growth of  single-cell genomics data has  must meticulously evaluate gene expression patterns to assign",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.02.04.636468.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Biological Reasoning with Reinforcement Learning through Natural Language Enables Generalizable Zero-Shot Cell Type Annotations",
    "authors": [
      "X Wang",
      "R Tan",
      "B Wang",
      "S Cristea"
    ],
    "year": "2025",
    "abstract": "biology, enabling the study of gene expression in individual cells and revealing previously   scGPT15 single-cell foundation model for benchmarking cell type annotation at the single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.06.17.659642.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=11442478999387854190&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Empirical Evaluation of Single-Cell Foundation Models for Predicting Cancer Outcomes",
    "authors": [
      "H Elmarakeby",
      "A Roman",
      "S Johri",
      "EM Van Allen"
    ],
    "year": "2025",
    "abstract": "single-cell datasets are increasingly applied to decode this complexity in non-cancer settings,  and they may hold promise for interpreting cancer single cell  influence foundation model",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.10.31.685892.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "ChromFound: Towards A Universal Foundation Model for Single-Cell Chromatin Accessibility Data",
    "authors": [
      "Y Jiao",
      "Y Liu",
      "Y Zhang",
      "X Guo",
      "Y Wu",
      "C Jiang"
    ],
    "year": "2025",
    "abstract": "spatial and temporal gene expression patterns [34]. Identifying OCRs at single-cell level is   -scale pretrained deep language model for cell type annotation of single-cell rna-seq data.",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2505.12638",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Multimodal learning of transcriptomes and text enables interactive single-cell RNA-seq data exploration with natural-language chats",
    "authors": [
      "M Schaefer",
      "P Peneder",
      "D Malzl",
      "M Peycheva",
      "J Burton"
    ],
    "year": "2024",
    "abstract": "fluent large language model that we fine-tuned to analyze bulk and single-cell transcriptome   part of the gene set) and the gene expression enrichment across all genes in the gene set,",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.10.15.618501.abstract",
    "num_citations": 14,
    "citedby_url": "/scholar?cites=11809725582178661256&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scGenAI: A generative AI platform with biological context embedding of multimodal features enhances single cell state classification",
    "authors": [
      "R Wang",
      "M Ung",
      "HG Ge"
    ],
    "year": "2025",
    "abstract": "Summary Single-cell sequencing has advanced the understanding of cellular heterogeneity  , or disease-specific studies where unique gene expression patterns are critical. To address",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.05.07.652733.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Knowledge-Enriched Cell-Type Annotation in Single-Cell Transcriptomics via LLM Embeddings",
    "authors": [
      "A Fabbricatore",
      "FM Buffa"
    ],
    "year": "2025",
    "abstract": "the ability to profile gene expression at single-cell resolution, allowing  Poon, “Domain-specific  language model pretraining for  : toward building a foundation model for single-cell multi-",
    "venue": "2025 IEEE Conference …",
    "url": "https://ieeexplore.ieee.org/abstract/document/11177124/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Tissue-Specific Cell Type Annotation with Supervised Representation Learning using Split Vector Quantization and Its Comparisons with Single-cell Foundation …",
    "authors": [
      "YD Heryanto",
      "Y Zhang",
      "S Imoto"
    ],
    "year": "2024",
    "abstract": "dataset based on their gene expression profiles or molecular  a comprehensive comparison  of foundation model (FM)-based  deep language model for cell type annotation of single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.09.627458.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "EpiFoundation: A foundation model for single-cell ATAC-seq via peak-to-gene alignment",
    "authors": [
      "J Wu",
      "C Wan",
      "Z Ji",
      "Y Zhou",
      "W Hou"
    ],
    "year": "2025",
    "abstract": "Gene activity is widely applied as the replacement of gene expression in single-cell ATAC-seq  data by summarizing the ATAC-seq reads near the transcription start sites of genes. Here,",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11839112/",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=2119754277011458954&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Abstract B041: A Cellular Network-Aware Foundation Model Improves Single-Cell Level Predictions",
    "authors": [
      "M Zhang",
      "V Swamy",
      "L Dupire",
      "R Cassius"
    ],
    "year": "2025",
    "abstract": "These networks can also enhance language model  improve single cell foundation model  performance. For this  structure understanding, and gene expression predictions. The cellular",
    "venue": "Clinical Cancer …",
    "url": "https://aacrjournals.org/clincancerres/article/31/13_Supplement/B041/763341",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Diffusion-based Representation Integration for Foundation Models Improves Spatial Transcriptomics Analysis",
    "authors": [
      "A Jain",
      "TM Pham",
      "DH Laidlaw",
      "Y Ma",
      "R Singh"
    ],
    "year": "2025",
    "abstract": "into pre-trained single-cell foundation models by leveraging  -based or masked  language-model architectures. The  the input gene expression matrix from the foundation model’",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.20.689624.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Generalized biological foundation model with unified nucleic acid and protein language",
    "authors": [
      "Y He",
      "P Fang",
      "Y Shan",
      "Y Pan",
      "Y Wei",
      "Y Chen"
    ],
    "year": "2025",
    "abstract": "The attempt to build a universal biological language model is to develop a sophisticated  cataloguing and retrieval system for ‘The Library of Mendel’—the genetic version of ‘The Library",
    "venue": "Nature Machine …",
    "url": "https://www.nature.com/articles/s42256-025-01044-4",
    "num_citations": 28,
    "citedby_url": "/scholar?cites=9914143331159372864&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Consequences of training data composition for deep learning models in single-cell biology",
    "authors": [
      "A Nadig",
      "A Thoutam",
      "M Hughes",
      "A Gupta",
      "AW Navia"
    ],
    "year": "2025",
    "abstract": "Intercellular variability in gene expression gives rise to a wide variety of complex biological   In alignment with this view, fitting a “complete” foundation model of single-cell transcriptomic",
    "venue": "…",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11888162/",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=10190200238312337035&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "UniCell: Towards a Unified Solution for Cell Annotation, Nomenclature Harmonization, Atlas Construction in Single-Cell Transcriptomics",
    "authors": [
      "L Hu",
      "Q Chen",
      "P Qiu",
      "H Qin",
      "Y Zhang",
      "L Cao",
      "T Xia"
    ],
    "year": "2025",
    "abstract": ", or a pre-trained single-cell foundation model (scFM) that enhances  Gene expression data  are first encoded into cell embeddings () via an encoder. An optional large language model",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.05.06.652331.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "stFormer: a foundation model for spatial transcriptomics",
    "authors": [
      "S Cao",
      "K Yang",
      "J Cheng",
      "J Li",
      "HB Shen",
      "X Pan",
      "Y Yuan"
    ],
    "year": "2024",
    "abstract": "The large language model based on the Generative Pretrained  One is how to incorporate  spatial information into gene expression  of a single-cell transcriptomics foundation model,",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.09.27.615337.abstract",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=18030986262224806847&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Application of artificial intelligence large language models in drug target discovery",
    "authors": [
      "X Liu",
      "J Zhang",
      "X Wang",
      "M Teng",
      "G Wang"
    ],
    "year": "2025",
    "abstract": "language model has significantly enhanced the accuracy of pathogenic gene variant  identification and gene expression  Additionally, the single-cell multi-omics large language model",
    "venue": "Frontiers in …",
    "url": "https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2025.1597351/full",
    "num_citations": 10,
    "citedby_url": "/scholar?cites=3496256397716272858&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CellMemory: hierarchical interpretation of out-of-distribution cells using bottlenecked transformer",
    "authors": [
      "Q Wang",
      "H Zhu",
      "Y Hu",
      "Y Chen",
      "Y Wang",
      "G Li",
      "Y Li"
    ],
    "year": "2025",
    "abstract": "Without pre-training, CellMemory outperforms existing single-cell foundation models and   to characterize features such as genes, while gene expression is processed in a bag-of-words",
    "venue": "Genome Biology",
    "url": "https://link.springer.com/article/10.1186/s13059-025-03638-y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Weighted Diversified Sampling for Efficient Data-Driven Single-Cell Gene-Gene Interaction Discovery",
    "authors": [
      "Y Wu",
      "Y Yang",
      "Z Liu",
      "Z Li",
      "K Pahwa",
      "R Li"
    ],
    "year": "2024",
    "abstract": "Single-cell transcriptomic is a technology that profiles gene expression at the individual cell   different from the data on which the foundation model was trained, the model might struggle",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2410.15616",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=3061880940199240315&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Evaluating Single-Cell Foundation Models for Cell Retrieval",
    "authors": [
      "Y Fan",
      "L KinHei",
      "K Dallakyan",
      "X Wang",
      "Y Wang",
      "L Zong"
    ],
    "year": "NA",
    "abstract": ", VAE-based methods and single-cell foundation model (scFM) based  Therefore, we analyze  the consistency of gene expression  pre-trained language model for single-cell analysis. In",
    "venue": "NA",
    "url": "https://openreview.net/forum?id=iOltCu4TPS",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CeLLTra: Aligning Cell Names with Gene Expression via a Pathway-Informed Transformer",
    "authors": [
      "Z Li",
      "Z Zheng",
      "R Li",
      "W Chen",
      "Y Yang",
      "MA Ali",
      "J Li"
    ],
    "year": "2025",
    "abstract": "pretrained language model to  single-cell gene expression data for clustering cancerous  cell states, we demonstrated improved clustering accuracy compared to using gene expression",
    "venue": "…",
    "url": "https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaf655/8371888",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "CellPatch: a Highly Efficient Foundation Model for Single-Cell Transcriptomics with Heuristic Patching",
    "authors": [
      "H Zhu",
      "Y Yuan",
      "J Yang",
      "K Cai",
      "N Wei",
      "S Zhang",
      "L Wang"
    ],
    "year": "2024",
    "abstract": "435 (https://support.10xgenomics.com/single-cell-gene-expression/datasets)23, 436  pancreatic datasets from the scGPT foundation model processed datasets 437 (https://hemberg-lab.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.11.15.623701.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Generalized biological foundation model with unified nucleic acid and protein",
    "authors": [
      "Y He",
      "P Fang",
      "Y Shan",
      "Y Pan",
      "Y Wei",
      "Y Chen",
      "Y Chen"
    ],
    "year": "NA",
    "abstract": "",
    "venue": "NA",
    "url": "",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A systematic assessment of single-cell language model configurations",
    "authors": [
      "G De Waele",
      "G Menschaert",
      "W Waegeman"
    ],
    "year": "2025",
    "abstract": ": if one wants a single-cell foundation model to be applicable  of full 19331-length gene  expression profiles. All rows in X  task is constructed where gene expression levels of one gene is",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.04.02.646825.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=11053363893907171184&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "BioToken and BioFM–Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models",
    "authors": [
      "A Medvedev",
      "K Viswanathan",
      "P Kanithi",
      "K Vishniakov"
    ],
    "year": "2025",
    "abstract": "as gene expression, alternative splicing, and variant pathogenicity prediction. Built on BioToken,  our genomic foundation model,  Another direction is to add information from single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.03.27.645711.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=15635018522662661457&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Assessing Scale and Predictive Diversity in Models for Single-Cell Transcriptomics based on Geneformer",
    "authors": [
      "J Chen",
      "F Schmidt",
      "R Henao"
    ],
    "year": "2025",
    "abstract": "single-cell profiles and show strong performance in tasks including cell type classification  and gene expression  , as an extension of the masked language model GF. The model retains",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.04.686458.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Gene-LLMs: a comprehensive survey of transformer-based genomic language models for regulatory and clinical genomics",
    "authors": [
      "P Balakrishnan",
      "A Anny Leema",
      "V Dhivya Shree"
    ],
    "year": "2025",
    "abstract": "provide a brief overview of single-cell RNA-based foundation  strategies for the genomic  language model, covering pretext  to single-cell RNA data for studies on gene expression in",
    "venue": "Frontiers in …",
    "url": "https://www.frontiersin.org/journals/genetics/articles/10.3389/fgene.2025.1634882/full",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Multi-Modal Foundation Models for Computational Pathology: A Survey",
    "authors": [
      "D Li",
      "G Wan",
      "X Wu",
      "X Wu",
      "X Chen",
      "Y He"
    ],
    "year": "2025",
    "abstract": "data with gene expression information, vision-gene expression  are mapped to the language  model input space, leveraging a  scGPT: toward building a foundation model for single-cell",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2503.09091",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=16920467224894306443&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Large language models in bioinformatics: A survey",
    "authors": [
      "Z Wang",
      "Z Wang",
      "J Jiang",
      "P Chen",
      "X Shi"
    ],
    "year": "2025",
    "abstract": "of different molecule’s language model features and uses  the examination of gene expression  and transcription levels  -the-art foundation model designed for single-cell multi-omics",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2503.04490",
    "num_citations": 17,
    "citedby_url": "/scholar?cites=2490941921436261790&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scOTM: a deep learning framework for predicting single-cell perturbation responses with large Language models",
    "authors": [
      "Y Wang",
      "T Lu",
      "X Chen",
      "Z Yao",
      "KC Wong"
    ],
    "year": "2025",
    "abstract": "- β -induced gene expression changes at single-cell resolution holds great  Belinostat alters  gene expression by modulating chromatin  transcriptional responses at single-cell resolution.",
    "venue": "Bioengineering",
    "url": "https://www.mdpi.com/2306-5354/12/8/884",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=187839712554095086&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Automated Single-Cell RNA Sequencing Analysis Supported by Large Language Models",
    "authors": [
      "YC Lu"
    ],
    "year": "2025",
    "abstract": "Data-driven methods, including machine learning, have advanced single-cell RNA sequencing  (scRNA-seq) analysis, but they often fail to integrate research context, limiting their ability",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/067e65f3fddf428f12284c899f2b7cc5/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Cell-JEPA: Latent Representation Learning for Single-Cell Transcriptomics",
    "authors": [
      "A ElSheikh",
      "RX Wang",
      "W Wu",
      "Y Wen"
    ],
    "year": "2026",
    "abstract": "a self-supervised foundation model for single-cell transcriptomics. Single-cell transcriptomics   facilitates learning more informative representations from single-cell gene expression data.",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2602.02093",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "dGeneralized Biological Foundation Model with Unified Nucleic Acid and Protein Language",
    "authors": [
      "Y He",
      "P Fang",
      "Y Shan",
      "Y Pan",
      "Y Wei",
      "Y Chen",
      "Y Chen"
    ],
    "year": "2024",
    "abstract": "The attempt to build a universal biological language model is to develop a sophisticated  cata-loging and retrieval system for ”The Library of Mendel” - the genetic version of ”The Library",
    "venue": "BioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.05.10.592927.abstract",
    "num_citations": 24,
    "citedby_url": "/scholar?cites=364962197484193845&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "A comprehensive survey of foundation models in medicine",
    "authors": [
      "W Khan",
      "S Leem",
      "KB See",
      "JK Wong"
    ],
    "year": "2025",
    "abstract": "large-scale clinical language model developed from scratch  hit-like molecules utilizing  gene expression signatures. This  in annotating cell types using singlecell RNA-seq data. The",
    "venue": "IEEE Reviews in …",
    "url": "https://ieeexplore.ieee.org/abstract/document/10847310/",
    "num_citations": 106,
    "citedby_url": "/scholar?cites=16328295851361080311&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Clifti-GPT: Privacy-preserving federated fine-tuning and transferable inference of foundation models on clinical single-cell data",
    "authors": [
      "M Bakhtiari",
      "ML Elkjaer",
      "AO Can",
      "F Theis",
      "M Oubounyt"
    ],
    "year": "2025",
    "abstract": "analysis using the scGPT foundation model, we compared the  pretrained foundation model,  and all gene expression values  For cell type annotation tasks, gene expression values were",
    "venue": "NA",
    "url": "https://www.researchsquare.com/article/rs-7917089/latest",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Predicting drug responses of unseen cell types through transfer learning with foundation models",
    "authors": [
      "Y Wang",
      "X Liu",
      "Y Fan",
      "B Xie",
      "J Cheng"
    ],
    "year": "2026",
    "abstract": "biological information using language model frameworks.  Single-cell measurements are  inherently unpaired since cell  , CRISP employs a foundation-model-assisted paired control",
    "venue": "Nature Computational …",
    "url": "https://www.nature.com/articles/s43588-025-00887-6",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=15067645104333734119&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scLinguist: A pre-trained hyena-based foundation model for cross-modality translation in single-cell multi-omics",
    "authors": [
      "Z Fang",
      "Z Miao",
      "J Lin",
      "Y Xie",
      "J Tang",
      "J Ding",
      "M Li"
    ],
    "year": "2025",
    "abstract": "Given a corrupted single-cell gene expression profile, scLinguist learns to reconstruct the  original uncorrupted version by minimizing the mean squared error (MSE) between the",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.09.30.679123.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "PULSAR: a Foundation Model for Multi-scale and Multicellular Biology",
    "authors": [
      "K Pang",
      "Y Rosen",
      "K Kedzierska",
      "Z He",
      "A Rajagopal"
    ],
    "year": "2025",
    "abstract": "ESM2 [19], a protein language model trained on amino-acid  raw gene expression profiles  into single-cell representations.  that leverages existing single-cell atlases for disease",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.24.685470.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "Large language models in plant biology",
    "authors": [
      "HYI Lam",
      "XE Ong",
      "M Mutwil"
    ],
    "year": "2024",
    "abstract": "transformer (GPT) foundation model that was pretrained on vast  single-cell RNA-sequencing  data, where gene expression  of atomic-level protein structure with a language model",
    "venue": "Trends in Plant Science",
    "url": "https://www.cell.com/trends/plant-science/abstract/S1360-1385(24)00118-3",
    "num_citations": 55,
    "citedby_url": "/scholar?cites=15506419241408041992&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_primary",
    "title": "scPRINT-2: Towards the next-generation of cell foundation models and benchmarks",
    "authors": [
      "J Kalfon",
      "G Peyré",
      "L Cantini"
    ],
    "year": "2025",
    "abstract": "foundation models trained on large single-cell RNA-seq databases scPRINT-2, a single-cell  Foundation Model pre-trained across  We encode the gene expression using the scPRINT-1",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.11.693702.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative artificial intelligence, integrative bioinformatics, and single-cell analysis reveal Alzheimer's genetic and immune landscape",
    "authors": [
      "A Das",
      "M Bhattacharya",
      "AS Abdelhameed"
    ],
    "year": "2025",
    "abstract": "The single-cell gene expression  generative pre-trained transformer (GPT) architecture and  it was released on November 30, 2022. After it was released, it became famous, and the GPT",
    "venue": "… Therapy Nucleic Acids",
    "url": "https://www.cell.com/molecular-therapy-family/nucleic-acids/fulltext/S2162-2531(25)00100-3",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=11263180132721306704&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative pretraining from large-scale transcriptomes for single-cell deciphering",
    "authors": [
      "H Shen",
      "J Liu",
      "J Hu",
      "X Shen",
      "C Zhang",
      "D Wu",
      "M Feng"
    ],
    "year": "2023",
    "abstract": "Rank-based methods for gene expression have been demonstrated to be insensitive to   Representative pretraining models include BERT 14 and GPT. The advantage of these",
    "venue": "Iscience",
    "url": "https://www.cell.com/iscience/fulltext/S2589-0042(23)00613-2",
    "num_citations": 46,
    "citedby_url": "/scholar?cites=354754442171636807&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Deep Learning of Discriminative Gene Expression Models and Generative Models of Molecule and Protein Sequences",
    "authors": [
      "E Honig"
    ],
    "year": "2025",
    "abstract": "In addition to the Gonadotropes cell type, we test our method on two other cell types from  our single-cell gene expression data: Somatotropes and Stem Cells. We find that our distilled",
    "venue": "NA",
    "url": "https://escholarship.org/uc/item/9038j3dw",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Recent advances in generative adversarial networks for gene expression data: a comprehensive review",
    "authors": [
      "M Lee"
    ],
    "year": "2023",
    "abstract": ", the auxiliary information was single-cell RNA-seq data, which captures gene expression at  an  to generate realistic synthetic gene expression data at a single-cell resolution, enhancing",
    "venue": "Mathematics",
    "url": "https://www.mdpi.com/2227-7390/11/14/3055",
    "num_citations": 68,
    "citedby_url": "/scholar?cites=16065450184500639286&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Prompt engineering-enabled generative artificial intelligence (GenAI), instigative bioinformatics, and single-cell analysis reveal the Alzheimer's genetic and immune …",
    "authors": [
      "A Das",
      "M Bhattacharya",
      "AS Abdelhameed"
    ],
    "year": "2025",
    "abstract": "single-cell analysis. Here, 169 we performed the study in different directions using the  single-cell  immune cell type and their single-cell gene expression study reveal that the top ten",
    "venue": "… Therapy Nucleic Acids",
    "url": "https://www.sciencedirect.com/science/article/pii/S2162253125001003",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "A Systematic Review on the Generative AI Applications in Human Medical Genomics",
    "authors": [
      "A Changalidis",
      "Y Barbitoff",
      "Y Nasykhova"
    ],
    "year": "2025",
    "abstract": "Genomic and medical Imaging) aligned gene expression and MRI via contrastive learning   eg, CRISPR-GPT) to predicting cellular responses to perturbations at single-cell resolution (eg",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2508.20275",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative pretraining from large-scale transcriptomes: Implications for single-cell deciphering and clinical translation",
    "authors": [
      "H Shen",
      "X Shen",
      "J Hu",
      "J Liu",
      "C Zhang",
      "D Wu",
      "M Feng"
    ],
    "year": "2022",
    "abstract": "22.3 million single-cell transcriptomes by modeling gene expression rankings as generative   Representative pretraining models include BERT 14 and GPT 15 . The advantage of these",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2022.01.31.478596.abstract",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=5497693222328925394&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "BioNexusSentinel: a visual tool for bioregulatory network and cytohistological RNA-seq genetic expression profiling within the context of multicellular simulation …",
    "authors": [
      "RO Matzko",
      "S Konur"
    ],
    "year": "2024",
    "abstract": "engineering collaboration with generative natural language  GPT-3 used the same architecture  as GPT-2 except using  Clearly, nTPM values could vary drastically within a single cell",
    "venue": "Bioinformatics Advances",
    "url": "https://academic.oup.com/bioinformaticsadvances/advance-article/doi/10.1093/bioadv/vbae046/7632747",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=9024287248050607852&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "DeepSeq: High–Throughput Single–Cell RNA Sequencing Data Labeling via Web Search–Augmented Agentic Generative AI Foundation Models",
    "authors": [
      "SA Al Dajani",
      "A Sanchez",
      "JR Williams"
    ],
    "year": "2025",
    "abstract": "Unlike bulk sequencing, which averages gene expression across thousands of cells, single-cell   Our results show that foundation models, particularly agentic variants like gpt-4o, can",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.06.17.660107.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=18308415637037219278&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "GeST: Towards Building A Generative Pretrained Transformer for Learning Cellular Spatial Context",
    "authors": [
      "M Hao",
      "N Yan",
      "H Bian",
      "Y Chen",
      "J Gu",
      "L Wei",
      "X Zhang"
    ],
    "year": "2025",
    "abstract": "As detailed in Table 3, our model greatly outperformed the single-cell methods at both  resolutions. This is because the niche labels were annotated in terms of both gene expression",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.04.09.648072.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=11165988457319836705&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative artificial intelligence in genetics: A comprehensive review",
    "authors": [
      "NL Franciss"
    ],
    "year": "2025",
    "abstract": "model GPT for single-cell biology called scGPT, whereby the GPT is  are employing generative  AI to predict gene expression,  networks that control gene expression. These advances",
    "venue": "Deep Learning in Genetics and Genomics",
    "url": "https://www.sciencedirect.com/science/article/pii/B9780443275234000056",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "A pre-trained large generative model for translating single-cell transcriptomes to proteomes",
    "authors": [
      "L Liu",
      "W Li",
      "F Wang",
      "Y Li",
      "LK Huang",
      "KC Wong"
    ],
    "year": "2025",
    "abstract": "generative model named single-cell translator (scTranslator). scTranslator can generate  multi-omics data by inferring the missing single-cell  technique measures gene expression in",
    "venue": "Nature Biomedical …",
    "url": "https://www.nature.com/articles/s41551-025-01528-z",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=12215509917757635638&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Assessing GPT-4 for cell type annotation in single-cell RNA-seq analysis",
    "authors": [
      "W Hou",
      "Z Ji"
    ],
    "year": "2024",
    "abstract": "Generative pre-trained transformers (GPT), including GPT-3.5 and  GPT-4. In contrast, other  methods like SingleR and ScType require additional steps to reprocess the gene expression",
    "venue": "Nature methods",
    "url": "https://www.nature.com/articles/s41592-024-02235-4",
    "num_citations": 230,
    "citedby_url": "/scholar?cites=18196665830696178387&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "13 Single-Cell RNA-seq Data",
    "authors": [
      "QB Baker",
      "S Singh",
      "A Agrawal"
    ],
    "year": "2025",
    "abstract": "of gene expression patterns in their native tissue context, including  generative pretrained  transformer (GPT) and bidirectional encoder  on the utility of generative AI in single-cell biology:",
    "venue": "Next-Generation Sequencing …",
    "url": "https://books.google.com/books?hl=en&lr=&id=ib5VEQAAQBAJ&oi=fnd&pg=PA184&dq=GPT+%22single+cell%22+%22gene+expression%22+generative&ots=kPb8y1Jdj_&sig=w0KRMMBpfHon9FlkbcT297cw5Bw",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=8192203079858658886&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances",
    "authors": [
      "R Alvi",
      "SB Zaman",
      "W Karim",
      "AI Abian"
    ],
    "year": "2025",
    "abstract": "and GPT have penetrated key areas, including protein structure prediction, drug discovery,  gene expression  by jointly predicting singlecell gene expression, chromatin accessibility, and",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2511.03354",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Multifaceted Representation of Genes via Deep Learning of Gene Expression Networks",
    "authors": [
      "Z Su",
      "M Fang",
      "A Smolnikov",
      "ME Dinger",
      "EC Oates"
    ],
    "year": "2024",
    "abstract": "architectures like the Generative Pre-Training (GPT) model 16 ,  deep learning models  on large gene expression data, we began  and removing potential single-cell samples (Methods),",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.03.07.583777.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=12102838028403199749&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Beyond the hype: The complexity of automated cell type annotations with GPT-4",
    "authors": [
      "A Kazmi",
      "D Singh",
      "S Jatav",
      "S Luthra"
    ],
    "year": "2025",
    "abstract": "In this study, we selected nine diverse single cell RNA sequencing datasets (scRNA-seq)   multiple cell types share overlapping gene expression patterns. Retrieval contextualized the",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.02.11.637659.abstract",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=149581071517773797&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "scEMB: Learning context representation of genes based on large-scale single-cell transcriptomics",
    "authors": [
      "KL Hsieh",
      "Y Chu",
      "X Li",
      "PG Pilié",
      "Y Dai"
    ],
    "year": "2024",
    "abstract": "More recently, large-language models (LLM) such as GPT 20,21  in predicting cellular  gene expression responses to specific  Leveraging generative modeling, scEMB can implicitly",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11463607/",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=460942038494400564&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Mouse-Geneformer: A deep learning model for mouse single-cell transcriptome and its cross-species utility",
    "authors": [
      "K Ito",
      "T Hirakawa",
      "S Shigenobu",
      "H Fujiyoshi"
    ],
    "year": "2025",
    "abstract": "powerful technique that quantifies gene expression profiles at the  generative model  Gaussian-mixture VAE (GMVAE) [26] to  can likely be attributed to its GPT-based architecture,",
    "venue": "Plos …",
    "url": "https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1011420",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=17923889343830776220&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Transcriptome-conditioned molecule generation via gene interaction-aware fragment modeling with a GPT-based architecture",
    "authors": [
      "B Koo",
      "BK Park",
      "S Kim"
    ],
    "year": "2025",
    "abstract": "For instance, generative adversarial networks and  Building upon this concept, this work  aims to develop a generative  on large-scale single-cell gene expression data. The model",
    "venue": "Scientific Reports",
    "url": "https://www.nature.com/articles/s41598-025-17439-7",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Multimodal learning enables chat-based exploration of single-cell data",
    "authors": [
      "M Schaefer",
      "P Peneder",
      "D Malzl",
      "SD Lombardo"
    ],
    "year": "2025",
    "abstract": "We downloaded and preprocessed the gene expression profiles from GEO and visualized   into brief textual annotations with an LLM such as GPT-4 (through the OpenAI API, used in this",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41587-025-02857-9",
    "num_citations": 10,
    "citedby_url": "/scholar?cites=514310125858997326&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "GeneRAIN: multifaceted representation of genes via deep learning of gene expression networks",
    "authors": [
      "Z Su",
      "M Fang",
      "A Smolnikov",
      "ME Dinger",
      "EC Oates"
    ],
    "year": "2025",
    "abstract": "architectures like the generative pre-training (GPT) model [4],  learning models on large  gene expression Data, we began  quality samples and removing potential single-cell samples (“",
    "venue": "Genome Biology",
    "url": "https://link.springer.com/article/10.1186/s13059-025-03749-6",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative AI models in time varying biomedical data: a systematic review",
    "authors": [
      "RY He",
      "V Sarwal",
      "X Qiu",
      "Y Zhuang",
      "L Zhang"
    ],
    "year": "2024",
    "abstract": "Single-cell transcriptomics data has revolutionized our  for reconstructing cellular trajectories  from singlecell data. The idea  Bifurcation analysis of singlecell gene expression data",
    "venue": "…",
    "url": "https://s3.ca-central-1.amazonaws.com/assets.jmir.org/assets/preprints/preprint-59792-submitted.pdf",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=1236718146295848544&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative AI models in time-varying biomedical data: scoping review",
    "authors": [
      "R He",
      "V Sarwal",
      "X Qiu",
      "Y Zhuang",
      "L Zhang",
      "Y Liu"
    ],
    "year": "2025",
    "abstract": "cell relationships based on gene expression and enhance understanding  Single-Cell  Gradients apply generative modeling to map out potential landscapes from time-series single-cell",
    "venue": "Journal of Medical …",
    "url": "https://www.jmir.org/2025/1/e59792/",
    "num_citations": 19,
    "citedby_url": "/scholar?cites=2559690490465676106&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative modeling and analyses of perturbations in single-cell experiments",
    "authors": [
      "C De Donno"
    ],
    "year": "2024",
    "abstract": "and technical perturbations in single-cell RNA-seq (scRNA-seq Despite the rapid development  of single-cell technologies  a generative model capable of decomposing gene expression",
    "venue": "NA",
    "url": "https://mediatum.ub.tum.de/1725023",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative language models on nucleotide sequences of human genes",
    "authors": [
      "MN Ihtiyar",
      "A Özgür"
    ],
    "year": "2024",
    "abstract": "generative side of the coin is still largely unexplored. Therefore, we have focused on the  development of an autoregressive generative language model such as GPT for gene expression",
    "venue": "Scientific Reports",
    "url": "https://www.nature.com/articles/s41598-024-72512-x",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=1630017202993411100&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "A general single-cell analysis framework via conditional diffusion generative models",
    "authors": [
      "W Tang",
      "R Liu",
      "H Wen",
      "X Dai",
      "J Ding",
      "H Li",
      "W Fan"
    ],
    "year": "2023",
    "abstract": "From a high level, scDiff aims to recover the clean single cell gene expression x 0 given  the  the hidden representation back to the gene expression space to recover the input cell’s",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2023.10.13.562243.abstract",
    "num_citations": 10,
    "citedby_url": "/scholar?cites=9876147466325927106&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Machine Learning Methods for Single Cell RNA-Sequencing Data to Improve Clinical Oncology",
    "authors": [
      "R Boiarsky"
    ],
    "year": "2025",
    "abstract": "novel generative model that explicitly accounts for the impact of CNVs on gene expression  when  The key idea is to model gene expression as a combination of CNV-driven effects and",
    "venue": "NA",
    "url": "https://dspace.mit.edu/handle/1721.1/163710",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "CSI-GEP: A GPU-based unsupervised machine learning approach for recovering gene expression programs in atlas-scale single-cell RNA-seq data",
    "authors": [
      "X Liu",
      "RH Chapple",
      "D Bennett",
      "WC Wright",
      "A Sanjali"
    ],
    "year": "2025",
    "abstract": "gene expression programs from single-cell RNA-seq data  Since its development over  a decade ago, single-cell RNA  as a linear combination of “gene expression programs” (GEPs).",
    "venue": "Cell Genomics",
    "url": "https://www.cell.com/cell-genomics/fulltext/S2666-979X(24)00368-9?",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=10233144222271869513&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Single-Cell RNA-seq Data Analysis in the Era of Artificial Intelligence",
    "authors": [
      "QB Baker",
      "S Singh",
      "A Agrawal"
    ],
    "year": "NA",
    "abstract": "of gene expression patterns in their native tissue context, including  generative pretrained  transformer (GPT) and bidirectional encoder  on the utility of generative AI in single-cell biology:",
    "venue": "Next-Generation Sequencing",
    "url": "https://www.taylorfrancis.com/chapters/edit/10.1201/9781003354062-13/single-cell-rna-seq-data-analysis-era-artificial-intelligence-qanita-bani-baker-sakshi-singh-ankit-agrawal",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Advances in Artificial Intelligence (AI) Models and Generative Algorithms Represent a New Paradigm for Genomics Research",
    "authors": [
      "DH Lee",
      "EG Park",
      "YJ Lee",
      "H Jeong",
      "HY Roh"
    ],
    "year": "2025",
    "abstract": "regions influence gene expression across  Generative algorithms are increasingly aiding  the conduct of genomics research. As a representative example, conversational AI like GPT has",
    "venue": "International Journal of …",
    "url": "https://www.mdpi.com/1422-0067/26/22/10925",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=11731706881075054713&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Small, Open-Source Text-Embedding Models as Substitutes to OpenAI Models for Gene Analysis",
    "authors": [
      "D Gan",
      "J Li"
    ],
    "year": "2025",
    "abstract": "models developed for gene expression data analysis can be  trained on extensive collections  of single-cell RNA-seq data that  than our S-LLMs—and GPT-4 has 1.76 trillion parameters.",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11870524/",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=255574229365194052&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Appendix for Single-Cell Omics Arena: Evaluation of Large Language Models for Automatic Cell Type Annotations on Single-Cell Omics Data via RNA-seq Bridging",
    "authors": [
      "J Liu",
      "S Xu",
      "Y Wu",
      "J Zhang"
    ],
    "year": "NA",
    "abstract": "gene expression matrices (x) were obtained directly from the corresponding publications. For  DEG analysis, raw gene expression  -consistency loss as the generative term and ELBO as",
    "venue": "Human Cell",
    "url": "https://pdfs.semanticscholar.org/d1fe/86220dc9a8a271929e16ed880ab008688c08.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Artificial Intelligence Revolution in Transcriptomics: From Single Cells to Spatial Atlases",
    "authors": [
      "S Li",
      "T Xiao",
      "Y Lan",
      "C Wu",
      "Z Li",
      "R Liu",
      "Q Fang"
    ],
    "year": "2026",
    "abstract": "gene expression and underlies disease pathogenesis.  of single-cell data, potentially improving  generative modeling  GPTCelltype demonstrates that models such as GPT-4 can directly",
    "venue": "Advanced …",
    "url": "https://advanced.onlinelibrary.wiley.com/doi/abs/10.1002/advs.202518949",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "scGNN+: Adapting ChatGPT for Seamless Tutorial and Code Optimization",
    "authors": [
      "Y Jiang",
      "S Wang",
      "S Feng",
      "C Wang",
      "W Wu",
      "X Huang"
    ],
    "year": "2024",
    "abstract": "tool engineering in single-cell research remains underutilized. To  1D, our Duo-GPT  framework outperformed the single GPT  : large-scale single-cell gene expression data analysis.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.09.30.615735.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=16697389620605619446&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets",
    "authors": [
      "Y Yuan",
      "XYM Ge",
      "AA Waterman",
      "T Biancalani"
    ],
    "year": "2025",
    "abstract": "a HYPOGENEAGENT that couples single-cell clustering with  For every cluster in gene-expression  space and every  S2, AUC metric for GPT-4o top1 group and GPT-o3 top1 group",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2509.09740",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Gene regulatory network inference from pre-trained single-cell transcriptomics transformer with joint graph learning",
    "authors": [
      "S Kommu",
      "Y Wang",
      "Y Wang",
      "X Wang"
    ],
    "year": "2024",
    "abstract": "this challenge by leveraging the single-cell BERTbased pre- learned by pretrained single-cell  language models with the  over both the gene expression level constraints provided by",
    "venue": "arXiv preprint arXiv:2407.18181",
    "url": "https://arxiv.org/abs/2407.18181",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=4033621912077190127&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Modeling and predicting single-cell multi-gene perturbation responses with scLAMBDA",
    "authors": [
      "G Wang",
      "T Liu",
      "J Zhao",
      "Y Cheng",
      "H Zhao"
    ],
    "year": "2024",
    "abstract": ", a deep generative learning framework designed to model and predict single-cell transcriptional   In the scLAMBDA framework, we model the gene expression of a single cell using the",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11643044/",
    "num_citations": 10,
    "citedby_url": "/scholar?cites=2371335961038107302&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Benchmarking AI Models for In Silico Gene Perturbation of Cells",
    "authors": [
      "C Li",
      "H Gao",
      "Y She",
      "H Bian",
      "Q Chen",
      "K Liu",
      "L Wei"
    ],
    "year": "2024",
    "abstract": "to as Linear and 134 Linear-GPT, respectively), correlation-based method, CellOracle  Additionally, we found that single-cell foundation 333 models often predict lower gene expression",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.20.629581.abstract",
    "num_citations": 20,
    "citedby_url": "/scholar?cites=3734360638551609746&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs--Evaluation through Synthetic Data Generation",
    "authors": [
      "T Afonja",
      "I Sheth",
      "R Binkyte",
      "W Hanif",
      "T Ulas"
    ],
    "year": "2024",
    "abstract": "datasets by conducting single-cell RNA sequencing analysis  GPT-4 GRN and GRNBoost2  GRN, suggesting, that the GPT- Enhancing generative perturbation models with llm-informed",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2410.15828",
    "num_citations": 9,
    "citedby_url": "/scholar?cites=16977507428936115388&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "GeneQuery: A General QA-based Framework for Spatial Gene Expression Predictions from Histology Images",
    "authors": [
      "Y Xiong",
      "L Liu",
      "Y Cui",
      "S Wu",
      "X Liu",
      "AB Chan"
    ],
    "year": "2024",
    "abstract": "a sample, while single-cell methods capture heterogeneity  , or even generated content by  generative models. GeneQuery  the state-of-the-art large language model GPT-4 to generate",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2411.18391",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Joint embedding of transcriptomes and text enables interactive single-cell RNA-seq data exploration via natural language",
    "authors": [
      "M Schaefer",
      "P Peneder",
      "D Malzl"
    ],
    "year": "2024",
    "abstract": "in repositories such as the Gene Expression Omnibus (GEO) interactive analysis of single-cell  transcriptomes with natural  LLM and slightly modified prompt (GPT-4, USD 400 budget),",
    "venue": "ICLR 2024 Workshop …",
    "url": "https://openreview.net/forum?id=yWiZaE4k3K",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=6709342046038144475&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Transcriptomics data generation with deep generative models",
    "authors": [
      "A Lacan"
    ],
    "year": "2025",
    "abstract": "differential gene expression and mRNA splicing. Advancements in next-generation sequencing  have expanded RNAseq applications, enabling studies of single-cell gene expression,",
    "venue": "NA",
    "url": "https://theses.hal.science/tel-04996930/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "AI AGENT FOR DATA-DRIVEN HYPOTHESIS EXPLORATION IN SINGLE-CELL TRANSCRIPTOMICS",
    "authors": [
      "A Bakulin",
      "P Boyeau",
      "N Yosef"
    ],
    "year": "NA",
    "abstract": "Several strategies have been developed to use LLMs in single-cell analysis. Broadly, these  ap These models aim to learn a mapping from gene expression to the token space of LLM.",
    "venue": "… 2025 Workshop on Machine Learning for …",
    "url": "https://openreview.net/forum?id=DjxLkshuSx",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Reference-free and cost-effective automated cell type annotation with GPT-4 in single-cell RNA-seq analysis",
    "authors": [
      "W Hou",
      "Z Ji"
    ],
    "year": "2023",
    "abstract": "showing GPT-4 prompts and answers for annotating human prostate cells with increasing  granularity. c, An example showing GPT-4 prompts and answers for annotating single cell",
    "venue": "Research Square",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10187429/",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=7724580419844200819&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Analýza single cell dat za pomoci transformerů",
    "authors": [
      "T Preisler"
    ],
    "year": "2024",
    "abstract": "the annotation of cells based on their gene expression (single-cell data). In particular, it is   Modely GPT (Generative pre-trained transformer) se řadí mezi tzv. decoder-only modely. To",
    "venue": "NA",
    "url": "https://dspace.cuni.cz/handle/20.500.11956/191330",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Deep learning in single-cell and spatial transcriptomics data analysis: advances and challenges from a data science perspective",
    "authors": [
      "S Ge",
      "S Sun",
      "H Xu",
      "Q Cheng",
      "Z Ren"
    ],
    "year": "2025",
    "abstract": "The scRNA-seq addresses this limitation by profiling gene expression at the single-cell  level.  For each cell, the generative distribution can be expressed as the following integral:",
    "venue": "Briefings in Bioinformatics",
    "url": "https://academic.oup.com/bib/article-abstract/26/2/bbaf136/8106554",
    "num_citations": 32,
    "citedby_url": "/scholar?cites=7824480720258528747&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Regularized Optimal Transport for Single-Cell Temporal Trajectory Analysis",
    "authors": [
      "J Peng",
      "X Song",
      "Z He",
      "M Zitnik",
      "M Kellis",
      "Y Zhang"
    ],
    "year": "NA",
    "abstract": "consider the biological priors of gene expression from both  all test genes produces the  accuracy of GPT-G. Similarly, we  Low-dose ct image denoising using a generative adversarial",
    "venue": "NA",
    "url": "https://openreview.net/forum?id=5JXvgNCQUq",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Personalized gene expression prediction in the era of deep learning: a review",
    "authors": [
      "V Dubey",
      "L Shen"
    ],
    "year": "2026",
    "abstract": "and supporting both discriminative and generative applications in genome-scale settings.   near the scale of LLMs like GPT-4 [59] or Grok 4 [60]. Whether a GPT-like gLM holds the key",
    "venue": "Briefings in Bioinformatics",
    "url": "https://academic.oup.com/bib/article-abstract/27/1/bbag022/8445445",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Enhancing generative perturbation models with llm-informed gene embeddings",
    "authors": [
      "K Märtens",
      "R Donovan-Maiye"
    ],
    "year": "2024",
    "abstract": "can observe changes in gene expression and cellular behavior single-cell transcriptomics  (scRNA-seq) readout (Peidli et al. large-scale single-cell datasets containing gene expression",
    "venue": "ICLR 2024 Workshop …",
    "url": "https://openreview.net/forum?id=eb3ndUlkt4",
    "num_citations": 19,
    "citedby_url": "/scholar?cites=18073243870388867317&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generating synthetic single cell data from bulk rna-seq using a pretrained variational autoencoder",
    "authors": [
      "HJ Cho",
      "E Xie",
      "A Zhang",
      "S Bekiranov"
    ],
    "year": "2024",
    "abstract": "full advantage of powerful generative AI approaches and  While the release of large language  models including GPT-4  the networks and predict single cell gene expression response to",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.05.18.594837.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=1812208649312351188&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Benchmarking LLM-based Agents for Single-cell Omics Analysis",
    "authors": [
      "Y Liu",
      "L Zhou",
      "R He",
      "R Shen",
      "Y Li"
    ],
    "year": "2025",
    "abstract": "We employ GPT-4o for assessing the  scVI's generative framework to spatially resolve  cell-type proportions and cell-typespecific gene expression within spots by integrating single-cell",
    "venue": "arXiv preprint arXiv:2508.13201",
    "url": "https://arxiv.org/abs/2508.13201",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=9469715844412223719&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "GexMolGen: cross-modal generation of hit-like molecules via large language model encoding of gene expression signatures",
    "authors": [
      "J Cheng",
      "X Pan",
      "Y Fang",
      "K Yang",
      "Y Xue"
    ],
    "year": "2024",
    "abstract": "In addition, we employ an advanced single-cell large language model for input flexibility   generative adversarial network (WGAN) [4] and Gex2SGen [5], directly input gene expression",
    "venue": "Briefings in …",
    "url": "https://academic.oup.com/bib/article-abstract/25/6/bbae525/7845937",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=1766137869252071637&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Unraveling Cell-Cell Communication: Ligand Identification via Single-Cell Transcriptome Changes Using Geneformer",
    "authors": [
      "T Nissens"
    ],
    "year": "2024",
    "abstract": "ligands induce specific gene expression changes is critical  of compound induced gene  expression changes. However,  for understanding CCC at single cell resolution. By comparing",
    "venue": "NA",
    "url": "https://libstore.ugent.be/fulltxt/RUG01/003/208/060/RUG01-003208060_2024_0001_AC.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Gene set summarization using large language models",
    "authors": [
      "MP Joachimiak",
      "JH Caufield",
      "NL Harris",
      "H Kim"
    ],
    "year": "2024",
    "abstract": "For example, a recent study measured gene expression at the single cell level in   generative, and relies solely on the massive corpus of documents ingested as training for the GPT",
    "venue": "ArXiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10246080/",
    "num_citations": 33,
    "citedby_url": "/scholar?cites=15954548982778649318&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "scRAG: Hybrid Retrieval-Augmented Generation for LLM-based Cross-Tissue Single-Cell Annotation",
    "authors": [
      "Z Yu",
      "C Zheng",
      "C Chen",
      "XS Hua"
    ],
    "year": "2025",
    "abstract": "), convert single-cell gene expression profiles into natural  2024) evaluates GPT-4’s natural  language capabilities in cell  GPT-3.5 on textual gene summaries and creates single-cell",
    "venue": "Findings of the …",
    "url": "https://aclanthology.org/2025.findings-acl.53/",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=11357156214545675512&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "What do single-cell models already know about perturbations?",
    "authors": [
      "A Bjerregaard",
      "I Prada-Luengo",
      "V Das",
      "A Krogh"
    ],
    "year": "2025",
    "abstract": "of single-cell data and to reconstruct gene expression from such  We hypothesize that  generative models already encode  We run the following prompt for each pathway, using GPT-5 (",
    "venue": "Genes",
    "url": "https://www.mdpi.com/2073-4425/16/12/1439",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Engineering Cells Using Artificial Intelligence",
    "authors": [
      "Y Roohani"
    ],
    "year": "2024",
    "abstract": "), a foundation model for single-cell gene expression that is  of new single-cell gene  expression datasets with no model fine for single cell gene expression Integrating single-cell RNA",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/3d7bfa2b9cce978c33494f095009cf67/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Multimodal Cell Context Instruction Tuning for Conditional DNA Regulatory Sequence Generation with Large Language Models",
    "authors": [
      "J Liu",
      "P Zhang",
      "S Xu",
      "SS Srinivasan"
    ],
    "year": "2025",
    "abstract": "-trained Geneformer single cell transcriptomes encoder [ -GPT-2. These results emphasize  the critical role of pretraining on extensive DNA text corpora in enhancing both the generative",
    "venue": "… Conference on Image …",
    "url": "https://ieeexplore.ieee.org/abstract/document/11084625/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "scSelector: A Flexible Single-Cell Data Analysis Assistant for Biomedical Researchers",
    "authors": [
      "X Gao",
      "P Wu",
      "J Yu",
      "X Zhu",
      "S Zhang",
      "H Shao",
      "D Lu"
    ],
    "year": "2025",
    "abstract": "The public datasets analyzed during the current study are available in the Gene Expression  Omnibus (GEO) repository. These include the human PBMC dataset (accession no.",
    "venue": "Genes",
    "url": "https://www.mdpi.com/2073-4425/17/1/2",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "An overview of computational methods in single-cell transcriptomic cell type annotation",
    "authors": [
      "T Li",
      "Z Wang",
      "Y Liu",
      "S He",
      "Q Zou"
    ],
    "year": "2025",
    "abstract": "",
    "venue": "Briefings in …",
    "url": "https://academic.oup.com/bib/article/26/3/bbaf207/8128431",
    "num_citations": 13,
    "citedby_url": "/scholar?cites=884517243741139390&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "scGraPhT: Merging Transformers and Graph Neural Networks for Single-Cell Annotation",
    "authors": [
      "E Koç",
      "E Kulkul",
      "G Kaynar",
      "T Çukur"
    ],
    "year": "2025",
    "abstract": "for single-cell transcriptomic analysis using a generative pre- directly based on the gene  expression matrix in our formulation In terms of segregation between respective GPT and GNN",
    "venue": "IEEE Transactions on …",
    "url": "https://ieeexplore.ieee.org/abstract/document/11015257/",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=9889938894434175340&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Tahoe-x1: Scaling perturbation-trained single-cell foundation models to 3 billion parameters",
    "authors": [
      "S Gandhi",
      "F Javadi",
      "V Svensson",
      "U Khan",
      "MG Jones"
    ],
    "year": "2025",
    "abstract": "Tx1 models are transformer-based generative architectures trained on single-cell data  using a masked gene-expression prediction task that encourages the model to learn gene-gene",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.10.23.683759.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=4580219551893491243&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Modeling Gene Expression Distributional Shifts for Unseen Genetic Perturbations",
    "authors": [
      "K Ramakrishnan",
      "JG Hedley",
      "S Qu",
      "PK Dokania"
    ],
    "year": "2025",
    "abstract": "Several deep generative models have been developed to predict gene expression responses  to  We evaluate our method on three single-cell Perturb-seq datasets across two cell lines.",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2507.02980",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "An agentic AI framework for ingestion and standardization of single-cell RNA-seq data analysis",
    "authors": [
      "N Nouri",
      "R Artzi",
      "V Savova"
    ],
    "year": "2026",
    "abstract": "We therefore repeated the analysis using gpt-4o-mini as the agentic controller; all benchmarking  runs again completed successfully without manual intervention. The average agentic",
    "venue": "npj Artificial Intelligence",
    "url": "https://www.nature.com/articles/s44387-025-00064-0",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=9390239371817910989&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Regularized Optimal Transport for Temporal Trajectory Analysis in Single-Cell Data",
    "authors": [
      "J Peng",
      "X Song",
      "Y Zhang",
      "Z He",
      "M Zitnik",
      "M Kellis"
    ],
    "year": "NA",
    "abstract": "biological priors of gene expression from both developmental  Low-dose ct image denoising  using a generative adversarial  clarification of differences between GPT-G and GPT-P, we",
    "venue": "NA",
    "url": "https://openreview.net/forum?id=xpyBQn6gJY",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "The application of deep learning in microbiome research",
    "authors": [
      "L Janssen"
    ],
    "year": "2024",
    "abstract": "single-cell sequencing analysis, with autoencoders, variational autoencoders and generative   [54] is a generative transformer model that comes from the GPT-2 model architecture and",
    "venue": "NA",
    "url": "https://studenttheses.uu.nl/handle/20.500.12932/48097",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "MoRE: Batch-Robust Multi-Omics Representations from Frozen Pre-trained Transformers",
    "authors": [
      "APH Chen"
    ],
    "year": "2025",
    "abstract": "deep generative framework that performs scalable probabilistic modeling of gene expression  profiles ( Inspired by models such as GPT-4 in natural language processing, the single-cell",
    "venue": "arXiv preprint arXiv:2511.20382",
    "url": "https://arxiv.org/abs/2511.20382",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Unveiling Zero Shot Prediction for Gene Attributes Through Interpretable AI",
    "authors": [
      "A Jararweh",
      "O Macaulay",
      "D Arredondo"
    ],
    "year": "NA",
    "abstract": "of cells, we utilize their gene expression data. GeneLLM cell  We chose GPT-2 for comparison  as it represents the highest- gene summaries instead of single-cell transcriptomic data. We",
    "venue": "ICLR 2024 Workshop on …",
    "url": "https://openreview.net/forum?id=DtdLDKe32W",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Benchmarking AI scientists in omics data-driven biological research",
    "authors": [
      "E Luo",
      "J Jia",
      "Y Xiong",
      "X Li",
      "X Guo",
      "B Yu",
      "L Wei"
    ],
    "year": "2025",
    "abstract": "(B) Construction of BAIS-CTA: We collected single-cell transcriptomic  We sent these papers  to the GPT-4o and asked it to  Towards scientific discovery with generative ai: Progress,",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2505.08341",
    "num_citations": 9,
    "citedby_url": "/scholar?cites=10649581210199698215&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "SmartImpute is a targeted imputation framework for single-cell transcriptome data",
    "authors": [
      "S Yao",
      "T Li",
      "JT Davis",
      "TI Shaw",
      "X Yu",
      "X Wang"
    ],
    "year": "2025",
    "abstract": "data by training with a generative adversarial approach. While  by comparing heatmaps  of gene expression with and without  To encourage reproducibility, we have provided a GPT",
    "venue": "Cell Reports Methods",
    "url": "https://www.cell.com/cell-reports-methods/fulltext/S2667-2375(25)00158-4",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=5304999460487433222&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Emerging AI approaches for cancer spatial omics",
    "authors": [
      "J Noorbakhsh",
      "A Foroughi Pour",
      "J Chuang"
    ],
    "year": "2025",
    "abstract": "been to extend approaches from single-cell analysis—that is, first models used widely in  generative image AI and increasingly  be used to link gene expression to signal concentration or",
    "venue": "GigaScience",
    "url": "https://academic.oup.com/gigascience/article-abstract/doi/10.1093/gigascience/giaf128/8287720",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=5784474562046824567&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Cellagent: An llm-driven multi-agent framework for automated single-cell data analysis",
    "authors": [
      "Y Xiao",
      "J Liu",
      "Y Zheng",
      "X Xie",
      "J Hao",
      "M Li"
    ],
    "year": "2024",
    "abstract": "the function of generating gene expression umap plots and  its use of powerful AI generative  models, which are capable of  the potential of GPT-4 in handling single-cell data analysis",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2407.09811",
    "num_citations": 66,
    "citedby_url": "/scholar?cites=17975972937045939146&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Multi-agent AI enables evidence-based cell annotation in single-cell transcriptomics",
    "authors": [
      "G Ahuja",
      "A Antill",
      "Y Su",
      "GM Dall'Olio",
      "S Basnayake"
    ],
    "year": "2025",
    "abstract": "LLM (GPT-5), alongside established reference-based methods: CellTypist 18 and SingleR  19 . Using identical models (GPT- 13 have demonstrated that generative models can produce",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.06.686964.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=9624448453787687058&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "scExtract: leveraging large language models for fully automated single-cell RNA-seq data annotation and prior-informed multi-dataset integration",
    "authors": [
      "Y Wu",
      "F Tang"
    ],
    "year": "2025",
    "abstract": "Automated annotation of single-cell datasets using reference  Cell annotation methods  utilizing LLMs like GPT-4 have  single cells on differential gene expression, we constructed",
    "venue": "Genome Biology",
    "url": "https://link.springer.com/article/10.1186/s13059-025-03639-x",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=5830769562482953453&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "CompBioAgent: An LLM-powered agent for single-cell RNA-seq data exploration",
    "authors": [
      "H Zhang",
      "YH Sun",
      "W Hu",
      "X Cui",
      "Z Ouyang",
      "D Cheng"
    ],
    "year": "2025",
    "abstract": "as a public repository of single-cell gene expression data, allowing  workflows for single-cell  RNA-seq data analyses.  working with more advanced models like GPT-3.5, GPT-4o. If the ‘",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.03.17.643771.abstract",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=14414347058812751302&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Probing genomic language models: Nucleotide Generative Pretrained Transformer and the role of pretraining in learned representations",
    "authors": [
      "SM Mclaughlin",
      "DA Lim"
    ],
    "year": "2026",
    "abstract": "than the more diverse but less frequent regulatory elements that govern gene expression.   We trained four variants of Nucleotide GPT with different loss weights applied to tokens",
    "venue": "Briefings in Bioinformatics",
    "url": "https://academic.oup.com/bib/article/27/1/bbag011/8456488",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Precious3GPT: Multimodal Multi-Species Multi-Omics Multi-Tissue Transformer for Aging Research and Drug Discovery",
    "authors": [
      "F Galkin",
      "V Naumov",
      "S Pushkov",
      "D Sidorenko",
      "A Urban"
    ],
    "year": "2024",
    "abstract": "in natural language, generative pretrained transformers (GPTs In this article, we present  Precious3-GPT (P3GPT), a new  omics experiments involving gene expression, DNA methylation",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.07.25.605062.abstract",
    "num_citations": 14,
    "citedby_url": "/scholar?cites=1597434752302845138&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "ScDiVa: Masked Discrete Diffusion for Joint Modeling of Single-Cell Identity and Expression",
    "authors": [
      "M Wang",
      "C Chen",
      "G Jiang",
      "Z Ren",
      "C Zhao"
    ],
    "year": "2026",
    "abstract": "We evaluate generative capability via a  Single-cell RNA sequencing measurements can  be viewed as noisy observations of an underlying biological state, where gene expression",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2602.03477",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Cell2Sentence: teaching large language models the language of biology",
    "authors": [
      "D Levine",
      "SA Rizvi",
      "S Lévy",
      "N Pallikkavaliyaveetil"
    ],
    "year": "2024",
    "abstract": "in single-cell datasets, which dictates the size of the resulting  types is crucial for generative  approaches on single-cell data, as  We also benchmark the performance of GPT-2 small and",
    "venue": "BioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11565894/",
    "num_citations": 63,
    "citedby_url": "/scholar?cites=12860459433909422728&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Generative AI for Knowledge Mining of Synthetic Biology and Bioprocess Engineering Literature",
    "authors": [
      "Z Xiao",
      "YJ Tang"
    ],
    "year": "2026",
    "abstract": "Generative AI now offers automated extraction of data at scale. This paradigm shift not only  acceler Generative artificial intelligence GPT-4 accelerates knowledge mining and machine",
    "venue": "Machine Learning and Big Data‐enabled …",
    "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/9783527850532.ch9",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "GRNFormer: A Biologically-Guided Framework for Integrating Gene Regulatory Networks into RNA Foundation Models",
    "authors": [
      "M Qiu",
      "X Hu",
      "F Zhan",
      "S Yun",
      "J Peng",
      "R Zhang"
    ],
    "year": "2025",
    "abstract": "single-cell RNA sequencing (scRNA-seq) have shown promising capabilities in capturing  gene expression  2024) employs generative pretraining with specialized attention masking for",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2503.01682",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=5836266455673887429&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "RAGCell: Retrieval-Augmented Generation as Supervision for Versatile Single-cell Analysis",
    "authors": [
      "F Zhang",
      "K Wang",
      "H Li",
      "K Ding",
      "S Qian",
      "T Liu",
      "D Zhou"
    ],
    "year": "NA",
    "abstract": "With the rapid advancement of generative artificial  2022) applies a bag-of-words strategy  to discretize gene expression  In this paper, we opt for the GPT-4o mini model to generate cell-",
    "venue": "NA",
    "url": "https://openreview.net/forum?id=w4JmosnaUH",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning",
    "authors": [
      "Y Fang",
      "Q Jin",
      "G Xiong",
      "B Jin",
      "X Zhong"
    ],
    "year": "2025",
    "abstract": "Single-Cell Annotation. Recent research efforts have explored adapting single-cell gene  expression  Closed-source models such as GPT-4o and o1 show stronger instruction-following",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2506.02911",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=4424530763913304426&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Memory-Efficient Learning Algorithms for Feature and Relation Extraction with Applications to Genomics Data and Clinical Notes",
    "authors": [
      "Y Geng"
    ],
    "year": "2024",
    "abstract": "is the regulatory relationship among the genes from the gene expression data. The problem  is often  models and utilize Generative Pre-trained Transformer (GPT) for data augmentation,",
    "venue": "NA",
    "url": "https://scholars.hkbu.edu.hk/ws/portalfiles/portal/105471707/G24THFL-041001T.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "GenePert: Leveraging GenePT embeddings for gene perturbation prediction",
    "authors": [
      "Y Chen",
      "J Zou"
    ],
    "year": "2024",
    "abstract": "the gene expression profile to extract principal components, or (ii) extensive pre-training like  other single-cell  We observe that our GenePert approach using GPT-4 gene embeddings",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.10.27.620513.abstract",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=3254170617808811840&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "A transformer-based language model reveals developmental constraint and network complexity during zebrafish embryogenesis",
    "authors": [
      "JF Poyatos"
    ],
    "year": "2025",
    "abstract": ", trained on single-cell gene expression data from zebrafish  Specifically, we test whether  single-cell expression data contain  The author used OpenAI’s Chat-GPT to assist with text",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.07.09.663853.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Multi-Scale AI-Assisted Gene Expression Decoding",
    "authors": [
      "F Yan"
    ],
    "year": "2024",
    "abstract": "We are actively exploring the potential of generative AI to aid  , models like Generative  Pre-trained Transformers (GPT) have  a single-cell level, the methylation state can only be binary.",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/fdd70a4c5c83ac064f1261e9d73716b9/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=799168906672851604&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Phenotype-Guided In Silico Molecular Generation Using Large Language Models",
    "authors": [
      "Q Jiang",
      "X Ye",
      "Z Guo",
      "Y Xia",
      "Z Liu",
      "J Xu",
      "P Jin",
      "F Ju"
    ],
    "year": "2026",
    "abstract": "the Tahoe 100M single cell chemical perturbation dataset (20) how cell-state–level generative  modeling can 410 serve as a  instructions, we then used GPT-4o to generate paraphrased",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2026.01.03.697483.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "A Deep Learning Pipeline for Epilepsy Genomic Analysis Using GPT-2 XL and NVIDIA H100",
    "authors": [
      "MO Latif",
      "H Ullah",
      "MA Shafique",
      "Z Dong"
    ],
    "year": "2025",
    "abstract": "such as bulk and single-cell RNA sequencing has revolu-  robust pattern recognition and  generative capabilities that can  transforming how we decode gene expression landscapes. In",
    "venue": "arXiv preprint arXiv:2510.00392",
    "url": "https://arxiv.org/abs/2510.00392",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Scouter predicts transcriptional responses to genetic perturbations with large language model embeddings",
    "authors": [
      "O Zhu",
      "J Li"
    ],
    "year": "2025",
    "abstract": "However, given the growing interest in adapting gene expression foundation models for this  task, we also conducted additional experiments to benchmark Scouter against several such",
    "venue": "Nature Computational Science",
    "url": "https://www.nature.com/articles/s43588-025-00912-8",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=9537313761203905127&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Deep-learning methods for unveiling large-scale single-cell transcriptomes",
    "authors": [
      "X Shen",
      "X Li"
    ],
    "year": "2024",
    "abstract": "FFN to acquire insight into gene expression patterns and impute  The emergence of GPT-4,  boasting 1.8 trillion parameters and  of single-cell transcriptomics data with deep generative",
    "venue": "Cancer Biology & Medicine",
    "url": "https://www.cancerbiomed.org/content/cbm/20/12/972.full-text.pdf",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=9064417224085192787&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine",
    "authors": [
      "Y Luo",
      "J Zhang",
      "S Fan",
      "K Yang",
      "Y Wu",
      "M Qiao"
    ],
    "year": "2023",
    "abstract": "open multimodal generative pre-trained transformer (GPT)  language via a large generative  language model, namely,  3D structure data, and single-cell sequencing data. With extensive",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2308.09442",
    "num_citations": 152,
    "citedby_url": "/scholar?cites=7974639153697399925&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Foundation model for comprehensive transcriptional regulation analysis",
    "authors": [
      "Z Yu",
      "Y Zhang"
    ],
    "year": "2024",
    "abstract": ", such as GPT-4, DALLE-3 and MidJourney, has heightened interest in using generative AI   GLUE) has successfully applied this method to integrate single-cell multi-modality data [16].",
    "venue": "National Science Review",
    "url": "https://academic.oup.com/nsr/article-abstract/11/11/nwae355/7821662",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=3389056067575149703&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "scMBERT: A Pre-Trained Deep Learning Model for Single-Cell Multiomic Data Representation and Prediction (Student Abstract)",
    "authors": [
      "X Chen",
      "K Yu",
      "MZ Jiang",
      "C Xiao",
      "Z Fu"
    ],
    "year": "2025",
    "abstract": "Single-cell sequencing technologies such as single-cell RNA-seq have become the leading  method for exploring gene expression  While scGPT can handle variable input, the GPT",
    "venue": "Proceedings of the AAAI …",
    "url": "https://ojs.aaai.org/index.php/AAAI/article/view/35242",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Predicting transcriptional responses to novel chemical perturbations using deep generative model for drug discovery",
    "authors": [
      "X Qi",
      "L Zhao",
      "C Tian",
      "Y Li",
      "ZL Chen",
      "P Huo"
    ],
    "year": "2024",
    "abstract": "of PRnet in single-cell HTS data, we followed commonly used metric 4,5,6 to compare  the R 2 score between the true and predicted post-perturbation gene expression for the hold-out",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41467-024-53457-1",
    "num_citations": 42,
    "citedby_url": "/scholar?cites=148887849738553810&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Graph-augmented deep learning using literature-informed biological priors for predicting perturbations in single-cell RNA sequencing",
    "authors": [
      "LSW Tu"
    ],
    "year": "2025",
    "abstract": "After training on single-cell gene expression data, the model can accurately predict the effects   Generative AI tools were used to assist in the writing of this thesis. The tools were used to",
    "venue": "NA",
    "url": "https://open.library.ubc.ca/soa/cIRcle/collections/ubctheses/24/items/1.0449273",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "UNICORN: Towards universal cellular expression prediction with a multi-task learning framework",
    "authors": [
      "T Liu",
      "T Huang",
      "L Wang",
      "Y Lin",
      "R Ying"
    ],
    "year": "2025",
    "abstract": "of specific cell types, and predicting single-cell gene expression is still difficult since our   DNA sequences of the given genes and the GPT 3.5 embedding layer of the text description of",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41467-025-64506-8",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=14172498877011521292&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "A systematic comparison of single-cell perturbation response prediction models",
    "authors": [
      "L Li",
      "Y You",
      "Y Fu",
      "W Liao",
      "X Fan",
      "S Lu",
      "Y Cao",
      "B Li"
    ],
    "year": "2024",
    "abstract": "derived from GPT as inputs for gene embedding in GEARS.  The model employs a VAE to  encode single-cell gene expression  [56] utilizes a deep generative framework to disentangle",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.23.630036.abstract",
    "num_citations": 16,
    "citedby_url": "/scholar?cites=14833461740056426872&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Genomas: A multi-agent framework for scientific discovery via code-driven gene expression analysis",
    "authors": [
      "H Liu",
      "Y Li",
      "H Wang"
    ],
    "year": "2025",
    "abstract": "We evaluate automated gene expression analysis methods using the GenoTEX benchmark  [66], which provides standardized evaluation for each stage of the analysis pipeline",
    "venue": "arXiv preprint arXiv:2507.21035",
    "url": "https://arxiv.org/abs/2507.21035",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=10256697766103714661&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "ChIP-GPT: a managed large language model for robust data extraction from biomedical database records",
    "authors": [
      "O Cinquin"
    ],
    "year": "2024",
    "abstract": "",
    "venue": "Briefings in bioinformatics",
    "url": "https://academic.oup.com/bib/article/25/2/bbad535/7600389",
    "num_citations": 19,
    "citedby_url": "/scholar?cites=1607152873497136680&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Machine learning for perturbational single-cell omics",
    "authors": [
      "Y Ji",
      "M Lotfollahi",
      "FA Wolf",
      "FJ Theis"
    ],
    "year": "2021",
    "abstract": "Factorization methods and generative approaches can produce latent structure in an   Figure 3 Generative neural network modeling to learn a latent representation of single-cell",
    "venue": "Cell Systems",
    "url": "https://www.cell.com/cell-systems/fulltext/S2405-4712(21)00202-7?ref=https://githubhelp.com",
    "num_citations": 150,
    "citedby_url": "/scholar?cites=181060056102329316&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Interpreting attention mechanisms in genomic transformer models: a framework for biological insights",
    "authors": [
      "ME Consens",
      "A Diaz-Navarro",
      "V Chu",
      "L Stein",
      "HH He"
    ],
    "year": "2025",
    "abstract": "In contrast, scGPT is a transformer model trained on single-cell gene expression data,   models, such as GPT-2 XL, using GPT-4 21 . They did this using three models, a subject model (",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.06.26.661544.abstract",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=9720549931019715218&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Biodiscoveryagent: An ai agent for designing genetic perturbation experiments",
    "authors": [
      "Y Roohani",
      "A Lee",
      "Q Huang",
      "J Vora",
      "Z Steinhart"
    ],
    "year": "2024",
    "abstract": "Here, each query consists of two genes perturbed in a single cell simultaneously. This   Chatgpt as research scientist: Probing gpt’s capabilities as a research librarian, research",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2405.17631",
    "num_citations": 67,
    "citedby_url": "/scholar?cites=4289675909511074670&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "PerturbAgent: An Agentic AI system for Analysis and Prediction of Genetic Perturbations",
    "authors": [
      "K Pei",
      "S Qu",
      "P Torr",
      "JG Hedley"
    ],
    "year": "2026",
    "abstract": "to a single cell, and columns correspond to gene expression  -informed embeddings from  UniProt+GPT are sufficient for in- Enhancing generative perturbation models with LLMinformed",
    "venue": "Second Workshop on …",
    "url": "https://openreview.net/forum?id=FfHATDCkCQ",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_gpt_bio",
    "title": "Influence of Gender-Specific Data Imbalance on scGPT Fine-Tuning for Single-Cell Genomics",
    "authors": [
      "MAU Al Amin",
      "D Filienko",
      "H Qin"
    ],
    "year": "2025",
    "abstract": "generative pre-training techniques from natural language processing (NLP) to learn meaningful  representations of gene expression at the single-cell  scGPT is a GPT-style transformer",
    "venue": "Proceedings of the AAAI Symposium …",
    "url": "https://ojs.aaai.org/index.php/AAAI-SS/article/view/36914",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data",
    "authors": [
      "F Yang",
      "W Wang",
      "F Wang",
      "Y Fang",
      "D Tang"
    ],
    "year": "2022",
    "abstract": "learning model. It has made breakthrough progress in the fields of natural language processing  ( the generalizability of the AI model. Inspired by such exciting progress, we developed",
    "venue": "Nature Machine …",
    "url": "https://www.nature.com/articles/s42256-022-00534-z",
    "num_citations": 548,
    "citedby_url": "/scholar?cites=3659605473260346103&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Abstract A029: Evaluating and interpreting scGPT: A foundation model for single-cell biology in real-world cancer clinical trial data",
    "authors": [
      "R Tan",
      "H Cui",
      "B Wang",
      "K Perez",
      "AD Costa"
    ],
    "year": "2024",
    "abstract": "in natural language processing has inspired a series of LLMs for single-cell analysis,  such  We fine-tuned the model for downstream tasks like cell type annotation, treatment",
    "venue": "Cancer …",
    "url": "https://aacrjournals.org/cancerres/article/84/17_Supplement_2/A029/747634",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=17614710814394755790&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Transcoder-based Circuit Analysis for Interpretable Single-Cell Foundation Models",
    "authors": [
      "S Hosokawa",
      "T Kawakami",
      "S Kodera",
      "M Ito"
    ],
    "year": "2025",
    "abstract": ", we analyzed how the C2S model performs cell type classification. We extracted a cell   from natural language processing to bioinformatics models such as single-cell analysis models",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2509.14723",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Reply to: Deeper evaluation of a single-cell foundation model",
    "authors": [
      "F Yang",
      "F Wang",
      "L Huang",
      "L Liu",
      "J Huang"
    ],
    "year": "2024",
    "abstract": "At the beginning, we would like to discuss the performance on cell type annotation task  with few-shot learning. First, the so-called few-shot learning experiment conducted in the",
    "venue": "Nature Machine …",
    "url": "https://www.nature.com/articles/s42256-024-00948-x",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=1164784704229682443&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Integrating Single-Cell Foundation Models with Graph Neural Networks for Drug Response Prediction",
    "authors": [
      "T Rossner",
      "Z Li",
      "J Balke",
      "N Salehfard",
      "T Seifert"
    ],
    "year": "2025",
    "abstract": "for tasks like cell type annotation, gene  single-cell foundation model pretrained on over  33 million cells. Inspired by the success of selfsupervised pretraining in natural language",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2504.14361",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=16355070234397525750&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation",
    "authors": [
      "R Li",
      "W Chen",
      "Z Li",
      "R Munoz-Castaneda",
      "J Li"
    ],
    "year": "2025",
    "abstract": "cell type–specific marker gene sets derived from single-cell  structured ontology terms into  natural language descriptions while  scGPT: toward building a foundation model for single-cell",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2510.17064",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "… -Specific Cell Type Annotation with Supervised Representation Learning using Split Vector Quantization and Its Comparisons with Single-cell Foundation Models",
    "authors": [
      "YD Heryanto",
      "Y Zhang",
      "S Imoto"
    ],
    "year": "2024",
    "abstract": "the TF-IDF transformation to the utilization of codes within each cell type. Drawing an analogy  to natural language processing, the codes in the codebooks are analogous to words, cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.09.627458.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Benchmarking large language models for cell typing in single-cell RNA-Seq",
    "authors": [
      "T Xiao",
      "D Hua",
      "Y Wang",
      "X Lu"
    ],
    "year": "2025",
    "abstract": "In this work, we systematically benchmarked seven leading large language model  families for cell type annotation in scRNA-seq data, demonstrating their clear superiority over",
    "venue": "Briefings in …",
    "url": "https://academic.oup.com/bib/article-abstract/26/6/bbaf677/8380197",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Continually adapting pre-trained language model to universal annotation of single-cell RNA-seq data",
    "authors": [
      "H Wan",
      "M Yuan",
      "Y Fu",
      "M Deng"
    ],
    "year": "2024",
    "abstract": "paradigm used in natural language processing.  models severely suffer. Also, most current  online methods aim at unlabeled single-cell data integration; none is customized for cell-type",
    "venue": "Briefings in bioinformatics",
    "url": "https://academic.oup.com/bib/article-abstract/25/2/bbae047/7611935",
    "num_citations": 10,
    "citedby_url": "/scholar?cites=7748464738166584689&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Scale-free and unbiased transformer with tokenization for cell type annotation from single-cell RNA-seq data",
    "authors": [
      "H Zhang",
      "Z Jiang",
      "S Zhang",
      "L Tu",
      "D Carlson"
    ],
    "year": "2025",
    "abstract": ", making the development of efficient cell type annotation methods an ever more pressing   -to-end model (scSFUT) which can flexibly annotate scalable single-cell datasets in a purely",
    "venue": "Pattern Recognition",
    "url": "https://www.sciencedirect.com/science/article/pii/S003132032500384X",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=9981020101827492225&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "AtlasAgent: Vision language model and Agent-guided Framework for Evaluation of Atlas-scale Single-cell Integration",
    "authors": [
      "D Yin",
      "Z Zhang",
      "X Liu",
      "K Ni",
      "H Su",
      "NL Li",
      "H Dong"
    ],
    "year": "2025",
    "abstract": "them, allowing the cell type annotation, and additional  While scIB provides a structured  foundation for integration  to democratize single-cell analysis through natural language-guided",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.07.15.663271.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "A perspective on developing foundation models for analyzing spatial transcriptomic data",
    "authors": [
      "T Liu",
      "M Hao",
      "X Liu",
      "H Zhao"
    ],
    "year": "2025",
    "abstract": "The success of FMs in modeling natural language and  FMs by pretraining the base model  with large-scale single-cell  of current models in several downstream tasks, including cell-type",
    "venue": "Quantitative Biology",
    "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/qub2.70010",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=16271448331664981422&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Evaluation of cell type annotation reliability using a large language model-based identifier",
    "authors": [
      "W Ye",
      "Y Ma",
      "J Xiang",
      "H Liang",
      "J Luo",
      "Y Li"
    ],
    "year": "2025",
    "abstract": "Ensuring accurate cell type annotation in single-cell RNA  On this foundation, we developed  LICT (LLM-based Identifier  chose these models due to their advanced natural language",
    "venue": "Communications …",
    "url": "https://www.nature.com/articles/s42003-025-08745-x",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=14092511553754340531&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "The Human Cell Atlas from a cell census to a unified foundation model",
    "authors": [
      "JE Rood",
      "S Wynne",
      "L Robson",
      "A Hupalowska"
    ],
    "year": "2025",
    "abstract": "to cell-type-specific expression, gene programs and/or cell proportion traits in single-cell data   text enables interactive single-cell RNA-seq data exploration via natural language. In ICLR",
    "venue": "Nature",
    "url": "https://www.nature.com/articles/s41586-024-08338-4",
    "num_citations": 113,
    "citedby_url": "/scholar?cites=5195962964398164197&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Generalized cell phenotyping for spatial proteomics with language-informed vision models",
    "authors": [
      "XJ Wang",
      "R Dilip",
      "AR Iqbal",
      "Y Bussi",
      "C Brown"
    ],
    "year": "2025",
    "abstract": "image and natural language to build foundation models, and  To generate single-cell images  to train cell phenotyping models We also standardized marker names and cell type labels",
    "venue": "…",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11601246/",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=18410708565679536137&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Atacformer: A transformer-based foundation model for analysis and interpretation of ATAC-seq data",
    "authors": [
      "NJ LeRoy",
      "G Zheng",
      "O Khoroshevskyi",
      "DR Campbell Jr"
    ],
    "year": "2025",
    "abstract": "in Natural Language Processing. Beyond the Atacformer  that this was because the cell-type  fine-tuned Atacformer model was fine- single-cell embeddings, we first tokenize a single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.03.685753.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=16788247285911835292&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "CellOntologyMapper: Consensus mapping of cell type annotation",
    "authors": [
      "Z Zeng",
      "X Wang",
      "H Du",
      "C Xing"
    ],
    "year": "2025",
    "abstract": "natural language processing techniques, including advanced sentence transformers and  large language models ( challenge of inconsistent cell type naming across single‐cell studies,",
    "venue": "iMetaOmics",
    "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/imo2.70064",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "scPlantAnnotate: an accurate and robust transformer-based model for plant cell type annotation",
    "authors": [
      "C Lu",
      "MS Immadi",
      "YO Chan",
      "S Dhakal",
      "D Xu"
    ],
    "year": "2026",
    "abstract": "Accurate cell type annotation remains a major bottleneck in plant single-cell RNA sequencing  (scRNA-seq), where existing tools are often adapted from animal studies and perform sub-",
    "venue": "Journal of Advanced …",
    "url": "https://www.sciencedirect.com/science/article/pii/S2090123226000603",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "A Foundation Model for Single-Cell Transcriptomics in Alzheimer's Disease",
    "authors": [
      "A Balomenos",
      "C Petrou",
      "T Siozos"
    ],
    "year": "2025",
    "abstract": "natural language processing, have recently been adapted to biological sequence and single-cell   We standardized key metadata fields, including cell type labels, brain region identifiers,",
    "venue": "2025 IEEE 25th …",
    "url": "https://ieeexplore.ieee.org/abstract/document/11273515/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following",
    "authors": [
      "Y Fang",
      "X Deng",
      "K Liu",
      "N Zhang",
      "J Qian",
      "P Yang"
    ],
    "year": "2025",
    "abstract": "natural language as a medium for more direct and flexible  critical tasks-such as cell type  annotation, conditional pseudo- the performance of existing single-cell foundation models, while",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2501.08187",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=2001376965491196374&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "scGREAT: Transformer-based deep-language model for gene regulatory network inference from single-cell transcriptomics",
    "authors": [
      "Y Wang",
      "X Chen",
      "Z Zheng",
      "L Huang",
      "W Xie",
      "F Wang"
    ],
    "year": "2024",
    "abstract": "deep learning model for GRN inference from single-cell  (SOTA) transformer model in  natural language processing (NLP -best model GENELink on seven datasets with Cell-type-specific",
    "venue": "Iscience",
    "url": "https://www.cell.com/iscience/fulltext/S2589-0042(24)00573-X",
    "num_citations": 17,
    "citedby_url": "/scholar?cites=14330458716191025848&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "annATAC: automatic cell type annotation for scATAC-seq data based on language model",
    "authors": [
      "L Cui",
      "F Wang",
      "H Li",
      "Q Liu",
      "M Zhou",
      "G Wang"
    ],
    "year": "2025",
    "abstract": "This significant difference indicates that the pre-trained model provides a good foundation   This study first uses the scATAC-seq data provided by the single-cell reference atlas of human",
    "venue": "BMC biology",
    "url": "https://link.springer.com/article/10.1186/s12915-025-02244-5",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=3096932665200995837&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "GREmLN: A Cellular Regulatory Network-Aware Transcriptomics Foundation Model",
    "authors": [
      "M Zhang",
      "V Swamy",
      "R Cassius",
      "L Dupire"
    ],
    "year": "2025",
    "abstract": "multi-omics single cell profiling, such as single cell RNA-seq ( in natural language  understanding, foundation models learn  cell type label y i , we aim to learn the distribution of cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.07.03.663009.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=2477554410120362549&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Methods for cell-type annotation on scRNA-seq data: A recent overview",
    "authors": [
      "K Lazaros",
      "P Vlamos",
      "AG Vrahatis"
    ],
    "year": "2023",
    "abstract": "Cell type annotation is a significant step in single-cell  methodology from the field of natural  language processing (NLP) primarily on the foundation of single-cell cluster levels, deploying",
    "venue": "Journal of Bioinformatics and …",
    "url": "https://www.worldscientific.com/doi/abs/10.1142/S0219720023400024",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=3154287255917969405&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "PanFoMa: A Lightweight Foundation Model and Benchmark for Pan-Cancer",
    "authors": [
      "X Huang",
      "T Zhu",
      "Y Zuo",
      "X Xia",
      "Z Wu",
      "J Yan"
    ],
    "year": "2025",
    "abstract": "in Natural Language Processing (NLP), Foundation Models  is evaluated by the tasks of  Batch integration, cell type  the recent proposed singlecell foundation models to demonstrate our",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2512.03111",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "mCAFoundation: A Single-Cell RNA Sequencing Foundation Model for Mouse Cell Types Annotations",
    "authors": [
      "C Zheng",
      "X Wu",
      "H Zhu",
      "X Liu",
      "A Yang",
      "R He"
    ],
    "year": "NA",
    "abstract": "We introduce mCAFoundation, a foundational model for mouse cell type annotation with   by natural language processing, applying selfsupervised learning on extensive single-cell",
    "venue": "Available at SSRN …",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5643031",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "OmniPert: A Deep Learning Foundation Model for Predicting Responses to Genetic and Chemical Perturbations in Single Cancer Cells",
    "authors": [
      "F Taj",
      "LD Stein"
    ],
    "year": "2025",
    "abstract": "The data produced by these single cell omics technologies  accurate predictive models based  on individual cell type,  we filtered and harmonized 20 single-cell perturbation studies from",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.07.02.662744.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "A natural language processing system for the efficient extraction of cell markers",
    "authors": [
      "P Cheng",
      "Y Peng",
      "XL Zhang",
      "S Chen",
      "BB Fang"
    ],
    "year": "2024",
    "abstract": "in the context of single-cell sequencing studies. Leveraging  This advancement has laid  the foundation for comprehensive  the cell type annotation results of single-cell sequencing in",
    "venue": "Scientific Reports",
    "url": "https://www.nature.com/articles/s41598-024-72204-6",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=13165874329844049334&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Representing and extracting knowledge from single-cell data",
    "authors": [
      "IS Mihai",
      "S Chafle",
      "J Henriksson"
    ],
    "year": "2024",
    "abstract": "our ontology and models, and some pointers will be given to how natural language  processing (NLP) may help overcome our cognitive limitations for understanding single-cell data.",
    "venue": "Biophysical Reviews",
    "url": "https://link.springer.com/article/10.1007/s12551-023-01091-4",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=3951828910556228530&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Adding layers of information to scRNA-seq data using pre-trained language models",
    "authors": [
      "SM Krißmer",
      "J Menger",
      "J Rollin",
      "T Vogel",
      "H Binder"
    ],
    "year": "2025",
    "abstract": "single-cell tasks and novel applications like dataset interpretation via natural language   Aligning the embeddings of cell type labels with single-cell data and the additional information",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.08.23.671699.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=13433306096738351329&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "CIForm as a transformer-based model for cell-type annotation of large-scale single-cell RNA-seq data",
    "authors": [
      "J Xu",
      "A Zhang",
      "F Liu",
      "L Chen"
    ],
    "year": "2023",
    "abstract": "Single-cell omics  the cell type of each cell is a crucial goal in single-cell RNA-seq (scRNA-seq)  analysis. Apart from overcoming the batch effects arising from various factors, single-cell",
    "venue": "Briefings in bioinformatics",
    "url": "https://academic.oup.com/bib/article-abstract/24/4/bbad195/7169137",
    "num_citations": 57,
    "citedby_url": "/scholar?cites=17905627897655511474&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Artificial Intelligence for Single-Cell Biology: From Representation Learning to Predictive Modeling",
    "authors": [
      "W Li",
      "Y Luo"
    ],
    "year": "2025",
    "abstract": "Automated Cell Type Annotation and Uncertainty  , the field has begun exploring ‘ foundation  models' based on self- scGPT, inspired by Transformer architectures in natural language",
    "venue": "iCell",
    "url": "https://www.icelljoural.com/index.php/iCell/article/view/47",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Self-supervised learning of T cell receptor sequences exposes core properties for T cell membership",
    "authors": [
      "R Goldner Kabeli",
      "S Zevin",
      "A Abargel",
      "A Zilberberg"
    ],
    "year": "2024",
    "abstract": "This is evident in natural language processing (NLP) in  Using these rich single-cell data, we  developed scCVC—a model  the role of CDR3 sequences in encoding cell type information.",
    "venue": "Science …",
    "url": "https://www.science.org/doi/abs/10.1126/sciadv.adk4670",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=14546133549939557420&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "scFormer: a universal representation learning approach for single-cell data using transformers",
    "authors": [
      "H Cui",
      "C Wang",
      "H Maan",
      "N Duan",
      "B Wang"
    ],
    "year": "2022",
    "abstract": "of single-cell data modelling. Cell embeddings are the foundation for various downstream  tasks, such as cell type  to the word/token embeddings in natural language modeling (NLM). In",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2022.11.20.517285.abstract",
    "num_citations": 10,
    "citedby_url": "/scholar?cites=4827781957854084436&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Into the single cell multiverse: an end-to-end dataset for procedural knowledge extraction in biomedical texts",
    "authors": [
      "R Dannenfelser",
      "J Zhong"
    ],
    "year": "2023",
    "abstract": "advances in a range of natural language processing (NLP)  , we also provide tissue/cell  type annotations in 1,195 paper  a useful foundation for future “science-know-how” modeling",
    "venue": "Advances in Neural …",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/23e3d86c9a19d0caf2ec997e73dfcfbd-Abstract-Datasets_and_Benchmarks.html",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=510395196438078277&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Large Language Models Meet Virtual Cell: A Survey",
    "authors": [
      "K Li",
      "X Xiao",
      "S Deng",
      "L He",
      "Z Zhong",
      "Y Zou"
    ],
    "year": "2025",
    "abstract": "-powered single-cell studies and foundation model research,  representations with natural  language understanding and  ), is also a benchmark for cell type classification. This dataset",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2510.07706",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Single-cell multimodal prediction via transformers",
    "authors": [
      "W Tang",
      "H Wen",
      "R Liu",
      "J Ding",
      "W Jin",
      "Y Xie"
    ],
    "year": "2023",
    "abstract": "Transformer [34] has made significant achievements in the field of Natural Language  -scale  pretrained deep language model for cell type annotation of single-cell RNA-seq data.",
    "venue": "Proceedings of the …",
    "url": "https://dl.acm.org/doi/abs/10.1145/3583780.3615061",
    "num_citations": 24,
    "citedby_url": "/scholar?cites=1349089069420132252&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Sparse Autoencoders Reveal Interpretable Features in Single-Cell Foundation Models",
    "authors": [
      "F Pedrocchi",
      "F Barkmann",
      "A Joudaki",
      "V Boeva"
    ],
    "year": "2025",
    "abstract": "are largely inherited from natural language processing models, with only minimal adaptation   each cell type, we observed several features that were strongly correlated with the cell type",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.10.22.681631.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Improving Classification of Cell Types in Acute Myeloid Leukemia with Self-guided Masking",
    "authors": [
      "A Naziri",
      "A Asgari",
      "E Sachlos",
      "A An",
      "L Seyyed-Kalantari"
    ],
    "year": "NA",
    "abstract": "and autoregressive language modeling in natural language and  Foundation models for  single-cell RNA data: Recent work  Each point represents a single cell colored by (top) cell type.",
    "venue": "NA",
    "url": "https://ai4d3.github.io/2025/papers/11_Improving_Classification_of.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "uHAF: a unified hierarchical annotation framework for cell type standardization and harmonization",
    "authors": [
      "H Bian",
      "Y Chen",
      "L Wei",
      "X Zhang"
    ],
    "year": "2025",
    "abstract": "In single-cell biology, cell type labels are the most crucial  model-based tool that takes  users’ customized cell type lists  knowledge and natural language processing ability of GPT-4.",
    "venue": "Bioinformatics",
    "url": "https://academic.oup.com/bioinformatics/article-abstract/41/4/btaf149/8104046",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=16974182066661045904&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Hierarchical Interpretation of Out-of-Distribution Cells Using Bottlenecked Transformer",
    "authors": [
      "Q Wang",
      "H Zhu",
      "Y Hu",
      "Y Chen",
      "Y Wang",
      "X Zhang",
      "J Zou"
    ],
    "year": "2024",
    "abstract": "a strategy of natural language processing (NLP) models for  To overcome this, we utilized  CellMemory to model a single-cell  In this study, we utilized the implementation of the cell type",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.17.628533.abstract",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=11922795146980986872&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Past: A multimodal single-cell foundation model for histopathology and spatial transcriptomics in cancer",
    "authors": [
      "C Yang",
      "H Li",
      "Y Wu",
      "Y Zhang",
      "Y Jiao",
      "Y Zhang"
    ],
    "year": "2025",
    "abstract": "expression maps can be directly used for other single-cell analysis, such as automatic  cell-type annotation and discovery of rare subpopulations without additional wet-lab cost; (2)",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2507.06418",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=288966041974653052&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Designing Cell–Cell Relation Extraction Models: A Systematic Evaluation of Entity Representation and Pre-training Strategies",
    "authors": [
      "M Yoshikawa",
      "T Miuzuno",
      "Y Ohto",
      "H Fujimoto"
    ],
    "year": "2025",
    "abstract": "approaches, including single-cell and spatial transcriptomics least two cell-type mentions  were identified using a cell-type  , this work provides a concrete foundation for future studies on",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.01.691726.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Explainable modeling of single-cell perturbation data using attention and sparse dictionary learning",
    "authors": [
      "Y Xu",
      "S Fleming",
      "M Tegtmeyer",
      "SA McCarroll",
      "M Babadi"
    ],
    "year": "2025",
    "abstract": "modeling single-cell perturbation data. CellCap builds upon the foundation laid by the CPA  model  In our study, we specifically trained CellCap on datasets featuring a single cell type,",
    "venue": "Cell Systems",
    "url": "https://www.cell.com/cell-systems/abstract/S2405-4712(25)00078-X",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=2175136610874862164&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Toward ai-driven digital organism: Multiscale foundation models for predicting, simulating and programming biology at all levels",
    "authors": [
      "L Song",
      "E Segal",
      "E Xing"
    ],
    "year": "2024",
    "abstract": "Single-cell pretrained models can be constructed based on data from cellxgene, and tissue  and cell type image models  linear positions in a natural language sentence or sequence,",
    "venue": "arXiv preprint arXiv:2412.06993",
    "url": "https://arxiv.org/abs/2412.06993",
    "num_citations": 19,
    "citedby_url": "/scholar?cites=14135864296763526724&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Transformer-Based Integrative Patient Representations from Single-Cell RNA Data",
    "authors": [
      "B von Querfurth",
      "J Lohmöller",
      "J Pennekamp"
    ],
    "year": "2025",
    "abstract": "2019), well-known in Natural Language Processing (NLP). The architecture and training  methods  cells stratified by cell type. These cells are separately processed by the model, before",
    "venue": "… of Life (LMRL) …",
    "url": "https://openreview.net/forum?id=0G4B0YQ6xX",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=1621461003653513448&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "scGraphformer: unveiling cellular heterogeneity and interactions in scRNA-seq data using a scalable graph transformer network",
    "authors": [
      "X Fan",
      "J Liu",
      "Y Yang",
      "C Gu",
      "Y Han",
      "B Wu"
    ],
    "year": "2024",
    "abstract": "not only excels in cell type identification but also in revealing  , a common choice in  single-cell analyses. The connectivity  in the realm of natural language processing due to its",
    "venue": "Communications …",
    "url": "https://www.nature.com/articles/s42003-024-07154-w",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=1908215617007066279&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "From Task-Specific Tools to Foundation Models in Single-Cell Genomics",
    "authors": [
      "J Ding"
    ],
    "year": "2025",
    "abstract": "TABULA, a foundation model for single-cell genomics that  Unlike prior models that  repurpose Natural Language  is at a single-cell resolution with a known single-cell cell type, a",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/78c1e49a1176ebace5cf165d1c2cb1b2/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "CELLetter: leveraging large language model and dual-stream network to identify context-specific ligand–receptor interactions for cell–cell communication analysis",
    "authors": [
      "W Wu",
      "J Huang",
      "Y Jiang",
      "L Nie"
    ],
    "year": "2025",
    "abstract": ", failing to fully capture the cell-type-specific interactome within the single-cell context [10].   natural language processing and computer vision tasks [43–46], and it enables our model",
    "venue": "Briefings in …",
    "url": "https://academic.oup.com/bib/article-abstract/26/6/bbaf693/8405044",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Benchmarking algorithms for generalizable single-cell perturbation response prediction",
    "authors": [
      "Z Wei",
      "Y Wang",
      "Y Gao",
      "S Wang",
      "P Li",
      "D Si",
      "Y Gao"
    ],
    "year": "2025",
    "abstract": "machine learning models, particularly foundation models, we  (predicting perturbation effects  in a new cell type), 3 that are focused on  that models relying on unaligned natural language",
    "venue": "Nature …",
    "url": "https://www.nature.com/articles/s41592-025-02980-0",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "A mini-review on perturbation modelling across single-cell omic modalities",
    "authors": [
      "GI Gavriilidis",
      "V Vasileiou",
      "A Orfanou"
    ],
    "year": "2024",
    "abstract": "transformers, have excelled in natural language processing and computer vision.  cell  type clustering [77]. Still in its infancy, this niche of foundation models in perturbation single-cell",
    "venue": "Computational and …",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11076269/",
    "num_citations": 44,
    "citedby_url": "/scholar?cites=15372616041549854932&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Detecting cell-level transcriptomic changes of Perturb-seq using Contrastive Fine-tuning of Single-Cell Foundation Models",
    "authors": [
      "W Zhao",
      "A Solaguren-Beascoa",
      "G Neilson",
      "R Reynolds"
    ],
    "year": "2025",
    "abstract": "In this paper, we introduce a method for learning representations of single-cell  for single-cell  foundation models using contrastive learning. By fine-tuning these models on single-cell",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.04.17.649395.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "Bridging Large Language Models and Single-Cell Transcriptomics in Dissecting Selective Motor Neuron Vulnerability",
    "authors": [
      "D Jiang",
      "Z Dai",
      "L Zhang",
      "Q Yu",
      "H Sun",
      "F Tian"
    ],
    "year": "2025",
    "abstract": "applications such as cell type clustering, cell vulnerability  LLMs has transformed natural  language processing and has  a foundation for applying LLMbased embeddings in single-cell",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2505.07896",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_nl_cell",
    "title": "scPRINT: pre-training on 50 million cells allows robust gene network predictions",
    "authors": [
      "J Kalfon",
      "J Samaran",
      "G Peyré",
      "L Cantini"
    ],
    "year": "2025",
    "abstract": "A We extract cell type-specific gene networks for each cell type in the  RNAseq tools on  multiple important tasks of single-cell  An assumption in natural language processing is that fewer",
    "venue": "Nature Communications",
    "url": "https://www.nature.com/articles/s41467-025-58699-1",
    "num_citations": 30,
    "citedby_url": "/scholar?cites=5958606526020131993&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model",
    "authors": [
      "A Fallahpour",
      "A Magnuson",
      "P Gupta",
      "S Ma"
    ],
    "year": "2025",
    "abstract": "This novel connection enables the LLM to directly process and reason with genomic   integrates a DNA foundation model with an LLM, enabling a new paradigm of multimodal biological",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2505.23579",
    "num_citations": 23,
    "citedby_url": "/scholar?cites=16996025195502593553&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Comprehensive Review of Multimodal Large Language Models for Medical Imaging and Omics Data",
    "authors": [
      "R Vavekanand"
    ],
    "year": "2026",
    "abstract": "This review focuses on how Multimodal Large Language Models (MLLMs) and multimodal  AI models are advancing healthcare by integrating medical imaging and omics data. By",
    "venue": "Archives of Computational Methods in Engineering",
    "url": "https://link.springer.com/article/10.1007/s11831-026-10504-y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Geneverse: A collection of open-source multimodal large language models for genomic and proteomic research",
    "authors": [
      "T Liu",
      "Y Xiao",
      "X Luo",
      "H Xu",
      "W Zheng"
    ],
    "year": "2024",
    "abstract": "Therefore, we still need a better foundation model for  To finetune an LLM as an AI assistant  for genomic and proteomic  c based on the spatial transcriptomic data. Understanding the",
    "venue": "Findings of the …",
    "url": "https://aclanthology.org/2024.findings-emnlp.277/",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=2479026569607258996&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Comprehensive Survey of Multimodal LLMs for Scientific Discovery",
    "authors": [
      "L Yan",
      "X Jiang",
      "J Ma",
      "Y Liu",
      "T Bian",
      "Q Wang"
    ],
    "year": "NA",
    "abstract": "This line of research has since been extended by LLM-MPP [78], Mol-LLM [89], and related   St-align: A multimodal foundation model for image-gene alignment in spatial transcriptomics",
    "venue": "1st Workshop on …",
    "url": "https://openreview.net/forum?id=HSz1Kr5BeC",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Harnessing artificial intelligence in multimodal omics data integration: paving the path for the next frontier in precision medicine",
    "authors": [
      "Y Nam",
      "J Kim",
      "SH Jung",
      "J Woerner"
    ],
    "year": "2024",
    "abstract": "between the genome and transcriptome in individual cells,  With technological improvements  in the foundation model,  While forging a multimodal omics-centric LLM is a formidable",
    "venue": "Annual review of …",
    "url": "https://www.annualreviews.org/content/journals/10.1146/annurev-biodatasci-102523-103801",
    "num_citations": 79,
    "citedby_url": "/scholar?cites=6281130611334680784&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "LLMAgent4Bio: LLM Agents for Biological Intelligence Across Genomics, Proteomics, Spatial Biology, and Biomedicine",
    "authors": [
      "SA Dip",
      "D Mallick",
      "UA Shuvo",
      "SB Soummo",
      "F Rafsani"
    ],
    "year": "2025",
    "abstract": ", genomics and transcriptomics represent one of the most mature domains for biological  LLM  Leveraging multi-modal foundation model image encoders to enhance brain MRI-based",
    "venue": "NA",
    "url": "https://www.researchsquare.com/article/rs-8349177/latest",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "BioLM-NET: an interpretable deep learning model combining prior biological knowledge and contextual LLM gene embeddings on multi-omics data to predict disease",
    "authors": [
      "JIM Rifat",
      "T Tabashum",
      "MM Rahman"
    ],
    "year": "2025",
    "abstract": "-omics data—including genomics, transcriptomics, epigenomics,  and was tested only on bulk  transcriptomic data from glioblastoma.  To understand how multimodal features, genes, and",
    "venue": "… 2026: Proceedings of …",
    "url": "https://www.worldscientific.com/doi/abs/10.1142/9789819824755_0047",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=10270963763919511556&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Challenges in AI-driven biomedical multimodal data fusion and analysis",
    "authors": [
      "J Liu",
      "X Cen",
      "C Yi",
      "F Wang",
      "J Ding"
    ],
    "year": "2025",
    "abstract": "from genomics, transcriptomics, proteomics, and metabolomics to radiology and electronic  health records (EHRs) [1]. Single or unified multimodal  LLM: A type of foundation model",
    "venue": "Genomics …",
    "url": "https://academic.oup.com/gpb/article/23/1/qzaf011/8045317",
    "num_citations": 34,
    "citedby_url": "/scholar?cites=9090432419601438585&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A survey of scientific large language models: From data foundations to agent frontiers",
    "authors": [
      "M Hu",
      "C Ma",
      "W Li",
      "W Xu",
      "J Wu",
      "J Hu",
      "T Li"
    ],
    "year": "2025",
    "abstract": "multimodal Mixture-of-Experts (MoE) [48] foundation model  for Sci-LLM development, distilling  the multimodal, cross-scale biological layers (eg, genomics, transcriptomics, proteomics).",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2508.21148",
    "num_citations": 15,
    "citedby_url": "/scholar?cites=5210907917610085418&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Large language models for bioinformatics",
    "authors": [
      "W Ruan",
      "Y Lyu",
      "J Zhang",
      "J Cai",
      "P Shu",
      "Y Ge"
    ],
    "year": "2026",
    "abstract": "LLMs are a type of foundation model trained on vast datasets to  omics data (eg, genomics,  transcriptomics, proteomics) and  Recent advances in multi-modal LLM architecture have",
    "venue": "Quantitative …",
    "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/qub2.70014",
    "num_citations": 22,
    "citedby_url": "/scholar?cites=15751936151905413808&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Procyon: A multimodal foundation model for protein phenotypes",
    "authors": [
      "O Queen",
      "Y Huang",
      "R Calef",
      "V Giunchiglia",
      "T Chen"
    ],
    "year": "2024",
    "abstract": "LLM (OpenAI’s GPT models [25]) to 208 rephrase the descriptions in PROCYON-INSTRUCT  (Figure 2b). We provide three critical com- 209 ponents to the LLM— that instruct the LLM to",
    "venue": "BioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.12.10.627665.abstract",
    "num_citations": 10,
    "citedby_url": "/scholar?cites=10105357754974394415&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Foundation Model for Biomedical Graphs: Integrating Knowledge Graphs and Protein Structures to Large Language Models",
    "authors": [
      "Y Kim"
    ],
    "year": "2024",
    "abstract": ", multimodal LLM in the biomedical domain is primarily limited to images, text, and/or sequence  data. Here I propose to work on multimodal LLM  -art foundation model with genetics and",
    "venue": "Proceedings of the 62nd Annual Meeting of the …",
    "url": "https://aclanthology.org/2024.acl-srw.58/",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=16223182676233166215&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A novel sequence-based transformer model architecture for integrating multi-omics data in preterm birth risk prediction",
    "authors": [
      "S Zhou",
      "C Guan",
      "S Deng",
      "Y Zhu",
      "W Yang",
      "X Zhang"
    ],
    "year": "2025",
    "abstract": "between GeneLLM-based LLM and the rich biological  , we leveraged the GeneLLM  foundation model to map gene  generalizability and develop robust multi-modal LLMs for clinical",
    "venue": "NPJ Digital …",
    "url": "https://www.nature.com/articles/s41746-025-01942-2",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=13113463895760730200&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "From classical machine learning to emerging foundation models: review on multimodal data integration for cancer Research",
    "authors": [
      "A Muneer",
      "M Waqas",
      "MB Saad",
      "E Showkatian"
    ],
    "year": "2025",
    "abstract": "deep and foundation-model approaches increasingly target  across omics layers (genomics,  transcriptomics, proteomics,  GenePT [145] represents genes and cells by leveraging LLM",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2507.09028",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=18432181753299941901&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Biology Instructions: A Dataset and Benchmark for Multi-Omics Sequence Understanding Capability of Large Language Models",
    "authors": [
      "H He",
      "Y Ren",
      "Y Tang",
      "Z Xu",
      "J Li",
      "M Yang"
    ],
    "year": "2024",
    "abstract": "LLM capable of handling tasks related to multi-omics sequences by training an open-source  LLM  Chatnt: A multimodal conversational agent for dna, rna and protein tasks. bioRxiv, pp.",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2412.19191",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=11409820284762410284&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Multimodal large language models in health care: applications, challenges, and future outlook",
    "authors": [
      "R AlSaad",
      "A Abd-Alrazaq",
      "S Boughorbel"
    ],
    "year": "2024",
    "abstract": "This paper aims to present a detailed, practical, and solution-oriented perspective on the  use of multimodal LLMs (M-LLMs) in the medical field. Our investigation spanned M-LLM",
    "venue": "Journal of medical …",
    "url": "https://www.jmir.org/2024/1/e59505/",
    "num_citations": 269,
    "citedby_url": "/scholar?cites=17919196981757168275&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "The large language models on biomedical data analysis: a survey",
    "authors": [
      "W Lan",
      "Z Tang",
      "M Liu",
      "Q Chen",
      "W Peng"
    ],
    "year": "2025",
    "abstract": "of LLMs in genomics, proteomics, transcriptomics, single-cell  BERT-based LLM that uses a  multi-modal self-supervised pre foundation model and benchmark for multi-species genome.",
    "venue": "IEEE Journal of …",
    "url": "https://ieeexplore.ieee.org/abstract/document/10878496/",
    "num_citations": 50,
    "citedby_url": "/scholar?cites=10866564886245049443&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Large language models for biological sequence analysis in infectious disease research",
    "authors": [
      "J Luo",
      "X Cai",
      "Y Li"
    ],
    "year": "2025",
    "abstract": "models, genomic language models, and multimodal models,  the emergence of computational,  LLM-based approaches for  foundation model and benchmark for multi species genomes",
    "venue": "Biosafety and Health",
    "url": "https://mednexus.org/doi/abs/10.1016/j.bsheal.2025.09.007",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Large language models in biomedicine and healthcare",
    "authors": [
      "J Zhou",
      "H Li",
      "S Chen",
      "Z Chen",
      "Z Han",
      "X Gao"
    ],
    "year": "2025",
    "abstract": "Below, we explore how LLMs are advancing transcriptomics  MolFM 97 is a multimodal  molecular foundation model that  multimodal inputs (molecules, proteins, text) in a single LLM,",
    "venue": "npj Artificial Intelligence",
    "url": "https://www.nature.com/articles/s44387-025-00047-1",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=3279933981847022408&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Embedding-Based Deep Learning Frameworks for Multimodal Oncology Data Integration",
    "authors": [
      "AG Tripathi"
    ],
    "year": "2025",
    "abstract": "our foundation model-driven approach to generating multimodal oncology datasets. We show   We discuss the challenges and limitations of implementing multimodal data-fusion models",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/3ebf3cf10fca5be838ff2a9aa9f16e8b/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=14616990116232695739&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "ModalTune: Fine-Tuning Slide-Level Foundation Models with Multi-Modal Information for Multi-task Learning in Digital Pathology",
    "authors": [
      "V Ramanathan",
      "T Xu",
      "P Pati",
      "F Ahmed"
    ],
    "year": "2025",
    "abstract": "Prism: A multi-modal generative foundation model for slide- by replacing transcriptomics  tokens from the genomic encoder  when using a different text embedding LLM, we tested Llama-",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2503.17564",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=6406421845767150491&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "BiOmics: A Foundational Agent for Grounded and Autonomous Multi-omics Interpretation",
    "authors": [
      "L Cao",
      "Y Li",
      "H Qin",
      "Y Shang",
      "Y Zhang",
      "B Jovanovic"
    ],
    "year": "2026",
    "abstract": "data to a 175 shared multi-modal reasoning space to complete  a mouse pancreas single-cell  281 transcriptome dataset[44]. In a  retrieval performance, we developed an LLM-based",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2026.01.17.699830.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Ai for biomedicine in the era of large language models",
    "authors": [
      "Z Bi",
      "SA Dip",
      "D Hajialigol",
      "S Kommu",
      "H Liu"
    ],
    "year": "2024",
    "abstract": "methods to integrate multi-modal and multi-omic LLMs into one powerful unified LLM? This   scgpt: toward building a foundation model for single-cell multi-omics using generative ai.",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2403.15673",
    "num_citations": 18,
    "citedby_url": "/scholar?cites=1318854114377831158&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Survey of Multimodal Large Language Models in Biomedical Engineering and Healthcare",
    "authors": [
      "A Hornback",
      "H Sathu",
      "K Kim",
      "Y Wang",
      "Y Yuan"
    ],
    "year": "2025",
    "abstract": "data are inherently multimodal: imaging, waveforms, genomics,  fine-tunes the Otter  foundation model to generate volumetric CT  Xu, “Do we really need a multimodal llm decoder?",
    "venue": "Authorea …",
    "url": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.176291728.82597243",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=8379274519939820283&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "AI-Driven Digital Pathology: Deep Learning and Multimodal Integration for Precision Oncology",
    "authors": [
      "HJ Jang",
      "SH Lee"
    ],
    "year": "2025",
    "abstract": "to associate morphology with genomic, transcriptomic, and  upon large language model  (LLM)-vision encoder integration  radiology foundation model trained on web-scale multimodal",
    "venue": "International Journal of Molecular Sciences",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12785522/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling",
    "authors": [
      "H Zhang",
      "T Xu",
      "D Cao",
      "S Liang"
    ],
    "year": "2025",
    "abstract": "and sharing the same copy of genome. The complex, robust and  our ability to measure  transcriptomic abundance at individual cell  for foundation model training and downstream tasks.",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2504.02148",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=18199933212478306942&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Bridging artificial intelligence and biological sciences: a comprehensive review of large language models in bioinformatics",
    "authors": [
      "A Lin",
      "J Ye",
      "C Qi",
      "L Zhu",
      "W Mou",
      "W Gan"
    ],
    "year": "2025",
    "abstract": "In biological sequence analysis and function prediction, LLM- on DNA sequences and the  incorporation of multimodal data  As a pioneering pre-trained foundation model for genomic",
    "venue": "Briefings in …",
    "url": "https://academic.oup.com/bib/article-abstract/26/4/bbaf357/8212018",
    "num_citations": 17,
    "citedby_url": "/scholar?cites=6931383883292187581&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "OmicsNavigator: an LLM-driven multi-agent system for autonomous zero-shot biological analysis in spatial omics",
    "authors": [
      "L Yiyao",
      "N Vakharia",
      "W Liang",
      "AT Mayer",
      "R Luo"
    ],
    "year": "2025",
    "abstract": "Spatial omics, including spatial transcriptomics and proteomics, is reshaping biological   Multimodal vision–language models integrating radiology or pathology images with free-",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.07.21.665821.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Multimodal Generative AI for Anatomic Pathology—A Review of Current Applications to Envisage the Future Direction",
    "authors": [
      "E Ullah",
      "MM Baig",
      "A Waqas",
      "G Rasool"
    ],
    "year": "2025",
    "abstract": "use of multimodal Gen-AI models as a foundation model surrogate for  , multimodal projector  to conform and connect the vision encoder outputs to the LLM, and Llama2-based LLM for",
    "venue": "Advances in …",
    "url": "https://journals.lww.com/anatomicpathology/fulltext/9900/multimodal_generative_ai_for_anatomic_pathology_a.150.aspx",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=9085091665201866344&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Foundations for Genome-Scale Artificial Intelligence",
    "authors": [
      "Y Ektefaie"
    ],
    "year": "2025",
    "abstract": "The same multimodal approach can be extended to genome  true foundation model capable  of operating over full genomes— how LLM-based agents can perform complex, multimodal",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/653da152f2fe878e8dcd914f55c22571/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Integrating Multi-Modal Artificial Intelligence for Enhanced Cancer Recurrence Detection Using Biomarkers, Imaging and Radiology Reports",
    "authors": [
      "JY Wei"
    ],
    "year": "2025",
    "abstract": "biomarkers from advanced -omics technologies and the potential for AI-based multimodal   records and sources of data, ML and AI can enable comprehensive analyses of multimodal",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/f2a83988f6bb3838154d4c9fc5488873/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "EnrichGT: a comprehensive R-based tool for functional genomics enrichment analysis based on large language models",
    "authors": [
      "R Wang",
      "Z Ye",
      "Q Wang",
      "B Liang",
      "N Fu"
    ],
    "year": "2026",
    "abstract": "We implemented multi-stage LLM-assisted annotation of clustering results to accommodate  the limited context window of LLMs. In this study, the LLM component served as an optional",
    "venue": "Artificial Intelligence …",
    "url": "https://www.oaepublish.com/articles/ais.2025.67",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Comprehensive Survey of AI Models in Precision Medicine",
    "authors": [
      "Z Wang",
      "H Tang"
    ],
    "year": "2025",
    "abstract": "These multimodal systems have achieved high performance  learning, have further integrated  genomics with other omics data to  with transcriptomics can effectively identify key genomic",
    "venue": "Authorea Preprints",
    "url": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.176127323.31251816",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=9329338267886011606&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Continually evolved multimodal foundation models for cancer prognosis",
    "authors": [
      "J Peng",
      "S Zhou",
      "L Yang",
      "Y Song",
      "M Zhang"
    ],
    "year": "2025",
    "abstract": "continually evolving multi-modal foundation model. Extensive  histology WSIs and  transcriptomic profiles for survival  To mitigate the computational overhead of LLM processing",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2501.18170",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=18389678116579269908&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "PyTDC: A multimodal machine learning training, evaluation, and inference platform for biomedical foundation models",
    "authors": [
      "A Velez-Arce",
      "M Zitnik"
    ],
    "year": "2025",
    "abstract": "Foundation models pre-trained on structural, genomic, and network biology data have   PyTDC allows the user to extract single-cell foundation model embeddings from complex",
    "venue": "arXiv preprint arXiv:2505.05577",
    "url": "https://arxiv.org/abs/2505.05577",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=8421626693728576348&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology",
    "authors": [
      "K Vasilev",
      "A Misrahi",
      "E Jain",
      "PF Cheng"
    ],
    "year": "2025",
    "abstract": "with foundation model-based tools that enhance multi-modal and  testbed for advancing  multimodal LLM reasoning, reliability,  tool that combines foundation model embeddings with",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2511.20490",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=4782315023435914780&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "QuST-LLM: Integrating Large Language Models for Comprehensive Spatial Transcriptomics Analysis",
    "authors": [
      "CH Huang"
    ],
    "year": "2024",
    "abstract": "analysis platform for effectively utilizing multimodal and high-throughput  transcriptomics  (ST) analysis, embodied in the QuST-LLM tool, signifies a considerable leap in the genomics",
    "venue": "arXiv preprint arXiv:2406.14307",
    "url": "https://arxiv.org/abs/2406.14307",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=11754611287347054065&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Clinically aligned multi-modal image-text model for pan-cancer prognosis prediction",
    "authors": [
      "J Lee",
      "JS Leiby",
      "L Takemaru",
      "Y Huang",
      "MG Noh",
      "J Kim"
    ],
    "year": "2025",
    "abstract": "morphology to genomic and transcriptomic profiles, and extend  image and language  foundation model built on the BEITv3  , we prompted the LLM to generate plausible descriptions for",
    "venue": "BioData Mining",
    "url": "https://link.springer.com/article/10.1186/s13040-025-00495-0",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Multimodal AI predicts clinical outcomes of drug combinations from preclinical data",
    "authors": [
      "Y Huang",
      "X Su",
      "V Ullanat",
      "I Moon",
      "I Liang"
    ],
    "year": "2025",
    "abstract": ", pathway, cell viability, and transcriptomic data to predict drug  Multimodal MADRIGAL  combined with patient genomic  MADRIGAL with an LLM, resulting in MADRIGAL-LLM. This",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2503.02781",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=9956430910247539934&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Chatnt: A multimodal conversational agent for dna, rna and protein tasks",
    "authors": [
      "G Richard",
      "BP de Almeida",
      "H Dalla-Torre",
      "C Blum"
    ],
    "year": "2024",
    "abstract": "a pre-trained GPT-style LLM, to comprehend the user  using the DNA foundation model  Nucleotide Transformer as a DNA  not only in genomics but also transcriptomics and proteomics",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.04.30.591835.abstract",
    "num_citations": 20,
    "citedby_url": "/scholar?cites=4718974721304161102&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Genos: a human-centric genomic foundation model",
    "authors": [
      "A Lin",
      "B Xie",
      "C Ye",
      "C Wang",
      "D Chen",
      "E Wang",
      "F Lu"
    ],
    "year": "2025",
    "abstract": "between genomic sequences and their corresponding transcriptomic expressions.  To  evaluate the performance of a multimodal large language model (combining a genome",
    "venue": "…",
    "url": "https://academic.oup.com/gigascience/article-abstract/doi/10.1093/gigascience/giaf132/8296738",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=10077209050096204371&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Advancing non-coding RNA annotation with RNA sequence foundation models: structure and function perspectives",
    "authors": [
      "N Vahab",
      "S Tyagi"
    ],
    "year": "2025",
    "abstract": "human genome transcribes to RNA, but only a small proportion of it is coding transcriptome.   The first published specialised foundation model for RNA was called RNA-FM [26]. Built",
    "venue": "BMC Artificial Intelligence",
    "url": "https://link.springer.com/article/10.1186/s44398-025-00012-7",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Generative Models in Computational Pathology: A Comprehensive Survey on Methods, Applications, and Challenges",
    "authors": [
      "Y Zhang",
      "X Zhang",
      "X Qi",
      "X Wu",
      "F Chen",
      "G Yang"
    ],
    "year": "2025",
    "abstract": "Diffusion models and LLM/VLM  multimodal retrieval and few-shot learning. THREADS [199]  represents the largest slidelevel multimodal foundation model integrating H&E with genomic",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2505.10993",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=17414883368905599649&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "HONeYBEE: enabling scalable multimodal AI in oncology through foundation model-driven embeddings",
    "authors": [
      "A Tripathi",
      "A Waqas",
      "MB Schabath",
      "Y Yilmaz"
    ],
    "year": "2025",
    "abstract": "We evaluated HONeYBEE using multimodal patient-level data from The Cancer Genome  Atlas ( These results demonstrate the superior cancer type discrimination after LLM fine-tuning.",
    "venue": "npj Digital …",
    "url": "https://www.nature.com/articles/s41746-025-02003-4",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=15893619256660060625&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Foundation models and intelligent decision-making: Progress, challenges, and perspectives",
    "authors": [
      "J Huang",
      "Y Xu",
      "Q Wang",
      "QC Wang",
      "X Liang",
      "F Wang"
    ],
    "year": "2025",
    "abstract": "the LLM and utilizes instruction tuning to adapt the LLM to  multimodal foundation model  (MMFM) technology has become a popular topic in both research and applications. Multimodal",
    "venue": "The Innovation",
    "url": "https://www.cell.com/the-innovation/fulltext/S2666-6758(25)00151-1",
    "num_citations": 56,
    "citedby_url": "/scholar?cites=9551083190424854816&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Multi-Modal Tumor Survival Prediction via Graph-Guided Mixture of Experts",
    "authors": [
      "H Mathavan"
    ],
    "year": "2024",
    "abstract": "Rather than directly training a single foundation model to  LLM for Multi-modal Tasks: LLMs  have been extended to  that highlight the most influential genomic, transcriptomic, or clinical",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/990e84df0f4c2739b238f78a555b8e1b/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A visual–omics foundation model to bridge histopathology image with transcriptomics",
    "authors": [
      "W Chen",
      "P Zhang",
      "TN Tran",
      "Y Xiao",
      "S Li"
    ],
    "year": "2025",
    "abstract": "Inspired by large language model (LLM)-based single-cell  CLIP-based foundation model,  integrating both genomic and  tools to further enhance multi-modal tissue reconstruction and",
    "venue": "Research …",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12047990/",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=13848281445137188355&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Foundation Model for Medical Imaging: A Comprehensive Review",
    "authors": [
      "L Jiao",
      "J Yang",
      "R Li",
      "F Liu",
      "X Liu",
      "P Chen"
    ],
    "year": "2025",
    "abstract": ") model, a multimodal medical foundation model with both  imaging, and genomics. The  researchers first propose a new  CLIP with LLM, which focuses mainly on multimodal input fusion",
    "venue": "IEEE Transactions …",
    "url": "https://ieeexplore.ieee.org/abstract/document/11202641/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Analysing the Applicability of Foundational Models for Healthcare",
    "authors": [
      "R Ahmed"
    ],
    "year": "2025",
    "abstract": "the most advanced transformer based LLM, that can generate  in healthcare are called  Medical Foundation Model (MFM) [35]  [40] Med-PaLM M is a multi-modal AI system designed for",
    "venue": "NA",
    "url": "https://aaltodoc.aalto.fi/items/1c05bdfa-ee42-4fa3-ae05-e21be6d8d1a7",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Artificial intelligence for central dogma-centric multi-omics: challenges and breakthroughs",
    "authors": [
      "L Xin",
      "C Huang",
      "H Li",
      "S Huang",
      "Y Feng",
      "Z Kong"
    ],
    "year": "2024",
    "abstract": "proteomics with genomic and transcriptomic data have revealed  of nonlinear factors during  multimodal alignment. To effectively  The foundation model has recently become a hot topic,",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2412.12668",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=6654820281331665886&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Foundation models in computational pathology: A review of challenges, opportunities, and impact",
    "authors": [
      "M Bilal",
      "M Raza",
      "Y Altherwy",
      "A Alsuhaibani"
    ],
    "year": "2025",
    "abstract": "foundation model that learns comprehensive WSI embeddings by aligning morphological  features with genomic and transcriptomic  This multimodal foundation model employs a two-",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2502.08333",
    "num_citations": 25,
    "citedby_url": "/scholar?cites=4269928905068127546&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review",
    "authors": [
      "S Yang",
      "X Huang",
      "D Bernardo",
      "JE Ding"
    ],
    "year": "2025",
    "abstract": "Adaptive Large Foundation model for EEG signal representation  -to-end Multimodal LLM  achieves direct language decoding  , trained on large genomic and transcriptomic datasets, are",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2510.16658",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=8783428054783569894&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Mapping the Landscape of AI-Enabled Biological Design",
    "authors": [
      "C Science",
      "T Board"
    ],
    "year": "2025",
    "abstract": "A foundation model can be trained with different objectives that  modalities when training  multimodal language models.  As both LLM capabilities and biological automation continue to",
    "venue": "The Age of AI in the …",
    "url": "https://www.ncbi.nlm.nih.gov/books/NBK614597/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Multimodal Artificial Intelligence in Medicine: Integrating Imaging, Genomics, Electronic Health Records, and Wearable Data",
    "authors": [
      "BM Ayeyemi",
      "KO Shobowale",
      "TB Aliyu",
      "AO Abdulkabir"
    ],
    "year": "NA",
    "abstract": "Genome and an EHR). Such datasets are rare and prone to selection bias. Patients with  complete multimodal  This review will comprehensively analyze the state of the art in Multimodal",
    "venue": "NA",
    "url": "https://www.researchgate.net/profile/Bolaji-Ayeyemi/publication/399278858_Multimodal_Artificial_Intelligence_in_Medicine_Integrating_Imaging_Genomics_Electronic_Health_Records_and_Wearable_Data/links/695c6f8e9aa6b4649dc8517c/Multimodal-Artificial-Intelligence-in-Medicine-Integrating-Imaging-Genomics-Electronic-Health-Records-and-Wearable-Data.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Large language models for drug discovery and development",
    "authors": [
      "Y Zheng",
      "HY Koh",
      "J Ju",
      "M Yang",
      "LT May",
      "GI Webb",
      "L Li"
    ],
    "year": "2025",
    "abstract": "41 Spe LLM-based genomic analysis  LLM-based transcriptomics analysis mRNA expression  analysis; gene network analysis gene sequence cell type annotation; spatial transcriptomic",
    "venue": "Patterns",
    "url": "https://www.cell.com/patterns/fulltext/S2666-3899(25)00194-1",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=3910978958449253251&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Multi-Layered Framework for Modeling Human Biology: From Basic AI Agents to a Full-Body AI Agent",
    "authors": [
      "A Wang",
      "J Liu",
      "J Wen",
      "Y Luo",
      "Z Fan",
      "L Yang",
      "X Hu"
    ],
    "year": "2025",
    "abstract": "is defined by an explosion of multi-modal, multi-omics data  and QuST-LLM support spatial  transcriptomics by inferring cell  A vision language foundation model for precision oncology",
    "venue": "ArXiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12407623/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Biomni: A general-purpose biomedical ai agent",
    "authors": [
      "K Huang",
      "S Zhang",
      "H Wang",
      "Y Qu",
      "Y Lu",
      "Y Roohani"
    ],
    "year": "2025",
    "abstract": "to interpret complex, multi-modal biomedical datasets and  First, we introduce an LLM-based  tool selection mechanism  ), paired with spatial transcriptomics data collected from human",
    "venue": "biorxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12157518/",
    "num_citations": 80,
    "citedby_url": "/scholar?cites=14966565037202862571&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Comparative Survey on Large Language Models for Biological Data",
    "authors": [
      "R Mousa",
      "A Sarabadani",
      "T Taami",
      "AA Bengari"
    ],
    "year": "2025",
    "abstract": "This study created a generative clinical LLM, GatorTronGPT,  SCIENCEQA [115], a large-scale  multimodal dataset for  fall short, particularly in multimodal reasoning. CoT allows models",
    "venue": "NA",
    "url": "https://www.preprints.org/manuscript/202504.2464/download/final_file",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=3781725489920230570&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Data science opportunities of large language models for neuroscience and biomedicine",
    "authors": [
      "D Bzdok",
      "A Thieme",
      "O Levkovskyy",
      "P Wren",
      "T Ray"
    ],
    "year": "2024",
    "abstract": "a foundation model of the “grammar” of transcriptome  to train an LLM or fine-tune a foundation  model for the purpose of  In a not-so-distant future, such multi-modal LLMs could become",
    "venue": "Neuron",
    "url": "https://www.cell.com/neuron/fulltext/S0896-6273(24)00042-4?s=09",
    "num_citations": 52,
    "citedby_url": "/scholar?cites=14682905804971619803&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Understanding the LLM-based gene embeddings",
    "authors": [
      "Y Cai",
      "D Gan",
      "H Zhang",
      "J Li"
    ],
    "year": "2025",
    "abstract": "multimodal frameworks that integrate gene-expression data with spatial transcriptomics or   in electronic health records, where LLM-derived embeddings of concept descriptions have",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.19.695582.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Pre-training genomic language model with variants for better modeling functional genomics",
    "authors": [
      "T Liu",
      "X Zhang",
      "J Lin",
      "L Pinello",
      "R Ying",
      "H Zhao"
    ],
    "year": "2025",
    "abstract": "with transcriptomics data to understand regulatory processes and their effects on complex  phenotypes. The genomic  , a foundation model pre-trained with both reference genome and",
    "venue": "bioRxiv",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12393247/",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=5815500947775379641&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Generative vector search to improve pathology foundation models across multimodal vision-language tasks",
    "authors": [
      "M Ekvall",
      "L Bergenstråhle",
      "P Truong",
      "B Murrell"
    ],
    "year": "2025",
    "abstract": ", the LLM prompts the retriever to fetch relevant documents that can be included in the context  of the LLM to  current limitations imposed by the foundation model. STHLM offers a flexible",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2512.19360",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A deep learning and large language hybrid workflow for omics interpretation",
    "authors": [
      "D Tang",
      "C Zhang",
      "W Zhang",
      "F Lu",
      "L Xiao"
    ],
    "year": "2026",
    "abstract": "that integrates graph learning and LLM reasoning to facilitate omics  Next, we collected  transcriptomic, proteomic and/or  Geneformer, as a foundation model for single-cell omics data,",
    "venue": "Nature Biomedical …",
    "url": "https://www.nature.com/articles/s41551-025-01576-5",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "BioLab: End-to-end autonomous life sciences research with multi-agents system integrating biological foundation models",
    "authors": [
      "R Jin",
      "Y Guo",
      "Y Qu",
      "M Yang",
      "C Shang",
      "Q Yang",
      "L Chao"
    ],
    "year": "2025",
    "abstract": "xTrimo platform integration and foundation model usage within  A dedicated Query Rewrite  LLM Agent analyzes the initial  a distinct component of our multimodal knowledge base. This",
    "venue": "BioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.09.03.674085.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=432055160100249621&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "AI Agent in Biology Research: A Survey",
    "authors": [
      "C Qi",
      "W Wang",
      "S Jiang",
      "Q Liu",
      "X Song",
      "H Fang"
    ],
    "year": "2025",
    "abstract": "2, agents commonly adopt a foundation model as their core  capabilities compared to the  original LLM model. The RAG-HPO  Multimodal mapping combining mass spectrometry and",
    "venue": "Authorea …",
    "url": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.176417742.26205344",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Signals in the cells: multimodal and contextualized machine learning foundations for therapeutics",
    "authors": [
      "A Velez-Arce",
      "MM Li",
      "W Gao",
      "X Lin",
      "K Huang",
      "T Fu"
    ],
    "year": "2024",
    "abstract": "LLM multi-agent frameworks have also succeeded at  RNA sequencing to analyze the entire  transcriptome for each cell. We  , metrics, and foundation model tooling lay the foundation for",
    "venue": "…",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11212894/",
    "num_citations": 9,
    "citedby_url": "/scholar?cites=8658793425031174047&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A multimodal conversational agent for DNA, RNA and protein tasks",
    "authors": [
      "BP de Almeida",
      "G Richard",
      "H Dalla-Torre"
    ],
    "year": "2025",
    "abstract": "typically a pretrained GPT-style LLM, to comprehend the user  using the DNA foundation  model Nucleotide Transformer as  only in genomics but also in transcriptomics and proteomics,",
    "venue": "Nature Machine …",
    "url": "https://www.nature.com/articles/s42256-025-01047-1",
    "num_citations": 28,
    "citedby_url": "/scholar?cites=17639291540173187577&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Harness Behavioural Analysis for Unpacking the Bio-Interpretability of Pathology Foundation Models",
    "authors": [
      "Y Hu",
      "G Batchkala",
      "K Gaitskell",
      "E Domingo",
      "B Li"
    ],
    "year": "2026",
    "abstract": "Multi-modal variants further integrate textual annotations or genomic profiles, promising a   To further investigate how interpretative behaviours are shaped by foundation-model features,",
    "venue": "medRxiv",
    "url": "https://www.medrxiv.org/content/10.64898/2025.12.31.25343151.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Applications of large models in medicine",
    "authors": [
      "YH Su",
      "Z Lu",
      "J Liu",
      "K Pang",
      "H Dai",
      "S Liu",
      "Y Jia"
    ],
    "year": "2025",
    "abstract": ", such as clinical text, imaging, and genomic data, to provide a more  The recent introduction  of multimodal LLM and neuro- is introduced as a graph foundation model for zero-shot drug",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2502.17132",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=10041861992605248978&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Advancing Biological Image and Spatial Transcriptomics Analysis with Machine Learning",
    "authors": [
      "R Xie"
    ],
    "year": "2025",
    "abstract": "of jointly analyzing biological images and transcriptomic profiles. I first  a multimodal  foundation model for spatial transcriptomics designed to jointly analyze image and transcriptomic",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/c1be2b2818daee6435d570b1ef316cf1/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Multimodal Large Language Models for Medicine: A Comprehensive Survey",
    "authors": [
      "J Ye",
      "H Tang"
    ],
    "year": "2025",
    "abstract": "with a large language model (LLM) and fine-tuned using freely  Xie, “Towards generalist  foundation model for radiology,”  foundation model and benchmark for multi-species genome,”",
    "venue": "arXiv preprint arXiv:2504.21051",
    "url": "https://arxiv.org/abs/2504.21051",
    "num_citations": 21,
    "citedby_url": "/scholar?cites=16601485799765423274&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Large Language Models for Accessible Reporting of Bioinformatics Analyses in Interdisciplinary Contexts",
    "authors": [
      "L Yu",
      "D Kim",
      "Y Cao",
      "MW Shun Shu",
      "M Shen",
      "X Liang"
    ],
    "year": "2025",
    "abstract": "reports generated by the different LLM models, we performed a  stylistic variation between  the LLM models except average  of LLMs on cases containing multi-modal data types that are",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.09.687479.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Large language models in drug discovery and development: From disease mechanisms to clinical trials",
    "authors": [
      "Y Zheng",
      "HY Koh",
      "M Yang",
      "L Li",
      "LT May"
    ],
    "year": "2024",
    "abstract": "We explore the evolving landscape of LLM development,  the language of transcriptomics  through specialized LLMs,  2023b), an application of multimodal learning for learning",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2409.04481",
    "num_citations": 60,
    "citedby_url": "/scholar?cites=15565654673571819225&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Artificial intelligence for comprehensive DNA methylation analysis: overview, challenges, and future directions",
    "authors": [
      "A Aghziel",
      "MA Mahraz",
      "H Tairi"
    ],
    "year": "2025",
    "abstract": "explainability in the design of LLM-based frameworks [87, 89].  frameworks, support for  multimodal inputs, and clinically  ScWGBS-GPT: a foundation model for capturing long-range",
    "venue": "Briefings in …",
    "url": "https://academic.oup.com/bib/article-pdf/doi/10.1093/bib/bbaf468/64273821/bbaf468.pdf",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=5862893119214186060&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Comprehensive Review of Large AI Model Applications in Lung Cancer, From Screening to Treatment Planning",
    "authors": [
      "Z Wang",
      "J Zhong",
      "D Zhu"
    ],
    "year": "2025",
    "abstract": "We further examine their performance in multimodal learning  Beyond the medical domain,  LLM-powered frameworks such  Spatial transcriptomics and histology were jointly modeled",
    "venue": "… to Treatment Planning (June 08, 2025)",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5633170",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=2469669383219073516&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Informatics at the Frontier of Cancer Research",
    "authors": [
      "K Noller",
      "T Botsis",
      "PG Camara",
      "L Ciotti"
    ],
    "year": "2025",
    "abstract": ", and hence many non-LLM clinical text extraction tools are still in use. A  , high-resolution,  and multimodal, we anticipate that the  A pathology foundation model for cancer diagnosis and",
    "venue": "Cancer …",
    "url": "https://aacrjournals.org/cancerres/article/doi/10.1158/0008-5472.CAN-24-2829/763401",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Clinical stage prompt induced multi-modal prognosis",
    "authors": [
      "T Jin",
      "X Xie",
      "Q Li",
      "X Li",
      "Y Wang"
    ],
    "year": "2025",
    "abstract": "This paper jointly incorporates genomics and Whole Slide  Concretely, we leverage the  capabilities of the advanced LLM  ], a visual-language foundation model developed using diverse",
    "venue": "IEEE Transactions on Medical …",
    "url": "https://ieeexplore.ieee.org/abstract/document/11080170/",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=8245653187286707410&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "spaLLM: enhancing spatial domain analysis in multi-omics data through large language model integration",
    "authors": [
      "L Li",
      "L Dong",
      "H Zhang",
      "D Xu",
      "Y Li"
    ],
    "year": "2025",
    "abstract": "Our approach integrates LLM-generated representations from single-cell transcriptome data   an unsupervised GNN to perform encoding for multi-modal data. This approach captures",
    "venue": "Briefings in Bioinformatics",
    "url": "https://academic.oup.com/bib/article/26/4/bbaf304/8184496",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=10081306625081454828&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Decoding the interactions and functions of non-coding RNA with artificial intelligence",
    "authors": [
      "V Jung",
      "C Vincent-Cuaz",
      "C Tumescheit"
    ],
    "year": "2025",
    "abstract": "with high-throughput transcriptomic, proteomic and genomic screens (Supplementary Tables  1 and  b, The RNA interactome is multimodal, encompassing interactions with thousands of",
    "venue": "… Reviews Molecular Cell …",
    "url": "https://www.nature.com/articles/s41580-025-00857-w",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=3787638975186488411&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "GALAX: Graph-Augmented Language Model for Explainable Reinforcement-Guided Subgraph Reasoning in Precision Medicine",
    "authors": [
      "H Zhang",
      "D Huang",
      "W Li",
      "M Province",
      "Y Chen"
    ],
    "year": "2025",
    "abstract": "structured domain knowledge or multi-modal signals. To address  Built upon TOSG, our  model GALAX couples LLM-based  For foundation model pretraining, we collect dataset of 336",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2509.20935",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Genomic language models: opportunities and challenges",
    "authors": [
      "G Benegas",
      "C Ye",
      "C Albors",
      "JC Li",
      "YS Song"
    ],
    "year": "2025",
    "abstract": "IsoFormer [47] is an example of multi-modal transfer learning between DNA and pLMs for   This framework has been used to train the seminal LLM BERT [74] and pLM ESM-1b [75] and",
    "venue": "Trends in Genetics",
    "url": "https://www.cell.com/trends/genetics/abstract/S0168-9525(24)00295-6",
    "num_citations": 106,
    "citedby_url": "/scholar?cites=1884514547531684393&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "LLM-scCurator: Data-centric feature distillation for zero-shot cell-type annotation",
    "authors": [
      "K Furudate",
      "K Takahashi"
    ],
    "year": "2025",
    "abstract": "LLM-scCurator extends to spatial transcriptomics (Visium,  Although recent LLM-based  agents 5,6 and a foundation-model  prompting, LLM-scCurator complements these frameworks.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.28.696778.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "GenomeOcean: An Efficient Genome Foundation Model Trained on Large-Scale Metagenomic Assemblies",
    "authors": [
      "Z Zhou",
      "R Riley",
      "S Kautsar",
      "W Wu",
      "R Egan"
    ],
    "year": "2025",
    "abstract": "This study presents GenomeOcean, a genome foundation model capable of zero-shot  generation of biologically meaningful sequences at multiple scales. From producing protein-",
    "venue": "…",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11838515/",
    "num_citations": 8,
    "citedby_url": "/scholar?cites=4552217160264091415&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Deciphering genomic codes using advanced natural language processing techniques: a scoping review",
    "authors": [
      "S Cheng",
      "Y Wei",
      "Y Zhou",
      "Z Xu",
      "DN Wright"
    ],
    "year": "2025",
    "abstract": "This integration not only enables scientists to leverage the power of LLM to gain a more   integrating multimodal data more, such as combining genomic sequences with transcriptomic",
    "venue": "Journal of the …",
    "url": "https://academic.oup.com/jamia/article-abstract/32/4/761/8042189",
    "num_citations": 6,
    "citedby_url": "/scholar?cites=4235578472261314618&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "OmniCellAgent: Towards AI Co-Scientists for Scientific Discovery in Precision Medicine",
    "authors": [
      "D Huang",
      "H Li",
      "W Li",
      "H Zhang",
      "P Dickson",
      "M Zhan"
    ],
    "year": "2025",
    "abstract": "However, even a fine-tuned biomedical LLM may fail to recall a specific up-to-date clinical   pipeline, from experimental design to multi-modal data analysis and hypothesis generation,",
    "venue": "…",
    "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12324537/",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=14715467248768811569&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Large language models enable tumor-type classification and localization of cancers of unknown primary from genomic data",
    "authors": [
      "J Liu",
      "M Yang",
      "Y Bi",
      "J Zhang",
      "Y Yang",
      "Y Li",
      "H Shen"
    ],
    "year": "2025",
    "abstract": "while DNA methylation and transcriptomic profiling classify 75%  Second, expanding the  feature space to include multimodal data To enable training of the large language model (LLM),",
    "venue": "Cell Reports …",
    "url": "https://www.cell.com/cell-reports-medicine/fulltext/S2666-3791(25)00405-7",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=9840857187203462490&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Deep learning for genomics: from early neural nets to modern large language models",
    "authors": [
      "T Yue",
      "Y Wang",
      "L Zhang",
      "C Gu",
      "H Xue",
      "W Wang"
    ],
    "year": "2023",
    "abstract": "[70] proposed an LLM-based genomic model that expands the  [147] utilized a multi-modal  DBN framework to integrate an  further with a hybrid multi-modal framework combining CNNs",
    "venue": "International Journal of …",
    "url": "https://www.mdpi.com/1422-0067/24/21/15858",
    "num_citations": 54,
    "citedby_url": "/scholar?cites=8874799884959600351&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Perspective on Foundation Models in Intensive Care Medicine",
    "authors": [
      "C Harris",
      "S Schmidgall",
      "S Rapuri",
      "K Hwang"
    ],
    "year": "2025",
    "abstract": "Realizing the FMIC vision will require advances in multimodal  More recently, a GPT-style  foundation model applied to EHR  validated LLM-augmented system (COMPOSER-LLM) more",
    "venue": "Available at SSRN …",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5924162",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Incorporating LLM-Derived Information into Hypothesis Testing for Genomics Applications",
    "authors": [
      "JG Bryan",
      "H Niu",
      "D Li"
    ],
    "year": "2025",
    "abstract": "While it may seem natural to construct a foundation model for  This viability profile may be  compared to transcriptomic data  , assessing how embeddings trained on multimodal data (eg,",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.04.30.651464.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Multimodal Spatial Omics: From Data Acquisition to Computational Integration",
    "authors": [
      "EB Isik",
      "YH Usta",
      "H Liu",
      "M Riazi",
      "W Roach"
    ],
    "year": "2026",
    "abstract": "10x Genomics Visium platform supports whole transcriptome profiling  multimodal foundation  model pretrained on massive human and mouse imaged-based spatial transcriptomics and",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2601.12381",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "OwkinZero: Accelerating biological discovery with AI",
    "authors": [
      "N Bigaud",
      "V Cabeli",
      "M Gürel",
      "A Pignet",
      "J Klein"
    ],
    "year": "2025",
    "abstract": "from MOSAIC Visium spatial transcriptomics data, this dataset probes  We presented the  Judge LLM with a question and two  fine-tuning, RL being mainly used for the multimodal aspect.",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2508.16315",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=16731170950974584056&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "JanusDNA: A Powerful Bi-directional Hybrid DNA Foundation Model",
    "authors": [
      "Q Duan",
      "B Huang",
      "Z Song",
      "I Lehmann",
      "L Gu"
    ],
    "year": "2025",
    "abstract": "Additionally, traditional LLM training approaches are  of multimodal data such as epigenetic  states (eg, chromatin accessibility, histone modifications) and single-cell transcriptomic",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2505.17257",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=13908083578255275577&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Aligning foundation models on encoded synthetic omic data for patient stratification",
    "authors": [
      "N Janakarajan",
      "AF Rodríguez"
    ],
    "year": "2025",
    "abstract": "world health data for Foundation Model training often comes  ip-llm: Semantic space informed  prompt learning with llm for  “Pathgptomic: A balanced multi-modal learning framework for",
    "venue": "2025 IEEE International …",
    "url": "https://ieeexplore.ieee.org/abstract/document/11120511/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "FIMP: Foundation Model-Informed Message Passing for Graph Neural Networks",
    "authors": [
      "SA Rizvi",
      "N Pallikkavaliyaveetil",
      "D Zhang",
      "Z Lyu"
    ],
    "year": "2022",
    "abstract": "For all spatial transcriptomics datasets, we follow standard  , as well as supporting multimodal  graphs, heterogeneous graphs,  Our work can be seen as a parallel work to LLM-based",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2210.09475",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=17886831217806012656&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Artificial Intelligence in Clinical Oncology: From Productivity Enhancement to Creative Discovery",
    "authors": [
      "M Kuno",
      "H Osumi",
      "S Udagawa",
      "K Yoshikawa",
      "A Ooki"
    ],
    "year": "2025",
    "abstract": "creative discovery by integrating multimodal data to identify  Foundation-model efforts are  emerging as evidenced by the  as an oncology-specific LLM with multi-institutional validation",
    "venue": "Current …",
    "url": "https://www.mdpi.com/1718-7729/32/11/588",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Query-driven generative AI synthesizes multi-modal spatial omics from histology",
    "authors": [
      "M Pang",
      "TK Roy",
      "X Wu",
      "K Tan"
    ],
    "year": "2025",
    "abstract": "pave the way for large language model (LLM)-driven systems to  spatial proteomics and  transcriptomics from the exact same  To assess its capabilities as a foundation model, we then",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.11.693669.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Leveraging Natural Language Processing to Unravel the Mystery of Life: A Review of NLP Approaches in Genomics, Transcriptomics, and Proteomics",
    "authors": [
      "E Rannon",
      "D Burstein"
    ],
    "year": "2025",
    "abstract": "and viral gene sequences, leveraging a hierarchical LLM. It is comprised of a generative  pre- The latest advancement, ESM3115, is a multimodal generative language model trained on",
    "venue": "arXiv preprint arXiv:2506.02212",
    "url": "https://arxiv.org/abs/2506.02212",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=1887967515649205689&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Duke & Chen Institute Joint Boot Camp for AI & AI Accelerated Medical Research 2025 Course Note",
    "authors": [
      "P Xiao"
    ],
    "year": "2025",
    "abstract": "kind of used alternatively with multimodal learning in this talk):  GM-AI is just a foundation  model that works on zero- to few- data can very similar to a masked LLM, for example, we can",
    "venue": "NA",
    "url": "https://patriciaxiao.github.io/www/files/Duke_AI_Boot_Camp_2025_Course_Note.pdf",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Can Lightweight LLM Agents Improve Spatial Transcriptomics Annotation?",
    "authors": [
      "SA Dip",
      "L Zhang"
    ],
    "year": "2025",
    "abstract": "We investigate whether lightweight LLM agents can improve ST annotation by integrating  rule-based  These findings high-light the potential of modular LLM agents as resource-efficient",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.11.08.687410.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Imaging-anchored Multiomics in Cardiovascular Disease: Integrating Cardiac Imaging, Bulk, Single-cell, and Spatial Transcriptomics",
    "authors": [
      "MHN Le",
      "T Vinh",
      "TH Nguyen",
      "T Li",
      "BQG Le"
    ],
    "year": "2026",
    "abstract": "downstream tasks such as multimodal fusion, radiogenomics,  as tools, and an LLM-based  agent can coordinate tasks such  HEIST: a graph foundation model for spatial transcriptomics",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2601.07871",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A multimodal framework to identify molecular mechanisms driving patient group-associated morphology through the integration of spatial transcriptomics and whole …",
    "authors": [
      "R Kulkarni",
      "A Maddox",
      "S Bailey",
      "A Rao"
    ],
    "year": "2026",
    "abstract": "In this study, we present a multi-modal integrative framework to  In the first module, we used  a foundation model encoder to  , and an LLM-based agent to perform all molecular analyses.",
    "venue": "npj Artificial Intelligence",
    "url": "https://www.nature.com/articles/s44387-025-00050-6",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Teampath: Building multimodal pathology experts with reasoning ai copilots",
    "authors": [
      "T Liu",
      "W Xuan",
      "H Wu",
      "P Humphrey",
      "M DiStasio"
    ],
    "year": "2025",
    "abstract": "a model for generating spatial transcriptomic data directly from  Second, our task selection  process relies on a trained LLM as a  Towards a generalizable pathology foundation model via",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2511.17652",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=3589114892054007970&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "SpatialFinder: A Human-in-the-Loop Vision-Language Framework for Prioritizing High-Value Regions in Spatial Transcriptomics",
    "authors": [
      "J Xu",
      "M Jiang",
      "S Koga",
      "N Zhang",
      "Z Huang"
    ],
    "year": "2025",
    "abstract": "The remaining patches are processed with the Multimodal  scores; adding a generative LLM  component could enable natural  Pathology-specific multimodal assistants already show that",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.08.16.670684.abstract",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=13433696133832983412&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "The Next Paradigm in Medical AI: A Survey of Agentic AI in Biomedicine",
    "authors": [
      "A Abdollahi",
      "MA Rezaei",
      "X Wang",
      "S He"
    ],
    "year": "2025",
    "abstract": "vision–language foundation model for computed tomography  MoleculeSTM [139] is a  multimodal foundation model that  drawing from recent surveys on LLMbased biomedical agents [",
    "venue": "Authorea …",
    "url": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.176472621.18843904",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Artificial Intelligence Virtual Cells: From Measurements to Decisions across Modality, Scale, Dynamics, and Evaluation",
    "authors": [
      "C Hu",
      "CYC Chen"
    ],
    "year": "2025",
    "abstract": "cell models directly from multimodal measurements to infer  sentences” and leverage LLM  pretraining for annotation and  slide imaging corpora and foundation-model pretraining have",
    "venue": "arXiv preprint arXiv:2510.12498",
    "url": "https://arxiv.org/abs/2510.12498",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "MAMMAL--Molecular Aligned Multi-Modal Architecture and Language",
    "authors": [
      "Y Shoshan",
      "M Raboh",
      "M Ozery-Flato",
      "V Ratner"
    ],
    "year": "2024",
    "abstract": ", proteins, or transcriptomic data, limiting their ability to capture complex,  Multi-Modal  Architecture and Language - a versatile method applied to create a multi-task foundation model that",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2410.22367",
    "num_citations": 5,
    "citedby_url": "/scholar?cites=6230748140642133117&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "CpGPT: a foundation model for DNA methylation",
    "authors": [
      "LP de Lima Camillo",
      "R Sehgal",
      "J Armstrong",
      "HE Miller"
    ],
    "year": "2024",
    "abstract": "of single-cell transcriptomic data, uncovering previously  the sequence context or genomic  positions of CpG sites and as  reflect functional genomic annotations than the raw DNA LLM",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2024.10.24.619766.abstract",
    "num_citations": 22,
    "citedby_url": "/scholar?cites=16829718903940276905&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning",
    "authors": [
      "Z Tang",
      "F Wang",
      "H He",
      "J Zhou",
      "T Lv",
      "J Zhu"
    ],
    "year": "2025",
    "abstract": "embeddings outperform scGPT, a single-cell foundation model pre-trained with large-scale   the single-cell multi-modal integration task [19]. We used BFT-based LLM to obtain protein",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2511.21075",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Rethinking Genomic Modeling Through Optical Character Recognition",
    "authors": [
      "H Xiang",
      "P Ma",
      "Y Cao",
      "D Yu",
      "H Chen",
      "X Yang"
    ],
    "year": "2026",
    "abstract": "DNA foundation model that learns genomic representations  utility for large-scale genomic  and transcriptomic analyses.  We represent each task instance as a structured multimodal",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2602.02014",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Prism2: Unlocking multi-modal general pathology ai with clinical dialogue",
    "authors": [
      "E Vorontsov",
      "G Shaikovski",
      "A Casson",
      "J Viret"
    ],
    "year": "2025",
    "abstract": ", a multimodal slide-level foundation model trained  foundation model development, and  model performance can be further improved by borrowing from the large language model (LLM)",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2506.13063",
    "num_citations": 9,
    "citedby_url": "/scholar?cites=7498064752912224911&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Narrative Review on Large AI Models in Lung Cancer Screening, Diagnosis, and Treatment Planning",
    "authors": [
      "J Zhong",
      "Y Wang",
      "D Zhu",
      "Z Wang"
    ],
    "year": "2025",
    "abstract": "We further examine their performance in multimodal learning  Beyond the medical domain,  LLM-powered frameworks such  Spatial transcriptomics and histology were jointly modeled",
    "venue": "arXiv preprint arXiv:2506.07236",
    "url": "https://arxiv.org/abs/2506.07236",
    "num_citations": 15,
    "citedby_url": "/scholar?cites=3629310008472011978&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Foundation models: the next level of AI in ART",
    "authors": [
      "HL Hammer",
      "V Thambawita",
      "MA Riegler"
    ],
    "year": "2025",
    "abstract": "process multimodal data (integrating text, images, genomics,  In such a framework, a  foundation model could serve as a  , where the foundation model provides supporting evidence or",
    "venue": "Human Reproduction",
    "url": "https://academic.oup.com/humrep/article-abstract/40/9/1595/8203021",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=4378883694262125936&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Radiomics in clinical radiology: advances, challenges, and future directions",
    "authors": [
      "K Linton-Reid",
      "M Chen",
      "MB Martell",
      "JM Posma"
    ],
    "year": "2025",
    "abstract": "a multimodality AI is deployed in 90 radiology, where an LLM  either transcriptomics or  proteomics data has been used 266  a new era defined by multimodal AI, federated learning, and",
    "venue": "Clinical Radiology",
    "url": "https://www.sciencedirect.com/science/article/pii/S0009926025003708",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=6373081458230587527&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Building an ethical and trustworthy biomedical AI ecosystem for the translational and clinical integration of foundation models",
    "authors": [
      "BS Sankar",
      "D Gilliland",
      "J Rincon",
      "H Hermjakob",
      "Y Yan"
    ],
    "year": "2024",
    "abstract": "to represent and contextualize multimodal biomedical data. These  The LLM is then trained  to achieve high feedback scores  indicators for “Foundation Model Transparency Reports”,",
    "venue": "Bioengineering",
    "url": "https://www.mdpi.com/2306-5354/11/10/984",
    "num_citations": 21,
    "citedby_url": "/scholar?cites=4668334085898362760&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Leveraging Attention Mechanism to Unlock Gene and Protein Attributes",
    "authors": [
      "A Jararweh"
    ],
    "year": "2025",
    "abstract": "We build a multimodal model that integrates the three  for each gene, we utilize an LLM  pre-trained on a biomedical  , we introduce LitGene, a foundation model for gene embedding.",
    "venue": "NA",
    "url": "https://search.proquest.com/openview/c8d984d26312ba0cb11ff225ca0be300/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Artificial Intelligence in Human Genetics",
    "authors": [
      "N Brandes"
    ],
    "year": "2025",
    "abstract": "-scale foundation model to simultaneously predict 5,930 human and 1,128 mouse genomic   Very recent studies have begun to explore multimodal genomic foundation models, such as",
    "venue": "NA",
    "url": "https://www.preprints.org/manuscript/202511.1875",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Foundation Models in Dermatology: Advances in Artificial Intelligence. A Narrative Review",
    "authors": [
      "DE Pimienta-Rosero",
      "EY Benavides-Tulcán"
    ],
    "year": "2025",
    "abstract": "this multimodality by integrating audio, video, genomics and  LLM have come into the  spotlight in medical AI following their  A multimodal biomedical foundation model trained from",
    "venue": "Actas Dermo …",
    "url": "https://www.sciencedirect.com/science/article/pii/S0001731025008361",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Evaluating the potential of leading large language models in reasoning biology questions",
    "authors": [
      "X Gong",
      "J Holmes",
      "Y Li",
      "Z Liu",
      "Q Gan",
      "Z Wu"
    ],
    "year": "2023",
    "abstract": "SenseNova is the foundation model set of SenseTime with  capable generative pretrained  multimodal models built on the  Each LLM was given the full set of 108 multiple choice biology",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2311.07582",
    "num_citations": 7,
    "citedby_url": "/scholar?cites=7036400576734332252&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Artificial intelligence in the discovery and modification of biological elements in medicinal plants",
    "authors": [
      "J Zhang",
      "Y Yang",
      "J Si",
      "D Chen",
      "C Dong"
    ],
    "year": "2025",
    "abstract": "In terms of whole genome sequences, Evo is an LLM based  In addition, we present a  multimodal deep-learning framework combining  , epigenomics, transcriptomics, proteomics, and",
    "venue": "Medicinal Plant …",
    "url": "https://www.maxapress.com/article/doi/10.48130/mpb-0025-0010?viewType=HTML",
    "num_citations": 3,
    "citedby_url": "/scholar?cites=13555199206685186039&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Large Language Models in Drug Discovery",
    "authors": [
      "A Gangwal",
      "A Lavecchia"
    ],
    "year": "2026",
    "abstract": "Below are some examples of LLM applications in the  between single-modal and multi-modal  objectives. It provides a  sentences in multi-domain or multi-modal setups. Single-domain",
    "venue": "Applied Artificial Intelligence for Drug Discovery …",
    "url": "https://link.springer.com/chapter/10.1007/978-3-031-98022-0_14",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Building an Ethical and Trustworthy Biomedical AI Ecosystem for the Translational and Clinical Integration of Foundational Models",
    "authors": [
      "SS Baradwaj",
      "D Gilliland",
      "J Rincon"
    ],
    "year": "2024",
    "abstract": "to represent and contextualize multimodal biomedical data.  The LLM is then trained to  achieve high feedback scores  al. have proposed a “Foundation Model Transparency Report”",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2408.01431",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=6161393008646814869&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Out of distribution learning in bioinformatics: advancements and challenges",
    "authors": [
      "Y Shi",
      "W Xu",
      "P Hu"
    ],
    "year": "2025",
    "abstract": "due to the variability and complexity of genomic data. Genomic datasets are often high-  the reliability of predictions derived from multi-modal datasets. This limitation is particularly",
    "venue": "Briefings in Bioinformatics",
    "url": "https://academic.oup.com/bib/article-pdf/doi/10.1093/bib/bbaf294/63605286/bbaf294.pdf",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=16088852178049633908&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "Patient-specific Biomolecular Instruction Tuning",
    "authors": [
      "I Adam",
      "Z Chen",
      "D Laub",
      "S Porwal",
      "A Pekis"
    ],
    "year": "2025",
    "abstract": "Note that while clinical metadata enhances instruction-tuning quality, our foundation model   Additionally, we evaluate the optimal representation to be integrated into multi-modal LLM",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2509.22853",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=5099845616931970622&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "NicheAgent: LLM-Guided Zero-Shot Niche Identification for Spatial Transcriptomics",
    "authors": [
      "SA Dip",
      "L Zhang"
    ],
    "year": "2025",
    "abstract": "and corrected by an LLM using only interpretable signals:  Our results demonstrate that  LLM-guided refinement, when  deep learning models for spatial transcriptomics annotation.",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.64898/2025.12.09.693287.abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_multimodal",
    "title": "A Comprehensive Review of Deep Learning Applications with Multi-Omics Data in Cancer Research",
    "authors": [
      "F Sartori",
      "F Codicè",
      "I Caranzano",
      "C Rollo",
      "G Birolo"
    ],
    "year": "2025",
    "abstract": "data with epigenetic, transcriptomic, and even environmental  By learning multimodal data  embeddings, it represents  [160] introduced a foundation model called BEPH, designed to",
    "venue": "Genes",
    "url": "https://www.mdpi.com/2073-4425/16/6/648",
    "num_citations": 20,
    "citedby_url": "/scholar?cites=1545051471229317704&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Genegpt: Augmenting large language models with domain tools for improved access to biomedical information",
    "authors": [
      "Q Jin",
      "Y Yang",
      "Q Chen",
      "Z Lu"
    ],
    "year": "2024",
    "abstract": "3.2 Compared methods We evaluate four settings of GeneGPT, a full setting (GeneGPT-full)  where all prompt components are used, as well as a slim setting (GeneGPT-slim) inspired by",
    "venue": "Bioinformatics",
    "url": "https://academic.oup.com/bioinformatics/article-abstract/40/2/btae075/7606338",
    "num_citations": 242,
    "citedby_url": "/scholar?cites=15010696175911896134&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "scGPT-spatial: Continual pretraining of single-cell foundation model for spatial transcriptomics",
    "authors": [
      "C Wang",
      "H Cui",
      "A Zhang",
      "R Xie",
      "H Goodarzi",
      "B Wang"
    ],
    "year": "2025",
    "abstract": "scGPT-spatial, a specialized foundation model for spatial transcriptomics continually pretrained  on our previously published scGPT  To facilitate integration, scGPT-spatial introduces a",
    "venue": "bioRxiv",
    "url": "https://www.biorxiv.org/content/10.1101/2025.02.05.636714.abstract",
    "num_citations": 31,
    "citedby_url": "/scholar?cites=15790904434456273423&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "scGPT: end-to-end protocol for fine-tuned retinal cell type annotation",
    "authors": [
      "S Ding",
      "J Li",
      "R Luo",
      "H Cui",
      "B Wang",
      "R Chen"
    ],
    "year": "2025",
    "abstract": "scGPT for cell-type classification in single-cell RNA sequencing data. We demonstrate how  to fine-tune scGPT on  This protocol enables researchers to efficiently deploy scGPT for their",
    "venue": "Nature Protocols",
    "url": "https://www.nature.com/articles/s41596-025-01220-1",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=5568308342175301607&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Let the data speak—single-cell analysis with CellWhisperer",
    "authors": [
      "M Schaefer"
    ],
    "year": "2026",
    "abstract": "In a comparison with conventional bioinformatics analysis of colon cells, CellWhisperer   of CellWhisperer to capture new and compelling biological insights. At its core, CellWhisperer",
    "venue": "Nature Reviews Genetics",
    "url": "https://www.nature.com/articles/s41576-025-00927-x",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "TGPT-PINN: Nonlinear model reduction with transformed GPT-PINNs",
    "authors": [
      "Y Chen",
      "Y Ji",
      "A Narayan",
      "Z Xu"
    ],
    "year": "2024",
    "abstract": "We introduce the Transformed Generative Pre-Trained Physics-Informed Neural Networks (TGPT-PINN)  for accomplishing nonlinear model order reduction (MOR) of transport-",
    "venue": "Computer Methods in Applied Mechanics …",
    "url": "https://www.sciencedirect.com/science/article/pii/S0045782524004547",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=14032100058955420789&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering",
    "authors": [
      "H Chen",
      "G Zuccon",
      "T Leelanupab"
    ],
    "year": "2025",
    "abstract": "In this work, we revisit and reproduce GeneGPT in a pilot  -agent framework that extends  GeneGPT by introducing agent  OpenBioLLM matches or outperforms GeneGPT on over 90%",
    "venue": "… in Information Retrieval in the Asia …",
    "url": "https://dl.acm.org/doi/abs/10.1145/3767695.3769488",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=10368974290804773819&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA",
    "authors": [
      "K Abedini",
      "F Shami",
      "G Silvello"
    ],
    "year": "2026",
    "abstract": "We first conduct a GeneGPT reproducibility  GeneGPT’s capabilities. Experimental results  show GenomAgent achieves an average performance score of 0.93 (+12% over GeneGPT’s",
    "venue": "arXiv preprint arXiv:2601.10581",
    "url": "https://arxiv.org/abs/2601.10581",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "ChatCell: Facilitating Single-Cell Analysis with Natural Language",
    "authors": [
      "Y Fang",
      "K Liu",
      "N Zhang",
      "X Deng",
      "P Yang"
    ],
    "year": "2024",
    "abstract": "To this end, we introduce ChatCell, which signifies a  and unified sequence generation,  ChatCell has acquired profound  Extensive experiments further demonstrate ChatCell's robust",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2402.08303",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=10847690823473094119&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Abstract B037: Revolutionizing stem cell classification and genotypic profiling with large language models: scGPT-driven advances in single-cell genomics",
    "authors": [
      "PH Chen",
      "YJ Chen",
      "PL Chen"
    ],
    "year": "2025",
    "abstract": "scGPT, a specialized adaptation of the GPT architecture tailored for single-cell genomics. By  utilizing scGPT, we  scGPT overcomes these limitations with its zero-shot learning capability,",
    "venue": "Cancer Research",
    "url": "https://aacrjournals.org/cancerres/article/85/5_Supplement/B037/751922",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=12511393141012847791&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Empowering single-cell genomics with scGPT: Precision clustering and genetic insights into acute lymphoblastic leukemia.",
    "authors": [
      "PH Chen"
    ],
    "year": "2025",
    "abstract": "The aim of this study is to take advantage of the scGPT,  , scrublet, harmony, and scGPT.  Highly variable genes were identified  confirmed the excellent ability of scGPT to identify rare cell",
    "venue": "NA",
    "url": "https://ascopubs.org/doi/abs/10.1200/JCO.2025.43.16_suppl.e18514",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=1962153477711061571&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "A Systematic Evaluation of Single-Cell Foundation Models on Cell-Type Classification Task",
    "authors": [
      "N Steiner",
      "Z Li",
      "O Vosoughi",
      "J Schrader",
      "S Roy"
    ],
    "year": "2025",
    "abstract": "We noticed an exception with the scGPT model.The performance of scGPT showed a   We hypothesize that this is because, unlike other foundation models, we fine-tuned scGPT",
    "venue": "Proceedings of the …",
    "url": "https://dl.acm.org/doi/abs/10.1145/3701551.3708811",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=9326623134935922906&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Automated Single-Cell Annotation Using Fine-Tuned scGPT Models with the Human Eye Cell Atlas",
    "authors": [
      "R Chen",
      "R Luo",
      "B Wang"
    ],
    "year": "2025",
    "abstract": "Purpose: Single-cell sequencing has revolutionized molecular profiling of tissues and organs.  Recently, we created the first integrated, multimodal reference atlas of the entire human",
    "venue": "Investigative Ophthalmology & …",
    "url": "https://iovs.arvojournals.org/article.aspx?articleid=2808930",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Single-cell foundation models evaluated: Bioinformatics",
    "authors": [
      "L Tang"
    ],
    "year": "2025",
    "abstract": "An array of evaluation tasks, including cell-type clustering and batch integration, were applied  to these two models, Geneformer and scGPT, as well as several baseline methods, using",
    "venue": "Nature Methods",
    "url": "https://www.nature.com/articles/s41592-025-02735-x",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Biomedical Question Answering: Extending GeneGPT with the code act paradigm",
    "authors": [
      "K Abedini"
    ],
    "year": "NA",
    "abstract": "We evaluated GenomAgent against GeneGPT, a pioneering  comparable to or exceeding  GeneGPT on all evaluated tasks  We evaluated GenomAgent against GeneGPT, a pioneering",
    "venue": "NA",
    "url": "https://thesis.unipd.it/handle/20.500.12608/98449",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Unveiling potential threats: backdoor attacks in single-cell pre-trained models",
    "authors": [
      "S Feng",
      "S Li",
      "L Chen",
      "S Chen"
    ],
    "year": "2024",
    "abstract": "-tuned the pre-trained scGPT model using the training set and  Next, we fine-tuned the official  pre-trained scGPT model on  the high efficacy of our backdoor on scGPT. Furthermore, we",
    "venue": "Cell Discovery",
    "url": "https://www.nature.com/articles/s41421-024-00753-1",
    "num_citations": 4,
    "citedby_url": "/scholar?cites=6695043212613536932&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Benchmarking foundation cell models for post-perturbation RNA-seq prediction",
    "authors": [
      "G Csendes",
      "G Sanz",
      "KZ Szalay",
      "B Szalai"
    ],
    "year": "2025",
    "abstract": "Our results show that the scGPT models we reproduced achieved similar performance to  those in the original publication (Fig. 1BE; Supplementary Table 2). In the raw gene expression",
    "venue": "BMC genomics",
    "url": "https://link.springer.com/article/10.1186/s12864-025-11600-2",
    "num_citations": 30,
    "citedby_url": "/scholar?cites=3112638669510800305&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "AI-Driven Identification of Drug-Tolerant Persister Cells in Lung Cancer",
    "authors": [
      "B Selvaraj",
      "A Vairam",
      "PA Moreno Cortez"
    ],
    "year": "2025",
    "abstract": "The default one-hot cross-entropy loss of the scGPT model assumes label certainty and will  lead to overfitting. To overcome this, we fine-tuned a pre-trained scGPT model using a label",
    "venue": "Cancer …",
    "url": "https://aacrjournals.org/cancerres/article/85/8_Supplement_1/6312/759545",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Characterizing biological functional changes in cancer tumor microenvironment by integrating histology-based gene imputation with scRNA-seq foundation models",
    "authors": [
      "P Swaminathan",
      "P Dang",
      "H Zhu",
      "Z An",
      "X Lu",
      "Z Li"
    ],
    "year": "2025",
    "abstract": "scGPT - a foundation models trained on single-cell RNA-seq (scRNA-seq) data. We  hypothesize HI data can impute genes linked to TME, tissue structure, and cell types, while scGPT",
    "venue": "Cancer …",
    "url": "https://aacrjournals.org/cancerres/article/85/8_Supplement_1/1353/757700",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Toward learning a foundational representation of cells and genes",
    "authors": [
      "M Lotfollahi"
    ],
    "year": "2024",
    "abstract": "directly operating on the gene count space, whereas scGPT discretizes expression values  into expression bins. scGPT adapts masked language modeling by randomly picking sets of",
    "venue": "nature methods",
    "url": "https://www.nature.com/articles/s41592-024-02367-7",
    "num_citations": 10,
    "citedby_url": "/scholar?cites=9496074392713716071&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Single-cell exploration in natural language",
    "authors": [
      "L Tang"
    ],
    "year": "2026",
    "abstract": "At the heart of CellWhisperer is a  , CellWhisperer is 100% open science — we provide not  only the code and the model weights, but also all training data on the CellWhisperer website,",
    "venue": "nature methods",
    "url": "https://www.nature.com/articles/s41592-025-03000-x",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "GenoHoption: Bridging Gene Network Graphs and Single-Cell Foundation Models",
    "authors": [
      "J Cheng",
      "J Li",
      "K Yang",
      "H Shen"
    ],
    "year": "2024",
    "abstract": "scGPT. Our methods consistently surpass its backbone in different unseen perturbed-gene  cases. It is noticed that although scGPT  We speculate this phenomenon is because scGPT",
    "venue": "2024 IEEE International …",
    "url": "https://ieeexplore.ieee.org/abstract/document/10822153/",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Cost-effectiveness of tumor genomic profiling to guide first-line targeted therapy selection in patients with metastatic lung adenocarcinoma",
    "authors": [
      "OM Dong",
      "PJ Poonnen",
      "D Winski",
      "SD Reed"
    ],
    "year": "2022",
    "abstract": "and $188 425 for CGP) and yielded the least QALYs/person (0.53 vs 0.73 for TGPT and   952) for TGPT vs no tumor profiling and $445 545 ($322 297-$572 084) for CGP vs TGPT. All",
    "venue": "Value in Health",
    "url": "https://www.sciencedirect.com/science/article/pii/S1098301521017587",
    "num_citations": 13,
    "citedby_url": "/scholar?cites=3656358594383440407&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "GRIT: Graph-Regularized Logit Refinement for Zero-shot Cell Type Annotation",
    "authors": [
      "T Hu",
      "C Zhou",
      "J Liu",
      "J Wang",
      "R Chen",
      "H Xia"
    ],
    "year": "2025",
    "abstract": ", models like LangCell enable zero-shot annotation. While LangCell demonstrates decent  zero- In this paper, we propose to refine the zero-shot logits produced by LangCell through a",
    "venue": "arXiv preprint arXiv …",
    "url": "https://arxiv.org/abs/2508.04747",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=4485561055611765498&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "The legacy of a “Cell Whisperer”: celebrating the life of Dr. Prabodh Kumar Gupta",
    "authors": [
      "ZW Baloch"
    ],
    "year": "2021",
    "abstract": "My India My America: Success Yatra, he wrote that “I had many adventures and a very exciting  childhood. In the lottery of life, I had the lucky ticket: a supporting family and friends and",
    "venue": "Acta Cytologica",
    "url": "https://scholar.archive.org/work/fjdpjvqvi5fzzkzr363s7a2mwy/access/wayback/https://www.karger.com/Article/Pdf/514726",
    "num_citations": 1,
    "citedby_url": "/scholar?cites=9659529841297992393&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "SpikGPT: A High-Accuracy and Interpretable Spiking Attention Framework for Single-Cell Annotation",
    "authors": [
      "M Huang",
      "R Kamaleswaran"
    ],
    "year": "2025",
    "abstract": "After obtaining the cell embedding matrix E ∈ Rn×k from scGPT, we apply two expansion  steps to adapt the data for input into the Spikformer model and to enhance its capacity for",
    "venue": "arXiv preprint arXiv:2512.03286",
    "url": "https://arxiv.org/abs/2512.03286",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Integrating Histopathology and Spatial Transcriptomics for Tumor Microenvironment Analysis and Personalized Radiotherapy",
    "authors": [
      "X Xing",
      "L Xing"
    ],
    "year": "2025",
    "abstract": "CONCH (trained on 1.17 million pathology slides) and scGPT (trained on 33 million single-cell   We extract pathology patch features using CONCH and ST spot features using scGPT. To",
    "venue": "International Journal of Radiation Oncology, Biology …",
    "url": "https://www.redjournal.org/article/S0360-3016(25)03886-6/abstract",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Empirical evaluation of third-generation prospect theory",
    "authors": [
      "MH Birnbaum"
    ],
    "year": "2018",
    "abstract": "This paper reviews theoretical and empirical findings, to show that TGPT fails as a descriptive  model of both choices and judgments. Evidence refutes three implications of TGPT, but",
    "venue": "Theory and Decision",
    "url": "https://link.springer.com/article/10.1007/s11238-017-9607-y",
    "num_citations": 30,
    "citedby_url": "/scholar?cites=14193830887936751485&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Path-GPTOmic: A balanced multi-modal learning framework for survival outcome prediction",
    "authors": [
      "H Wang",
      "Y Yang",
      "Z Zhao",
      "P Gu"
    ],
    "year": "2024",
    "abstract": "In Section 2.1, we show how to smooth the scGPT-derived single-cell RNA-seq  scGPT  model, we fix the scGPT parameters and append a three-layer MLP-A to it to regulate the scGPT",
    "venue": "2024 IEEE …",
    "url": "https://ieeexplore.ieee.org/abstract/document/10635171/",
    "num_citations": 11,
    "citedby_url": "/scholar?cites=11443090202234093544&as_sdt=5,33&sciodt=0,33&hl=en"
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "AMIL: Automated Cell Grouping Framework for Phenotype Prediction with Multiple Instance Learning",
    "authors": [
      "J Noh",
      "M Kim",
      "M Oh"
    ],
    "year": "2025",
    "abstract": "optimized cell groups using pre-trained scGPT embeddings and gene expression profiles,   pre-trained scGPT model. Trained on large-scale scRNA-seq datasets, scGPT captures global",
    "venue": "한국정보과학회 학술발표논문집",
    "url": "https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE12318547",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Discovering Candidate Anti-Aging Perturbations Using a Foundation Model for Gene Expression",
    "authors": [
      "E Tadevosyan",
      "E Efimov",
      "D Kriukov"
    ],
    "year": "2025",
    "abstract": "Our results demonstrate that scGPT does capture age-related dependencies in single-cell  data and can be utilized to discover novel candidate gene perturbations—potential targets to",
    "venue": "International Journal of …",
    "url": "https://www.mdpi.com/1422-0067/26/24/11977",
    "num_citations": 0,
    "citedby_url": ""
  },
  {
    "source": "google_scholar",
    "query_id": "gs_model_names",
    "title": "Self-Attention Mechanisms as Representations for Gene Interaction Networks in Hypothesis-Driven Gene-based Transformer Genomics AI Models",
    "authors": [
      "H Qin"
    ],
    "year": "2024",
    "abstract": "scGPT builds on the transformer architecture with stacked layers and multi-head attention   Pre-trained on a dataset of over 33 million normal human cells from various organs, scGPT",
    "venue": "Proceedings of the AAAI Symposium Series",
    "url": "https://ojs.aaai.org/index.php/AAAI-SS/article/view/31813",
    "num_citations": 2,
    "citedby_url": "/scholar?cites=502622344450264359&as_sdt=5,33&sciodt=0,33&hl=en"
  }
]